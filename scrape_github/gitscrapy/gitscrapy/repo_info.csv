,Repository,User,Description,Date created,Date updated,Language,Number of forks,Number of stars,Readme
0,josephmisiti/awesome-machine-learning,josephmisiti,"A curated list of awesome Machine Learning frameworks, libraries and software.",2014-07-15 19:11:19,2020-06-18 16:02:29,Python,11393,45077,"b'# Awesome Machine Learning [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)\n\nA curated list of awesome machine learning frameworks, libraries and software (by language). Inspired by `awesome-php`.\n\nIf you want to contribute to this list (please do), send me a pull request or contact me [@josephmisiti](https://twitter.com/josephmisiti).\nAlso, a listed repository should be deprecated if:\n\n* Repository\'s owner explicitly say that ""this library is not maintained"".\n* Not committed for long time (2~3 years).\n\nFurther resources:\n\n* For a list of free machine learning books available for download, go [here](https://github.com/josephmisiti/awesome-machine-learning/blob/master/books.md).\n\n* For a list of professional machine learning events, go [here](https://github.com/josephmisiti/awesome-machine-learning/blob/master/events.md).\n\n* For a list of (mostly) free machine learning courses available online, go [here](https://github.com/josephmisiti/awesome-machine-learning/blob/master/courses.md).\n\n* For a list of blogs and newsletters on data science and machine learning, go [here](https://github.com/josephmisiti/awesome-machine-learning/blob/master/blogs.md).\n\n* For a list of free-to-attend meetups and local events, go [here](https://github.com/josephmisiti/awesome-machine-learning/blob/master/meetups.md).\n\n## Table of Contents\n\n### Frameworks and Libraries\n<!-- MarkdownTOC depth=4 -->\n\n- [Awesome Machine Learning ![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](#awesome-machine-learning-awesomehttpsgithubcomsindresorhusawesome)\n  - [Table of Contents](#table-of-contents)\n    - [Frameworks and Libraries](#frameworks-and-libraries)\n    - [Tools](#tools)\n  - [APL](#apl)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning)\n  - [C](#c)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-1)\n      - [Computer Vision](#computer-vision)\n  - [C++](#c)\n      - [Computer Vision](#computer-vision-1)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-2)\n      - [Natural Language Processing](#natural-language-processing)\n      - [Speech Recognition](#speech-recognition)\n      - [Sequence Analysis](#sequence-analysis)\n      - [Gesture Detection](#gesture-detection)\n  - [Common Lisp](#common-lisp)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-3)\n  - [Clojure](#clojure)\n      - [Natural Language Processing](#natural-language-processing-1)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-4)\n      - [Data Analysis / Data Visualization](#data-analysis--data-visualization)\n  - [Crystal](#crystal)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-5)\n  - [Elixir](#elixir)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-6)\n      - [Natural Language Processing](#natural-language-processing-2)\n  - [Erlang](#erlang)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-7)\n  - [Go](#go)\n      - [Natural Language Processing](#natural-language-processing-3)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-8)\n      - [Spatial analysis and geometry](#spatial-analysis-and-geometry)\n      - [Data Analysis / Data Visualization](#data-analysis--data-visualization-1)\n      - [Computer vision](#computer-vision-2)\n      - [Reinforcement learning](#reinforcement-learning)\n  - [Haskell](#haskell)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-9)\n  - [Java](#java)\n      - [Natural Language Processing](#natural-language-processing-4)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-10)\n      - [Speech Recognition](#speech-recognition-1)\n      - [Data Analysis / Data Visualization](#data-analysis--data-visualization-2)\n      - [Deep Learning](#deep-learning)\n  - [Javascript](#javascript)\n      - [Natural Language Processing](#natural-language-processing-5)\n      - [Data Analysis / Data Visualization](#data-analysis--data-visualization-3)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-11)\n      - [Misc](#misc)\n      - [Demos and Scripts](#demos-and-scripts)\n  - [Julia](#julia)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-12)\n      - [Natural Language Processing](#natural-language-processing-6)\n      - [Data Analysis / Data Visualization](#data-analysis--data-visualization-4)\n      - [Misc Stuff / Presentations](#misc-stuff--presentations)\n  - [Lua](#lua)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-13)\n      - [Demos and Scripts](#demos-and-scripts-1)\n  - [Matlab](#matlab)\n      - [Computer Vision](#computer-vision-3)\n      - [Natural Language Processing](#natural-language-processing-7)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-14)\n      - [Data Analysis / Data Visualization](#data-analysis--data-visualization-5)\n  - [.NET](#net)\n      - [Computer Vision](#computer-vision-4)\n      - [Natural Language Processing](#natural-language-processing-8)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-15)\n      - [Data Analysis / Data Visualization](#data-analysis--data-visualization-6)\n  - [Objective C](#objective-c)\n    - [General-Purpose Machine Learning](#general-purpose-machine-learning-16)\n  - [OCaml](#ocaml)\n    - [General-Purpose Machine Learning](#general-purpose-machine-learning-17)\n  - [Perl](#perl)\n    - [Data Analysis / Data Visualization](#data-analysis--data-visualization-7)\n    - [General-Purpose Machine Learning](#general-purpose-machine-learning-18)\n  - [Perl 6](#perl-6)\n    - [Data Analysis / Data Visualization](#data-analysis--data-visualization-8)\n    - [General-Purpose Machine Learning](#general-purpose-machine-learning-19)\n  - [PHP](#php)\n    - [Natural Language Processing](#natural-language-processing-9)\n    - [General-Purpose Machine Learning](#general-purpose-machine-learning-20)\n  - [Python](#python)\n      - [Computer Vision](#computer-vision-5)\n      - [Natural Language Processing](#natural-language-processing-10)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-21)\n      - [Data Analysis / Data Visualization](#data-analysis--data-visualization-9)\n      - [Misc Scripts / iPython Notebooks / Codebases](#misc-scripts--ipython-notebooks--codebases)\n      - [Neural Networks](#neural-networks)\n      - [Kaggle Competition Source Code](#kaggle-competition-source-code)\n      - [Reinforcement Learning](#reinforcement-learning-1)\n  - [Ruby](#ruby)\n      - [Natural Language Processing](#natural-language-processing-11)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-22)\n      - [Data Analysis / Data Visualization](#data-analysis--data-visualization-10)\n      - [Misc](#misc-1)\n  - [Rust](#rust)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-23)\n  - [R](#r)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-24)\n      - [Data Analysis / Data Visualization](#data-analysis--data-visualization-11)\n  - [SAS](#sas)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-25)\n      - [Data Analysis / Data Visualization](#data-analysis--data-visualization-12)\n      - [Natural Language Processing](#natural-language-processing-12)\n      - [Demos and Scripts](#demos-and-scripts-2)\n  - [Scala](#scala)\n      - [Natural Language Processing](#natural-language-processing-13)\n      - [Data Analysis / Data Visualization](#data-analysis--data-visualization-13)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-26)\n  - [Scheme](#scheme)\n      - [Neural Networks](#neural-networks-1)\n  - [Swift](#swift)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-27)\n  - [TensorFlow](#tensorflow)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-28)\n  - [Tools](#tools-1)\n      - [Neural Networks](#neural-networks-2)\n      - [Misc](#misc-2)\n  - [Credits](#credits)\n\xe5\x86\x99\xe4\xb8\xaa\xe8\x84\x9a\xe6\x9c\xac\xe6\x8a\x8a\xe5\xae\x83\xe4\xbb\xac\xe7\x88\xac\xe4\xb8\x8b\xe6\x9d\xa5 - [Demos and Scripts](#sas-demos)\n- [Scala](#scala)\n    - [Natural Language Processing](#scala-nlp)\n    - [Data Analysis / Data Visualization](#scala-data-analysis)\n    - [General-Purpose Machine Learning](#scala-general-purpose)\n- [Scheme](#scheme)\n    - [Neural Networks](#scheme-neural-networks)\n- [Swift](#swift)\n    - [General-Purpose Machine Learning](#swift-general-purpose)\n- [TensorFlow](#tensor)\n    - [General-Purpose Machine Learning](#tensor-general-purpose)\n\n### Tools\n\n- [Neural Networks](#tools-neural-networks)\n- [Misc](#tools-misc)\n\n\n[Credits](#credits)\n\n<!-- /MarkdownTOC -->\n\n<a name=""apl""></a>\n## APL\n\n<a name=""apl-general-purpose""></a>\n#### General-Purpose Machine Learning\n* [naive-apl](https://github.com/mattcunningham/naive-apl) - Naive Bayesian Classifier implementation in APL. **[Deprecated]**\n\n<a name=""c""></a>\n## C\n\n<a name=""c-general-purpose""></a>\n#### General-Purpose Machine Learning\n* [Darknet](https://github.com/pjreddie/darknet) - Darknet is an open source neural network framework written in C and CUDA. It is fast, easy to install, and supports CPU and GPU computation.\n* [Recommender](https://github.com/GHamrouni/Recommender) - A C library for product recommendations/suggestions using collaborative filtering (CF).\n* [Hybrid Recommender System](https://github.com/SeniorSA/hybrid-rs-trainner) - A hybrid recommender system based upon scikit-learn algorithms. **[Deprecated]**\n* [neonrvm](https://github.com/siavashserver/neonrvm) - neonrvm is an open source machine learning library based on RVM technique. It\'s written in C programming language and comes with Python programming language bindings.\n* [cONNXr](https://github.com/alrevuelta/cONNXr) - An `ONNX` runtime written in pure C (99) with zero dependancies focused on small embedded devices. Run inference on your machine learning models no matter which framework you train it with. Easy to install and compiles everywhere, even in very old devices.\n\n<a name=""c-cv""></a>\n#### Computer Vision\n\n* [CCV](https://github.com/liuliu/ccv) - C-based/Cached/Core Computer Vision Library, A Modern Computer Vision Library.\n* [VLFeat](http://www.vlfeat.org/) - VLFeat is an open and portable library of computer vision algorithms, which has Matlab toolbox.\n\n<a name=""cpp""></a>\n## C++\n\n<a name=""cpp-cv""></a>\n#### Computer Vision\n\n* [DLib](http://dlib.net/imaging.html) - DLib has C++ and Python interfaces for face detection and training general object detectors.\n* [EBLearn](http://eblearn.sourceforge.net/) - Eblearn is an object-oriented C++ library that implements various machine learning models **[Deprecated]**\n* [OpenCV](https://opencv.org) - OpenCV has C++, C, Python, Java and MATLAB interfaces and supports Windows, Linux, Android and Mac OS.\n* [VIGRA](https://github.com/ukoethe/vigra) - VIGRA is a generic cross-platform C++ computer vision and machine learning library for volumes of arbitrary dimensionality with Python bindings.\n* [Openpose](https://github.com/CMU-Perceptual-Computing-Lab/openpose) - A real-time multi-person keypoint detection library for body, face, hands, and foot estimation\n\n<a name=""cpp-general-purpose""></a>\n#### General-Purpose Machine Learning\n\n* [BanditLib](https://github.com/jkomiyama/banditlib) - A simple Multi-armed Bandit library. **[Deprecated]**\n* [Caffe](https://github.com/BVLC/caffe) - A deep learning framework developed with cleanliness, readability, and speed in mind. [DEEP LEARNING]\n* [CatBoost](https://github.com/catboost/catboost) - General purpose gradient boosting on decision trees library with categorical features support out of the box. It is easy to install, contains fast inference implementation and supports CPU and GPU (even multi-GPU) computation.\n* [CNTK](https://github.com/Microsoft/CNTK) - The Computational Network Toolkit (CNTK) by Microsoft Research, is a unified deep-learning toolkit that describes neural networks as a series of computational steps via a directed graph.\n* [CUDA](https://code.google.com/p/cuda-convnet/) - This is a fast C++/CUDA implementation of convolutional [DEEP LEARNING]\n* [DeepDetect](https://github.com/jolibrain/deepdetect) - A machine learning API and server written in C++11. It makes state of the art machine learning easy to work with and integrate into existing applications.\n* [Distributed Machine learning Tool Kit (DMTK)](http://www.dmtk.io/) - A distributed machine learning (parameter server) framework by Microsoft. Enables training models on large data sets across multiple machines. Current tools bundled with it include: LightLDA and Distributed (Multisense) Word Embedding.\n* [DLib](http://dlib.net/ml.html) - A suite of ML tools designed to be easy to imbed in other applications.\n* [DSSTNE](https://github.com/amznlabs/amazon-dsstne) - A software library created by Amazon for training and deploying deep neural networks using GPUs which emphasizes speed and scale over experimental flexibility.\n* [DyNet](https://github.com/clab/dynet) - A dynamic neural network library working well with networks that have dynamic structures that change for every training instance. Written in C++ with bindings in Python.\n* [Fido](https://github.com/FidoProject/Fido) - A highly-modular C++ machine learning library for embedded electronics and robotics.\n* [igraph](http://igraph.org/) - General purpose graph library.\n* [Intel(R) DAAL](https://github.com/intel/daal) - A high performance software library developed by Intel and optimized for Intel\'s architectures. Library provides algorithmic building blocks for all stages of data analytics and allows to process data in batch, online and distributed modes.\n* [LightGBM](https://github.com/Microsoft/LightGBM) - Microsoft\'s fast, distributed, high performance gradient boosting (GBDT, GBRT, GBM or MART) framework based on decision tree algorithms, used for ranking, classification and many other machine learning tasks.\n* [libfm](https://github.com/srendle/libfm) - A generic approach that allows to mimic most factorization models by feature engineering.\n* [MLDB](https://mldb.ai) - The Machine Learning Database is a database designed for machine learning. Send it commands over a RESTful API to store data, explore it using SQL, then train machine learning models and expose them as APIs.\n* [mlpack](https://www.mlpack.org/) - A scalable C++ machine learning library.\n* [MXNet](https://github.com/apache/incubator-mxnet) - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more.\n* [proNet-core](https://github.com/cnclabs/proNet-core) - A general-purpose network embedding framework: pair-wise representations optimization Network Edit.\n* [PyCUDA](https://mathema.tician.de/software/pycuda/) - Python interface to CUDA\n* [ROOT](https://root.cern.ch) - A modular scientific software framework. It provides all the functionalities needed to deal with big data processing, statistical analysis, visualization and storage.\n* [shark](http://image.diku.dk/shark/sphinx_pages/build/html/index.html) - A fast, modular, feature-rich open-source C++ machine learning library.\n* [Shogun](https://github.com/shogun-toolbox/shogun) - The Shogun Machine Learning Toolbox.\n* [sofia-ml](https://code.google.com/archive/p/sofia-ml) - Suite of fast incremental algorithms.\n* [Stan](http://mc-stan.org/) - A probabilistic programming language implementing full Bayesian statistical inference with Hamiltonian Monte Carlo sampling.\n* [Timbl](https://languagemachines.github.io/timbl/) - A software package/C++ library implementing several memory-based learning algorithms, among which IB1-IG, an implementation of k-nearest neighbor classification, and IGTree, a decision-tree approximation of IB1-IG. Commonly used for NLP.\n* [Vowpal Wabbit (VW)](https://github.com/VowpalWabbit/vowpal_wabbit) - A fast out-of-core learning system.\n* [Warp-CTC](https://github.com/baidu-research/warp-ctc) - A fast parallel implementation of Connectionist Temporal Classification (CTC), on both CPU and GPU.\n* [XGBoost](https://github.com/dmlc/xgboost) - A parallelized optimized general purpose gradient boosting library.\n* [ThunderGBM](https://github.com/Xtra-Computing/thundergbm) - A fast library for GBDTs and Random Forests on GPUs.\n* [ThunderSVM](https://github.com/Xtra-Computing/thundersvm) - A fast SVM library on GPUs and CPUs.\n* [LKYDeepNN](https://github.com/mosdeo/LKYDeepNN) - A header-only C++11 Neural Network library. Low dependency, native traditional chinese document.\n* [xLearn](https://github.com/aksnzhy/xlearn) - A high performance, easy-to-use, and scalable machine learning package, which can be used to solve large-scale machine learning problems. xLearn is especially useful for solving machine learning problems on large-scale sparse data, which is very common in Internet services such as online advertisement and recommender systems.\n* [Featuretools](https://github.com/featuretools/featuretools) - A library for automated feature engineering. It excels at transforming transactional and relational datasets into feature matrices for machine learning using reusable feature engineering ""primitives"".\n* [skynet](https://github.com/Tyill/skynet) - A library for learning neural network, has C-interface, net set in JSON. Written in C++ with bindings in Python, C++ and C#.\n* [Feast](https://github.com/gojek/feast) - A feature store for the management, discovery, and access of machine learning features. Feast provides a consistent view of feature data for both model training and model serving.\n* [Hopsworks](https://github.com/logicalclocks/hopsworks) - An data-intensive platorm for AI with the industry\'s first open-source feature store. The Hopsworks Feature Store provides both a feature warehouse for training and batch based on Apache Hive and a feature serving database, based on MySQL Cluster, for online applications.\n* [Polyaxon](https://github.com/polyaxon/polyaxon) - A platform for reproducible and scalable machine learning and deep learning.\n\n<a name=""cpp-nlp""></a>\n#### Natural Language Processing\n\n* [BLLIP Parser](https://github.com/BLLIP/bllip-parser) - BLLIP Natural Language Parser (also known as the Charniak-Johnson parser).\n* [colibri-core](https://github.com/proycon/colibri-core) - C++ library, command line tools, and Python binding for extracting and working with basic linguistic constructions such as n-grams and skipgrams in a quick and memory-efficient way.\n* [CRF++](https://taku910.github.io/crfpp/) - Open source implementation of Conditional Random Fields (CRFs) for segmenting/labeling sequential data & other Natural Language Processing tasks. **[Deprecated]**\n* [CRFsuite](http://www.chokkan.org/software/crfsuite/) - CRFsuite is an implementation of Conditional Random Fields (CRFs) for labeling sequential data. **[Deprecated]**\n* [frog](https://github.com/LanguageMachines/frog) - Memory-based NLP suite developed for Dutch: PoS tagger, lemmatiser, dependency parser, NER, shallow parser, morphological analyzer.\n* [libfolia](https://github.com/LanguageMachines/libfolia) - C++ library for the [FoLiA format](https://proycon.github.io/folia/)\n* [MeTA](https://github.com/meta-toolkit/meta) - [MeTA : ModErn Text Analysis](https://meta-toolkit.org/) is a C++ Data Sciences Toolkit that facilitates mining big text data.\n* [MIT Information Extraction Toolkit](https://github.com/mit-nlp/MITIE) - C, C++, and Python tools for named entity recognition and relation extraction\n* [ucto](https://github.com/LanguageMachines/ucto) - Unicode-aware regular-expression based tokenizer for various languages. Tool and C++ library. Supports FoLiA format.\n\n<a name=""cpp-speech-recognition""></a>\n#### Speech Recognition\n* [Kaldi](https://github.com/kaldi-asr/kaldi) - Kaldi is a toolkit for speech recognition written in C++ and licensed under the Apache License v2.0. Kaldi is intended for use by speech recognition researchers.\n\n<a name=""cpp-sequence""></a>\n#### Sequence Analysis\n* [ToPS](https://github.com/ayoshiaki/tops) - This is an objected-oriented framework that facilitates the integration of probabilistic models for sequences over a user defined alphabet. **[Deprecated]**\n\n<a name=""cpp-gestures""></a>\n#### Gesture Detection\n* [grt](https://github.com/nickgillian/grt) - The Gesture Recognition Toolkit (GRT) is a cross-platform, open-source, C++ machine learning library designed for real-time gesture recognition.\n\n<a name=""common-lisp""></a>\n## Common Lisp\n\n<a name=""common-lisp-general-purpose""></a>\n#### General-Purpose Machine Learning\n\n* [mgl](https://github.com/melisgl/mgl/) - Neural networks (boltzmann machines, feed-forward and recurrent nets), Gaussian Processes.\n* [mgl-gpr](https://github.com/melisgl/mgl-gpr/) - Evolutionary algorithms. **[Deprecated]**\n* [cl-libsvm](https://github.com/melisgl/cl-libsvm/) - Wrapper for the libsvm support vector machine library. **[Deprecated]**\n* [cl-online-learning](https://github.com/masatoi/cl-online-learning) - Online learning algorithms (Perceptron, AROW, SCW, Logistic Regression).\n* [cl-random-forest](https://github.com/masatoi/cl-random-forest) - Implementation of Random Forest in Common Lisp.\n\n<a name=""clojure""></a>\n## Clojure\n\n<a name=""clojure-nlp""></a>\n#### Natural Language Processing\n\n* [Clojure-openNLP](https://github.com/dakrone/clojure-opennlp) - Natural Language Processing in Clojure (opennlp).\n* [Infections-clj](https://github.com/r0man/inflections-clj) - Rails-like inflection library for Clojure and ClojureScript.\n\n<a name=""clojure-general-purpose""></a>\n#### General-Purpose Machine Learning\n\n* [Touchstone](https://github.com/ptaoussanis/touchstone) - Clojure A/B testing library. **[Deprecated]**\n* [Clojush](https://github.com/lspector/Clojush) - The Push programming language and the PushGP genetic programming system implemented in Clojure.\n* [Infer](https://github.com/aria42/infer) - Inference and machine learning in Clojure. **[Deprecated]**\n* [Clj-ML](https://github.com/antoniogarrote/clj-ml) - A machine learning library for Clojure built on top of Weka and friends. **[Deprecated]**\n* [DL4CLJ](https://github.com/yetanalytics/dl4clj) - Clojure wrapper for Deeplearning4j.\n* [Encog](https://github.com/jimpil/enclog) - Clojure wrapper for Encog (v3) (Machine-Learning framework that specializes in neural-nets). **[Deprecated]**\n* [Fungp](https://github.com/vollmerm/fungp) - A genetic programming library for Clojure. **[Deprecated]**\n* [Statistiker](https://github.com/clojurewerkz/statistiker) - Basic Machine Learning algorithms in Clojure. **[Deprecated]**\n* [clortex](https://github.com/htm-community/clortex) - General Machine Learning library using Numenta\xe2\x80\x99s Cortical Learning Algorithm. **[Deprecated]**\n* [comportex](https://github.com/htm-community/comportex) - Functionally composable Machine Learning library using Numenta\xe2\x80\x99s Cortical Learning Algorithm. **[Deprecated]**\n* [cortex](https://github.com/originrose/cortex) - Neural networks, regression and feature learning in Clojure.\n* [lambda-ml](https://github.com/cloudkj/lambda-ml) - Simple, concise implementations of machine learning techniques and utilities in Clojure.\n\n<a name=""clojure-data-analysis""></a>\n#### Data Analysis / Data Visualization\n\n* [Incanter](http://incanter.org/) - Incanter is a Clojure-based, R-like platform for statistical computing and graphics.\n* [PigPen](https://github.com/Netflix/PigPen) - Map-Reduce for Clojure.\n* [Envision](https://github.com/clojurewerkz/envision) - Clojure Data Visualisation library, based on Statistiker and D3.\n\n<a name=""crystal""></a>\n## Crystal\n\n<a name=""crystal-general-purpose""></a>\n#### General-Purpose Machine Learning\n\n* [machine](https://github.com/mathieulaporte/machine) - Simple machine learning algorithm.\n* [crystal-fann](https://github.com/NeuraLegion/crystal-fann) - FANN (Fast Artificial Neural Network) binding.\n\n<a name=""elixir""></a>\n## Elixir\n\n<a name=""elixir-general-purpose""></a>\n#### General-Purpose Machine Learning\n\n* [Simple Bayes](https://github.com/fredwu/simple_bayes) - A Simple Bayes / Naive Bayes implementation in Elixir.\n* [emel](https://github.com/mrdimosthenis/emel) - A simple and functional machine learning library written in Elixir.\n* [Tensorflex](https://github.com/anshuman23/tensorflex) - Tensorflow bindings for the Elixir programming language.\n\n<a name=""elixir-nlp""></a>\n#### Natural Language Processing\n\n* [Stemmer](https://github.com/fredwu/stemmer) - An English (Porter2) stemming implementation in Elixir.\n\n<a name=""erlang""></a>\n## Erlang\n\n<a name=""erlang-general-purpose""></a>\n#### General-Purpose Machine Learning\n\n* [Disco](https://github.com/discoproject/disco/) - Map Reduce in Erlang. **[Deprecated]**\n* [Yanni](https://bitbucket.org/nato/yanni/overview) - ANN neural networks using Erlangs leightweight processes.\n\n<a name=""go""></a>\n## Go\n\n<a name=""go-nlp""></a>\n#### Natural Language Processing\n\n* [snowball](https://github.com/tebeka/snowball) - Snowball Stemmer for Go.\n* [word-embedding](https://github.com/ynqa/word-embedding) - Word Embeddings: the full implementation of word2vec, GloVe in Go.\n* [sentences](https://github.com/neurosnap/sentences) - Golang implementation of Punkt sentence tokenizer.\n* [go-ngram](https://github.com/Lazin/go-ngram) - In-memory n-gram index with compression. *[Deprecated]*\n* [paicehusk](https://github.com/Rookii/paicehusk) - Golang implementation of the Paice/Husk Stemming Algorithm. *[Deprecated]*\n* [go-porterstemmer](https://github.com/reiver/go-porterstemmer) - A native Go clean room implementation of the Porter Stemming algorithm. **[Deprecated]**\n\n<a name=""go-general-purpose""></a>\n#### General-Purpose Machine Learning\n\n* [birdland](https://github.com/rlouf/birdland) - A recommendation library in Go.\n* [eaopt](https://github.com/MaxHalford/eaopt) - An evolutionary optimization library.\n* [leaves](https://github.com/dmitryikh/leaves) - A pure Go implementation of the prediction part of GBRTs, including XGBoost and LightGBM.\n* [gobrain](https://github.com/goml/gobrain) - Neural Networks written in Go.\n* [go-mxnet-predictor](https://github.com/songtianyi/go-mxnet-predictor) - Go binding for MXNet c_predict_api to do inference with pre-trained model.\n* [go-ml-transpiler](https://github.com/znly/go-ml-transpiler) - An open source Go transpiler for machine learning models.\n* [golearn](https://github.com/sjwhitworth/golearn) - Machine learning for Go.\n* [goml](https://github.com/cdipaolo/goml) - Machine learning library written in pure Go.\n* [gorgonia](https://github.com/gorgonia/gorgonia) - Deep learning in Go.\n* [goro](https://github.com/aunum/goro) - A high-level machine learning library in the vein of Keras.\n* [gorse](https://github.com/zhenghaoz/gorse) - An offline recommender system backend based on collaborative filtering written in Go.\n* [therfoo](https://github.com/therfoo/therfoo) - An embedded deep learning library for Go.\n* [neat](https://github.com/jinyeom/neat) - Plug-and-play, parallel Go framework for NeuroEvolution of Augmenting Topologies (NEAT). **[Deprecated]**\n* [go-pr](https://github.com/daviddengcn/go-pr) - Pattern recognition package in Go lang. **[Deprecated]**\n* [go-ml](https://github.com/alonsovidales/go_ml) - Linear / Logistic regression, Neural Networks, Collaborative Filtering and Gaussian Multivariate Distribution. **[Deprecated]**\n* [GoNN](https://github.com/fxsjy/gonn) - GoNN is an implementation of Neural Network in Go Language, which includes BPNN, RBF, PCN. **[Deprecated]**\n* [bayesian](https://github.com/jbrukh/bayesian) - Naive Bayesian Classification for Golang. **[Deprecated]**\n* [go-galib](https://github.com/thoj/go-galib) - Genetic Algorithms library written in Go / Golang. **[Deprecated]**\n* [Cloudforest](https://github.com/ryanbressler/CloudForest) - Ensembles of decision trees in Go/Golang. **[Deprecated]**\n* [go-dnn](https://github.com/sudachen/go-dnn) - Deep Neural Networks for Golang (powered by MXNet)\n\n<a name=""go-spatial-analysis""></a>\n#### Spatial analysis and geometry\n\n* [go-geom](https://github.com/twpayne/go-geom) - Go library to handle geometries.\n* [gogeo](https://github.com/golang/geo) - Spherical geometry in Go.\n\n<a name=""go-data-analysis""></a>\n#### Data Analysis / Data Visualization\n\n* [dataframe-go](https://github.com/rocketlaunchr/dataframe-go) - Dataframes for machine-learning and statistics (similar to pandas).\n* [gota](https://github.com/go-gota/gota) - Dataframes.\n* [gonum/mat](https://godoc.org/gonum.org/v1/gonum/mat) - A linear algebra package for Go.\n* [gonum/optimize](https://godoc.org/gonum.org/v1/gonum/optimize) - Implementations of optimization algorithms.\n* [gonum/plot](https://godoc.org/gonum.org/v1/plot) - A plotting library.\n* [gonum/stat](https://godoc.org/gonum.org/v1/gonum/stat) - A statistics library.\n* [SVGo](https://github.com/ajstarks/svgo) - The Go Language library for SVG generation.\n* [glot](https://github.com/arafatk/glot) - Glot is a plotting library for Golang built on top of gnuplot.\n* [globe](https://github.com/mmcloughlin/globe) - Globe wireframe visualization.\n* [gonum/graph](https://godoc.org/gonum.org/v1/gonum/graph) - General-purpose graph library.\n* [go-graph](https://github.com/StepLg/go-graph) - Graph library for Go/Golang language. **[Deprecated]**\n* [RF](https://github.com/fxsjy/RF.go) - Random forests implementation in Go. **[Deprecated]**\n\n<a name=""go-computer-vision""></a>\n#### Computer vision\n\n* [GoCV](https://github.com/hybridgroup/gocv) - Package for computer vision using OpenCV 4 and beyond.\n\n<a name=""go-reinforcement-learning""></a>\n#### Reinforcement learning\n\n* [gold](https://github.com/aunum/gold) - A reinforcement learning library.\n\n<a name=""haskell""></a>\n## Haskell\n\n<a name=""haskell-general-purpose""></a>\n#### General-Purpose Machine Learning\n* [haskell-ml](https://github.com/ajtulloch/haskell-ml) - Haskell implementations of various ML algorithms. **[Deprecated]**\n* [HLearn](https://github.com/mikeizbicki/HLearn) - a suite of libraries for interpreting machine learning models according to their algebraic structure. **[Deprecated]**\n* [hnn](https://github.com/alpmestan/HNN) - Haskell Neural Network library.\n* [hopfield-networks](https://github.com/ajtulloch/hopfield-networks) - Hopfield Networks for unsupervised learning in Haskell. **[Deprecated]**\n* [DNNGraph](https://github.com/ajtulloch/dnngraph) - A DSL for deep neural networks. **[Deprecated]**\n* [LambdaNet](https://github.com/jbarrow/LambdaNet) - Configurable Neural Networks in Haskell. **[Deprecated]**\n\n<a name=""java""></a>\n## Java\n\n<a name=""java-nlp""></a>\n#### Natural Language Processing\n* [Cortical.io](https://www.cortical.io/) - Retina: an API performing complex NLP operations (disambiguation, classification, streaming text filtering, etc...) as quickly and intuitively as the brain.\n* [IRIS](https://github.com/cortical-io/Iris) - [Cortical.io\'s](https://cortical.io) FREE NLP, Retina API Analysis Tool (written in JavaFX!) - [See the Tutorial Video](https://www.youtube.com/watch?v=CsF4pd7fGF0).\n* [CoreNLP](https://nlp.stanford.edu/software/corenlp.shtml) - Stanford CoreNLP provides a set of natural language analysis tools which can take raw English language text input and give the base forms of words.\n* [Stanford Parser](https://nlp.stanford.edu/software/lex-parser.shtml) - A natural language parser is a program that works out the grammatical structure of sentences.\n* [Stanford POS Tagger](https://nlp.stanford.edu/software/tagger.shtml) - A Part-Of-Speech Tagger (POS Tagger).\n* [Stanford Name Entity Recognizer](https://nlp.stanford.edu/software/CRF-NER.shtml) - Stanford NER is a Java implementation of a Named Entity Recognizer.\n* [Stanford Word Segmenter](https://nlp.stanford.edu/software/segmenter.shtml) - Tokenization of raw text is a standard pre-processing step for many NLP tasks.\n* [Tregex, Tsurgeon and Semgrex](https://nlp.stanford.edu/software/tregex.shtml) - Tregex is a utility for matching patterns in trees, based on tree relationships and regular expression matches on nodes (the name is short for ""tree regular expressions"").\n* [Stanford Phrasal: A Phrase-Based Translation System](https://nlp.stanford.edu/phrasal/)\n* [Stanford English Tokenizer](https://nlp.stanford.edu/software/tokenizer.shtml) - Stanford Phrasal is a state-of-the-art statistical phrase-based machine translation system, written in Java.\n* [Stanford Tokens Regex](https://nlp.stanford.edu/software/tokensregex.shtml) - A tokenizer divides text into a sequence of tokens, which roughly correspond to ""words"".\n* [Stanford Temporal Tagger](https://nlp.stanford.edu/software/sutime.shtml) - SUTime is a library for recognizing and normalizing time expressions.\n* [Stanford SPIED](https://nlp.stanford.edu/software/patternslearning.shtml) - Learning entities from unlabeled text starting with seed sets using patterns in an iterative fashion.\n* [Stanford Topic Modeling Toolbox](https://nlp.stanford.edu/software/tmt) - Topic modeling tools to social scientists and others who wish to perform analysis on datasets.\n* [Twitter Text Java](https://github.com/twitter/twitter-text/tree/master/java) - A Java implementation of Twitter\'s text processing library.\n* [MALLET](http://mallet.cs.umass.edu/) - A Java-based package for statistical natural language processing, document classification, clustering, topic modeling, information extraction, and other machine learning applications to text.\n* [OpenNLP](https://opennlp.apache.org/) - a machine learning based toolkit for the processing of natural language text.\n* [LingPipe](http://alias-i.com/lingpipe/index.html) - A tool kit for processing text using computational linguistics.\n* [ClearTK](https://github.com/ClearTK/cleartk) - ClearTK provides a framework for developing statistical natural language processing (NLP) components in Java and is built on top of Apache UIMA. **[Deprecated]**\n* [Apache cTAKES](https://ctakes.apache.org/) - Apache clinical Text Analysis and Knowledge Extraction System (cTAKES) is an open-source natural language processing system for information extraction from electronic medical record clinical free-text.\n* [NLP4J](https://github.com/emorynlp/nlp4j) - The NLP4J project provides software and resources for natural language processing. The project started at the Center for Computational Language and EducAtion Research, and is currently developed by the Center for Language and Information Research at Emory University. **[Deprecated]**\n* [CogcompNLP](https://github.com/CogComp/cogcomp-nlp) - This project collects a number of core libraries for Natural Language Processing (NLP) developed in the University of Illinois\' Cognitive Computation Group, for example `illinois-core-utilities` which provides a set of NLP-friendly data structures and a number of NLP-related utilities that support writing NLP applications, running experiments, etc, `illinois-edison` a library for feature extraction from illinois-core-utilities data structures and many other packages.\n\n<a name=""java-general-purpose""></a>\n#### General-Purpose Machine Learning\n\n* [aerosolve](https://github.com/airbnb/aerosolve) - A machine learning library by Airbnb designed from the ground up to be human friendly.\n* [AMIDST Toolbox](http://www.amidsttoolbox.com/) - A Java Toolbox for Scalable Probabilistic Machine Learning.\n* [Datumbox](https://github.com/datumbox/datumbox-framework) - Machine Learning framework for rapid development of Machine Learning and Statistical applications.\n* [ELKI](https://elki-project.github.io/) - Java toolkit for data mining. (unsupervised: clustering, outlier detection etc.)\n* [Encog](https://github.com/encog/encog-java-core) - An advanced neural network and machine learning framework. Encog contains classes to create a wide variety of networks, as well as support classes to normalize and process data for these neural networks. Encog trains using multithreaded resilient propagation. Encog can also make use of a GPU to further speed processing time. A GUI based workbench is also provided to help model and train neural networks.\n* [FlinkML in Apache Flink](https://ci.apache.org/projects/flink/flink-docs-master/dev/libs/ml/index.html) - Distributed machine learning library in Flink.\n* [H2O](https://github.com/h2oai/h2o-3) - ML engine that supports distributed learning on Hadoop, Spark or your laptop via APIs in R, Python, Scala, REST/JSON.\n* [htm.java](https://github.com/numenta/htm.java) - General Machine Learning library using Numenta\xe2\x80\x99s Cortical Learning Algorithm.\n* [liblinear-java](https://github.com/bwaldvogel/liblinear-java) - Java version of liblinear.\n* [Mahout](https://github.com/apache/mahout) - Distributed machine learning.\n* [Meka](http://meka.sourceforge.net/) - An open source implementation of methods for multi-label classification and evaluation (extension to Weka).\n* [MLlib in Apache Spark](https://spark.apache.org/docs/latest/mllib-guide.html) - Distributed machine learning library in Spark\n* [Hydrosphere Mist](https://github.com/Hydrospheredata/mist) - a service for deployment Apache Spark MLLib machine learning models as realtime, batch or reactive web services.\n* [Neuroph](http://neuroph.sourceforge.net/) - Neuroph is lightweight Java neural network framework\n* [ORYX](https://github.com/oryxproject/oryx) - Lambda Architecture Framework using Apache Spark and Apache Kafka with a specialization for real-time large-scale machine learning.\n* [Samoa](https://samoa.incubator.apache.org/) SAMOA is a framework that includes distributed machine learning for data streams with an interface to plug-in different stream processing platforms.\n* [RankLib](https://sourceforge.net/p/lemur/wiki/RankLib/) - RankLib is a library of learning to rank algorithms. **[Deprecated]**\n* [rapaio](https://github.com/padreati/rapaio) - statistics, data mining and machine learning toolbox in Java.\n* [RapidMiner](https://rapidminer.com) - RapidMiner integration into Java code.\n* [Stanford Classifier](https://nlp.stanford.edu/software/classifier.shtml) - A classifier is a machine learning tool that will take data items and place them into one of k classes.\n* [SmileMiner](https://github.com/haifengl/smile) - Statistical Machine Intelligence & Learning Engine.\n* [SystemML](https://github.com/apache/systemml) - flexible, scalable machine learning (ML) language.\n* [Weka](https://www.cs.waikato.ac.nz/ml/weka/) - Weka is a collection of machine learning algorithms for data mining tasks.\n* [LBJava](https://github.com/CogComp/lbjava) - Learning Based Java is a modeling language for the rapid development of software systems, offers a convenient, declarative syntax for classifier and constraint definition directly in terms of the objects in the programmer\'s application.\n\n\n<a name=""java-speech-recognition""></a>\n#### Speech Recognition\n* [CMU Sphinx](https://cmusphinx.github.io) - Open Source Toolkit For Speech Recognition purely based on Java speech recognition library.\n\n<a name=""java-data-analysis""></a>\n#### Data Analysis / Data Visualization\n\n* [Flink](https://flink.apache.org/) - Open source platform for distributed stream and batch data processing.\n* [Hadoop](https://github.com/apache/hadoop) - Hadoop/HDFS.\n* [Onyx](https://github.com/onyx-platform/onyx) - Distributed, masterless, high performance, fault tolerant data processing. Written entirely in Clojure.\n* [Spark](https://github.com/apache/spark) - Spark is a fast and general engine for large-scale data processing.\n* [Storm](https://storm.apache.org/) - Storm is a distributed realtime computation system.\n* [Impala](https://github.com/cloudera/impala) - Real-time Query for Hadoop.\n* [DataMelt](https://jwork.org/dmelt/) - Mathematics software for numeric computation, statistics, symbolic calculations, data analysis and data visualization.\n* [Dr. Michael Thomas Flanagan\'s Java Scientific Library](https://www.ee.ucl.ac.uk/~mflanaga/java/) **[Deprecated]**\n\n<a name=""java-deep-learning""></a>\n#### Deep Learning\n\n* [Deeplearning4j](https://github.com/deeplearning4j/deeplearning4j) - Scalable deep learning for industry with parallel GPUs.\n* [Keras Beginner Tutorial](https://victorzhou.com/blog/keras-neural-network-tutorial/) - Friendly guide on using Keras to implement a simple Neural Network in Python\n\n<a name=""javascript""></a>\n## Javascript\n\n<a name=""javascript-nlp""></a>\n#### Natural Language Processing\n\n* [Twitter-text](https://github.com/twitter/twitter-text) - A JavaScript implementation of Twitter\'s text processing library.\n* [natural](https://github.com/NaturalNode/natural) - General natural language facilities for node.\n* [Knwl.js](https://github.com/loadfive/Knwl.js) - A Natural Language Processor in JS.\n* [Retext](https://github.com/retextjs/retext) - Extensible system for analyzing and manipulating natural language.\n* [NLP Compromise](https://github.com/spencermountain/compromise) - Natural Language processing in the browser.\n* [nlp.js](https://github.com/axa-group/nlp.js) - An NLP library built in node over Natural, with entity extraction, sentiment analysis, automatic language identify, and so more\n\n\n\n<a name=""javascript-data-analysis""></a>\n#### Data Analysis / Data Visualization\n\n* [D3.js](https://d3js.org/)\n* [High Charts](https://www.highcharts.com/)\n* [NVD3.js](http://nvd3.org/)\n* [dc.js](https://dc-js.github.io/dc.js/)\n* [chartjs](https://www.chartjs.org/)\n* [dimple](http://dimplejs.org/)\n* [amCharts](https://www.amcharts.com/)\n* [D3xter](https://github.com/NathanEpstein/D3xter) - Straight forward plotting built on D3. **[Deprecated]**\n* [statkit](https://github.com/rigtorp/statkit) - Statistics kit for JavaScript. **[Deprecated]**\n* [datakit](https://github.com/nathanepstein/datakit) - A lightweight framework for data analysis in JavaScript\n* [science.js](https://github.com/jasondavies/science.js/) - Scientific and statistical computing in JavaScript. **[Deprecated]**\n* [Z3d](https://github.com/NathanEpstein/Z3d) - Easily make interactive 3d plots built on Three.js **[Deprecated]**\n* [Sigma.js](http://sigmajs.org/) - JavaScript library dedicated to graph drawing.\n* [C3.js](https://c3js.org/) - customizable library based on D3.js for easy chart drawing.\n* [Datamaps](https://datamaps.github.io/) - Customizable SVG map/geo visualizations using D3.js. **[Deprecated]**\n* [ZingChart](https://www.zingchart.com/) - library written on Vanilla JS for big data visualization.\n* [cheminfo](https://www.cheminfo.org/) - Platform for data visualization and analysis, using the [visualizer](https://github.com/npellet/visualizer) project.\n* [Learn JS Data](http://learnjsdata.com/)\n* [AnyChart](https://www.anychart.com/)\n* [FusionCharts](https://www.fusioncharts.com/)\n* [Nivo](https://nivo.rocks) - built on top of the awesome d3 and Reactjs libraries\n\n\n<a name=""javascript-general-purpose""></a>\n#### General-Purpose Machine Learning\n\n* [Auto ML](https://github.com/ClimbsRocks/auto_ml) - Automated machine learning, data formatting, ensembling, and hyperparameter optimization for competitions and exploration- just give it a .csv file!\n* [Convnet.js](https://cs.stanford.edu/people/karpathy/convnetjs/) - ConvNetJS is a Javascript library for training Deep Learning models[DEEP LEARNING] **[Deprecated]**\n* [Clusterfck](https://harthur.github.io/clusterfck/) - Agglomerative hierarchical clustering implemented in Javascript for Node.js and the browser. **[Deprecated]**\n* [Clustering.js](https://github.com/emilbayes/clustering.js) - Clustering algorithms implemented in Javascript for Node.js and the browser. **[Deprecated]**\n* [Decision Trees](https://github.com/serendipious/nodejs-decision-tree-id3) - NodeJS Implementation of Decision Tree using ID3 Algorithm. **[Deprecated]**\n* [DN2A](https://github.com/antoniodeluca/dn2a.js) - Digital Neural Networks Architecture. **[Deprecated]**\n* [figue](https://code.google.com/archive/p/figue) - K-means, fuzzy c-means and agglomerative clustering.\n* [Gaussian Mixture Model](https://github.com/lukapopijac/gaussian-mixture-model) - Unsupervised machine learning with multivariate Gaussian mixture model.\n* [Node-fann](https://github.com/rlidwka/node-fann) - FANN (Fast Artificial Neural Network Library) bindings for Node.js **[Deprecated]**\n* [Keras.js](https://github.com/transcranial/keras-js) - Run Keras models in the browser, with GPU support provided by WebGL 2.\n* [Kmeans.js](https://github.com/emilbayes/kMeans.js) - Simple Javascript implementation of the k-means algorithm, for node.js and the browser. **[Deprecated]**\n* [LDA.js](https://github.com/primaryobjects/lda) - LDA topic modeling for Node.js\n* [Learning.js](https://github.com/yandongliu/learningjs) - Javascript implementation of logistic regression/c4.5 decision tree **[Deprecated]**\n* [machinelearn.js](https://github.com/machinelearnjs/machinelearnjs) - Machine Learning library for the web, Node.js and developers\n* [mil-tokyo](https://github.com/mil-tokyo) - List of several machine learning libraries.\n* [Node-SVM](https://github.com/nicolaspanel/node-svm) - Support Vector Machine for Node.js\n* [Brain](https://github.com/harthur/brain) - Neural networks in JavaScript **[Deprecated]**\n* [Brain.js](https://github.com/BrainJS/brain.js) - Neural networks in JavaScript - continued community fork of [Brain](https://github.com/harthur/brain).\n* [Bayesian-Bandit](https://github.com/omphalos/bayesian-bandit.js) - Bayesian bandit implementation for Node and the browser. **[Deprecated]**\n* [Synaptic](https://github.com/cazala/synaptic) - Architecture-free neural network library for Node.js and the browser.\n* [kNear](https://github.com/NathanEpstein/kNear) - JavaScript implementation of the k nearest neighbors algorithm for supervised learning.\n* [NeuralN](https://github.com/totemstech/neuraln) - C++ Neural Network library for Node.js. It has advantage on large dataset and multi-threaded training. **[Deprecated]**\n* [kalman](https://github.com/itamarwe/kalman) - Kalman filter for Javascript. **[Deprecated]**\n* [shaman](https://github.com/luccastera/shaman) - Node.js library with support for both simple and multiple linear regression. **[Deprecated]**\n* [ml.js](https://github.com/mljs/ml) - Machine learning and numerical analysis tools for Node.js and the Browser!\n* [ml5](https://github.com/ml5js/ml5-library) - Friendly machine learning for the web!\n* [Pavlov.js](https://github.com/NathanEpstein/Pavlov.js) - Reinforcement learning using Markov Decision Processes.\n* [MXNet](https://github.com/apache/incubator-mxnet) - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more.\n* [TensorFlow.js](https://js.tensorflow.org/) - A WebGL accelerated, browser based JavaScript library for training and deploying ML models.\n* [JSMLT](https://github.com/jsmlt/jsmlt) - Machine learning toolkit with classification and clustering for Node.js; supports visualization (see [visualml.io](https://visualml.io)).\n* [xgboost-node](https://github.com/nuanio/xgboost-node) - Run XGBoost model and make predictions in Node.js.\n* [Netron](https://github.com/lutzroeder/netron) - Visualizer for machine learning models.\n* [WebDNN](https://github.com/mil-tokyo/webdnn) - Fast Deep Neural Network Javascript Framework. WebDNN uses next generation JavaScript API, WebGPU for GPU execution, and WebAssembly for CPU execution.  \n\n<a name=""javascript-misc""></a>\n#### Misc\n\n* [stdlib](https://github.com/stdlib-js/stdlib) - A standard library for JavaScript and Node.js, with an emphasis on numeric computing. The library provides a collection of robust, high performance libraries for mathematics, statistics, streams, utilities, and more.\n* [sylvester](https://github.com/jcoglan/sylvester) - Vector and Matrix math for JavaScript. **[Deprecated]**\n* [simple-statistics](https://github.com/simple-statistics/simple-statistics) - A JavaScript implementation of descriptive, regression, and inference statistics. Implemented in literate JavaScript with no dependencies, designed to work in all modern browsers (including IE) as well as in Node.js.\n* [regression-js](https://github.com/Tom-Alexander/regression-js) - A javascript library containing a collection of least squares fitting methods for finding a trend in a set of data.\n* [Lyric](https://github.com/flurry/Lyric) - Linear Regression library. **[Deprecated]**\n* [GreatCircle](https://github.com/mwgg/GreatCircle) - Library for calculating great circle distance.\n* [MLPleaseHelp](https://github.com/jgreenemi/MLPleaseHelp) - MLPleaseHelp is a simple ML resource search engine. You can use this search engine right now at [https://jgreenemi.github.io/MLPleaseHelp/](https://jgreenemi.github.io/MLPleaseHelp/), provided via Github Pages.\n* [Pipcook](https://github.com/alibaba/pipcook) - A JavaScript application framework for machine learning and its engineering.\n\n<a name=""javascript-demos""></a>\n#### Demos and Scripts\n* [The Bot](https://github.com/sta-ger/TheBot) - Example of how the neural network learns to predict the angle between two points created with [Synaptic](https://github.com/cazala/synaptic).\n* [Half Beer](https://github.com/sta-ger/HalfBeer) - Beer glass classifier created with [Synaptic](https://github.com/cazala/synaptic).\n* [NSFWJS](http://nsfwjs.com) - Indecent content checker with TensorFlow.js\n* [Rock Paper Scissors](https://rps-tfjs.netlify.com/) - Rock Paper Scissors trained in the browser with TensorFlow.js\n\n<a name=""julia""></a>\n## Julia\n\n<a name=""julia-general-purpose""></a>\n#### General-Purpose Machine Learning\n\n* [MachineLearning](https://github.com/benhamner/MachineLearning.jl) - Julia Machine Learning library. **[Deprecated]**\n* [MLBase](https://github.com/JuliaStats/MLBase.jl) - A set of functions to support the development of machine learning algorithms.\n* [PGM](https://github.com/JuliaStats/PGM.jl) - A Julia framework for probabilistic graphical models.\n* [DA](https://github.com/trthatcher/DiscriminantAnalysis.jl) - Julia package for Regularized Discriminant Analysis.\n* [Regression](https://github.com/lindahua/Regression.jl) - Algorithms for regression analysis (e.g. linear regression and logistic regression). **[Deprecated]**\n* [Local Regression](https://github.com/JuliaStats/Loess.jl) - Local regression, so smooooth!\n* [Naive Bayes](https://github.com/nutsiepully/NaiveBayes.jl) - Simple Naive Bayes implementation in Julia. **[Deprecated]**\n* [Mixed Models](https://github.com/dmbates/MixedModels.jl) - A Julia package for fitting (statistical) mixed-effects models.\n* [Simple MCMC](https://github.com/fredo-dedup/SimpleMCMC.jl) - basic mcmc sampler implemented in Julia. **[Deprecated]**\n* [Distances](https://github.com/JuliaStats/Distances.jl) - Julia module for Distance evaluation.\n* [Decision Tree](https://github.com/bensadeghi/DecisionTree.jl) - Decision Tree Classifier and Regressor.\n* [Neural](https://github.com/compressed/BackpropNeuralNet.jl) - A neural network in Julia.\n* [MCMC](https://github.com/doobwa/MCMC.jl) - MCMC tools for Julia. **[Deprecated]**\n* [Mamba](https://github.com/brian-j-smith/Mamba.jl) - Markov chain Monte Carlo (MCMC) for Bayesian analysis in Julia.\n* [GLM](https://github.com/JuliaStats/GLM.jl) - Generalized linear models in Julia.\n* [Gaussian Processes](https://github.com/STOR-i/GaussianProcesses.jl) - Julia package for Gaussian processes.\n* [Online Learning](https://github.com/lendle/OnlineLearning.jl) **[Deprecated]**\n* [GLMNet](https://github.com/simonster/GLMNet.jl) - Julia wrapper for fitting Lasso/ElasticNet GLM models using glmnet.\n* [Clustering](https://github.com/JuliaStats/Clustering.jl) - Basic functions for clustering data: k-means, dp-means, etc.\n* [SVM](https://github.com/JuliaStats/SVM.jl) - SVM\'s for Julia. **[Deprecated]**\n* [Kernel Density](https://github.com/JuliaStats/KernelDensity.jl) - Kernel density estimators for julia.\n* [MultivariateStats](https://github.com/JuliaStats/MultivariateStats.jl) - Methods for dimensionality reduction.\n* [NMF](https://github.com/JuliaStats/NMF.jl) - A Julia package for non-negative matrix factorization.\n* [ANN](https://github.com/EricChiang/ANN.jl) - Julia artificial neural networks. **[Deprecated]**\n* [Mocha](https://github.com/pluskid/Mocha.jl) - Deep Learning framework for Julia inspired by Caffe. **[Deprecated]**\n* [XGBoost](https://github.com/dmlc/XGBoost.jl) - eXtreme Gradient Boosting Package in Julia.\n* [ManifoldLearning](https://github.com/wildart/ManifoldLearning.jl) - A Julia package for manifold learning and nonlinear dimensionality reduction.\n* [MXNet](https://github.com/apache/incubator-mxnet) - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more.\n* [Merlin](https://github.com/hshindo/Merlin.jl) - Flexible Deep Learning Framework in Julia.\n* [ROCAnalysis](https://github.com/davidavdav/ROCAnalysis.jl) - Receiver Operating Characteristics and functions for evaluation probabilistic binary classifiers.\n* [GaussianMixtures](https://github.com/davidavdav/GaussianMixtures.jl) - Large scale Gaussian Mixture Models.\n* [ScikitLearn](https://github.com/cstjean/ScikitLearn.jl) - Julia implementation of the scikit-learn API.\n* [Knet](https://github.com/denizyuret/Knet.jl) - Ko\xc3\xa7 University Deep Learning Framework.\n* [Flux](https://fluxml.ai/) - Relax! Flux is the ML library that doesn\'t make you tensor\n* [MLJ](https://github.com/alan-turing-institute/MLJ.jl) - A Julia machine learning framework\n\n<a name=""julia-nlp""></a>\n#### Natural Language Processing\n\n* [Topic Models](https://github.com/slycoder/TopicModels.jl) - TopicModels for Julia. **[Deprecated]**\n* [Text Analysis](https://github.com/JuliaText/TextAnalysis.jl) - Julia package for text analysis.\n* [Word Tokenizers](https://github.com/JuliaText/WordTokenizers.jl) - Tokenizers for Natural Language Processing in Julia\n* [Corpus Loaders](https://github.com/JuliaText/CorpusLoaders.jl) - A julia package providing a variety of loaders for various NLP corpora.\n* [Embeddings](https://github.com/JuliaText/Embeddings.jl) - Functions and data dependencies for loading various word embeddings\n* [Languages](https://github.com/JuliaText/Languages.jl) - Julia package for working with various human languages\n* [WordNet](https://github.com/JuliaText/WordNet.jl) - A Julia package for Princeton\'s WordNet\n\n<a name=""julia-data-analysis""></a>\n#### Data Analysis / Data Visualization\n\n* [Graph Layout](https://github.com/IainNZ/GraphLayout.jl) - Graph layout algorithms in pure Julia.\n* [LightGraphs](https://github.com/JuliaGraphs/LightGraphs.jl) - Graph modeling and analysis.\n* [Data Frames Meta](https://github.com/JuliaData/DataFramesMeta.jl) - Metaprogramming tools for DataFrames.\n* [Julia Data](https://github.com/nfoti/JuliaData) - library for working with tabular data in Julia. **[Deprecated]**\n* [Data Read](https://github.com/queryverse/ReadStat.jl) - Read files from Stata, SAS, and SPSS.\n* [Hypothesis Tests](https://github.com/JuliaStats/HypothesisTests.jl) - Hypothesis tests for Julia.\n* [Gadfly](https://github.com/GiovineItalia/Gadfly.jl) - Crafty statistical graphics for Julia.\n* [Stats](https://github.com/JuliaStats/StatsKit.jl) - Statistical tests for Julia.\n* [RDataSets](https://github.com/johnmyleswhite/RDatasets.jl) - Julia package for loading many of the data sets available in R.\n* [DataFrames](https://github.com/JuliaData/DataFrames.jl) - library for working with tabular data in Julia.\n* [Distributions](https://github.com/JuliaStats/Distributions.jl) - A Julia package for probability distributions and associated functions.\n* [Data Arrays](https://github.com/JuliaStats/DataArrays.jl) - Data structures that allow missing values. **[Deprecated]**\n* [Time Series](https://github.com/JuliaStats/TimeSeries.jl) - Time series toolkit for Julia.\n* [Sampling](https://github.com/lindahua/Sampling.jl) - Basic sampling algorithms for Julia.\n\n<a name=""julia-misc""></a>\n#### Misc Stuff / Presentations\n\n* [DSP](https://github.com/JuliaDSP/DSP.jl) - Digital Signal Processing (filtering, periodograms, spectrograms, window functions).\n* [JuliaCon Presentations](https://github.com/JuliaCon/presentations) - Presentations for JuliaCon.\n* [SignalProcessing](https://github.com/JuliaDSP/DSP.jl) - Signal Processing tools for Julia.\n* [Images](https://github.com/JuliaImages/Images.jl) - An image library for Julia.\n* [DataDeps](https://github.com/oxinabox/DataDeps.jl) - Reproducible data setup for reproducible science.\n\n<a name=""lua""></a>\n## Lua\n\n<a name=""lua-general-purpose""></a>\n#### General-Purpose Machine Learning\n\n* [Torch7](http://torch.ch/)\n  * [cephes](https://github.com/deepmind/torch-cephes) - Cephes mathematical functions library, wrapped for Torch. Provides and wraps the 180+ special mathematical functions from the Cephes mathematical library, developed by Stephen L. Moshier. It is used, among many other places, at the heart of SciPy. **[Deprecated]**\n  * [autograd](https://github.com/twitter/torch-autograd) - Autograd automatically differentiates native Torch code. Inspired by the original Python version.\n  * [graph](https://github.com/torch/graph) - Graph package for Torch. **[Deprecated]**\n  * [randomkit](https://github.com/deepmind/torch-randomkit) - Numpy\'s randomkit, wrapped for Torch. **[Deprecated]**\n  * [signal](https://github.com/soumith/torch-signal) - A signal processing toolbox for Torch-7. FFT, DCT, Hilbert, cepstrums, stft.\n  * [nn](https://github.com/torch/nn) - Neural Network package for Torch.\n  * [torchnet](https://github.com/torchnet/torchnet) - framework for torch which provides a set of abstractions aiming at encouraging code re-use as well as encouraging modular programming.\n  * [nngraph](https://github.com/torch/nngraph) - This package provides graphical computation for nn library in Torch7.\n  * [nnx](https://github.com/clementfarabet/lua---nnx) - A completely unstable and experimental package that extends Torch\'s builtin nn library.\n  * [rnn](https://github.com/Element-Research/rnn) - A Recurrent Neural Network library that extends Torch\'s nn. RNNs, LSTMs, GRUs, BRNNs, BLSTMs, etc.\n  * [dpnn](https://github.com/Element-Research/dpnn) - Many useful features that aren\'t part of the main nn package.\n  * [dp](https://github.com/nicholas-leonard/dp) - A deep learning library designed for streamlining research and development using the Torch7 distribution. It emphasizes flexibility through the elegant use of object-oriented design patterns. **[Deprecated]**\n  * [optim](https://github.com/torch/optim) - An optimization library for Torch. SGD, Adagrad, Conjugate-Gradient, LBFGS, RProp and more.\n  * [unsup](https://github.com/koraykv/unsup) - A package for unsupervised learning in Torch. Provides modules that are compatible with nn (LinearPsd, ConvPsd, AutoEncoder, ...), and self-contained algorithms (k-means, PCA). **[Deprecated]**\n  * [manifold](https://github.com/clementfarabet/manifold) - A package to manipulate manifolds.\n  * [svm](https://github.com/koraykv/torch-svm) - Torch-SVM library. **[Deprecated]**\n  * [lbfgs](https://github.com/clementfarabet/lbfgs) - FFI Wrapper for liblbfgs. **[Deprecated]**\n  * [vowpalwabbit](https://github.com/clementfarabet/vowpal_wabbit) - An old vowpalwabbit interface to torch. **[Deprecated]**\n  * [OpenGM](https://github.com/clementfarabet/lua---opengm) - OpenGM is a C++ library for graphical modeling, and inference. The Lua bindings provide a simple way of describing graphs, from Lua, and then optimizing them with OpenGM. **[Deprecated]**\n  * [spaghetti](https://github.com/MichaelMathieu/lua---spaghetti) - Spaghetti (sparse linear) module for torch7 by @MichaelMathieu **[Deprecated]**\n  * [LuaSHKit](https://github.com/ocallaco/LuaSHkit) - A lua wrapper around the Locality sensitive hashing library SHKit **[Deprecated]**\n  * [kernel smoothing](https://github.com/rlowrance/kernel-smoothers) - KNN, kernel-weighted average, local linear regression smoothers. **[Deprecated]**\n  * [cutorch](https://github.com/torch/cutorch) - Torch CUDA Implementation.\n  * [cunn](https://github.com/torch/cunn) - Torch CUDA Neural Network Implementation.\n  * [imgraph](https://github.com/clementfarabet/lua---imgraph) - An image/graph library for Torch. This package provides routines to construct graphs on images, segment them, build trees out of them, and convert them back to images. **[Deprecated]**\n  * [videograph](https://github.com/clementfarabet/videograph) - A video/graph library for Torch. This package provides routines to construct graphs on videos, segment them, build trees out of them, and convert them back to videos. **[Deprecated]**\n  * [saliency](https://github.com/marcoscoffier/torch-saliency) - code and tools around integral images. A library for finding interest points based on fast integral histograms. **[Deprecated]**\n  * [stitch](https://github.com/marcoscoffier/lua---stitch) - allows us to use hugin to stitch images and apply same stitching to a video sequence. **[Deprecated]**\n  * [sfm](https://github.com/marcoscoffier/lua---sfm) - A bundle adjustment/structure from motion package. **[Deprecated]**\n  * [fex](https://github.com/koraykv/fex) - A package for feature extraction in Torch. Provides SIFT and dSIFT modules. **[Deprecated]**\n  * [OverFeat](https://github.com/sermanet/OverFeat) - A state-of-the-art generic dense feature extractor. **[Deprecated]**\n  * [wav2letter](https://github.com/facebookresearch/wav2letter) - a simple and efficient end-to-end Automatic Speech Recognition (ASR) system from Facebook AI Research.\n* [Numeric Lua](http://numlua.luaforge.net/)\n* [Lunatic Python](https://labix.org/lunatic-python)\n* [SciLua](http://scilua.org/)\n* [Lua - Numerical Algorithms](https://bitbucket.org/lucashnegri/lna) **[Deprecated]**\n* [Lunum](https://github.com/jzrake/lunum) **[Deprecated]**\n\n<a name=""lua-demos""></a>\n#### Demos and Scripts\n* [Core torch7 demos repository](https://github.com/e-lab/torch7-demos).\n  * linear-regression, logistic-regression\n  * face detector (training and detection as separate demos)\n  * mst-based-segmenter\n  * train-a-digit-classifier\n  * train-autoencoder\n  * optical flow demo\n  * train-on-housenumbers\n  * train-on-cifar\n  * tracking with deep nets\n  * kinect demo\n  * filter-bank visualization\n  * saliency-networks\n* [Training a Convnet for the Galaxy-Zoo Kaggle challenge(CUDA demo)](https://github.com/soumith/galaxyzoo)\n* [Music Tagging](https://github.com/mbhenaff/MusicTagging) - Music Tagging scripts for torch7.\n* [torch-datasets](https://github.com/rosejn/torch-datasets) - Scripts to load several popular datasets including:\n  * BSR 500\n  * CIFAR-10\n  * COIL\n  * Street View House Numbers\n  * MNIST\n  * NORB\n* [Atari2600](https://github.com/fidlej/aledataset) - Scripts to generate a dataset with static frames from the Arcade Learning Environment.\n\n\n\n<a name=""matlab""></a>\n## Matlab\n\n<a name=""matlab-cv""></a>\n#### Computer Vision\n\n* [Contourlets](http://www.ifp.illinois.edu/~minhdo/software/contourlet_toolbox.tar) - MATLAB source code that implements the contourlet transform and its utility functions.\n* [Shearlets](https://www3.math.tu-berlin.de/numerik/www.shearlab.org/software) - MATLAB code for shearlet transform.\n* [Curvelets](http://www.curvelet.org/software.html) - The Curvelet transform is a higher dimensional generalization of the Wavelet transform designed to represent images at different scales and different angles.\n* [Bandlets](http://www.cmap.polytechnique.fr/~peyre/download/) - MATLAB code for bandlet transform.\n* [mexopencv](https://kyamagu.github.io/mexopencv/) - Collection and a development kit of MATLAB mex functions for OpenCV library.\n\n<a name=""matlab-nlp""></a>\n#### Natural Language Processing\n\n* [NLP](https://amplab.cs.berkeley.edu/an-nlp-library-for-matlab/) - An NLP library for Matlab.\n\n<a name=""matlab-general-purpose""></a>\n#### General-Purpose Machine Learning\n\n* [Training a deep autoencoder or a classifier\non MNIST digits](https://www.cs.toronto.edu/~hinton/MatlabForSciencePaper.html) - Training a deep autoencoder or a classifier\non MNIST digits[DEEP LEARNING].\n* [Convolutional-Recursive Deep Learning for 3D Object Classification](https://www.socher.org/index.php/Main/Convolutional-RecursiveDeepLearningFor3DObjectClassification) - Convolutional-Recursive Deep Learning for 3D Object Classification[DEEP LEARNING].\n* [Spider](https://people.kyb.tuebingen.mpg.de/spider/) - The spider is intended to be a complete object orientated environment for machine learning in Matlab.\n* [LibSVM](https://www.csie.ntu.edu.tw/~cjlin/libsvm/#matlab) - A Library for Support Vector Machines.\n* [ThunderSVM](https://github.com/Xtra-Computing/thundersvm) - An Open-Source SVM Library on GPUs and CPUs\n* [LibLinear](https://www.csie.ntu.edu.tw/~cjlin/liblinear/#download) - A Library for Large Linear Classification.\n* [Machine Learning Module](https://github.com/josephmisiti/machine-learning-module) - Class on machine w/ PDF, lectures, code\n* [Caffe](https://github.com/BVLC/caffe) - A deep learning framework developed with cleanliness, readability, and speed in mind.\n* [Pattern Recognition Toolbox](https://github.com/covartech/PRT) - A complete object-oriented environment for machine learning in Matlab.\n* [Pattern Recognition and Machine Learning](https://github.com/PRML/PRMLT) - This package contains the matlab implementation of the algorithms described in the book Pattern Recognition and Machine Learning by C. Bishop.\n* [Optunity](https://optunity.readthedocs.io/en/latest/) - A library dedicated to automated hyperparameter optimization with a simple, lightweight API to facilitate drop-in replacement of grid search. Optunity is written in Python but interfaces seamlessly with MATLAB.\n* [MXNet](https://github.com/apache/incubator-mxnet/) - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more.\n* [Machine Learning in MatLab/Octave](https://github.com/trekhleb/machine-learning-octave) - examples of popular machine learning algorithms (neural networks, linear/logistic regressions, K-Means, etc.) with code examples and mathematics behind them being explained.\n\n\n<a name=""matlab-data-analysis""></a>\n#### Data Analysis / Data Visualization\n\n* [matlab_bgl](https://www.cs.purdue.edu/homes/dgleich/packages/matlab_bgl/) - MatlabBGL is a Matlab package for working with graphs.\n* [gaimc](https://www.mathworks.com/matlabcentral/fileexchange/24134-gaimc---graph-algorithms-in-matlab-code) - Efficient pure-Matlab implementations of graph algorithms to complement MatlabBGL\'s mex functions.\n\n<a name=""net""></a>\n## .NET\n\n<a name=""net-cv""></a>\n#### Computer Vision\n\n* [OpenCVDotNet](https://code.google.com/archive/p/opencvdotnet) - A wrapper for the OpenCV project to be used with .NET applications.\n* [Emgu CV](http://www.emgu.com/wiki/index.php/Main_Page) - Cross platform wrapper of OpenCV which can be compiled in Mono to be run on Windows, Linus, Mac OS X, iOS, and Android.\n* [AForge.NET](http://www.aforgenet.com/framework/) - Open source C# framework for developers and researchers in the fields of Computer Vision and Artificial Intelligence. Development has now shifted to GitHub.\n* [Accord.NET](http://accord-framework.net) - Together with AForge.NET, this library can provide image processing and computer vision algorithms to Windows, Windows RT and Windows Phone. Some components are also available for Java and Android.\n\n<a name=""net-nlp""></a>\n#### Natural Language Processing\n\n* [Stanford.NLP for .NET](https://github.com/sergey-tihon/Stanford.NLP.NET/) - A full port of Stanford NLP packages to .NET and also available precompiled as a NuGet package.\n\n<a name=""net-general-purpose""></a>\n#### General-Purpose Machine Learning\n\n* [Accord-Framework](http://accord-framework.net/) -The Accord.NET Framework is a complete framework for building machine learning, computer vision, computer audition, signal processing and statistical applications.\n* [Accord.MachineLearning](https://www.nuget.org/packages/Accord.MachineLearning/) - Support Vector Machines, Decision Trees, Naive Bayesian models, K-means, Gaussian Mixture models and general algorithms such as Ransac, Cross-validation and Grid-Search for machine-learning applications. This package is part of the Accord.NET Framework.\n* [DiffSharp](https://diffsharp.github.io/DiffSharp/) - An automatic differentiation (AD) library providing exact and efficient derivatives (gradients, Hessians, Jacobians, directional derivatives, and matrix-free Hessian- and Jacobian-vector products) for machine learning and optimization applications. Operations can be nested to any level, meaning that you can compute exact higher-order derivatives and differentiate functions that are internally making use of differentiation, for applications such as hyperparameter optimization.\n* [Encog](https://www.nuget.org/packages/encog-dotnet-core/) - An advanced neural network and machine learning framework. Encog contains classes to create a wide variety of networks, as well as support classes to normalize and process data for these neural networks. Encog trains using multithreaded resilient propagation. Encog can also make use of a GPU to further speed processing time. A GUI based workbench is also provided to help model and train neural networks.\n* [GeneticSharp](https://github.com/giacomelli/GeneticSharp) - Multi-platform genetic algorithm library for .NET Core and .NET Framework. The library has several implementations of GA operators, like: selection, crossover, mutation, reinsertion and termination.\n* [Infer.NET](https://dotnet.github.io/infer/) - Infer.NET is a framework for running Bayesian inference in graphical models. One can use Infer.NET to solve many different kinds of machine learning problems, from standard problems like classification, recommendation or clustering through to customised solutions to domain-specific problems. Infer.NET has been used in a wide variety of domains including information retrieval, bioinformatics, epidemiology, vision, and many others.\n* [ML.NET](https://github.com/dotnet/machinelearning) - ML.NET is a cross-platform open-source machine learning framework which makes machine learning accessible to .NET developers. ML.NET was originally developed in Microsoft Research and evolved into a significant framework over the last decade and is used across many product groups in Microsoft like Windows, Bing, PowerPoint, Excel and more.\n* [Neural Network Designer](https://sourceforge.net/projects/nnd/) - DBMS management system and designer for neural networks. The designer application is developed using WPF, and is a user interface which allows you to design your neural network, query the network, create and configure chat bots that are capable of asking questions and learning from your feed back. The chat bots can even scrape the internet for information to return in their output as well as to use for learning.\n* [Synapses](https://github.com/mrdimosthenis/Synapses) - Neural network library in F#.\n* [Vulpes](https://github.com/fsprojects/Vulpes) - Deep belief and deep learning implementation written in F# and leverages CUDA GPU execution with Alea.cuBase.\n* [MxNet.Sharp](https://github.com/tech-quantum/MxNet.Sharp) - .NET Standard bindings for Apache MxNet with Imperative, Symbolic and Gluon Interface for developing, training and deploying Machine Learning models in C#. https://mxnet.tech-quantum.com/\n\n<a name=""net-data-analysis""></a>\n#### Data Analysis / Data Visualization\n\n* [numl](https://www.nuget.org/packages/numl/) - numl is a machine learning library intended to ease the use of using standard modeling techniques for both prediction and clustering.\n* [Math.NET Numerics](https://www.nuget.org/packages/MathNet.Numerics/) - Numerical foundation of the Math.NET project, aiming to provide methods and algorithms for numerical computations in science, engineering and every day use. Supports .Net 4.0, .Net 3.5 and Mono on Windows, Linux and Mac; Silverlight 5, WindowsPhone/SL 8, WindowsPhone 8.1 and Windows 8 with PCL Portable Profiles 47 and 344; Android/iOS with Xamarin.\n* [Sho](https://www.microsoft.com/en-us/research/project/sho-the-net-playground-for-data/) - Sho is an interactive environment for data analysis and scientific computing that lets you seamlessly connect scripts (in IronPython) with compiled code (in .NET) to enable fast and flexible prototyping. The environment includes powerful and efficient libraries for linear algebra as well as data visualization that can be used from any .NET language, as well as a feature-rich interactive shell for rapid development.\n\n<a name=""objectivec""></a>\n## Objective C\n\n<a name=""objectivec-general-purpose""></a>\n### General-Purpose Machine Learning\n\n* [YCML](https://github.com/yconst/YCML) - A Machine Learning framework for Objective-C and Swift (OS X / iOS).\n* [MLPNeuralNet](https://github.com/nikolaypavlov/MLPNeuralNet) - Fast multilayer perceptron neural network library for iOS and Mac OS X. MLPNeuralNet predicts new examples by trained neural network. It is built on top of the Apple\'s Accelerate Framework, using vectorized operations and hardware acceleration if available. **[Deprecated]**\n* [MAChineLearning](https://github.com/gianlucabertani/MAChineLearning) - An Objective-C multilayer perceptron library, with full support for training through backpropagation. Implemented using vDSP and vecLib, it\'s 20 times faster than its Java equivalent. Includes sample code for use from Swift.\n* [BPN-NeuralNetwork](https://github.com/Kalvar/ios-BPN-NeuralNetwork) - It implemented 3 layers neural network ( Input Layer, Hidden Layer and Output Layer ) and it named Back Propagation Neural Network (BPN). This network can be used in products recommendation, user behavior analysis, data mining and data analysis. **[Deprecated]**\n* [Multi-Perceptron-NeuralNetwork](https://github.com/Kalvar/ios-Multi-Perceptron-NeuralNetwork) - it implemented multi-perceptrons neural network (\xe3\x83\x8b\xe3\x83\xa5\xe3\x83\xbc\xe3\x83\xa9\xe3\x83\xab\xe3\x83\x8d\xe3\x83\x83\xe3\x83\x88\xe3\x83\xaf\xe3\x83\xbc\xe3\x82\xaf) based on Back Propagation Neural Network (BPN) and designed unlimited-hidden-layers.\n* [KRHebbian-Algorithm](https://github.com/Kalvar/ios-KRHebbian-Algorithm) - It is a non-supervisor and self-learning algorithm (adjust the weights) in neural network of Machine Learning. **[Deprecated]**\n* [KRKmeans-Algorithm](https://github.com/Kalvar/ios-KRKmeans-Algorithm) - It implemented K-Means the clustering and classification algorithm. It could be used in data mining and image compression. **[Deprecated]**\n* [KRFuzzyCMeans-Algorithm](https://github.com/Kalvar/ios-KRFuzzyCMeans-Algorithm) - It implemented Fuzzy C-Means (FCM) the fuzzy clustering / classification algorithm on Machine Learning. It could be used in data mining and image compression. **[Deprecated]**\n\n<a name=""ocaml""></a>\n## OCaml\n\n<a name=""ocaml-general-purpose""></a>\n### General-Purpose Machine Learning\n\n* [Oml](https://github.com/rleonid/oml) - A general statistics and machine learning library.\n* [GPR](https://mmottl.github.io/gpr/) - Efficient Gaussian Process Regression in OCaml.\n* [Libra-Tk](https://libra.cs.uoregon.edu) - Algorithms for learning and inference with discrete probabilistic models.\n* [TensorFlow](https://github.com/LaurentMazare/tensorflow-ocaml) - OCaml bindings for TensorFlow.\n\n<a name=""perl""></a>\n## Perl\n\n<a name=""perl-data""></a>\n### Data Analysis / Data Visualization\n\n* [Perl Data Language](https://metacpan.org/pod/Paws::MachineLearning), a pluggable architecture for data and image processing, which can\nbe [used for machine learning](https://github.com/zenogantner/PDL-ML).\n\n<a name=""perl-ml""></a>\n### General-Purpose Machine Learning\n\n* [MXnet for Deep Learning, in Perl](https://github.com/apache/incubator-mxnet/tree/master/perl-package),\nalso [released in CPAN](https://metacpan.org/pod/AI::MXNet).\n* [Perl Data Language](https://metacpan.org/pod/Paws::MachineLearning),\nusing AWS machine learning platform from Perl.\n* [Algorithm::SVMLight](https://metacpan.org/pod/Algorithm::SVMLight),\n  implementation of Support Vector Machines with SVMLight under it. **[Deprecated]**\n* Several machine learning and artificial intelligence models are\n  included in the [`AI`](https://metacpan.org/search?size=20&q=AI)\n  namespace. For instance, you can\n  find [Na\xc3\xafve Bayes](https://metacpan.org/pod/AI::NaiveBayes).\n\n<a name=""perl6""></a>\n## Perl 6\n\n* [Support Vector Machines](https://github.com/titsuki/p6-Algorithm-LibSVM)\n* [Na\xc3\xafve Bayes](https://github.com/titsuki/p6-Algorithm-NaiveBayes)\n\n### Data Analysis / Data Visualization\n\n* [Perl Data Language](https://metacpan.org/pod/Paws::MachineLearning),\na pluggable architecture for data and image processing, which can\nbe\n[used for machine learning](https://github.com/zenogantner/PDL-ML).\n\n### General-Purpose Machine Learning\n\n<a name=""php""></a>\n## PHP\n\n<a name=""php-nlp""></a>\n### Natural Language Processing\n\n* [jieba-php](https://github.com/fukuball/jieba-php) - Chinese Words Segmentation Utilities.\n\n<a name=""php-general-purpose""></a>\n### General-Purpose Machine Learning\n\n* [PHP-ML](https://github.com/php-ai/php-ml) - Machine Learning library for PHP. Algorithms, Cross Validation, Neural Network, Preprocessing, Feature Extraction and much more in one library.\n* [PredictionBuilder](https://github.com/denissimon/prediction-builder) - A library for machine learning that builds predictions using a linear regression.\n* [Rubix ML](https://github.com/RubixML) - A high-level machine learning (ML) library that lets you build programs that learn from data using the PHP language.\n* [19 Questions](https://github.com/fulldecent/19-questions) - A machine learning / bayesian inference assigning attributes to objects.\n\n<a name=""python""></a>\n## Python\n\n<a name=""python-cv""></a>\n#### Computer Vision\n\n* [Scikit-Image](https://github.com/scikit-image/scikit-image) - A collection of algorithms for image processing in Python.\n* [SimpleCV](http://simplecv.org/) - An open source computer vision framework that gives access to several high-powered computer vision libraries, such as OpenCV. Written on Python and runs on Mac, Windows, and Ubuntu Linux.\n* [Vigranumpy](https://github.com/ukoethe/vigra) - Python bindings for the VIGRA C++ computer vision library.\n* [OpenFace](https://cmusatyalab.github.io/openface/) - Free and open source face recognition with deep neural networks.\n* [PCV](https://github.com/jesolem/PCV) - Open source Python module for computer vision. **[Deprecated]**\n* [face_recognition](https://github.com/ageitgey/face_recognition) - Face recognition library that recognize and manipulate faces from Python or from the command line.\n* [dockerface](https://github.com/natanielruiz/dockerface) - Easy to install and use deep learning Faster R-CNN face detection for images and video in a docker container.\n* [Detectron](https://github.com/facebookresearch/Detectron) - FAIR\'s software system that implements state-of-the-art object detection algorithms, including Mask R-CNN. It is written in Python and powered by the Caffe2 deep learning framework. **[Deprecated]**\n* [detectron2](https://github.com/facebookresearch/detectron2) - FAIR\'s next-generation research platform for object detection and segmentation. It is a ground-up rewrite of the previous version, Detectron, and is powered by the PyTorch deep learning framework. \n* [albumentations](https://github.com/albu/albumentations) - \xd0\x90 fast and framework agnostic image augmentation library that implements a diverse set of augmentation techniques. Supports classification, segmentation, detection out of the box. Was used to win a number of Deep Learning competitions at Kaggle, Topcoder and those that were a part of the CVPR workshops.\n* [pytessarct](https://github.com/madmaze/pytesseract) - Python-tesseract is an optical character recognition (OCR) tool for python. That is, it will recognize and ""read"" the text embedded in images.Python-tesseract is a wrapper for [Google\'s Tesseract-OCR Engine](https://github.com/tesseract-ocr/tesseract)>.\n* [imutils](https://github.com/jrosebr1/imutils) - A library containg Convenience functions to make basic image processing operations such as translation, rotation, resizing, skeletonization, and displaying Matplotlib images easier with OpenCV and Python.\n* [PyTorchCV](https://github.com/donnyyou/PyTorchCV) - A PyTorch-Based Framework for Deep Learning in Computer Vision.\n* [neural-style-pt](https://github.com/ProGamerGov/neural-style-pt) - A PyTorch implementation of Justin Johnson\'s neural-style (neural style transfer).\n* [Detecto](https://github.com/alankbi/detecto) - Train and run a computer vision model with 5-10 lines of code.\n* [neural-dream](https://github.com/ProGamerGov/neural-dream) - A PyTorch implementation of DeepDream.\n* [Openpose](https://github.com/CMU-Perceptual-Computing-Lab/openpose) - A real-time multi-person keypoint detection library for body, face, hands, and foot estimation\n* [Deep High-Resolution-Net](https://github.com/leoxiaobin/deep-high-resolution-net.pytorch) - A Pytorch implementation of CVPR2019 paper ""Deep High-Resolution Representation Learning for Human Pose Estimation""\n\n<a name=""python-nlp""></a>\n#### Natural Language Processing\n\n* [pkuseg-python](https://github.com/lancopku/pkuseg-python) - A better version of Jieba, developed by Peking University.\n* [NLTK](https://www.nltk.org/) - A leading platform for building Python programs to work with human language data.\n* [Pattern](http://www.clips.ua.ac.be/pattern) - A web mining module for the Python programming language. It has tools for natural language processing, machine learning, among others.\n* [Quepy](https://github.com/machinalis/quepy) - A python framework to transform natural language questions to queries in a database query language.\n* [TextBlob](http://textblob.readthedocs.io/en/dev/) - Providing a consistent API for diving into common natural language processing (NLP) tasks. Stands on the giant shoulders of NLTK and Pattern, and plays nicely with both.\n* [YAlign](https://github.com/machinalis/yalign) - A sentence aligner, a friendly tool for extracting parallel sentences from comparable corpora. **[Deprecated]**\n* [jieba](https://github.com/fxsjy/jieba#jieba-1) - Chinese Words Segmentation Utilities.\n* [SnowNLP](https://github.com/isnowfy/snownlp) - A library for processing Chinese text.\n* [spammy](https://github.com/tasdikrahman/spammy) - A library for email Spam filtering built on top of nltk\n* [loso](https://github.com/fangpenlin/loso) - Another Chinese segmentation library. **[Deprecated]**\n* [genius](https://github.com/duanhongyi/genius) - A Chinese segment base on Conditional Random Field.\n* [KoNLPy](http://konlpy.org) - A Python package for Korean natural language processing.\n* [nut](https://github.com/pprett/nut) - Natural language Understanding Toolkit. **[Deprecated]**\n* [Rosetta](https://github.com/columbia-applied-data-science/rosetta) - Text processing tools and wrappers (e.g. Vowpal Wabbit)\n* [BLLIP Parser](https://pypi.org/project/bllipparser/) - Python bindings for the BLLIP Natural Language Parser (also known as the Charniak-Johnson parser). **[Deprecated]**\n* [PyNLPl](https://github.com/proycon/pynlpl) - Python Natural Language Processing Library. General purpose NLP library for Python. Also contains some specific modules for parsing common NLP formats, most notably for [FoLiA](https://proycon.github.io/folia/), but also ARPA language models, Moses phrasetables, GIZA++ alignments.\n* [PySS3](https://github.com/sergioburdisso/pyss3) - Python package that implements a novel white-box machine learning model for text classification, called SS3. Since SS3 has the ability to visually explain its rationale, this package also comes with easy-to-use interactive visualizations tools ([online demos](http://tworld.io/ss3/)).\n* [python-ucto](https://github.com/proycon/python-ucto) - Python binding to ucto (a unicode-aware rule-based tokenizer for various languages).\n* [python-frog](https://github.com/proycon/python-frog) - Python binding to Frog, an NLP suite for Dutch. (pos tagging, lemmatisation, dependency parsing, NER)\n* [python-zpar](https://github.com/EducationalTestingService/python-zpar) - Python bindings for [ZPar](https://github.com/frcchang/zpar), a statistical part-of-speech-tagger, constiuency parser, and dependency parser for English.\n* [colibri-core](https://github.com/proycon/colibri-core) - Python binding to C++ library for extracting and working with with basic linguistic constructions such as n-grams and skipgrams in a quick and memory-efficient way.\n* [spaCy](https://github.com/explosion/spaCy) - Industrial strength NLP with Python and Cython.\n* [PyStanfordDependencies](https://github.com/dmcc/PyStanfordDependencies) - Python interface for converting Penn Treebank trees to Stanford Dependencies.\n* [Distance](https://github.com/doukremt/distance) - Levenshtein and Hamming distance computation. **[Deprecated]**\n* [Fuzzy Wuzzy](https://github.com/seatgeek/fuzzywuzzy) - Fuzzy String Matching in Python.\n* [jellyfish](https://github.com/jamesturk/jellyfish) - a python library for doing approximate and phonetic matching of strings.\n* [editdistance](https://pypi.org/project/editdistance/) - fast implementation of edit distance.\n* [textacy](https://github.com/chartbeat-labs/textacy) - higher-level NLP built on Spacy.\n* [stanford-corenlp-python](https://github.com/dasmith/stanford-corenlp-python) - Python wrapper for [Stanford CoreNLP](https://github.com/stanfordnlp/CoreNLP) **[Deprecated]**\n* [CLTK](https://github.com/cltk/cltk) - The Classical Language Toolkit.\n* [rasa_nlu](https://github.com/RasaHQ/rasa_nlu) - turn natural language into structured data.\n* [yase](https://github.com/PPACI/yase) - Transcode sentence (or other sequence) to list of word vector .\n* [Polyglot](https://github.com/aboSamoor/polyglot) - Multilingual text (NLP) processing toolkit.\n* [DrQA](https://github.com/facebookresearch/DrQA) - Reading Wikipedia to answer open-domain questions.\n* [Dedupe](https://github.com/dedupeio/dedupe) - A python library for accurate and scalable fuzzy matching, record deduplication and entity-resolution.\n* [Snips NLU](https://github.com/snipsco/snips-nlu) - Natural Language Understanding library for intent classification and entity extraction\n* [NeuroNER](https://github.com/Franck-Dernoncourt/NeuroNER) - Named-entity recognition using neural networks providing state-of-the-art-results\n* [DeepPavlov](https://github.com/deepmipt/DeepPavlov/) - conversational AI library with many pretrained Russian NLP models.\n* [BigARTM](https://github.com/bigartm/bigartm) - topic modelling platform.\n\n<a name=""python-general-purpose""></a>\n#### General-Purpose Machine Learning\n * [Little Ball of Fur](https://github.com/benedekrozemberczki/littleballoffur) -> A graph sampling extension library for NetworkX with a Scikit-Learn like API.\n * [Karate Club](https://github.com/benedekrozemberczki/karateclub) -> An unsupervised machine learning extension library for NetworkX with a Scikit-Learn like API.\n* [Auto_ViML](https://github.com/AutoViML/Auto_ViML) -> Automatically Build Variant Interpretable ML models fast! Auto_ViML is pronounced ""auto vimal"", is a comprehensive and scalable Python AutoML toolkit with imbalanced handling, ensembling, stacking and built-in feature selection. Featured in <a href=""https://towardsdatascience.com/why-automl-is-an-essential-new-tool-for-data-scientists-2d9ab4e25e46?source=friends_link&sk=d03a0cc55c23deb497d546d6b9be0653"">Medium article</a>.\n* [PyOD](https://github.com/yzhao062/pyod) -> Python Outlier Detection, comprehensive and scalable Python toolkit for detecting outlying objects in multivariate data. Featured for Advanced models, including Neural Networks/Deep Learning and Outlier Ensembles.\n* [steppy](https://github.com/neptune-ml/steppy) -> Lightweight, Python library for fast and reproducible machine learning experimentation. Introduces very simple interface that enables clean machine learning pipeline design.\n* [steppy-toolkit](https://github.com/neptune-ml/steppy-toolkit) -> Curated collection of the neural networks, transformers and models that make your machine learning work faster and more effective.\n* [CNTK](https://github.com/Microsoft/CNTK) - Microsoft Cognitive Toolkit (CNTK), an open source deep-learning toolkit. Documentation can be found [here](https://docs.microsoft.com/cognitive-toolkit/).\n* [auto_ml](https://github.com/ClimbsRocks/auto_ml) - Automated machine learning for production and analytics. Lets you focus on the fun parts of ML, while outputting production-ready code, and detailed analytics of your dataset and results. Includes support for NLP, XGBoost, CatBoost, LightGBM, and soon, deep learning.\n* [machine learning](https://github.com/jeff1evesque/machine-learning) - automated build consisting of a [web-interface](https://github.com/jeff1evesque/machine-learning#web-interface), and set of [programmatic-interface](https://github.com/jeff1evesque/machine-learning#programmatic-interface) API, for support vector machines. Corresponding dataset(s) are stored into a SQL database, then generated model(s) used for prediction(s), are stored into a NoSQL datastore.\n* [XGBoost](https://github.com/dmlc/xgboost) - Python bindings for eXtreme Gradient Boosting (Tree) Library.\n* [Apache SINGA](https://singa.apache.org) - An Apache Incubating project for developing an open source machine learning library.\n* [Bayesian Methods for Hackers](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers) - Book/iPython notebooks on Probabilistic Programming in Python.\n* [Featureforge](https://github.com/machinalis/featureforge) A set of tools for creating and testing machine learning features, with a scikit-learn compatible API.\n* [MLlib in Apache Spark](http://spark.apache.org/docs/latest/mllib-guide.html) - Distributed machine learning library in Spark\n* [Hydrosphere Mist](https://github.com/Hydrospheredata/mist) - a service for deployment Apache Spark MLLib machine learning models as realtime, batch or reactive web services.\n* [scikit-learn](https://scikit-learn.org/) - A Python module for machine learning built on top of SciPy.\n* [metric-learn](https://github.com/metric-learn/metric-learn) - A Python module for metric learning.\n* [SimpleAI](https://github.com/simpleai-team/simpleai) Python implementation of many of the artificial intelligence algorithms described on the book ""Artificial Intelligence, a Modern Approach"". It focuses on providing an easy to use, well documented and tested library.\n* [astroML](https://www.astroml.org/) - Machine Learning and Data Mining for Astronomy.\n* [graphlab-create](https://turi.com/products/create/docs/) - A library with various machine learning models (regression, clustering, recommender systems, graph analytics, etc.) implemented on top of a disk-backed DataFrame.\n* [BigML](https://bigml.com) - A library that contacts external servers.\n* [pattern](https://github.com/clips/pattern) - Web mining module for Python.\n* [NuPIC](https://github.com/numenta/nupic) - Numenta Platform for Intelligent Computing.\n* [Pylearn2](https://github.com/lisa-lab/pylearn2) - A Machine Learning library based on [Theano](https://github.com/Theano/Theano). **[Deprecated]**\n* [keras](https://github.com/keras-team/keras) - High-level neural networks frontend for [TensorFlow](https://github.com/tensorflow/tensorflow), [CNTK](https://github.com/Microsoft/CNTK) and [Theano](https://github.com/Theano/Theano).\n* [Lasagne](https://github.com/Lasagne/Lasagne) - Lightweight library to build and train neural networks in Theano.\n* [hebel](https://github.com/hannes-brt/hebel) - GPU-Accelerated Deep Learning Library in Python. **[Deprecated]**\n* [Chainer](https://github.com/chainer/chainer) - Flexible neural network framework.\n* [prophet](https://facebook.github.io/prophet/) - Fast and automated time series forecasting framework by Facebook.\n* [gensim](https://github.com/RaRe-Technologies/gensim) - Topic Modelling for Humans.\n* [topik](https://github.com/ContinuumIO/topik) - Topic modelling toolkit. **[Deprecated]**\n* [PyBrain](https://github.com/pybrain/pybrain) - Another Python Machine Learning Library.\n* [Brainstorm](https://github.com/IDSIA/brainstorm) - Fast, flexible and fun neural networks. This is the successor of PyBrain.\n* [Surprise](https://surpriselib.com) - A scikit for building and analyzing recommender systems.\n* [implicit](https://implicit.readthedocs.io/en/latest/quickstart.html) - Fast Python Collaborative Filtering for Implicit Datasets.\n* [LightFM](https://making.lyst.com/lightfm/docs/home.html) -  A Python implementation of a number of popular recommendation algorithms for both implicit and explicit feedback.\n* [Crab](https://github.com/muricoca/crab) - A flexible, fast recommender engine. **[Deprecated]**\n* [python-recsys](https://github.com/ocelma/python-recsys) - A Python library for implementing a Recommender System.\n* [thinking bayes](https://github.com/AllenDowney/ThinkBayes) - Book on Bayesian Analysis.\n* [Image-to-Image Translation with Conditional Adversarial Networks](https://github.com/williamFalcon/pix2pix-keras) - Implementation of image to image (pix2pix) translation from the paper by [isola et al](https://arxiv.org/pdf/1611.07004.pdf).[DEEP LEARNING]\n* [Restricted Boltzmann Machines](https://github.com/echen/restricted-boltzmann-machines) -Restricted Boltzmann Machines in Python. [DEEP LEARNING]\n* [Bolt](https://github.com/pprett/bolt) - Bolt Online Learning Toolbox. **[Deprecated]**\n* [CoverTree](https://github.com/patvarilly/CoverTree) - Python implementation of cover trees, near-drop-in replacement for scipy.spatial.kdtree **[Deprecated]**\n* [nilearn](https://github.com/nilearn/nilearn) - Machine learning for NeuroImaging in Python.\n* [neuropredict](https://github.com/raamana/neuropredict) - Aimed at novice machine learners and non-expert programmers, this package offers easy (no coding needed) and comprehensive machine learning (evaluation and full report of predictive performance WITHOUT requiring you to code) in Python for NeuroImaging and any other type of features. This is aimed at absorbing the much of the ML workflow, unlike other packages like nilearn and pymvpa, which require you to learn their API and code to produce anything useful.\n* [imbalanced-learn](https://imbalanced-learn.org/en/stable/index.html) - Python module to perform under sampling and over sampling with various techniques.\n* [Shogun](https://github.com/shogun-toolbox/shogun) - The Shogun Machine Learning Toolbox.\n* [Pyevolve](https://github.com/perone/Pyevolve) - Genetic algorithm framework. **[Deprecated]**\n* [Caffe](https://github.com/BVLC/caffe) - A deep learning framework developed with cleanliness, readability, and speed in mind.\n* [breze](https://github.com/breze-no-salt/breze) - Theano based library for deep and recurrent neural networks. \n* [Cortex](https://github.com/cortexlabs/cortex) - Open source platform for deploying machine learning models in production.\n* [pyhsmm](https://github.com/mattjj/pyhsmm) - library for approximate unsupervised inference in Bayesian Hidden Markov Models (HMMs) and explicit-duration Hidden semi-Markov Models (HSMMs), focusing on the Bayesian Nonparametric extensions, the HDP-HMM and HDP-HSMM, mostly with weak-limit approximations.\n* [mrjob](https://pythonhosted.org/mrjob/) - A library to let Python program run on Hadoop.\n* [SKLL](https://github.com/EducationalTestingService/skll) - A wrapper around scikit-learn that makes it simpler to conduct experiments.\n* [neurolab](https://github.com/zueve/neurolab)\n* [Spearmint](https://github.com/HIPS/Spearmint) - Spearmint is a package to perform Bayesian optimization according to the algorithms outlined in the paper: Practical Bayesian Optimization of Machine Learning Algorithms. Jasper Snoek, Hugo Larochelle and Ryan P. Adams. Advances in Neural Information Processing Systems, 2012. **[Deprecated]**\n* [Pebl](https://github.com/abhik/pebl/) - Python Environment for Bayesian Learning. **[Deprecated]**\n* [Theano](https://github.com/Theano/Theano/) - Optimizing GPU-meta-programming code generating array oriented optimizing math compiler in Python.\n* [TensorFlow](https://github.com/tensorflow/tensorflow/) - Open source software library for numerical computation using data flow graphs.\n* [pomegranate](https://github.com/jmschrei/pomegranate) - Hidden Markov Models for Python, implemented in Cython for speed and efficiency.\n* [python-timbl](https://github.com/proycon/python-timbl) - A Python extension module wrapping the full TiMBL C++ programming interface. Timbl is an elaborate k-Nearest Neighbours machine learning toolkit.\n* [deap](https://github.com/deap/deap) - Evolutionary algorithm framework.\n* [pydeep](https://github.com/andersbll/deeppy) - Deep Learning In Python. **[Deprecated]**\n* [mlxtend](https://github.com/rasbt/mlxtend) - A library consisting of useful tools for data science and machine learning tasks.\n* [neon](https://github.com/NervanaSystems/neon) - Nervana\'s [high-performance](https://github.com/soumith/convnet-benchmarks) Python-based Deep Learning framework [DEEP LEARNING]. **[Deprecated]**\n* [Optunity](https://optunity.readthedocs.io/en/latest/) - A library dedicated to automated hyperparameter optimization with a simple, lightweight API to facilitate drop-in replacement of grid search.\n* [Neural Networks and Deep Learning](https://github.com/mnielsen/neural-networks-and-deep-learning) - Code samples for my book ""Neural Networks and Deep Learning"" [DEEP LEARNING].\n* [Annoy](https://github.com/spotify/annoy) - Approximate nearest neighbours implementation.\n* [TPOT](https://github.com/EpistasisLab/tpot) - Tool that automatically creates and optimizes machine learning pipelines using genetic programming. Consider it your personal data science assistant, automating a tedious part of machine learning.\n* [pgmpy](https://github.com/pgmpy/pgmpy) A python library for working with Probabilistic Graphical Models.\n* [DIGITS](https://github.com/NVIDIA/DIGITS) - The Deep Learning GPU Training System (DIGITS) is a web application for training deep learning models.\n* [Orange](https://orange.biolab.si/) - Open source data visualization and data analysis for novices and experts.\n* [MXNet](https://github.com/apache/incubator-mxnet) - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more.\n* [milk](https://github.com/luispedro/milk) - Machine learning toolkit focused on supervised classification. **[Deprecated]**\n* [TFLearn](https://github.com/tflearn/tflearn) - Deep learning library featuring a higher-level API for TensorFlow.\n* [REP](https://github.com/yandex/rep) - an IPython-based environment for conducting data-driven research in a consistent and reproducible way. REP is not trying to substitute scikit-learn, but extends it and provides better user experience. **[Deprecated]**\n* [rgf_python](https://github.com/RGF-team/rgf) - Python bindings for Regularized Greedy Forest (Tree) Library.\n* [skbayes](https://github.com/AmazaspShumik/sklearn-bayes) - Python package for Bayesian Machine Learning with scikit-learn API.\n* [fuku-ml](https://github.com/fukuball/fuku-ml) - Simple machine learning library, including Perceptron, Regression, Support Vector Machine, Decision Tree and more, it\'s easy to use and easy to learn for beginners.\n* [Xcessiv](https://github.com/reiinakano/xcessiv) - A web-based application for quick, scalable, and automated hyperparameter tuning and stacked ensembling.\n* [PyTorch](https://github.com/pytorch/pytorch) - Tensors and Dynamic neural networks in Python with strong GPU acceleration\n* [ML-From-Scratch](https://github.com/eriklindernoren/ML-From-Scratch) - Implementations of Machine Learning models from scratch in Python with a focus on transparency. Aims to showcase the nuts and bolts of ML in an accessible way.\n* [Edward](http://edwardlib.org/) - A library for probabilistic modeling, inference, and criticism. Built on top of TensorFlow.\n* [xRBM](https://github.com/omimo/xRBM) - A library for Restricted Boltzmann Machine (RBM) and its conditional variants in Tensorflow.\n* [CatBoost](https://github.com/catboost/catboost) - General purpose gradient boosting on decision trees library with categorical features support out of the box. It is easy to install, well documented and supports CPU and GPU (even multi-GPU) computation.\n* [stacked_generalization](https://github.com/fukatani/stacked_generalization) - Implementation of machine learning stacking technic as handy library in Python.\n* [modAL](https://github.com/modAL-python/modAL) - A modular active learning framework for Python, built on top of scikit-learn.\n* [Cogitare](https://github.com/cogitare-ai/cogitare): A Modern, Fast, and Modular Deep Learning and Machine Learning framework for Python.\n* [Parris](https://github.com/jgreenemi/Parris) - Parris, the automated infrastructure setup tool for machine learning algorithms.\n* [neonrvm](https://github.com/siavashserver/neonrvm) - neonrvm is an open source machine learning library based on RVM technique. It\'s written in C programming language and comes with Python programming language bindings.\n* [Turi Create](https://github.com/apple/turicreate) - Machine learning from Apple. Turi Create simplifies the development of custom machine learning models. You don\'t have to be a machine learning expert to add recommendations, object detection, image classification, image similarity or activity classification to your app.\n* [xLearn](https://github.com/aksnzhy/xlearn) - A high performance, easy-to-use, and scalable machine learning package, which can be used to solve large-scale machine learning problems. xLearn is especially useful for solving machine learning problems on large-scale sparse data, which is very common in Internet services such as online advertisement and recommender systems.\n* [mlens](https://github.com/flennerhag/mlens) - A high performance, memory efficient, maximally parallelized ensemble learning, integrated with scikit-learn.\n* [Netron](https://github.com/lutzroeder/netron) - Visualizer for machine learning models.\n* [Thampi](https://github.com/scoremedia/thampi) - Machine Learning Prediction System on AWS Lambda\n* [MindsDB](https://github.com/mindsdb/mindsdb) - Open Source framework to streamline use of neural networks.\n* [Microsoft Recommenders](https://github.com/Microsoft/Recommenders): Examples and best practices for building recommendation systems, provided as Jupyter notebooks. The repo contains some of the latest state of the art algorithms from Microsoft Research as well as from other companies and institutions.\n* [StellarGraph](https://github.com/stellargraph/stellargraph): Machine Learning on Graphs, a Python library for machine learning on graph-structured (network-structured) data.\n* [BentoML](https://github.com/bentoml/bentoml): Toolkit for package and deploy machine learning models for serving in production\n* [MiraiML](https://github.com/arthurpaulino/miraiml): An asynchronous engine for continuous & autonomous machine learning, built for real-time usage.\n* [numpy-ML](https://github.com/ddbourgin/numpy-ml): Reference implementations of ML models written in numpy\n* [creme](https://github.com/creme-ml/creme): A framework for online machine learning.\n* [Neuraxle](https://github.com/Neuraxio/Neuraxle): A framework providing the right abstractions to ease research, development, and deployment of your ML pipelines.\n* [Cornac](https://github.com/PreferredAI/cornac) - A comparative framework for multimodal recommender systems with a focus on models leveraging auxiliary data.\n* [JAX](https://github.com/google/jax) - JAX is Autograd and XLA, brought together for high-performance machine learning research.\n* [Catalyst](https://github.com/catalyst-team/catalyst) - High-level utils for PyTorch DL & RL research. It was developed with a focus on reproducibility, fast experimentation and code/ideas reusing. Being able to research/develop something new, rather than write another regular train loop.\n* [Fastai](https://github.com/fastai/fastai) - High-level wrapper built on the top of Pytorch which supports vision, text, tabular data and collaborative filtering.\n* [scikit-multiflow](https://github.com/scikit-multiflow/scikit-multiflow) - A machine learning framework for multi-output/multi-label and stream data.\n* [Lightwood](https://github.com/mindsdb/lightwood) - A Pytorch based framework that breaks down machine learning problems into smaller blocks that can be glued together seamlessly with objective to build predictive models with one line of code.\n* [bayeso](https://github.com/jungtaekkim/bayeso) - A simple, but essential Bayesian optimization package, written in Python.\n* [mljar-supervised](https://github.com/mljar/mljar-supervised) - An Automated Machine Learning (AutoML) python package for tabular data. It can handle: Binary Classification, MultiClass Classification and Regression. It provides explanations and markdown reports.\n\n<a name=""python-data-analysis""></a>\n#### Data Analysis / Data Visualization\n\n* [SciPy](https://www.scipy.org/) - A Python-based ecosystem of open-source software for mathematics, science, and engineering.\n* [NumPy](https://www.numpy.org/) - A fundamental package for scientific computing with Python.\n* [AutoViz](https://github.com/AutoViML/AutoViz) AutoViz performs automatic visualization of any dataset with a single line of Python code. Give it any input file (CSV, txt or json) of any size and AutoViz will visualize it. See <a href=""https://towardsdatascience.com/autoviz-a-new-tool-for-automated-visualization-ec9c1744a6ad?source=friends_link&sk=c9e9503ec424b191c6096d7e3f515d10"">Medium article</a>.\n* [Numba](https://numba.pydata.org/) - Python JIT (just in time) compiler to LLVM aimed at scientific Python by the developers of Cython and NumPy.\n* [Mars](https://github.com/mars-project/mars) - A tensor-based framework for large-scale data computation which often regarded as a parallel and distributed version of NumPy.\n* [NetworkX](https://networkx.github.io/) - A high-productivity software for complex networks.\n* [igraph](https://igraph.org/python/) - binding to igraph library - General purpose graph library.\n* [Pandas](https://pandas.pydata.org/) - A library providing high-performance, easy-to-use data structures and data analysis tools.\n* [Open Mining](https://github.com/mining/mining) - Business Intelligence (BI) in Python (Pandas web interface) **[Deprecated]**\n* [PyMC](https://github.com/pymc-devs/pymc) - Markov Chain Monte Carlo sampling toolkit.\n* [zipline](https://github.com/quantopian/zipline) - A Pythonic algorithmic trading library.\n* [PyDy](https://www.pydy.org/) - Short for Python Dynamics, used to assist with workflow in the modeling of dynamic motion based around NumPy, SciPy, IPython, and matplotlib.\n* [SymPy](https://github.com/sympy/sympy) - A Python library for symbolic mathematics.\n* [statsmodels](https://github.com/statsmodels/statsmodels) - Statistical modeling and econometrics in Python.\n* [astropy](https://www.astropy.org/) - A community Python library for Astronomy.\n* [matplotlib](https://matplotlib.org/) - A Python 2D plotting library.\n* [bokeh](https://github.com/bokeh/bokeh) - Interactive Web Plotting for Python.\n* [plotly](https://plot.ly/python/) - Collaborative web plotting for Python and matplotlib.\n* [altair](https://github.com/altair-viz/altair) - A Python to Vega translator.\n* [d3py](https://github.com/mikedewar/d3py) - A plotting library for Python, based on [D3.js](https://d3js.org/).\n* [PyDexter](https://github.com/D3xterjs/pydexter) - Simple plotting for Python. Wrapper for D3xterjs; easily render charts in-browser.\n* [ggplot](https://github.com/yhat/ggpy) - Same API as ggplot2 for R. **[Deprecated]**\n* [ggfortify](https://github.com/sinhrks/ggfortify) - Unified interface to ggplot2 popular R packages.\n* [Kartograph.py](https://github.com/kartograph/kartograph.py) - Rendering beautiful SVG maps in Python.\n* [pygal](http://pygal.org/en/stable/) - A Python SVG Charts Creator.\n* [PyQtGraph](https://github.com/pyqtgraph/pyqtgraph) - A pure-python graphics and GUI library built on PyQt4 / PySide and NumPy.\n* [pycascading](https://github.com/twitter/pycascading) **[Deprecated]**\n* [Petrel](https://github.com/AirSage/Petrel) - Tools for writing, submitting, debugging, and monitoring Storm topologies in pure Python.\n* [Blaze](https://github.com/blaze/blaze) - NumPy and Pandas interface to Big Data.\n* [emcee](https://github.com/dfm/emcee) - The Python ensemble sampling toolkit for affine-invariant MCMC.\n* [windML](https://github.com/cigroup-ol/windml) - A Python Framework for Wind Energy Analysis and Prediction.\n* [vispy](https://github.com/vispy/vispy) - GPU-based high-performance interactive OpenGL 2D/3D data visualization library.\n* [cerebro2](https://github.com/numenta/nupic.cerebro2) A web-based visualization and debugging platform for NuPIC. **[Deprecated]**\n* [NuPIC Studio](https://github.com/htm-community/nupic.studio) An all-in-one NuPIC Hierarchical Temporal Memory visualization and debugging super-tool! **[Deprecated]**\n* [SparklingPandas](https://github.com/sparklingpandas/sparklingpandas) Pandas on PySpark (POPS).\n* [Seaborn](https://seaborn.pydata.org/) - A python visualization library based on matplotlib.\n* [bqplot](https://github.com/bloomberg/bqplot) - An API for plotting in Jupyter (IPython).\n* [pastalog](https://github.com/rewonc/pastalog) - Simple, realtime visualization of neural network training performance.\n* [Superset](https://github.com/apache/incubator-superset) - A data exploration platform designed to be visual, intuitive, and interactive.\n* [Dora](https://github.com/nathanepstein/dora) - Tools for exploratory data analysis in Python.\n* [Ruffus](http://www.ruffus.org.uk) - Computation Pipeline library for python.\n* [SOMPY](https://github.com/sevamoo/SOMPY) - Self Organizing Map written in Python (Uses neural networks for data analysis).\n* [somoclu](https://github.com/peterwittek/somoclu) Massively parallel self-organizing maps: accelerate training on multicore CPUs, GPUs, and clusters, has python API.\n* [HDBScan](https://github.com/lmcinnes/hdbscan) - implementation of the hdbscan algorithm in Python - used for clustering\n* [visualize_ML](https://github.com/ayush1997/visualize_ML) - A python package for data exploration and data analysis. **[Deprecated]**\n* [scikit-plot](https://github.com/reiinakano/scikit-plot) - A visualization library for quick and easy generation of common plots in data analysis and machine learning.\n* [Bowtie](https://github.com/jwkvam/bowtie) - A dashboard library for interactive visualizations using flask socketio and react.\n* [lime](https://github.com/marcotcr/lime) - Lime is about explaining what machine learning classifiers (or models) are doing. It is able to explain any black box classifier, with two or more classes.\n* [PyCM](https://github.com/sepandhaghighi/pycm) - PyCM is a multi-class confusion matrix library written in Python that supports both input data vectors and direct matrix, and a proper tool for post-classification model evaluation that supports most classes and overall statistics parameters\n* [Dash](https://github.com/plotly/dash) - A framework for creating analytical web applications built on top of Plotly.js, React, and Flask\n* [Lambdo](https://github.com/asavinov/lambdo) - A workflow engine for solving machine learning problems by combining in one analysis pipeline (i) feature engineering and machine learning (ii) model training and prediction (iii) table population and column evaluation via user-defined (Python) functions.\n* [TensorWatch](https://github.com/microsoft/tensorwatch) - Debugging and visualization tool for machine learning and data science. It extensively leverages Jupyter Notebook to show real-time visualizations of data in running processes such as machine learning training.\n* [dowel](https://github.com/rlworkgroup/dowel) - A little logger for machine learning research. Output any object to the terminal, CSV, TensorBoard, text logs on disk, and more with just one call to `logger.log()`.\n\n<a name=""python-misc""></a>\n#### Misc Scripts / iPython Notebooks / Codebases\n* [Map/Reduce implementations of common ML algorithms](https://github.com/Yannael/BigDataAnalytics_INFOH515): Jupyter notebooks that cover how to implement from scratch different ML algorithms (ordinary least squares, gradient descent, k-means, alternating least squares), using Python NumPy, and how to then make these implementations scalable using Map/Reduce and Spark.\n* [BioPy](https://github.com/jaredthecoder/BioPy) - Biologically-Inspired and Machine Learning Algorithms in Python. **[Deprecated]**\n* [SVM Explorer](https://github.com/plotly/dash-svm) - Interactive SVM Explorer, using Dash and scikit-learn\n* [pattern_classification](https://github.com/rasbt/pattern_classification)\n* [thinking stats 2](https://github.com/Wavelets/ThinkStats2)\n* [hyperopt](https://github.com/hyperopt/hyperopt-sklearn)\n* [numpic](https://github.com/numenta/nupic)\n* [2012-paper-diginorm](https://github.com/dib-lab/2012-paper-diginorm)\n* [A gallery of interesting IPython notebooks](https://github.com/jupyter/jupyter/wiki/A-gallery-of-interesting-Jupyter-Notebooks)\n* [ipython-notebooks](https://github.com/ogrisel/notebooks)\n* [data-science-ipython-notebooks](https://github.com/donnemartin/data-science-ipython-notebooks) - Continually updated Data Science Python Notebooks: Spark, Hadoop MapReduce, HDFS, AWS, Kaggle, scikit-learn, matplotlib, pandas, NumPy, SciPy, and various command lines.\n* [decision-weights](https://github.com/CamDavidsonPilon/decision-weights)\n* [Sarah Palin LDA](https://github.com/Wavelets/sarah-palin-lda) - Topic Modeling the Sarah Palin emails.\n* [Diffusion Segmentation](https://github.com/Wavelets/diffusion-segmentation) - A collection of image segmentation algorithms based on diffusion methods.\n* [Scipy Tutorials](https://github.com/Wavelets/scipy-tutorials) - SciPy tutorials. This is outdated, check out scipy-lecture-notes.\n* [Crab](https://github.com/marcelcaraciolo/crab) - A recommendation engine library for Python.\n* [BayesPy](https://github.com/maxsklar/BayesPy) - Bayesian Inference Tools in Python.\n* [scikit-learn tutorials](https://github.com/GaelVaroquaux/scikit-learn-tutorial) - Series of notebooks for learning scikit-learn.\n* [sentiment-analyzer](https://github.com/madhusudancs/sentiment-analyzer) - Tweets Sentiment Analyzer\n* [sentiment_classifier](https://github.com/kevincobain2000/sentiment_classifier) - Sentiment classifier using word sense disambiguation.\n* [group-lasso](https://github.com/fabianp/group_lasso) - Some experiments with the coordinate descent algorithm used in the (Sparse) Group Lasso model.\n* [jProcessing](https://github.com/kevincobain2000/jProcessing) - Kanji / Hiragana / Katakana to Romaji Converter. Edict Dictionary & parallel sentences Search. Sentence Similarity between two JP Sentences. Sentiment Analysis of Japanese Text. Run Cabocha(ISO--8859-1 configured) in Python.\n* [mne-python-notebooks](https://github.com/mne-tools/mne-python-notebooks) - IPython notebooks for EEG/MEG data processing using mne-python.\n* [Neon Course](https://github.com/NervanaSystems/neon_course) - IPython notebooks for a complete course around understanding Nervana\'s Neon.\n* [pandas cookbook](https://github.com/jvns/pandas-cookbook) - Recipes for using Python\'s pandas library.\n* [climin](https://github.com/BRML/climin) - Optimization library focused on machine learning, pythonic implementations of gradient descent, LBFGS, rmsprop, adadelta and others.\n* [Allen Downey\xe2\x80\x99s Data Science Course](https://github.com/AllenDowney/DataScience) - Code for Data Science at Olin College, Spring 2014.\n* [Allen Downey\xe2\x80\x99s Think Bayes Code](https://github.com/AllenDowney/ThinkBayes) - Code repository for Think Bayes.\n* [Allen Downey\xe2\x80\x99s Think Complexity Code](https://github.com/AllenDowney/ThinkComplexity) - Code for Allen Downey\'s book Think Complexity.\n* [Allen Downey\xe2\x80\x99s Think OS Code](https://github.com/AllenDowney/ThinkOS) - Text and supporting code for Think OS: A Brief Introduction to Operating Systems.\n* [Python Programming for the Humanities](https://www.karsdorp.io/python-course/) - Course for Python programming for the Humanities, assuming no prior knowledge. Heavy focus on text processing / NLP.\n* [GreatCircle](https://github.com/mwgg/GreatCircle) - Library for calculating great circle distance.\n* [Optunity examples](http://optunity.readthedocs.io/en/latest/notebooks/index.html) - Examples demonstrating how to use Optunity in synergy with machine learning libraries.\n* [Dive into Machine Learning  with Python Jupyter notebook and scikit-learn](https://github.com/hangtwenty/dive-into-machine-learning) - ""I learned Python by hacking first, and getting serious *later.* I wanted to do this with Machine Learning. If this is your style, join me in getting a bit ahead of yourself.""\n* [TDB](https://github.com/ericjang/tdb) - TensorDebugger (TDB) is a visual debugger for deep learning. It features interactive, node-by-node debugging and visualization for TensorFlow.\n* [Suiron](https://github.com/kendricktan/suiron/) - Machine Learning for RC Cars.\n* [Introduction to machine learning with scikit-learn](https://github.com/justmarkham/scikit-learn-videos) - IPython notebooks from Data School\'s video tutorials on scikit-learn.\n* [Practical XGBoost in Python](https://parrotprediction.teachable.com/p/practical-xgboost-in-python) - comprehensive online course about using XGBoost in Python.\n* [Introduction to Machine Learning with Python](https://github.com/amueller/introduction_to_ml_with_python) - Notebooks and code for the book ""Introduction to Machine Learning with Python""\n* [Pydata book](https://github.com/wesm/pydata-book) - Materials and IPython notebooks for ""Python for Data Analysis"" by Wes McKinney, published by O\'Reilly Media\n* [Homemade Machine Learning](https://github.com/trekhleb/homemade-machine-learning) - Python examples of popular machine learning algorithms with interactive Jupyter demos and math being explained\n* [Prodmodel](https://github.com/prodmodel/prodmodel) - Build tool for data science pipelines.\n* [the-elements-of-statistical-learning](https://github.com/maitbayev/the-elements-of-statistical-learning) - This repository contains Jupyter notebooks implementing the algorithms found in the book and summary of the textbook.\n\n<a name=""python-neural-networks""></a>\n#### Neural Networks\n\n* [nn_builder](https://github.com/p-christ/nn_builder) - nn_builder is a python package that lets you build neural networks in 1 line\n* [NeuralTalk](https://github.com/karpathy/neuraltalk) - NeuralTalk is a Python+numpy project for learning Multimodal Recurrent Neural Networks that describe images with sentences.\n* [Neuron](https://github.com/molcik/python-neuron) - Neuron is simple class for time series predictions. It\'s utilize LNU (Linear Neural Unit), QNU (Quadratic Neural Unit), RBF (Radial Basis Function), MLP (Multi Layer Perceptron), MLP-ELM (Multi Layer Perceptron - Extreme Learning Machine) neural networks learned with Gradient descent or LeLevenberg\xe2\x80\x93Marquardt algorithm.\n=======\n* [NeuralTalk](https://github.com/karpathy/neuraltalk2) - NeuralTalk is a Python+numpy project for learning Multimodal Recurrent Neural Networks that describe images with sentences. **[Deprecated]**\n* [Neuron](https://github.com/molcik/python-neuron) - Neuron is simple class for time series predictions. It\'s utilize LNU (Linear Neural Unit), QNU (Quadratic Neural Unit), RBF (Radial Basis Function), MLP (Multi Layer Perceptron), MLP-ELM (Multi Layer Perceptron - Extreme Learning Machine) neural networks learned with Gradient descent or LeLevenberg\xe2\x80\x93Marquardt algorithm. **[Deprecated]**\n* [Data Driven Code](https://github.com/atmb4u/data-driven-code) - Very simple implementation of neural networks for dummies in python without using any libraries, with detailed comments.\n* [Machine Learning, Data Science and Deep Learning with Python](https://www.manning.com/livevideo/machine-learning-data-science-and-deep-learning-with-python) - LiveVideo course that covers machine learning, Tensorflow, artificial intelligence, and neural networks.\n* [TResNet: High Performance GPU-Dedicated Architecture](https://github.com/mrT23/TResNet) - TResNet models were designed and optimized to give the best speed-accuracy tradeoff out there on GPUs. \n\n<a name=""python-kaggle""></a>\n#### Kaggle Competition Source Code\n* [open-solution-home-credit](https://github.com/neptune-ml/open-solution-home-credit) -> source code and [experiments results](https://app.neptune.ml/neptune-ml/Home-Credit-Default-Risk) for [Home Credit Default Risk](https://www.kaggle.com/c/home-credit-default-risk).\n* [open-solution-googleai-object-detection](https://github.com/neptune-ml/open-solution-googleai-object-detection) -> source code and [experiments results](https://app.neptune.ml/neptune-ml/Google-AI-Object-Detection-Challenge) for [Google AI Open Images - Object Detection Track](https://www.kaggle.com/c/google-ai-open-images-object-detection-track).\n* [open-solution-salt-identification](https://github.com/neptune-ml/open-solution-salt-identification) -> source code and [experiments results](https://app.neptune.ml/neptune-ml/Salt-Detection) for [TGS Salt Identification Challenge](https://www.kaggle.com/c/tgs-salt-identification-challenge).\n* [open-solution-ship-detection](https://github.com/neptune-ml/open-solution-ship-detection) -> source code and [experiments results](https://app.neptune.ml/neptune-ml/Ships) for [Airbus Ship Detection Challenge](https://www.kaggle.com/c/airbus-ship-detection).\n* [open-solution-data-science-bowl-2018](https://github.com/neptune-ml/open-solution-data-science-bowl-2018) -> source code and [experiments results](https://app.neptune.ml/neptune-ml/Data-Science-Bowl-2018) for [2018 Data Science Bowl](https://www.kaggle.com/c/data-science-bowl-2018).\n* [open-solution-value-prediction](https://github.com/neptune-ml/open-solution-value-prediction) -> source code and [experiments results](https://app.neptune.ml/neptune-ml/Santander-Value-Prediction-Challenge) for [Santander Value Prediction Challenge](https://www.kaggle.com/c/santander-value-prediction-challenge).\n* [open-solution-toxic-comments](https://github.com/neptune-ml/open-solution-toxic-comments) -> source code for [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge).\n* [wiki challenge](https://github.com/hammer/wikichallenge) - An implementation of Dell Zhang\'s solution to Wikipedia\'s Participation Challenge on Kaggle.\n* [kaggle insults](https://github.com/amueller/kaggle_insults) - Kaggle Submission for ""Detecting Insults in Social Commentary"".\n* [kaggle_acquire-valued-shoppers-challenge](https://github.com/MLWave/kaggle_acquire-valued-shoppers-challenge) - Code for the Kaggle acquire valued shoppers challenge.\n* [kaggle-cifar](https://github.com/zygmuntz/kaggle-cifar) - Code for the CIFAR-10 competition at Kaggle, uses cuda-convnet.\n* [kaggle-blackbox](https://github.com/zygmuntz/kaggle-blackbox) - Deep learning made easy.\n* [kaggle-accelerometer](https://github.com/zygmuntz/kaggle-accelerometer) - Code for Accelerometer Biometric Competition at Kaggle.\n* [kaggle-advertised-salaries](https://github.com/zygmuntz/kaggle-advertised-salaries) - Predicting job salaries from ads - a Kaggle competition.\n* [kaggle amazon](https://github.com/zygmuntz/kaggle-amazon) - Amazon access control challenge.\n* [kaggle-bestbuy_big](https://github.com/zygmuntz/kaggle-bestbuy_big) - Code for the Best Buy competition at Kaggle.\n* [kaggle-bestbuy_small](https://github.com/zygmuntz/kaggle-bestbuy_small)\n* [Kaggle Dogs vs. Cats](https://github.com/kastnerkyle/kaggle-dogs-vs-cats) - Code for Kaggle Dogs vs. Cats competition.\n* [Kaggle Galaxy Challenge](https://github.com/benanne/kaggle-galaxies) - Winning solution for the Galaxy Challenge on Kaggle.\n* [Kaggle Gender](https://github.com/zygmuntz/kaggle-gender) - A Kaggle competition: discriminate gender based on handwriting.\n* [Kaggle Merck](https://github.com/zygmuntz/kaggle-merck) - Merck challenge at Kaggle.\n* [Kaggle Stackoverflow](https://github.com/zygmuntz/kaggle-stackoverflow) - Predicting closed questions on Stack Overflow.\n* [kaggle_acquire-valued-shoppers-challenge](https://github.com/MLWave/kaggle_acquire-valued-shoppers-challenge) - Code for the Kaggle acquire valued shoppers challenge.\n* [wine-quality](https://github.com/zygmuntz/wine-quality) - Predicting wine quality.\n\n<a name=""python-reinforcement-learning""></a>\n#### Reinforcement Learning\n* [DeepMind Lab](https://github.com/deepmind/lab) - DeepMind Lab is a 3D learning environment based on id Software\'s Quake III Arena via ioquake3 and other open source software. Its primary purpose is to act as a testbed for research in artificial intelligence, especially deep reinforcement learning.\n* [Gym](https://github.com/openai/gym) - OpenAI Gym is a toolkit for developing and comparing reinforcement learning algorithms.\n* [Serpent.AI](https://github.com/SerpentAI/SerpentAI) - Serpent.AI is a game agent framework that allows you to turn any video game you own into a sandbox to develop AI and machine learning experiments. For both researchers and hobbyists.\n* [ViZDoom](https://github.com/mwydmuch/ViZDoom) - ViZDoom allows developing AI bots that play Doom using only the visual information (the screen buffer). It is primarily intended for research in machine visual learning, and deep reinforcement learning, in particular.\n* [Roboschool](https://github.com/openai/roboschool) - Open-source software for robot simulation, integrated with OpenAI Gym.\n* [Retro](https://github.com/openai/retro) - Retro Games in Gym\n* [SLM Lab](https://github.com/kengz/SLM-Lab) - Modular Deep Reinforcement Learning framework in PyTorch.\n* [Coach](https://github.com/NervanaSystems/coach) - Reinforcement Learning Coach by Intel\xc2\xae AI Lab enables easy experimentation with state of the art Reinforcement Learning algorithms\n* [garage](https://github.com/rlworkgroup/garage) - A toolkit for reproducible reinforcement learning research\n* [metaworld](https://github.com/rlworkgroup/metaworld) - An open source robotics benchmark for meta- and multi-task reinforcement learning\n\n<a name=""ruby""></a>\n## Ruby\n\n<a name=""ruby-nlp""></a>\n#### Natural Language Processing\n\n* [Awesome NLP with Ruby](https://github.com/arbox/nlp-with-ruby) - Curated link list for practical natural language processing in Ruby.\n* [Treat](https://github.com/louismullie/treat) - Text REtrieval and Annotation Toolkit, definitely the most comprehensive toolkit I\xe2\x80\x99ve encountered so far for Ruby.\n* [Stemmer](https://github.com/aurelian/ruby-stemmer) - Expose libstemmer_c to Ruby. **[Deprecated]**\n* [Raspel](https://sourceforge.net/projects/raspell/) - raspell is an interface binding for ruby. **[Deprecated]**\n* [UEA Stemmer](https://github.com/ealdent/uea-stemmer) - Ruby port of UEALite Stemmer - a conservative stemmer for search and indexing.\n* [Twitter-text-rb](https://github.com/twitter/twitter-text/tree/master/rb) - A library that does auto linking and extraction of usernames, lists and hashtags in tweets.\n\n<a name=""ruby-general-purpose""></a>\n#### General-Purpose Machine Learning\n\n* [Awesome Machine Learning with Ruby](https://github.com/arbox/machine-learning-with-ruby) - Curated list of ML related resources for Ruby.\n* [Ruby Machine Learning](https://github.com/tsycho/ruby-machine-learning) - Some Machine Learning algorithms, implemented in Ruby. **[Deprecated]**\n* [Machine Learning Ruby](https://github.com/mizoR/machine-learning-ruby) **[Deprecated]**\n* [jRuby Mahout](https://github.com/vasinov/jruby_mahout) - JRuby Mahout is a gem that unleashes the power of Apache Mahout in the world of JRuby. **[Deprecated]**\n* [CardMagic-Classifier](https://github.com/cardmagic/classifier) - A general classifier module to allow Bayesian and other types of classifications.\n* [rb-libsvm](https://github.com/febeling/rb-libsvm) - Ruby language bindings for LIBSVM which is a Library for Support Vector Machines.\n* [Scoruby](https://github.com/asafschers/scoruby) - Creates Random Forest classifiers from PMML files.\n* [rumale](https://github.com/yoshoku/rumale) - Rumale is a machine learning library in Ruby\n\n<a name=""ruby-data-analysis""></a>\n#### Data Analysis / Data Visualization\n\n* [rsruby](https://github.com/alexgutteridge/rsruby) - Ruby - R bridge.\n* [data-visualization-ruby](https://github.com/chrislo/data_visualisation_ruby) - Source code and supporting content for my Ruby Manor presentation on Data Visualisation with Ruby. **[Deprecated]**\n* [ruby-plot](https://www.ruby-toolbox.com/projects/ruby-plot) - gnuplot wrapper for Ruby, especially for plotting ROC curves into SVG files. **[Deprecated]**\n* [plot-rb](https://github.com/zuhao/plotrb) - A plotting library in Ruby built on top of Vega and D3. **[Deprecated]**\n* [scruffy](https://github.com/delano/scruffy) - A beautiful graphing toolkit for Ruby.\n* [SciRuby](http://sciruby.com/)\n* [Glean](https://github.com/glean/glean) - A data management tool for humans. **[Deprecated]**\n* [Bioruby](https://github.com/bioruby/bioruby)\n* [Arel](https://github.com/nkallen/arel) **[Deprecated]**\n\n<a name=""ruby-misc""></a>\n#### Misc\n\n* [Big Data For Chimps](https://github.com/infochimps-labs/big_data_for_chimps)\n* [Listof](https://github.com/kevincobain2000/listof) - Community based data collection, packed in gem. Get list of pretty much anything (stop words, countries, non words) in txt, json or hash. [Demo/Search for a list](http://kevincobain2000.github.io/listof/)\n\n\n<a name=""rust""></a>\n## Rust\n\n<a name=""rust-general-purpose""></a>\n#### General-Purpose Machine Learning\n* [deeplearn-rs](https://github.com/tedsta/deeplearn-rs) - deeplearn-rs provides simple networks that use matrix multiplication, addition, and ReLU under the MIT license.\n* [rustlearn](https://github.com/maciejkula/rustlearn) - a machine learning framework featuring logistic regression, support vector machines, decision trees and random forests.\n* [rusty-machine](https://github.com/AtheMathmo/rusty-machine) - a pure-rust machine learning library.\n* [leaf](https://github.com/autumnai/leaf) - open source framework for machine intelligence, sharing concepts from TensorFlow and Caffe. Available under the MIT license. [**[Deprecated]**](https://medium.com/@mjhirn/tensorflow-wins-89b78b29aafb#.s0a3uy4cc)\n* [RustNN](https://github.com/jackm321/RustNN) - RustNN is a feedforward neural network library. **[Deprecated]**\n* [RusticSOM](https://github.com/avinashshenoy97/RusticSOM) - A Rust library for Self Organising Maps (SOM).\n\n\n<a name=""r""></a>\n## R\n\n<a name=""r-general-purpose""></a>\n#### General-Purpose Machine Learning\n\n* [ahaz](https://cran.r-project.org/web/packages/ahaz/index.html) - ahaz: Regularization for semiparametric additive hazards regression. **[Deprecated]**\n* [arules](https://cran.r-project.org/web/packages/arules/index.html) - arules: Mining Association Rules and Frequent Itemsets\n* [biglasso](https://cran.r-project.org/web/packages/biglasso/index.html) - biglasso: Extending Lasso Model Fitting to Big Data in R.\n* [bmrm](https://cran.r-project.org/web/packages/bmrm/index.html) - bmrm: Bundle Methods for Regularized Risk Minimization Package.\n* [Boruta](https://cran.r-project.org/web/packages/Boruta/index.html) - Boruta: A wrapper algorithm for all-relevant feature selection.\n* [bst](https://cran.r-project.org/web/packages/bst/index.html) - bst: Gradient Boosting.\n* [C50](https://cran.r-project.org/web/packages/C50/index.html) - C50: C5.0 Decision Trees and Rule-Based Models.\n* [caret](https://topepo.github.io/caret/index.html) - Classification and Regression Training: Unified interface to ~150 ML algorithms in R.\n* [caretEnsemble](https://cran.r-project.org/web/packages/caretEnsemble/index.html) - caretEnsemble: Framework for fitting multiple caret models as well as creating ensembles of such models. **[Deprecated]**\n* [CatBoost](https://github.com/catboost/catboost) - General purpose gradient boosting on decision trees library with categorical features support out of the box for R.\n* [Clever Algorithms For Machine Learning](https://machinelearningmastery.com/)\n* [CORElearn](https://cran.r-project.org/web/packages/CORElearn/index.html) - CORElearn: Classification, regression, feature evaluation and ordinal evaluation.\n* [CoxBoost](https://cran.r-project.org/web/packages/CoxBoost/index.html) - CoxBoost: Cox models by likelihood based boosting for a single survival endpoint or competing risks **[Deprecated]**\n* [Cubist](https://cran.r-project.org/web/packages/Cubist/index.html) - Cubist: Rule- and Instance-Based Regression Modeling.\n* [e1071](https://cran.r-project.org/web/packages/e1071/index.html) - e1071: Misc Functions of the Department of Statistics (e1071), TU Wien\n* [earth](https://cran.r-project.org/web/packages/earth/index.html) - earth: Multivariate Adaptive Regression Spline Models\n* [elasticnet](https://cran.r-project.org/web/packages/elasticnet/index.html) - elasticnet: Elastic-Net for Sparse Estimation and Sparse PCA.\n* [ElemStatLearn](https://cran.r-project.org/web/packages/ElemStatLearn/index.html) - ElemStatLearn: Data sets, functions and examples from the book: ""The Elements of Statistical Learning, Data Mining, Inference, and Prediction"" by Trevor Hastie, Robert Tibshirani and Jerome Friedman Prediction"" by Trevor Hastie, Robert Tibshirani and Jerome Friedman.\n* [evtree](https://cran.r-project.org/web/packages/evtree/index.html) - evtree: Evolutionary Learning of Globally Optimal Trees.\n* [forecast](https://cran.r-project.org/web/packages/forecast/index.html) - forecast: Timeseries forecasting using ARIMA, ETS, STLM, TBATS, and neural network models.\n* [forecastHybrid](https://cran.r-project.org/web/packages/forecastHybrid/index.html) - forecastHybrid: Automatic ensemble and cross validation of ARIMA, ETS, STLM, TBATS, and neural network models from the ""forecast"" package.\n* [fpc](https://cran.r-project.org/web/packages/fpc/index.html) - fpc: Flexible procedures for clustering.\n* [frbs](https://cran.r-project.org/web/packages/frbs/index.html) - frbs: Fuzzy Rule-based Systems for Classification and Regression Tasks. **[Deprecated]**\n* [GAMBoost](https://cran.r-project.org/web/packages/GAMBoost/index.html) - GAMBoost: Generalized linear and additive models by likelihood based boosting. **[Deprecated]**\n* [gamboostLSS](https://cran.r-project.org/web/packages/gamboostLSS/index.html) - gamboostLSS: Boosting Methods for GAMLSS.\n* [gbm](https://cran.r-project.org/web/packages/gbm/index.html) - gbm: Generalized Boosted Regression Models.\n* [glmnet](https://cran.r-project.org/web/packages/glmnet/index.html) - glmnet: Lasso and elastic-net regularized generalized linear models.\n* [glmpath](https://cran.r-project.org/web/packages/glmpath/index.html) - glmpath: L1 Regularization Path for Generalized Linear Models and Cox Proportional Hazards Model.\n* [GMMBoost](https://cran.r-project.org/web/packages/GMMBoost/index.html) - GMMBoost: Likelihood-based Boosting for Generalized mixed models. **[Deprecated]**\n* [grplasso](https://cran.r-project.org/web/packages/grplasso/index.html) - grplasso: Fitting user specified models with Group Lasso penalty.\n* [grpreg](https://cran.r-project.org/web/packages/grpreg/index.html) - grpreg: Regularization paths for regression models with grouped covariates.\n* [h2o](https://cran.r-project.org/web/packages/h2o/index.html) - A framework for fast, parallel, and distributed machine learning algorithms at scale -- Deeplearning, Random forests, GBM, KMeans, PCA, GLM.\n* [hda](https://cran.r-project.org/web/packages/hda/index.html) - hda: Heteroscedastic Discriminant Analysis. **[Deprecated]**\n* [Introduction to Statistical Learning](https://www-bcf.usc.edu/~gareth/ISL/)\n* [ipred](https://cran.r-project.org/web/packages/ipred/index.html) - ipred: Improved Predictors.\n* [kernlab](https://cran.r-project.org/web/packages/kernlab/index.html) - kernlab: Kernel-based Machine Learning Lab.\n* [klaR](https://cran.r-project.org/web/packages/klaR/index.html) - klaR: Classification and visualization.\n* [L0Learn](https://cran.r-project.org/web/packages/L0Learn/index.html) - L0Learn: Fast algorithms for best subset selection.\n* [lars](https://cran.r-project.org/web/packages/lars/index.html) - lars: Least Angle Regression, Lasso and Forward Stagewise. **[Deprecated]**\n* [lasso2](https://cran.r-project.org/web/packages/lasso2/index.html) - lasso2: L1 constrained estimation aka \xe2\x80\x98lasso\xe2\x80\x99.\n* [LiblineaR](https://cran.r-project.org/web/packages/LiblineaR/index.html) - LiblineaR: Linear Predictive Models Based On The Liblinear C/C++ Library.\n* [LogicReg](https://cran.r-project.org/web/packages/LogicReg/index.html) - LogicReg: Logic Regression.\n* [Machine Learning For Hackers](https://github.com/johnmyleswhite/ML_for_Hackers)\n* [maptree](https://cran.r-project.org/web/packages/maptree/index.html) - maptree: Mapping, pruning, and graphing tree models. **[Deprecated]**\n* [mboost](https://cran.r-project.org/web/packages/mboost/index.html) - mboost: Model-Based Boosting.\n* [medley](https://www.kaggle.com/general/3661) - medley: Blending regression models, using a greedy stepwise approach.\n* [mlr](https://cran.r-project.org/web/packages/mlr/index.html) - mlr: Machine Learning in R.\n* [ncvreg](https://cran.r-project.org/web/packages/ncvreg/index.html) - ncvreg: Regularization paths for SCAD- and MCP-penalized regression models.\n* [nnet](https://cran.r-project.org/web/packages/nnet/index.html) - nnet: Feed-forward Neural Networks and Multinomial Log-Linear Models. **[Deprecated]**\n* [pamr](https://cran.r-project.org/web/packages/pamr/index.html) - pamr: Pam: prediction analysis for microarrays. **[Deprecated]**\n* [party](https://cran.r-project.org/web/packages/party/index.html) - party: A Laboratory for Recursive Partytioning.\n* [partykit](https://cran.r-project.org/web/packages/partykit/index.html) - partykit: A Toolkit for Recursive Partytioning.\n* [penalized](https://cran.r-project.org/web/packages/penalized/index.html) - penalized: L1 (lasso and fused lasso) and L2 (ridge) penalized estimation in GLMs and in the Cox model.\n* [penalizedLDA](https://cran.r-project.org/web/packages/penalizedLDA/index.html) - penalizedLDA: Penalized classification using Fisher\'s linear discriminant. **[Deprecated]**\n* [penalizedSVM](https://cran.r-project.org/web/packages/penalizedSVM/index.html) - penalizedSVM: Feature Selection SVM using penalty functions.\n* [quantregForest](https://cran.r-project.org/web/packages/quantregForest/index.html) - quantregForest: Quantile Regression Forests.\n* [randomForest](https://cran.r-project.org/web/packages/randomForest/index.html) - randomForest: Breiman and Cutler\'s random forests for classification and regression.\n* [randomForestSRC](https://cran.r-project.org/web/packages/randomForestSRC/index.html) - randomForestSRC: Random Forests for Survival, Regression and Classification (RF-SRC).\n* [rattle](https://cran.r-project.org/web/packages/rattle/index.html) - rattle: Graphical user interface for data mining in R.\n* [rda](https://cran.r-project.org/web/packages/rda/index.html) - rda: Shrunken Centroids Regularized Discriminant Analysis.\n* [rdetools](https://cran.r-project.org/web/packages/rdetools/index.html) - rdetools: Relevant Dimension Estimation (RDE) in Feature Spaces. **[Deprecated]**\n* [REEMtree](https://cran.r-project.org/web/packages/REEMtree/index.html) - REEMtree: Regression Trees with Random Effects for Longitudinal (Panel) Data. **[Deprecated]**\n* [relaxo](https://cran.r-project.org/web/packages/relaxo/index.html) - relaxo: Relaxed Lasso. **[Deprecated]**\n* [rgenoud](https://cran.r-project.org/web/packages/rgenoud/index.html) - rgenoud: R version of GENetic Optimization Using Derivatives\n* [Rmalschains](https://cran.r-project.org/web/packages/Rmalschains/index.html) - Rmalschains: Continuous Optimization using Memetic Algorithms with Local Search Chains (MA-LS-Chains) in R.\n* [rminer](https://cran.r-project.org/web/packages/rminer/index.html) - rminer: Simpler use of data mining methods (e.g. NN and SVM) in classification and regression. **[Deprecated]**\n* [ROCR](https://cran.r-project.org/web/packages/ROCR/index.html) - ROCR: Visualizing the performance of scoring classifiers. **[Deprecated]**\n* [RoughSets](https://cran.r-project.org/web/packages/RoughSets/index.html) - RoughSets: Data Analysis Using Rough Set and Fuzzy Rough Set Theories. **[Deprecated]**\n* [rpart](https://cran.r-project.org/web/packages/rpart/index.html) - rpart: Recursive Partitioning and Regression Trees.\n* [RPMM](https://cran.r-project.org/web/packages/RPMM/index.html) - RPMM: Recursively Partitioned Mixture Model.\n* [RSNNS](https://cran.r-project.org/web/packages/RSNNS/index.html) - RSNNS: Neural Networks in R using the Stuttgart Neural Network Simulator (SNNS).\n* [RWeka](https://cran.r-project.org/web/packages/RWeka/index.html) - RWeka: R/Weka interface.\n* [RXshrink](https://cran.r-project.org/web/packages/RXshrink/index.html) - RXshrink: Maximum Likelihood Shrinkage via Generalized Ridge or Least Angle Regression.\n* [sda](https://cran.r-project.org/web/packages/sda/index.html) - sda: Shrinkage Discriminant Analysis and CAT Score Variable Selection. **[Deprecated]**\n* [spectralGraphTopology](https://cran.r-project.org/web/packages/spectralGraphTopology/index.html) - spectralGraphTopology: Learning Graphs from Data via Spectral Constraints.\n* [SuperLearner](https://github.com/ecpolley/SuperLearner) - Multi-algorithm ensemble learning packages.\n* [svmpath](https://cran.r-project.org/web/packages/svmpath/index.html) - svmpath: svmpath: the SVM Path algorithm. **[Deprecated]**\n* [tgp](https://cran.r-project.org/web/packages/tgp/index.html) - tgp: Bayesian treed Gaussian process models. **[Deprecated]**\n* [tree](https://cran.r-project.org/web/packages/tree/index.html) - tree: Classification and regression trees.\n* [varSelRF](https://cran.r-project.org/web/packages/varSelRF/index.html) - varSelRF: Variable selection using random forests.\n* [XGBoost.R](https://github.com/tqchen/xgboost/tree/master/R-package) - R binding for eXtreme Gradient Boosting (Tree) Library.\n* [Optunity](https://optunity.readthedocs.io/en/latest/) - A library dedicated to automated hyperparameter optimization with a simple, lightweight API to facilitate drop-in replacement of grid search. Optunity is written in Python but interfaces seamlessly to R.\n* [igraph](https://igraph.org/r/) - binding to igraph library - General purpose graph library.\n* [MXNet](https://github.com/apache/incubator-mxnet) - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more.\n* [TDSP-Utilities](https://github.com/Azure/Azure-TDSP-Utilities) - Two data science utilities in R from Microsoft: 1) Interactive Data Exploration, Analysis, and Reporting (IDEAR) ; 2) Automated Modeling and Reporting (AMR).\n\n<a name=""r-data-analysis""></a>\n#### Data Manipulation | Data Analysis | Data Visualization\n\n* [dplyr](https://www.rdocumentation.org/packages/dplyr/versions/0.7.8) - A data manipulation package that helps to solve the most common data manipulation problems.\n* [ggplot2](https://ggplot2.tidyverse.org/) - A data visualization package based on the grammar of graphics.\n* [tmap](https://cran.r-project.org/web/packages/tmap/vignettes/tmap-getstarted.html) for visualizing geospatial data with static maps and [leaflet](https://rstudio.github.io/leaflet/) for interactive maps\n* [tm](https://www.rdocumentation.org/packages/tm/) and [quanteda](https://quanteda.io/) are the main packages for managing,  analyzing, and visualizing textual data.\n* [shiny](https://shiny.rstudio.com/) is the basis for truly interactive displays and dashboards in R. However, some measure of interactivity can be achieved with [htmlwidgets](https://www.htmlwidgets.org/) bringing javascript libraries to R. These include, [plotly](https://plot.ly/r/), [dygraphs](http://rstudio.github.io/dygraphs), [highcharter](http://jkunst.com/highcharter/), and several others.\n\n<a name=""sas""></a>\n## SAS\n\n<a name=""sas-general-purpose""></a>\n#### General-Purpose Machine Learning\n\n* [Visual Data Mining and Machine Learning](https://www.sas.com/en_us/software/visual-data-mining-machine-learning.html) - Interactive, automated, and programmatic modeling with the latest machine learning algorithms in and end-to-end analytics environment, from data prep to deployment. Free trial available.\n* [Enterprise Miner](https://www.sas.com/en_us/software/enterprise-miner.html) - Data mining and machine learning that creates deployable models using a GUI or code.\n* [Factory Miner](https://www.sas.com/en_us/software/factory-miner.html) - Automatically creates deployable machine learning models across numerous market or customer segments using a GUI.\n\n<a name=""sas-data-analysis""></a>\n#### Data Analysis / Data Visualization\n\n* [SAS/STAT](https://www.sas.com/en_us/software/stat.html) - For conducting advanced statistical analysis.\n* [University Edition](https://www.sas.com/en_us/software/university-edition.html) - FREE! Includes all SAS packages necessary for data analysis and visualization, and includes online SAS courses.\n\n<a name=""sas-nlp""></a>\n#### Natural Language Processing\n\n* [Contextual Analysis](https://www.sas.com/en_us/software/contextual-analysis.html) - Add structure to unstructured text using a GUI.\n* [Sentiment Analysis](https://www.sas.com/en_us/software/sentiment-analysis.html) - Extract sentiment from text using a GUI.\n* [Text Miner](https://www.sas.com/en_us/software/text-miner.html) - Text mining using a GUI or code.\n\n<a name=""sas-demos""></a>\n#### Demos and Scripts\n\n* [ML_Tables](https://github.com/sassoftware/enlighten-apply/tree/master/ML_tables) - Concise cheat sheets containing machine learning best practices.\n* [enlighten-apply](https://github.com/sassoftware/enlighten-apply) - Example code and materials that illustrate applications of SAS machine learning techniques.\n* [enlighten-integration](https://github.com/sassoftware/enlighten-integration) - Example code and materials that illustrate techniques for integrating SAS with other analytics technologies in Java, PMML, Python and R.\n* [enlighten-deep](https://github.com/sassoftware/enlighten-deep) - Example code and materials that illustrate using neural networks with several hidden layers in SAS.\n* [dm-flow](https://github.com/sassoftware/dm-flow) - Library of SAS Enterprise Miner process flow diagrams to help you learn by example about specific data mining topics.\n\n\n<a name=""scala""></a>\n## Scala\n\n<a name=""scala-nlp""></a>\n#### Natural Language Processing\n\n* [ScalaNLP](http://www.scalanlp.org/) - ScalaNLP is a suite of machine learning and numerical computing libraries.\n* [Breeze](https://github.com/scalanlp/breeze) - Breeze is a numerical processing library for Scala.\n* [Chalk](https://github.com/scalanlp/chalk) - Chalk is a natural language processing library. **[Deprecated]**\n* [FACTORIE](https://github.com/factorie/factorie) - FACTORIE is a toolkit for deployable probabilistic modeling, implemented as a software library in Scala. It provides its users with a succinct language for creating relational factor graphs, estimating parameters and performing inference.\n* [Montague](https://github.com/Workday/upshot-montague) - Montague is a semantic parsing library for Scala with an easy-to-use DSL.\n* [Spark NLP](https://github.com/JohnSnowLabs/spark-nlp) - Natural language processing library built on top of Apache Spark ML to provide simple, performant, and accurate NLP annotations for machine learning pipelines, that scale easily in a distributed environment.\n\n<a name=""scala-data-analysis""></a>\n#### Data Analysis / Data Visualization\n\n* [MLlib in Apache Spark](https://spark.apache.org/docs/latest/mllib-guide.html) - Distributed machine learning library in Spark\n* [Hydrosphere Mist](https://github.com/Hydrospheredata/mist) - a service for deployment Apache Spark MLLib machine learning models as realtime, batch or reactive web services.\n* [Scalding](https://github.com/twitter/scalding) - A Scala API for Cascading.\n* [Summing Bird](https://github.com/twitter/summingbird) - Streaming MapReduce with Scalding and Storm.\n* [Algebird](https://github.com/twitter/algebird) - Abstract Algebra for Scala.\n* [xerial](https://github.com/xerial/xerial) - Data management utilities for Scala. **[Deprecated]**\n* [PredictionIO](https://github.com/apache/predictionio) - PredictionIO, a machine learning server for software developers and data engineers.\n* [BIDMat](https://github.com/BIDData/BIDMat) - CPU and GPU-accelerated matrix library intended to support large-scale exploratory data analysis.\n* [Flink](https://flink.apache.org/) - Open source platform for distributed stream and batch data processing.\n* [Spark Notebook](http://spark-notebook.io) - Interactive and Reactive Data Science using Scala and Spark.\n\n<a name=""scala-general-purpose""></a>\n#### General-Purpose Machine Learning\n\n* [DeepLearning.scala](https://deeplearning.thoughtworks.school/) - Creating statically typed dynamic neural networks from object-oriented & functional programming constructs.\n* [Conjecture](https://github.com/etsy/Conjecture) - Scalable Machine Learning in Scalding.\n* [brushfire](https://github.com/stripe/brushfire) - Distributed decision tree ensemble learning in Scala.\n* [ganitha](https://github.com/tresata/ganitha) - Scalding powered machine learning. **[Deprecated]**\n* [adam](https://github.com/bigdatagenomics/adam) - A genomics processing engine and specialized file format built using Apache Avro, Apache Spark and Parquet. Apache 2 licensed.\n* [bioscala](https://github.com/bioscala/bioscala) - Bioinformatics for the Scala programming language\n* [BIDMach](https://github.com/BIDData/BIDMach) - CPU and GPU-accelerated Machine Learning Library.\n* [Figaro](https://github.com/p2t2/figaro) - a Scala library for constructing probabilistic models.\n* [H2O Sparkling Water](https://github.com/h2oai/sparkling-water) - H2O and Spark interoperability.\n* [FlinkML in Apache Flink](https://ci.apache.org/projects/flink/flink-docs-master/dev/libs/ml/index.html) - Distributed machine learning library in Flink.\n* [DynaML](https://github.com/transcendent-ai-labs/DynaML) - Scala Library/REPL for Machine Learning Research.\n* [Saul](https://github.com/CogComp/saul) - Flexible Declarative Learning-Based Programming.\n* [SwiftLearner](https://github.com/valdanylchuk/swiftlearner/) - Simply written algorithms to help study ML or write your own implementations.\n* [Smile](https://haifengl.github.io/smile/) - Statistical Machine Intelligence and Learning Engine.\n* [doddle-model](https://github.com/picnicml/doddle-model) - An in-memory machine learning library built on top of Breeze. It provides immutable objects and exposes its functionality through a scikit-learn-like API.\n* [TensorFlow Scala](https://github.com/eaplatanios/tensorflow_scala) -   Strongly-typed Scala API for TensorFlow.\n\n<a name=""scheme""></a>\n## Scheme\n\n<a name=""scheme-neural-networks""></a>\n#### Neural Networks\n\n* [layer](https://github.com/cloudkj/layer) - Neural network inference from the command line, implemented in [CHICKEN Scheme](https://www.call-cc.org/).\n\n<a name=""swift""></a>\n## Swift\n\n<a name=""swift-general-purpose""></a>\n#### General-Purpose Machine Learning\n\n* [Bender](https://github.com/xmartlabs/Bender) - Fast Neural Networks framework built on top of Metal. Supports TensorFlow models.\n* [Swift AI](https://github.com/Swift-AI/Swift-AI) - Highly optimized artificial intelligence and machine learning library written in Swift.\n* [Swift for Tensorflow](https://github.com/tensorflow/swift) - a next-generation platform for machine learning, incorporating the latest research across machine learning, compilers, differentiable programming, systems design, and beyond.\n* [BrainCore](https://github.com/alejandro-isaza/BrainCore) - The iOS and OS X neural network framework.\n* [swix](https://github.com/stsievert/swix) - A bare bones library that includes a general matrix language and wraps some OpenCV for iOS development. **[Deprecated]**\n* [AIToolbox](https://github.com/KevinCoble/AIToolbox) - A toolbox framework of AI modules written in Swift: Graphs/Trees, Linear Regression, Support Vector Machines, Neural Networks, PCA, KMeans, Genetic Algorithms, MDP, Mixture of Gaussians.\n* [MLKit](https://github.com/Somnibyte/MLKit) - A simple Machine Learning Framework written in Swift. Currently features Simple Linear Regression, Polynomial Regression, and Ridge Regression.\n* [Swift Brain](https://github.com/vlall/Swift-Brain) - The first neural network / machine learning library written in Swift. This is a project for AI algorithms in Swift for iOS and OS X development. This project includes algorithms focused on Bayes theorem, neural networks, SVMs, Matrices, etc...\n* [Perfect TensorFlow](https://github.com/PerfectlySoft/Perfect-TensorFlow) - Swift Language Bindings of TensorFlow. Using native TensorFlow models on both macOS / Linux.\n* [PredictionBuilder](https://github.com/denissimon/prediction-builder-swift) - A library for machine learning that builds predictions using a linear regression.\n* [Awesome CoreML](https://github.com/SwiftBrain/awesome-CoreML-models) - A curated list of pretrained CoreML models.\n* [Awesome Core ML Models](https://github.com/likedan/Awesome-CoreML-Models) - A curated list of machine learning models in CoreML format.\n\n<a name=""tensor""></a>\n## TensorFlow\n\n<a name=""tensor-general-purpose""></a>\n#### General-Purpose Machine Learning\n* [Awesome TensorFlow](https://github.com/jtoy/awesome-tensorflow) - A list of all things related to TensorFlow.\n* [Golden TensorFlow](https://golden.com/wiki/TensorFlow) - A page of content on TensorFlow, including academic papers and links to related topics.\n\n<a name=""tools""></a>\n## Tools\n\n<a name=""tools-neural-networks""></a>\n#### Neural Networks\n* [layer](https://github.com/cloudkj/layer) - Neural network inference from the command line\n\n<a name=""tools-misc""></a>\n#### Misc\n* [ML Workspace](https://github.com/ml-tooling/ml-workspace) - All-in-one web-based IDE for machine learning and data science. The workspace is deployed as a docker container and is preloaded with a variety of popular data science libraries (e.g., Tensorflow, PyTorch) and dev tools (e.g., Jupyter, VS Code).\n* [Notebooks](https://github.com/rlan/notebooks) - A starter kit for Jupyter notebooks and machine learning. Companion docker images consist of all combinations of python versions, machine learning frameworks (Keras, PyTorch and Tensorflow) and CPU/CUDA versions.\n* [DVC](https://github.com/iterative/dvc) - Data Science Version Control is an open-source version control system for machine learning projects with pipelines support. It makes ML projects reproducible and shareable.\n* [Kedro](https://github.com/quantumblacklabs/kedro/) - Kedro is a data and development workflow framework that implements best practices for data pipelines with an eye towards productionizing machine learning models.\n* [guild.ai](https://guild.ai/) - Tool to log, analyze, compare and ""optimize"" experiments. It\'s cross-platform and framework independent, and provided integrated visualizers such as tensorboard.\n* [Sacred](https://github.com/IDSIA/sacred) - Python tool to help  you configure, organize, log and reproduce experiments. Like a notebook lab in the context of Chemestry/Biology. The community has built multiple add-ons leveraging the proposed standard.\n* [MLFlow](https://mlflow.org/) - platform to manage the ML lifecycle, including experimentation, reproducibility and deployment. Framework anf language agnostic, take a look at all the built-in integrations.\n* More tools to improve the ML lifecycle: [Catalyst](https://github.com/catalyst-team/catalyst), [PachydermIO](https://www.pachyderm.io/). The following are Github-alike and targetting teams [Weights & Biases](https://www.wandb.com/), [Neptune.Ml](https://neptune.ml/), [Comet.ml](https://www.comet.ml/), [Valohai.ai](https://valohai.com/).\n* [MachineLearningWithTensorFlow2ed](https://www.manning.com/books/machine-learning-with-tensorflow-second-edition) - a book on general purpose machine learning techniques regression, classification, unsupervised clustering, reinforcement learning, auto encoders, convolutional neural networks, RNNs, LSTMs, using TensorFlow 1.14.1.\n* [m2cgen](https://github.com/BayesWitnesses/m2cgen) - A tool that allows the conversion of ML models into native code (Java, C, Python, Go, JavaScript, Visual Basic, C#, R, PowerShell, PHP, Dart) with zero dependencies.\n\n<a name=""credits""></a>\n## Credits\n\n* Some of the python libraries were cut-and-pasted from [vinta](https://github.com/vinta/awesome-python)\n* References for Go were mostly cut-and-pasted from [gopherdata](https://github.com/gopherdata/resources/tree/master/tooling)\n'"
1,wepe/MachineLearning,wepe,Basic Machine Learning and Deep Learning,2014-12-05 14:53:17,2020-06-18 05:45:20,Python,2791,3800,b'MachineLearning\n====================\n\n\n\n\xe4\xb8\x80\xe4\xba\x9b\xe5\xb8\xb8\xe8\xa7\x81\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xae\x97\xe6\xb3\x95\xe7\x9a\x84\xe5\xae\x9e\xe7\x8e\xb0\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x8c\xe6\x9c\xac\xe4\xba\xba\xe5\xad\xa6\xe4\xb9\xa0\xe8\xbf\x87\xe7\xa8\x8b\xe4\xb8\xad\xe5\x81\x9a\xe7\x9a\x84\xe6\x80\xbb\xe7\xbb\x93\xef\xbc\x8c\xe8\xb5\x84\xe5\x8e\x86\xe5\xb0\x9a\xe6\xb5\x85\xef\xbc\x8c\xe5\xa6\x82\xe6\x9c\x89\xe9\x94\x99\xe8\xaf\xaf\xe8\xaf\xb7\xe4\xb8\x8d\xe5\x90\x9d\xe6\x8c\x87\xe5\x87\xba\xe3\x80\x82\n\n\n## \xe7\x9b\xae\xe5\xbd\x95\xe4\xbb\x8b\xe7\xbb\x8d\n\n- **DeepLearning Tutorials**\n\n   \xe8\xbf\x99\xe4\xb8\xaa\xe6\x96\x87\xe4\xbb\xb6\xe5\xa4\xb9\xe4\xb8\x8b\xe5\x8c\x85\xe5\x90\xab\xe4\xb8\x80\xe4\xba\x9b\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe7\xae\x97\xe6\xb3\x95\xe7\x9a\x84\xe5\xae\x9e\xe7\x8e\xb0\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x8c\xe4\xbb\xa5\xe5\x8f\x8a\xe5\x85\xb7\xe4\xbd\x93\xe7\x9a\x84\xe5\xba\x94\xe7\x94\xa8\xe5\xae\x9e\xe4\xbe\x8b\xef\xbc\x8c\xe5\x8c\x85\xe5\x90\xab\xef\xbc\x9a\n\n   [dive_into _keras](https://github.com/wepe/MachineLearning/tree/master/DeepLearning%20Tutorials/dive_into_keras) Keras\xe4\xbd\xbf\xe7\x94\xa8\xe8\xbf\x9b\xe9\x98\xb6\xe3\x80\x82\xe4\xbb\x8b\xe7\xbb\x8d\xe4\xba\x86\xe6\x80\x8e\xe4\xb9\x88\xe4\xbf\x9d\xe5\xad\x98\xe8\xae\xad\xe7\xbb\x83\xe5\xa5\xbd\xe7\x9a\x84CNN\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x8c\xe6\x80\x8e\xe4\xb9\x88\xe5\xb0\x86CNN\xe7\x94\xa8\xe4\xbd\x9c\xe7\x89\xb9\xe5\xbe\x81\xe6\x8f\x90\xe5\x8f\x96\xef\xbc\x8c\xe6\x80\x8e\xe4\xb9\x88\xe5\x8f\xaf\xe8\xa7\x86\xe5\x8c\x96\xe5\x8d\xb7\xe7\xa7\xaf\xe5\x9b\xbe\xe3\x80\x82[\xe6\x96\x87\xe7\xab\xa0\xe9\x93\xbe\xe6\x8e\xa5](http://blog.csdn.net/u012162613/article/details/45581421)\xef\xbc\x8c \xe6\x9b\xb4\xe5\xa4\x9a\xe8\xbf\x9b\xe9\x98\xb6\xe4\xbd\xbf\xe7\x94\xa8\xe6\x96\xb9\xe6\xb3\x95\xef\xbc\x9a[gist](https://gist.github.com/wepe/a05ad572dca002046de443061909ff7a)\n      \n   [keras_usage](https://github.com/wepe/MachineLearning/tree/master/DeepLearning%20Tutorials/keras_usage) \xe4\xbb\x8b\xe7\xbb\x8d\xe4\xba\x86\xe4\xb8\x80\xe4\xb8\xaa\xe7\xae\x80\xe5\x8d\x95\xe6\x98\x93\xe7\x94\xa8\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe6\xa1\x86\xe6\x9e\xb6keras\xef\xbc\x8c\xe7\x94\xa8\xe7\xbb\x8f\xe5\x85\xb8\xe7\x9a\x84Mnist\xe5\x88\x86\xe7\xb1\xbb\xe9\x97\xae\xe9\xa2\x98\xe5\xaf\xb9\xe8\xaf\xa5\xe6\xa1\x86\xe6\x9e\xb6\xe7\x9a\x84\xe4\xbd\xbf\xe7\x94\xa8\xe8\xbf\x9b\xe8\xa1\x8c\xe8\xaf\xb4\xe6\x98\x8e\xef\xbc\x8c\xe8\xae\xad\xe7\xbb\x83\xe4\xb8\x80\xe4\xb8\xaaCNN\xef\xbc\x8c\xe6\x80\xbb\xe5\x85\xb1\xe4\xb8\x8d\xe8\xb6\x85\xe8\xbf\x8730\xe8\xa1\x8c\xe4\xbb\xa3\xe7\xa0\x81\xe3\x80\x82[\xe6\x96\x87\xe7\xab\xa0\xe9\x93\xbe\xe6\x8e\xa5](http://blog.csdn.net/u012162613/article/details/45397033)\n\n   [FaceRecognition_CNN(olivettifaces)](https://github.com/wepe/MachineLearning-Demo/tree/master/DeepLearning%20Tutorials/FaceRecognition_CNN(olivettifaces))\n      \xe5\xb0\x86\xe5\x8d\xb7\xe7\xa7\xaf\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9cCNN\xe5\xba\x94\xe7\x94\xa8\xe4\xba\x8e\xe4\xba\xba\xe8\x84\xb8\xe8\xaf\x86\xe5\x88\xab\xe7\x9a\x84\xe4\xb8\x80\xe4\xb8\xaademo\xef\xbc\x8c\xe4\xba\xba\xe8\x84\xb8\xe6\x95\xb0\xe6\x8d\xae\xe5\xba\x93\xe9\x87\x87\xe7\x94\xa8olivettifaces\xef\xbc\x8cCNN\xe6\xa8\xa1\xe5\x9e\x8b\xe5\x8f\x82\xe8\x80\x83LeNet5\xef\xbc\x8c\xe5\x9f\xba\xe4\xba\x8epython+theano+numpy+PIL\xe5\xae\x9e\xe7\x8e\xb0\xe3\x80\x82\xe8\xaf\xa6\xe7\xbb\x86\xe4\xbb\x8b\xe7\xbb\x8d\xe8\xbf\x99\xe4\xb8\xaademo\xe7\x9a\x84\xe6\x96\x87\xe7\xab\xa0\xef\xbc\x9a[\xe6\x96\x87\xe7\xab\xa0\xe9\x93\xbe\xe6\x8e\xa5](http://blog.csdn.net/u012162613/article/details/43277187)\n\n\n   [cnn_LeNet](https://github.com/wepe/MachineLearning-Demo/tree/master/DeepLearning%20Tutorials/cnn_LeNet)  CNN\xe5\x8d\xb7\xe7\xa7\xaf\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe7\xae\x97\xe6\xb3\x95\xe7\x9a\x84\xe5\xae\x9e\xe7\x8e\xb0\xef\xbc\x8c\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xb8\xba\xe7\xae\x80\xe5\x8c\x96\xe7\x89\x88\xe7\x9a\x84LeNet\xef\xbc\x8c\xe5\xba\x94\xe7\x94\xa8\xe4\xba\x8eMNIST\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xef\xbc\x88\xe6\x89\x8b\xe5\x86\x99\xe6\x95\xb0\xe5\xad\x97\xef\xbc\x89\xef\xbc\x8c\xe6\x9d\xa5\xe8\x87\xaa\xe4\xba\x8eDeepLearning.net\xe4\xb8\x8a\xe7\x9a\x84\xe4\xb8\x80\xe4\xb8\xaa\xe6\x95\x99\xe7\xa8\x8b\xef\xbc\x8c\xe5\x9f\xba\xe4\xba\x8epython+theano\xef\xbc\x8c\xe6\x88\x91\xe7\x94\xa8\xe4\xba\x86\xe4\xb8\xad\xe6\x96\x87\xe5\xb0\x86\xe5\x8e\x9f\xe5\xa7\x8b\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81\xe8\xbf\x9b\xe8\xa1\x8c\xe8\xaf\xa6\xe7\xbb\x86\xe7\x9a\x84\xe8\xa7\xa3\xe8\xaf\xbb\xef\xbc\x8c\xe5\xb9\xb6\xe7\xae\x80\xe5\x8d\x95\xe6\x80\xbb\xe7\xbb\x93\xe4\xba\x86CNN\xe7\xae\x97\xe6\xb3\x95\xef\xbc\x8c\xe7\x9b\xb8\xe5\xba\x94\xe7\x9a\x84\xe6\x96\x87\xe7\xab\xa0\xe5\x8f\x91\xe5\x9c\xa8\xef\xbc\x9a[\xe6\x96\x87\xe7\xab\xa0\xe9\x93\xbe\xe6\x8e\xa5](http://blog.csdn.net/u012162613/article/details/43225445)\n\n   [mlp](https://github.com/wepe/MachineLearning-Demo/tree/master/DeepLearning%20Tutorials/mlp)  \xe5\xa4\x9a\xe5\xb1\x82\xe6\x84\x9f\xe7\x9f\xa5\xe6\x9c\xba\xe7\xae\x97\xe6\xb3\x95\xe7\x9a\x84\xe5\xae\x9e\xe7\x8e\xb0\xef\xbc\x8c\xe4\xbb\xa3\xe7\xa0\x81\xe5\xae\x9e\xe7\x8e\xb0\xe4\xba\x86\xe6\x9c\x80\xe7\xae\x80\xe5\x8d\x95\xe7\x9a\x84\xe4\xb8\x89\xe5\xb1\x82\xe6\x84\x9f\xe7\x9f\xa5\xe6\x9c\xba\xef\xbc\x8c\xe5\xb9\xb6\xe5\xba\x94\xe7\x94\xa8\xe4\xba\x8eMNIST\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xef\xbc\x8c\xe6\x9d\xa5\xe8\x87\xaaDeepLearning.net\xe4\xb8\x8a\xe7\x9a\x84\xe4\xb8\x80\xe4\xb8\xaa\xe6\x95\x99\xe7\xa8\x8b\xef\xbc\x8c\xe5\x9f\xba\xe4\xba\x8epython+theano\xef\xbc\x8c\xe6\x88\x91\xe5\x86\x99\xe4\xba\x86\xe4\xb8\x80\xe7\xaf\x87\xe6\x96\x87\xe7\xab\xa0\xe6\x80\xbb\xe7\xbb\x93\xe4\xbb\x8b\xe7\xbb\x8d\xe4\xba\x86MLP\xe7\xae\x97\xe6\xb3\x95\xef\xbc\x8c\xe5\x90\x8c\xe6\x97\xb6\xe7\x94\xa8\xe4\xb8\xad\xe6\x96\x87\xe8\xaf\xa6\xe7\xbb\x86\xe8\xa7\xa3\xe8\xaf\xbb\xe4\xba\x86\xe5\x8e\x9f\xe5\xa7\x8b\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a[\xe6\x96\x87\xe7\xab\xa0\xe9\x93\xbe\xe6\x8e\xa5](http://blog.csdn.net/u012162613/article/details/43221829)\n\n   [Softmax_sgd(or logistic_sgd)](https://github.com/wepe/MachineLearning-Demo/tree/master/DeepLearning%20Tutorials/Softmax_sgd(or%20logistic_sgd)) Softmax\xe5\x9b\x9e\xe5\xbd\x92\xe7\xae\x97\xe6\xb3\x95\xe7\x9a\x84\xe5\xae\x9e\xe7\x8e\xb0\xef\xbc\x8c\xe5\xba\x94\xe7\x94\xa8\xe4\xba\x8eMNIST\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xef\xbc\x8c\xe5\x9f\xba\xe4\xba\x8ePython+theano\xef\xbc\x8c\xe6\x9d\xa5\xe8\x87\xaaDeepLearning.net\xe4\xb8\x8a\xe7\x9a\x84\xe4\xb8\x80\xe4\xb8\xaa\xe6\x95\x99\xe7\xa8\x8b\xef\xbc\x8c\xe5\x9f\xba\xe4\xba\x8epython+theano\xef\xbc\x8c\xe6\x88\x91\xe5\x86\x99\xe4\xba\x86\xe4\xb8\x80\xe7\xaf\x87\xe6\x96\x87\xe7\xab\xa0\xe4\xbb\x8b\xe7\xbb\x8d\xe4\xba\x86Softmax\xe5\x9b\x9e\xe5\xbd\x92\xe7\xae\x97\xe6\xb3\x95\xef\xbc\x8c\xe5\x90\x8c\xe6\x97\xb6\xe7\x94\xa8\xe4\xb8\xad\xe6\x96\x87\xe8\xaf\xa6\xe7\xbb\x86\xe8\xa7\xa3\xe8\xaf\xbb\xe4\xba\x86\xe5\x8e\x9f\xe5\xa7\x8b\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a[\xe6\x96\x87\xe7\xab\xa0\xe9\x93\xbe\xe6\x8e\xa5](http://blog.csdn.net/u012162613/article/details/43157801)\n\n- **PCA**\n\n   \xe5\x9f\xba\xe4\xba\x8epython+numpy\xe5\xae\x9e\xe7\x8e\xb0\xe4\xba\x86\xe4\xb8\xbb\xe6\x88\x90\xe4\xbb\xbd\xe5\x88\x86\xe6\x9e\x90PCA\xe7\xae\x97\xe6\xb3\x95\xef\xbc\x8c\xe8\xbf\x99\xe9\x87\x8c\xe8\xaf\xa6\xe7\xbb\x86\xe5\x9c\xb0\xe4\xbb\x8b\xe7\xbb\x8d\xe4\xba\x86PCA\xe7\xae\x97\xe6\xb3\x95\xef\xbc\x8c\xe4\xbb\xa5\xe5\x8f\x8a\xe4\xbb\xa3\xe7\xa0\x81\xe5\xbc\x80\xe5\x8f\x91\xe6\xb5\x81\xe7\xa8\x8b\xef\xbc\x9a[\xe6\x96\x87\xe7\xab\xa0\xe9\x93\xbe\xe6\x8e\xa5](http://blog.csdn.net/u012162613/article/details/42177327)\n\n- **kNN**\n      \n   \xe5\x9f\xba\xe4\xba\x8epython+numpy\xe5\xae\x9e\xe7\x8e\xb0\xe4\xba\x86K\xe8\xbf\x91\xe9\x82\xbb\xe7\xae\x97\xe6\xb3\x95\xef\xbc\x8c\xe5\xb9\xb6\xe5\xb0\x86\xe5\x85\xb6\xe5\xba\x94\xe7\x94\xa8\xe5\x9c\xa8MNIST\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe4\xb8\x8a\xef\xbc\x8c\xe8\xaf\xa6\xe7\xbb\x86\xe7\x9a\x84\xe4\xbb\x8b\xe7\xbb\x8d\xef\xbc\x9a[\xe6\x96\x87\xe7\xab\xa0\xe9\x93\xbe\xe6\x8e\xa5](http://blog.csdn.net/u012162613/article/details/41768407)\n\n- **logistic regression**\n\n   - \xe5\x9f\xba\xe4\xba\x8eC++\xe4\xbb\xa5\xe5\x8f\x8a\xe7\xba\xbf\xe6\x80\xa7\xe4\xbb\xa3\xe6\x95\xb0\xe5\xba\x93Eigen\xe5\xae\x9e\xe7\x8e\xb0\xe7\x9a\x84logistic\xe5\x9b\x9e\xe5\xbd\x92\xef\xbc\x8c[\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/wepe/MachineLearning/tree/master/logistic%20regression/use_cpp_and_eigen)\n\n   - \xe5\x9f\xba\xe4\xba\x8epython+numpy\xe5\xae\x9e\xe7\x8e\xb0\xe4\xba\x86logistic\xe5\x9b\x9e\xe5\xbd\x92\xef\xbc\x88\xe4\xba\x8c\xe7\xb1\xbb\xe5\x88\xab\xef\xbc\x89\xef\xbc\x8c\xe8\xaf\xa6\xe7\xbb\x86\xe7\x9a\x84\xe4\xbb\x8b\xe7\xbb\x8d\xef\xbc\x9a[\xe6\x96\x87\xe7\xab\xa0\xe9\x93\xbe\xe6\x8e\xa5](http://blog.csdn.net/u012162613/article/details/41844495)\n\n- **ManifoldLearning**\n\n\t[DimensionalityReduction_DataVisualizing](https://github.com/wepe/MachineLearning/tree/master/ManifoldLearning/DimensionalityReduction_DataVisualizing) \xe8\xbf\x90\xe7\x94\xa8\xe5\xa4\x9a\xe7\xa7\x8d\xe6\xb5\x81\xe5\xbd\xa2\xe5\xad\xa6\xe4\xb9\xa0\xe6\x96\xb9\xe6\xb3\x95\xe5\xb0\x86\xe9\xab\x98\xe7\xbb\xb4\xe6\x95\xb0\xe6\x8d\xae\xe9\x99\x8d\xe7\xbb\xb4\xef\xbc\x8c\xe5\xb9\xb6\xe7\x94\xa8matplotlib\xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe5\x8f\xaf\xe8\xa7\x86\xe5\x8c\x96(2\xe7\xbb\xb4\xe5\x92\x8c3\xe7\xbb\xb4)\n     \n- **SVM**    \n\n\t[libsvm liblinear-usage](https://github.com/wepe/MachineLearning/tree/master/SVM/libsvm%20liblinear-usage) \xe5\xaf\xb9\xe4\xbd\xbf\xe7\x94\xa8\xe5\xb9\xbf\xe6\xb3\x9b\xe7\x9a\x84libsvm\xe3\x80\x81liblinear\xe7\x9a\x84\xe4\xbd\xbf\xe7\x94\xa8\xe6\x96\xb9\xe6\xb3\x95\xe8\xbf\x9b\xe8\xa1\x8c\xe4\xba\x86\xe6\x80\xbb\xe7\xbb\x93\xef\xbc\x8c\xe8\xaf\xa6\xe7\xbb\x86\xe4\xbb\x8b\xe7\xbb\x8d\xef\xbc\x9a[\xe6\x96\x87\xe7\xab\xa0\xe9\x93\xbe\xe6\x8e\xa5](http://blog.csdn.net/u012162613/article/details/45206813)\n\n    [SVM by SMO](./SVM/SVM_by_SMO) - \xe7\x94\xa8SMO\xe5\xae\x9e\xe7\x8e\xb0\xe4\xba\x86SVM\n\n    [SVM by QP](./SVM/SVM_by_QP) - \xe7\x94\xa8\xe4\xba\x8c\xe6\xac\xa1\xe7\xbc\x96\xe7\xa8\x8b\xef\xbc\x88QP\xef\xbc\x89\xe5\xae\x9e\xe7\x8e\xb0\xe4\xba\x86SVM\n\n\n- **GMM**\n\n\tGMM\xe5\x92\x8ck-means\xe4\xbd\x9c\xe4\xb8\xbaEM\xe7\xae\x97\xe6\xb3\x95\xe7\x9a\x84\xe5\xba\x94\xe7\x94\xa8\xef\xbc\x8c\xe5\x9c\xa8\xe6\x9f\x90\xe7\xa7\x8d\xe7\xa8\x8b\xe5\xba\xa6\xe6\x9c\x89\xe4\xba\x9b\xe7\x9b\xb8\xe4\xbc\xbc\xe4\xb9\x8b\xe5\xa4\x84\xef\xbc\x8c\xe4\xb8\x8d\xe8\xbf\x87GMM\xe6\x98\x8e\xe6\x98\xbe\xe5\xad\xa6\xe4\xb9\xa0\xe5\x87\xba\xe4\xb8\x80\xe4\xba\x9b\xe6\xa6\x82\xe7\x8e\x87\xe5\xaf\x86\xe5\xba\xa6\xe5\x87\xbd\xe6\x95\xb0\xe6\x9d\xa5\xef\xbc\x8c\xe7\xbb\x93\xe5\x90\x88\xe7\x9b\xb8\xe5\x85\xb3\xe7\x90\x86\xe8\xa7\xa3\xe5\x86\x99\xe6\x88\x90python\xe7\x89\x88\xe6\x9c\xac\xef\xbc\x8c\xe8\xaf\xa6\xe7\xbb\x86\xe4\xbb\x8b\xe7\xbb\x8d\xef\xbc\x9a[\xe6\x96\x87\xe7\xab\xa0\xe9\x93\xbe\xe6\x8e\xa5](http://blog.csdn.net/gugugujiawei/article/details/45583051)\n\n- **DecisionTree**\n\n\tPython\xe3\x80\x81Numpy\xe3\x80\x81Matplotlib\xe5\xae\x9e\xe7\x8e\xb0\xe7\x9a\x84ID3\xe3\x80\x81C4.5\xef\xbc\x8c\xe5\x85\xb6\xe4\xb8\xadC4.5\xe6\x9c\x89\xe5\xbe\x85\xe5\xae\x8c\xe5\x96\x84\xef\xbc\x8c\xe5\x90\x8e\xe7\xbb\xad\xe5\x8a\xa0\xe5\x85\xa5CART\xe3\x80\x82\xe6\x96\x87\xe7\xab\xa0\xe5\xbe\x85\xe6\x80\xbb\xe7\xbb\x93\xe3\x80\x82[\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/wepe/MachineLearning/tree/master/DecisionTree)\n\n- **KMeans**\n\n\t\xe4\xbb\x8b\xe7\xbb\x8d\xe4\xba\x86\xe8\x81\x9a\xe7\xb1\xbb\xe5\x88\x86\xe6\x9e\x90\xe4\xb8\xad\xe6\x9c\x80\xe5\xb8\xb8\xe7\x94\xa8\xe7\x9a\x84KMeans\xe7\xae\x97\xe6\xb3\x95\xef\xbc\x88\xe5\x8f\x8a\xe4\xba\x8c\xe5\x88\x86KMeans\xe7\xae\x97\xe6\xb3\x95\xef\xbc\x89\xef\xbc\x8c\xe5\x9f\xba\xe4\xba\x8eNumPy\xe7\x9a\x84\xe7\xae\x97\xe6\xb3\x95\xe5\xae\x9e\xe7\x8e\xb0\xef\xbc\x8c\xe4\xbb\xa5\xe5\x8f\x8a\xe5\x9f\xba\xe4\xba\x8eMatplotlib\xe7\x9a\x84\xe8\x81\x9a\xe7\xb1\xbb\xe8\xbf\x87\xe7\xa8\x8b\xe5\x8f\xaf\xe8\xa7\x86\xe5\x8c\x96\xe3\x80\x82[\xe6\x96\x87\xe7\xab\xa0\xe9\x93\xbe\xe6\x8e\xa5](http://blog.csdn.net/u012162613/article/details/47811235)\n\n- **NaiveBayes**\n\n\t\xe6\x9c\xb4\xe7\xb4\xa0\xe8\xb4\x9d\xe5\x8f\xb6\xe6\x96\xaf\xe7\xae\x97\xe6\xb3\x95\xe7\x9a\x84\xe7\x90\x86\xe8\xae\xba\xe6\x8e\xa8\xe5\xaf\xbc\xef\xbc\x8c\xe4\xbb\xa5\xe5\x8f\x8a\xe4\xb8\x89\xe7\xa7\x8d\xe5\xb8\xb8\xe8\xa7\x81\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x88\xe5\xa4\x9a\xe9\xa1\xb9\xe5\xbc\x8f\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x8c\xe9\xab\x98\xe6\x96\xaf\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x8c\xe4\xbc\xaf\xe5\x8a\xaa\xe5\x88\xa9\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x89\xe7\x9a\x84\xe4\xbb\x8b\xe7\xbb\x8d\xe4\xb8\x8e\xe7\xbc\x96\xe7\xa8\x8b\xe5\xae\x9e\xe7\x8e\xb0\xef\xbc\x88\xe5\x9f\xba\xe4\xba\x8ePython\xef\xbc\x8cNumpy\xef\xbc\x89\xe3\x80\x82[\xe6\x96\x87\xe7\xab\xa0\xe9\x93\xbe\xe6\x8e\xa5](http://blog.csdn.net/u012162613/article/details/48323777)\n\n- **Ridge and Kernel Ridge**\n\n    \xe4\xbb\x8b\xe7\xbb\x8d\xe4\xba\x86Ridge\xe5\x9b\x9e\xe5\xbd\x92\xe5\x92\x8c\xe5\xae\x83\xe7\x9a\x84Kernel\xe7\x89\x88\xe6\x9c\xac\xe3\x80\x82[\xe4\xbb\xa3\xe7\xa0\x81](./Ridge/kernel_ridge/kernel_ridge.py)\n\n## Contributor\n\n- [wepon](https://github.com/wepe)\n- [Gogary](https://github.com/enjoyhot)\n- [Locky](https://github.com/junlulocky)\n'
2,udacity/machine-learning,udacity,Content for Udacity's Machine Learning curriculum,2016-01-26 18:41:03,2020-06-17 17:38:13,Jupyter Notebook,6093,3214,"b'# machine-learning\nContent for Udacity\'s Machine Learning curriculum, which includes projects and their descriptions.\n\n<a rel=""license"" href=""http://creativecommons.org/licenses/by-nc-nd/4.0/""><img alt=""Creative Commons License"" style=""border-width:0"" src=""https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png"" /></a><br />This work is licensed under a <a rel=""license"" href=""http://creativecommons.org/licenses/by-nc-nd/4.0/"">Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License</a>. Please refer to [Udacity Terms of Service](https://www.udacity.com/legal) for further information.\n'"
3,ZuzooVn/machine-learning-for-software-engineers,ZuzooVn,A complete daily plan for studying to become a machine learning engineer.,2016-10-09 21:20:25,2020-06-18 18:12:33,,5619,23851,"b'# Top-down learning path: Machine Learning for Software Engineers\n\n<p align=""center"">\n  <a href=""https://github.com/ZuzooVn/machine-learning-for-software-engineers"">\n    <img alt=""Top-down learning path: Machine Learning for Software Engineers"" src=""https://img.shields.io/badge/Machine%20Learning-Software%20Engineers-blue.svg"">\n  </a>\n  <a href=""https://github.com/ZuzooVn/machine-learning-for-software-engineers/stargazers"">\n    <img alt=""GitHub stars"" src=""https://img.shields.io/github/stars/ZuzooVn/machine-learning-for-software-engineers.svg"">\n  </a>\n  <a href=""https://github.com/ZuzooVn/machine-learning-for-software-engineers/network"">\n    <img alt=""GitHub forks"" src=""https://img.shields.io/github/forks/ZuzooVn/machine-learning-for-software-engineers.svg"">\n  </a>\n</p>\n\nInspired by [Coding Interview University](https://github.com/jwasham/coding-interview-university).\n\nTranslations: [Brazilian Portuguese](https://github.com/ZuzooVn/machine-learning-for-software-engineers/blob/master/README-pt-BR.md) | [\xe4\xb8\xad\xe6\x96\x87\xe7\x89\x88\xe6\x9c\xac](https://github.com/ZuzooVn/machine-learning-for-software-engineers/blob/master/README-zh-CN.md) | [Fran\xc3\xa7ais](https://github.com/ZuzooVn/machine-learning-for-software-engineers/blob/master/README-fr-FR.md) | [\xe8\x87\xba\xe7\x81\xa3\xe8\x8f\xaf\xe8\xaa\x9e\xe7\x89\x88\xe6\x9c\xac](https://github.com/ZuzooVn/machine-learning-for-software-engineers/blob/master/README-zh-TW.md)\n\n[How I (Nam Vu) plan to become a machine learning engineer](https://www.codementor.io/zuzoovn/how-i-plan-to-become-a-machine-learning-engineer-a4metbcuk)\n\n## What is it?\n\nThis is my multi-month study plan for going from mobile developer (self-taught, no CS degree) to machine learning engineer.\n\nMy main goal was to find an approach to studying Machine Learning that is mainly hands-on and abstracts most of the Math for the beginner.\nThis approach is unconventional because it\xe2\x80\x99s the top-down and results-first approach designed for software engineers.\n\nPlease, feel free to make any contributions you feel will make it better.\n\n---\n\n## Table of Contents\n\n- [What is it?](#what-is-it)\n- [Why use it?](#why-use-it)\n- [How to use it](#how-to-use-it)\n- [Follow me](#follow-me)\n- [Don\'t feel you aren\'t smart enough](#dont-feel-you-arent-smart-enough)\n- [About Video Resources](#about-video-resources)\n- [Prerequisite Knowledge](#prerequisite-knowledge)\n- [The Daily Plan](#the-daily-plan)\n- [Motivation](#motivation)\n- [Machine learning overview](#machine-learning-overview)\n- [Machine learning mastery](#machine-learning-mastery)\n- [Machine learning is fun](#machine-learning-is-fun)\n- [Inky Machine Learning](#inky-machine-learning)\n- [Machine Learning: An In-Depth Guide](#machine-learning-an-in-depth-guide)\n- [Stories and experiences](#stories-and-experiences)\n- [Machine Learning Algorithms](#machine-learning-algorithms)\n- [Beginner Books](#beginner-books)\n- [Practical Books](#practical-books)\n- [Kaggle knowledge competitions](#kaggle-knowledge-competitions)\n- [Video Series](#video-series)\n- [MOOC](#mooc)\n- [Resources](#resources)\n- [Becoming an Open Source Contributor](#becoming-an-open-source-contributor)\n- [Games](#games)\n- [Podcasts](#podcasts)\n- [Communities](#communities)\n- [Conferences](#conferences)\n- [Interview Questions](#interview-questions)\n- [My admired companies](#my-admired-companies)\n\n---\n\n## Why use it?\n\nI\'m following this plan to prepare for my near-future job: Machine learning engineer. I\'ve been building native mobile applications (Android/iOS/Blackberry) since 2011. I have a Software Engineering degree, not a Computer Science degree. I have an itty-bitty amount of basic knowledge about: Calculus, Linear Algebra, Discrete Mathematics, Probability & Statistics from university.\nThink about my interest in machine learning:\n- [Can I learn and get a job in Machine Learning without studying CS Master and PhD?](https://www.quora.com/Can-I-learn-and-get-a-job-in-Machine-Learning-without-studying-CS-Master-and-PhD)\n    - *""You can, but it is far more difficult than when I got into the field.""* [Drac Smith](https://www.quora.com/Can-I-learn-and-get-a-job-in-Machine-Learning-without-studying-CS-Master-and-PhD/answer/Drac-Smith?srid=oT0p)\n- [How do I get a job in Machine Learning as a software programmer who self-studies Machine Learning, but  never has a chance to use it at work?](https://www.quora.com/How-do-I-get-a-job-in-Machine-Learning-as-a-software-programmer-who-self-studies-Machine-Learning-but-never-has-a-chance-to-use-it-at-work)\n    - *""I\'m hiring machine learning experts for my team and your MOOC will not get you the job (there is better news below). In fact, many people with a master\'s in machine learning will not get the job because they (and most who have taken MOOCs) do not have a deep understanding that will help me solve my problems.""* [Ross C. Taylor](https://www.quora.com/How-do-I-get-a-job-in-Machine-Learning-as-a-software-programmer-who-self-studies-Machine-Learning-but-never-has-a-chance-to-use-it-at-work/answer/Ross-C-Taylor?srid=oT0p)\n- [What skills are needed for machine learning jobs?](http://programmers.stackexchange.com/questions/79476/what-skills-are-needed-for-machine-learning-jobs)\n    - *""First, you need to have a decent CS/Math background. ML is an advanced topic so most textbooks assume that you have that background. Second, machine learning is a very general topic with many sub-specialties requiring unique skills. You may want to browse the curriculum of an MS program in Machine Learning to see the course, curriculum and textbook.""* [Uri](http://softwareengineering.stackexchange.com/a/79717)\n    - *""Probability, distributed computing, and Statistics.""* [Hydrangea](http://softwareengineering.stackexchange.com/a/79575)\n\nI find myself in times of trouble.\n\nAFAIK, [There are two sides to machine learning](http://machinelearningmastery.com/programmers-can-get-into-machine-learning/):\n- Practical Machine Learning: This is about querying databases, cleaning data, writing scripts to transform data and gluing algorithm and libraries together and writing custom code to squeeze reliable answers from data to satisfy difficult and ill-defined questions. It\xe2\x80\x99s the mess of reality.\n- Theoretical Machine Learning: This is about math and abstraction and idealized scenarios and limits and beauty and informing what is possible. It is a whole lot neater and cleaner and removed from the mess of reality.\n\nI think the best way for practice-focused methodology is something like [\'practice \xe2\x80\x94 learning \xe2\x80\x94 practice\'](http://machinelearningmastery.com/machine-learning-for-programmers/#comment-358985), that means where students first come with some existing projects with problems and solutions (practice) to get familiar with traditional methods in the area and perhaps also with their methodology. After practicing with some elementary experiences, they can go into the books and study the underlying theory, which serves to guide their future advanced practice and will enhance their toolbox of solving practical problems. Studying theory also further improves their understanding on the elementary experiences, and will help them acquire advanced experiences more quickly.\n\n It\'s a long plan. It\'s going to take me years. If you are familiar with a lot of this already it will take you a lot less time.\n\n## How to use it\nEverything below is an outline, and you should tackle the items in order from top to bottom.\n\nI\'m using Github\'s special markdown flavor, including tasks lists to check progress.\n\n- [x] Create a new branch so you can check items like this, just put an x in the brackets: [x]\n\n[More about Github-flavored markdown](https://guides.github.com/features/mastering-markdown/#GitHub-flavored-markdown)\n\n## Follow me\nI\'m a Vietnamese Software Engineer who is really passionate and wants to work in the USA.\n\nHow much did I work during this plan? Roughly 4 hours/night after a long, hard day at work.\n\nI\'m on the journey.\n\n- Twitter: [@Nam Vu](https://twitter.com/zuzoovn)\n\n| ![Nam Vu - Top-down learning path: machine learning for software engineers](http://sv1.upsieutoc.com/2016/10/08/331f241c8da44d0c43e9324d55440db6.md.jpg)|\n|:---:|\n| USA as heck |\n\n## Don\'t feel you aren\'t smart enough\nI get discouraged from books and courses that tell me as soon as I open them that multivariate calculus, inferential statistics and linear algebra are prerequisites. I still don\xe2\x80\x99t know how to get started\xe2\x80\xa6\n\n- [What if I\xe2\x80\x99m Not Good at Mathematics](http://machinelearningmastery.com/what-if-im-not-good-at-mathematics/)\n- [5 Techniques To Understand Machine Learning Algorithms Without the Background in Mathematics](http://machinelearningmastery.com/techniques-to-understand-machine-learning-algorithms-without-the-background-in-mathematics/)\n- [How do I learn machine learning?](https://www.quora.com/Machine-Learning/How-do-I-learn-machine-learning-1)\n\n## About Video Resources\n\nSome videos are available only by enrolling in a Coursera or EdX class. It is free to do so, but sometimes the classes\nare no longer in session so you have to wait a couple of months, so you have no access. I\'m going to be adding more videos\nfrom public sources and replacing the online course videos over time. I like using university lectures.\n\n## Prerequisite Knowledge\n\nThis short section were prerequisites/interesting info I wanted to learn before getting started on the daily plan.\n\n- [ ] [What is the difference between Data Analytics, Data Analysis, Data Mining, Data Science, Machine Learning, and Big Data?](https://www.quora.com/What-is-the-difference-between-Data-Analytics-Data-Analysis-Data-Mining-Data-Science-Machine-Learning-and-Big-Data-1)\n- [ ] [Learning How to Learn](https://www.coursera.org/learn/learning-how-to-learn)\n- [ ] [Don\xe2\x80\x99t Break The Chain](http://lifehacker.com/281626/jerry-seinfelds-productivity-secret)\n- [ ] [How to learn on your own](https://metacademy.org/roadmaps/rgrosse/learn_on_your_own)\n\n## The Daily Plan\n\nEach subject does not require a whole day to be able to understand it fully, and you can do multiple of these in a day.\n\nEach day I take one subject from the list below, read it cover to cover, take notes, do the exercises and write an implementation in Python or R.\n\n# Motivation\n- [ ] [Dream](https://www.youtube.com/watch?v=g-jwWYX7Jlo)\n\n## Machine learning overview\n- [ ] [A Visual Introduction to Machine Learning](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/)\n- [ ] [A Gentle Guide to Machine Learning](https://blog.monkeylearn.com/a-gentle-guide-to-machine-learning/)\n- [ ] [Introduction to Machine Learning for Developers](http://blog.algorithmia.com/introduction-machine-learning-developers/)\n- [ ] [Machine Learning basics for a newbie](https://www.analyticsvidhya.com/blog/2015/06/machine-learning-basics/)\n- [ ] [How do you explain Machine Learning and Data Mining to non Computer Science people?](https://www.quora.com/How-do-you-explain-Machine-Learning-and-Data-Mining-to-non-Computer-Science-people)\n- [ ] [Machine Learning: Under the hood. Blog post explains the principles of machine learning in layman terms. Simple and clear](https://georgemdallas.wordpress.com/2013/06/11/big-data-data-mining-and-machine-learning-under-the-hood/)\n- [ ] [What is machine learning, and how does it work?](https://www.youtube.com/watch?v=elojMnjn4kk&list=PL5-da3qGB5ICeMbQuqbbCOQWcS6OYBr5A&index=1)\n- [ ] [Deep Learning - A Non-Technical Introduction](http://www.slideshare.net/AlfredPong1/deep-learning-a-nontechnical-introduction-69385936)\n\n## Machine learning mastery\n- [ ] [The Machine Learning Mastery Method](http://machinelearningmastery.com/machine-learning-mastery-method/)\n- [ ] [Machine Learning for Programmers](http://machinelearningmastery.com/machine-learning-for-programmers/)\n- [ ] [Applied Machine Learning with Machine Learning Mastery](http://machinelearningmastery.com/start-here/)\n- [ ] [Python Machine Learning Mini-Course](http://machinelearningmastery.com/python-machine-learning-mini-course/)\n- [ ] [Machine Learning Algorithms Mini-Course](http://machinelearningmastery.com/machine-learning-algorithms-mini-course/)\n\n## Machine learning is fun\n- [ ] [Machine Learning is Fun!](https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471#.37ue6caww)\n- [ ] [Part 2: Using Machine Learning to generate Super Mario Maker levels](https://medium.com/@ageitgey/machine-learning-is-fun-part-2-a26a10b68df3#.kh7qgvp1b)\n- [ ] [Part 3: Deep Learning and Convolutional Neural Networks](https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721#.44rhxy637)\n- [ ] [Part 4: Modern Face Recognition with Deep Learning](https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78#.3rwmq0ddc)\n- [ ] [Part 5: Language Translation with Deep Learning and the Magic of Sequences](https://medium.com/@ageitgey/machine-learning-is-fun-part-5-language-translation-with-deep-learning-and-the-magic-of-sequences-2ace0acca0aa#.wyfthap4c)\n- [ ] [Part 6: How to do Speech Recognition with Deep Learning](https://medium.com/@ageitgey/machine-learning-is-fun-part-6-how-to-do-speech-recognition-with-deep-learning-28293c162f7a#.lhr1nnpcy)\n- [ ] [Part 7: Abusing Generative Adversarial Networks to Make 8-bit Pixel Art](https://medium.com/@ageitgey/abusing-generative-adversarial-networks-to-make-8-bit-pixel-art-e45d9b96cee7)\n- [ ] [Part 8: How to Intentionally Trick Neural Networks](https://medium.com/@ageitgey/machine-learning-is-fun-part-8-how-to-intentionally-trick-neural-networks-b55da32b7196)\n\n## [Inky Machine Learning](https://triskell.github.io/2016/11/15/Inky-Machine-Learning.html)\n- [ ] [Part 1: What is Machine Learning ?](https://triskell.github.io/2016/10/23/What-is-Machine-Learning.html)\n- [ ] [Part 2: Supervised Learning and Unsupervised Learning](https://triskell.github.io/2016/11/13/Supervised-Learning-and-Unsupervised-Learning.html)\n\n## Machine Learning: An In-Depth Guide\n- [ ] [Overview, goals, learning types, and algorithms](http://www.innoarchitech.com/machine-learning-an-in-depth-non-technical-guide/)\n- [ ] [Data selection, preparation, and modeling](http://www.innoarchitech.com/machine-learning-an-in-depth-non-technical-guide-part-2/)\n- [ ] [Model evaluation, validation, complexity, and improvement](http://www.innoarchitech.com/machine-learning-an-in-depth-non-technical-guide-part-3/)\n- [ ] [Model performance and error analysis](http://www.innoarchitech.com/machine-learning-an-in-depth-non-technical-guide-part-4/)\n- [ ] [Unsupervised learning, related fields, and machine learning in practice](http://www.innoarchitech.com/machine-learning-an-in-depth-non-technical-guide-part-5/)\n\n## Stories and experiences\n- [ ] [Machine Learning in a Week](https://medium.com/learning-new-stuff/machine-learning-in-a-week-a0da25d59850#.tk6ft2kcg)\n- [ ] [Machine Learning in a Year](https://medium.com/learning-new-stuff/machine-learning-in-a-year-cdb0b0ebd29c#.hhcb9fxk1)\n- [ ] [How I wrote my first Machine Learning program in 3 days](http://blog.adnansiddiqi.me/how-i-wrote-my-first-machine-learning-program-in-3-days/)\n- [ ] [Learning Path : Your mentor to become a machine learning expert](https://www.analyticsvidhya.com/learning-path-learn-machine-learning/)\n- [ ] [You Too Can Become a Machine Learning Rock Star! No PhD](https://backchannel.com/you-too-can-become-a-machine-learning-rock-star-no-phd-necessary-107a1624d96b#.g9p16ldp7)\n- [ ] How to become a Data Scientist in 6 months: A hacker\xe2\x80\x99s approach to career planning\n    - [Video](https://www.youtube.com/watch?v=rIofV14c0tc)\n    - [Slide](http://www.slideshare.net/TetianaIvanova2/how-to-become-a-data-scientist-in-6-months)\n- [ ] [5 Skills You Need to Become a Machine Learning Engineer](http://blog.udacity.com/2016/04/5-skills-you-need-to-become-a-machine-learning-engineer.html)\n- [ ] [Are you a self-taught machine learning engineer? If yes, how did you do it & how long did it take you?](https://www.quora.com/Are-you-a-self-taught-machine-learning-engineer-If-yes-how-did-you-do-it-how-long-did-it-take-you)\n- [ ] [How can one become a good machine learning engineer?](https://www.quora.com/How-can-one-become-a-good-machine-learning-engineer)\n- [ ] [A Learning Sabbatical focused on Machine Learning](http://karlrosaen.com/ml/)\n\n## Machine Learning Algorithms\n- [ ] [10 Machine Learning Algorithms Explained to an \xe2\x80\x98Army Soldier\xe2\x80\x99](https://www.analyticsvidhya.com/blog/2015/12/10-machine-learning-algorithms-explained-army-soldier/)\n- [ ] [Top 10 data mining algorithms in plain English](https://rayli.net/blog/data/top-10-data-mining-algorithms-in-plain-english/)\n- [ ] [10 Machine Learning Terms Explained in Simple English](http://blog.aylien.com/10-machine-learning-terms-explained-in-simple/)\n- [ ] [A Tour of Machine Learning Algorithms](http://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/)\n- [ ] [The 10 Algorithms Machine Learning Engineers Need to Know](https://gab41.lab41.org/the-10-algorithms-machine-learning-engineers-need-to-know-f4bb63f5b2fa#.ofc7t2965)\n- [ ] [Comparing supervised learning algorithms](http://www.dataschool.io/comparing-supervised-learning-algorithms/)\n- [ ] [Machine Learning Algorithms: A collection of minimal and clean implementations of machine learning algorithms](https://github.com/rushter/MLAlgorithms)\n\n## Beginner Books\n- [ ] [Data Smart: Using Data Science to Transform Information into Insight 1st Edition](https://www.amazon.com/Data-Smart-Science-Transform-Information/dp/111866146X)\n- [ ] [Data Science for Business: What you need to know about data mining and data\xc2\xad analytic-thinking](https://www.amazon.com/Data-Science-Business-Data-Analytic-Thinking/dp/1449361323/)\n- [ ] [Predictive Analytics: The Power to Predict Who Will Click, Buy, Lie, or Die](https://www.amazon.com/Predictive-Analytics-Power-Predict-Click/dp/1118356853)\n\n## Practical Books\n- [ ] [Machine Learning for Hackers](https://www.amazon.com/Machine-Learning-Hackers-Drew-Conway/dp/1449303714)\n    - [GitHub repository(R)](https://github.com/johnmyleswhite/ML_for_Hackers)\n    - [GitHub repository(Python)](https://github.com/carljv/Will_it_Python)\n- [ ] [Python Machine Learning](https://www.amazon.com/Python-Machine-Learning-Sebastian-Raschka-ebook/dp/B00YSILNL0)\n    - [GitHub repository](https://github.com/rasbt/python-machine-learning-book)\n- [ ] [Programming Collective Intelligence: Building Smart Web 2.0 Applications](https://www.amazon.com/Programming-Collective-Intelligence-Building-Applications-ebook/dp/B00F8QDZWG)\n- [ ] [Machine Learning: An Algorithmic Perspective, Second Edition](https://www.amazon.com/Machine-Learning-Algorithmic-Perspective-Recognition/dp/1466583282)\n    - [GitHub repository](https://github.com/alexsosn/MarslandMLAlgo)\n    - [Resource repository](http://seat.massey.ac.nz/personal/s.r.marsland/MLbook.html)\n- [ ] [Introduction to Machine Learning with Python: A Guide for Data Scientists](http://shop.oreilly.com/product/0636920030515.do)\n    - [GitHub repository](https://github.com/amueller/introduction_to_ml_with_python)\n- [ ] [Data Mining: Practical Machine Learning Tools and Techniques, Third Edition](https://www.amazon.com/Data-Mining-Practical-Techniques-Management/dp/0123748569)\n    - Teaching material\n        - [Slides for Chapters 1-5 (zip)](http://www.cs.waikato.ac.nz/ml/weka/Slides3rdEd_Ch1-5.zip)\n        - [Slides for Chapters 6-8 (zip)](http://www.cs.waikato.ac.nz/ml/weka/Slides3rdEd_Ch6-8.zip)\n- [ ] [Machine Learning in Action](https://www.amazon.com/Machine-Learning-Action-Peter-Harrington/dp/1617290181/)\n    - [GitHub repository](https://github.com/pbharrin/machinelearninginaction)\n- [ ] [Reactive Machine Learning Systems(MEAP)](https://www.manning.com/books/reactive-machine-learning-systems)\n    - [GitHub repository](https://github.com/jeffreyksmithjr/reactive-machine-learning-systems)\n- [ ] [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/)\n    - [GitHub repository(R)](http://www-bcf.usc.edu/~gareth/ISL/code.html)\n    - [GitHub repository(Python)](https://github.com/JWarmenhoven/ISLR-python)\n    - [Videos](http://www.dataschool.io/15-hours-of-expert-machine-learning-videos/)\n- [ ] [Building Machine Learning Systems with Python](https://www.packtpub.com/big-data-and-business-intelligence/building-machine-learning-systems-python)\n    - [GitHub repository](https://github.com/luispedro/BuildingMachineLearningSystemsWithPython)\n- [ ] [Learning scikit-learn: Machine Learning in Python](https://www.packtpub.com/big-data-and-business-intelligence/learning-scikit-learn-machine-learning-python)\n    - [GitHub repository](https://github.com/gmonce/scikit-learn-book)\n- [ ] [Probabilistic Programming & Bayesian Methods for Hackers](https://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/)\n- [ ] [Probabilistic Graphical Models: Principles and Techniques](https://www.amazon.com/Probabilistic-Graphical-Models-Principles-Computation/dp/0262013193)\n- [ ] [Machine Learning: Hands-On for Developers and Technical Professionals](https://www.amazon.com/Machine-Learning-Hands-Developers-Professionals/dp/1118889061)\n    - [Machine Learning Hands-On for Developers and Technical Professionals review](https://blogs.msdn.microsoft.com/querysimon/2015/01/01/book-review-machine-learning-hands-on-for-developers-and-technical-professionals/)\n    - [GitHub repository](https://github.com/jasebell/mlbook)\n- [ ] [Learning from Data](https://www.amazon.com/Learning-Data-Yaser-S-Abu-Mostafa/dp/1600490069)\n    - [Online tutorials](https://work.caltech.edu/telecourse.html)\n- [ ] [Reinforcement Learning: An Introduction (2nd Edition)](https://webdocs.cs.ualberta.ca/~sutton/book/the-book-2nd.html)\n    - [GitHub repository](https://github.com/ShangtongZhang/reinforcement-learning-an-introduction)\n- [ ] [Machine Learning with TensorFlow(MEAP)](https://www.manning.com/books/machine-learning-with-tensorflow)\n    - [GitHub repository](https://github.com/BinRoot/TensorFlow-Book)\n- [ ] [How Machine Learning Works (MEAP)](https://www.manning.com/books/how-machine-learning-works)\n    - [GitHub repository](https://github.com/Mostafa-Samir/How-Machine-Learning-Works)\n- [ ] [Succeeding with AI](https://www.manning.com/books/succeeding-with-ai)\n\n## Kaggle knowledge competitions\n- [ ] [Kaggle Competitions: How and where to begin?](https://www.analyticsvidhya.com/blog/2015/06/start-journey-kaggle/)\n- [ ] [How a Beginner Used Small Projects To Get Started in Machine Learning and Compete on Kaggle](http://machinelearningmastery.com/how-a-beginner-used-small-projects-to-get-started-in-machine-learning-and-compete-on-kaggle)\n- [ ] [Master Kaggle By Competing Consistently](http://machinelearningmastery.com/master-kaggle-by-competing-consistently/)\n\n## Video Series\n- [ ] [Machine Learning for Hackers](https://www.youtube.com/playlist?list=PL2-dafEMk2A4ut2pyv0fSIXqOzXtBGkLj)\n- [ ] [Fresh Machine Learning](https://www.youtube.com/playlist?list=PL2-dafEMk2A6Kc7pV6gHH-apBFxwFjKeY)\n- [ ] [Machine Learning Recipes with Josh Gordon](https://www.youtube.com/playlist?list=PLOU2XLYxmsIIuiBfYad6rFYQU_jL2ryal)\n- [ ] [Everything You Need to know about Machine Learning in 30 Minutes or Less](https://vimeo.com/43547079)\n- [ ] [A Friendly Introduction to Machine Learning](https://www.youtube.com/watch?v=IpGxLWOIZy4)\n- [ ] [Nuts and Bolts of Applying Deep Learning - Andrew Ng](https://www.youtube.com/watch?v=F1ka6a13S9I)\n- [ ] BigML Webinar\n    - [Video](https://www.youtube.com/watch?list=PL1bKyu9GtNYHcjGa6ulrvRVcm1lAB8he3&v=W62ehrnOVqo)\n    - [Resources](https://bigml.com/releases)\n- [ ] [mathematicalmonk\'s Machine Learning tutorials](https://www.youtube.com/playlist?list=PLD0F06AA0D2E8FFBA)\n- [ ] [Machine learning in Python with scikit-learn](https://www.youtube.com/playlist?list=PL5-da3qGB5ICeMbQuqbbCOQWcS6OYBr5A)\n    - [GitHub repository](https://github.com/justmarkham/scikit-learn-videos)\n    - [Blog](http://blog.kaggle.com/author/kevin-markham/)\n- [ ] [My playlist \xe2\x80\x93 Top YouTube Videos on Machine Learning, Neural Network & Deep Learning](https://www.analyticsvidhya.com/blog/2015/07/top-youtube-videos-machine-learning-neural-network-deep-learning/)\n- [ ] [16 New Must Watch Tutorials, Courses on Machine Learning](https://www.analyticsvidhya.com/blog/2016/10/16-new-must-watch-tutorials-courses-on-machine-learning/)\n- [ ] [DeepLearning.TV](https://www.youtube.com/channel/UC9OeZkIwhzfv-_Cb7fCikLQ)\n- [ ] [Learning To See](https://www.youtube.com/playlist?list=PLiaHhY2iBX9ihLasvE8BKnS2Xg8AhY6iV)\n- [ ] [Neural networks class - Universit\xc3\xa9 de Sherbrooke](https://www.youtube.com/playlist?list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH)\n- [ ] [21 Deep Learning Videos, Tutorials & Courses on Youtube from 2016](https://www.analyticsvidhya.com/blog/2016/12/21-deep-learning-videos-tutorials-courses-on-youtube-from-2016/)\n- [ ] [30 Top Videos, Tutorials & Courses on Machine Learning & Artificial Intelligence from 2016](https://www.analyticsvidhya.com/blog/2016/12/30-top-videos-tutorials-courses-on-machine-learning-artificial-intelligence-from-2016/)\n- [ ] [Practical Deep Learning For Coders](http://course.fast.ai/index.html)\n- [ ]  [Practical Deep Learning For Coders Version 2 (PyTorch)](http://forums.fast.ai/t/welcome-to-part-1-v2/5787)\n\n## MOOC\n- [ ] [Coursera\xe2\x80\x99s AI For Everyone](https://www.coursera.org/learn/ai-for-everyone)\n- [ ] [edX\'s Introduction to Artificial Intelligence (AI)](https://www.edx.org/course/introduction-artificial-intelligence-ai-microsoft-dat263x)\n- [ ] [Udacity\xe2\x80\x99s Intro to Machine Learning](https://www.udacity.com/course/intro-to-machine-learning--ud120)\n    - [Udacity Intro to Machine Learning Review](http://hamelg.blogspot.com/2014/12/udacity-intro-to-machine-learning-review.html)\n- [ ] [Udacity\xe2\x80\x99s Supervised, Unsupervised & Reinforcement](https://www.udacity.com/course/machine-learning--ud262)\n- [ ] [Machine Learning Foundations: A Case Study Approach](https://www.coursera.org/learn/ml-foundations)\n- [ ] [Machine Learning & AI Foundations: Value Estimations](https://www.lynda.com/Data-Science-tutorials/Machine-Learning-Essential-Training-Value-Estimations/548594-2.html)\n- [ ] [Kaggle\'s Hands-On Data Science Education](https://www.kaggle.com/learn/overview)\n- [ ] [Microsoft Professional Program for Artificial Intelligence](https://academy.microsoft.com/en-us/professional-program/tracks/artificial-intelligence/)\n- [ ] [Coursera\xe2\x80\x99s Machine Learning](https://www.coursera.org/learn/machine-learning)\n    - [Video only](https://www.youtube.com/playlist?list=PLZ9qNFMHZ-A4rycgrgOYma6zxF4BZGGPW)\n    - [Coursera Machine Learning review](https://rayli.net/blog/data/coursera-machine-learning-review/)\n    - [Coursera: Machine Learning Roadmap](https://metacademy.org/roadmaps/cjrd/coursera_ml_supplement)\n- [ ] [Machine Learning Distilled](https://code.tutsplus.com/courses/machine-learning-distilled)\n- [ ] [BigML training](https://bigml.com/training)\n- [ ] [Coursera\xe2\x80\x99s Neural Networks for Machine Learning](https://www.coursera.org/learn/neural-networks)\n    - Taught by Geoffrey Hinton, a pioneer in the field of neural networks\n- [ ] [Machine Learning\xe2\x80\x8a-\xe2\x80\x8aCS\xe2\x80\x8a-\xe2\x80\x8aOxford University](https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/)\n- [ ] [Creative Applications of Deep Learning with TensorFlow](https://www.kadenze.com/courses/creative-applications-of-deep-learning-with-tensorflow/info)\n- [ ] [Intro to Descriptive Statistics](https://www.udacity.com/course/intro-to-descriptive-statistics--ud827)\n- [ ] [Intro to Inferential Statistics](https://www.udacity.com/course/intro-to-inferential-statistics--ud201)\n- [ ] [6.S094: Deep Learning for Self-Driving Cars](http://selfdrivingcars.mit.edu/)\n- [ ] [6.S191: Introduction to Deep Learning](http://introtodeeplearning.com/index.html)\n- [ ] [Coursera\xe2\x80\x99s Deep Learning](https://www.coursera.org/specializations/deep-learning)\n\n## Resources\n- [ ] [Absolute Beginning into Machine Learning](https://hackernoon.com/absolute-beginning-into-machine-learning-e90ceda5a4bc)\n- [ ] [Learn Machine Learning in a Single Month](https://elitedatascience.com/machine-learning-masterclass)\n- [ ] [The Non-Technical Guide to Machine Learning & Artificial Intelligence](https://medium.com/@samdebrule/a-humans-guide-to-machine-learning-e179f43b67a0#.cpzf3a5c0)\n- [ ] [Programming Community Curated Resources for learning Machine Learning](https://hackr.io/tutorials/learn-machine-learning-ml)\n- [ ] [Best practices rule book for Machine Learning engineering from Google](http://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf)\n- [ ] [Machine Learning for Software Engineers on Hacker News](https://news.ycombinator.com/item?id=12898718)\n- [ ] [Machine Learning for Developers](https://xyclade.github.io/MachineLearning/)\n- [ ] [Machine Learning for Humans\xf0\x9f\xa4\x96\xf0\x9f\x91\xb6](https://medium.com/machine-learning-for-humans/why-machine-learning-matters-6164faf1df12)\n- [ ] [Machine Learning Advice for Developers](https://dev.to/thealexlavin/machine-learning-advice-for-developers)\n- [ ] [Machine Learning For Complete Beginners](http://pythonforengineers.com/machine-learning-for-complete-beginners/)\n- [ ] [Getting Started with Machine Learning: For absolute beginners and fifth graders](https://medium.com/@suffiyanz/getting-started-with-machine-learning-f15df1c283ea#.yjtiy7ei9)\n- [ ] [How to Learn Machine Learning: The Self-Starter Way](https://elitedatascience.com/learn-machine-learning)\n- [ ] [Machine Learning Self-study Resources](https://ragle.sanukcode.net/articles/machine-learning-self-study-resources/)\n- [ ] [Level-Up Your Machine Learning](https://metacademy.org/roadmaps/cjrd/level-up-your-ml)\n- [ ] [An Honest Guide to Machine Learning](https://medium.com/axiomzenteam/an-honest-guide-to-machine-learning-2f6d7a6df60e#.ib12a1yw5)\n- [ ] Enough Machine Learning to Make Hacker News Readable Again\n    - [Video](https://www.youtube.com/watch?v=O7IezJT9uSI)\n    - [Slide](https://speakerdeck.com/pycon2014/enough-machine-learning-to-make-hacker-news-readable-again-by-ned-jackson-lovely)\n- [ ] [Dive into Machine Learning](https://github.com/hangtwenty/dive-into-machine-learning)\n- [ ] [{Machine, Deep} Learning for software engineers](https://speakerdeck.com/pmigdal/machine-deep-learning-for-software-engineers)\n- [ ] [Deep Learning For Beginners](https://deeplearning4j.org/deeplearningforbeginners.html)\n- [ ] [Foundations for deep learning](https://github.com/pauli-space/foundations_for_deep_learning)\n- [ ] [Machine Learning Mindmap / Cheatsheet](https://github.com/dformoso/machine-learning-mindmap)\n- Machine Learning courses in Universities\n    - [ ] [Stanford](http://ai.stanford.edu/courses/)\n    - [ ] [Machine Learning Summer Schools](http://mlss.cc/)\n    - [ ] [Oxford](https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/)\n    - [ ] [Cambridge](http://mlg.eng.cam.ac.uk/)\n- Flipboard Topics\n    - [Machine learning](https://flipboard.com/topic/machinelearning)\n    - [Deep learning](https://flipboard.com/topic/deeplearning)\n    - [Artificial Intelligence](https://flipboard.com/topic/artificialintelligence)\n- Medium Topics\n    - [Machine learning](https://medium.com/tag/machine-learning/latest)\n    - [Deep learning](https://medium.com/tag/deep-learning)\n    - [Artificial Intelligence](https://medium.com/tag/artificial-intelligence)\n- Monthly top 10 articles\n    - [Machine Learning](https://medium.mybridge.co/search?q=%22Machine%20Learning%22)\n    - [Algorithms](https://medium.mybridge.co/search?q=Algorithms)\n- [Comprehensive list of data science resources](http://www.datasciencecentral.com/group/resources/forum/topics/comprehensive-list-of-data-science-resources)\n- [DigitalMind\'s Artificial Intelligence resources](http://blog.digitalmind.io/post/artificial-intelligence-resources)\n- [Awesome Machine Learning](https://github.com/josephmisiti/awesome-machine-learning)\n- [Awesome Graph Classification](https://github.com/benedekrozemberczki/awesome-graph-classification)\n- [Awesome Community Detection](https://github.com/benedekrozemberczki/awesome-community-detection)\n- [CreativeAi\'s Machine Learning](http://www.creativeai.net/?cat%5B0%5D=machine-learning)\n\n## Games\n- [Halite: A.I. Coding Game](https://halite.io/)\n- [Vindinium: A.I. Programming Challenge](http://vindinium.org/)\n- [General Video Game AI Competition](http://www.gvgai.net/)\n- [Angry Birds AI Competition](https://aibirds.org/)\n- [The AI Games](http://theaigames.com/)\n- [Fighting Game AI Competition](http://www.ice.ci.ritsumei.ac.jp/~ftgaic/)\n- [CodeCup](http://www.codecup.nl/intro.php)\n- [Student StarCraft AI Tournament](http://sscaitournament.com/)\n- [AIIDE StarCraft AI Competition](http://www.cs.mun.ca/~dchurchill/starcraftaicomp/)\n- [CIG StarCraft AI Competition](https://sites.google.com/site/starcraftaic/)\n- [CodinGame - AI Bot Games](https://www.codingame.com/training/machine-learning)\n\n## Becoming an Open Source Contributor\n- [ ] [tensorflow/magenta: Magenta: Music and Art Generation with Machine Intelligence](https://github.com/tensorflow/magenta)\n- [ ] [tensorflow/tensorflow: Computation using data flow graphs for scalable machine learning](https://github.com/tensorflow/tensorflow)\n- [ ] [cmusatyalab/openface: Face recognition with deep neural networks.](https://github.com/cmusatyalab/openface)\n- [ ] [tensorflow/models/syntaxnet: Neural Models of Syntax.](https://github.com/tensorflow/models/tree/master/syntaxnet)\n\n## Podcasts\n- ### Podcasts for Beginners:\n    - [Talking Machines](http://www.thetalkingmachines.com/)\n    - [Linear Digressions](http://lineardigressions.com/)\n    - [Data Skeptic](http://dataskeptic.com/)\n    - [This Week in Machine Learning & AI](https://twimlai.com/)\n    - [Machine Learning Guide](http://ocdevel.com/podcasts/machine-learning)\n    \n- ### Interviews with ML Practitioners, Researchers and Kagglers about their Joureny\n    - [Chai Time Data Science](https://www.youtube.com/playlist?list=PLLvvXm0q8zUbiNdoIazGzlENMXvZ9bd3x), [Audio](http://anchor.fm/chaitimedatascience), [Writeups](https://sanyambhutani.com/tag/chaitimedatascience/)\n\n- ### ""More"" advanced podcasts\n    - [Partially Derivative](http://partiallyderivative.com/)\n    - [O\xe2\x80\x99Reilly Data Show](http://radar.oreilly.com/tag/oreilly-data-show-podcast)\n    - [Not So Standard Deviation](https://soundcloud.com/nssd-podcast)\n\n- ### Podcasts to think outside the box:\n    - [Data Stories](http://datastori.es/)\n    \n## Communities\n- Quora\n    - [Machine Learning](https://www.quora.com/topic/Machine-Learning)\n    - [Statistics](https://www.quora.com/topic/Statistics-academic-discipline)\n    - [Data Mining](https://www.quora.com/topic/Data-Mining)\n\n- Reddit\n    - [Machine Learning](https://www.reddit.com/r/machinelearning)\n    - [Computer Vision](https://www.reddit.com/r/computervision)\n    - [Natural Language](https://www.reddit.com/r/languagetechnology)\n    - [Data Science](https://www.reddit.com/r/datascience)\n    - [Big Data](https://www.reddit.com/r/bigdata)\n    - [Statistics](https://www.reddit.com/r/statistics)\n\n- [Data Tau](http://www.datatau.com/)\n\n- [Deep Learning News](http://news.startup.ml/)\n\n- [KDnuggets](http://www.kdnuggets.com/)\n\n## Conferences\n- Neural Information Processing Systems ([NIPS](https://nips.cc/))\n- International Conference on Learning Representations ([ICLR](http://www.iclr.cc/doku.php?id=ICLR2017:main&redirect=1))\n- Association for the Advancement of Artificial Intelligence ([AAAI](http://www.aaai.org/Conferences/AAAI/aaai17.php))\n- IEEE Conference on Computational Intelligence and Games ([CIG](http://www.ieee-cig.org/))\n- IEEE International Conference on Machine Learning and Applications ([ICMLA](http://www.icmla-conference.org/))\n- International Conference on Machine Learning ([ICML](https://2017.icml.cc/))\n- International Joint Conferences on Artificial Intelligence ([IJCAI](http://www.ijcai.org/))\n- Association for Computational Linguistics ([ACL](http://acl2017.org/))\n\n## Interview Questions\n- [ ] [How To Prepare For A Machine Learning Interview](http://blog.udacity.com/2016/05/prepare-machine-learning-interview.html)\n- [ ] [40 Interview Questions asked at Startups in Machine Learning / Data Science](https://www.analyticsvidhya.com/blog/2016/09/40-interview-questions-asked-at-startups-in-machine-learning-data-science)\n- [ ] [21 Must-Know Data Science Interview Questions and Answers](http://www.kdnuggets.com/2016/02/21-data-science-interview-questions-answers.html)\n- [ ] [Top 50 Machine learning Interview questions & Answers](http://career.guru99.com/top-50-interview-questions-on-machine-learning/)\n- [ ] [Machine Learning Engineer interview questions](https://resources.workable.com/machine-learning-engineer-interview-questions)\n- [ ] [Popular Machine Learning Interview Questions](http://www.learn4master.com/machine-learning/popular-machine-learning-interview-questions)\n- [ ] [What are some common Machine Learning interview questions?](https://www.quora.com/What-are-some-common-Machine-Learning-interview-questions)\n- [ ] [What are the best interview questions to evaluate a machine learning researcher?](https://www.quora.com/What-are-the-best-interview-questions-to-evaluate-a-machine-learning-researcher)\n- [ ] [Collection of Machine Learning Interview Questions](http://analyticscosm.com/machine-learning-interview-questions-for-data-scientist-interview/)\n- [ ] [121 Essential Machine Learning Questions & Answers](https://elitedatascience.com/mlqa-reading-list)\n\n\n## My admired companies\n- [ ] [ELSA - Your virtual pronunciation coach](https://www.elsanow.io/home)\n'"
4,rasbt/python-machine-learning-book,rasbt,"The ""Python Machine Learning (1st edition)""  book code repository and info resource",2015-08-07 20:39:29,2020-06-18 15:43:36,Jupyter Notebook,4165,10701,"b'# Python Machine Learning book code repository\n\n\n[![Google Group](https://img.shields.io/badge/-Google%20Group-lightgrey.svg)](https://groups.google.com/forum/#!forum/python-machine-learning-reader-discussion-board)\n\n---\n\n#### IMPORTANT NOTE (09/21/2017):\n\nThis GitHub repository contains the code examples of the **1st Edition** of Python Machine Learning book. If you are looking for the code examples of the **2nd Edition**, please refer to [this](https://github.com/rasbt/python-machine-learning-book-2nd-edition#whats-new-in-the-second-edition-from-the-first-edition) repository instead. \n\n---\n\nWhat you can expect are 400 pages rich in useful material just about everything you need to know to get started with machine learning ... from theory to the actual code that you can directly put into action! This is not yet just another ""this is how scikit-learn works"" book. I aim to explain all the underlying concepts, tell you everything you need to know in terms of best practices and caveats, and\nwe will put those concepts into action mainly using NumPy, scikit-learn, and Theano.\n\nYou are not sure if this book is for you? Please checkout the excerpts from the [Foreword](./docs/foreword_ro.pdf) and [Preface](./docs/preface_sr.pdf), or take a look at the [FAQ](#faq) section for further information.\n\n\n\n---\n\n[![](./images/pymle_cover_double_small.jpg)](https://www.amazon.com/Python-Machine-Learning-Sebastian-Raschka/dp/1783555130/ref=sr_1_1?ie=UTF8&qid=1470882464&sr=8-1&keywords=python+machine+learning)\n\n1st edition, published September 23rd 2015<br>\nPaperback: 454 pages<br>\nPublisher: Packt Publishing<br>  \nLanguage: English<br>\nISBN-10: 1783555130<br>  \nISBN-13: 978-1783555130<br>\nKindle ASIN: B00YSILNL0<br>\n\n<br>\n\n[![](./images/CRBadgeNotableBook.jpg)](http://www.computingreviews.com/recommend/bestof/notableitems.cfm?bestYear=2016)\n\n<br>\n\nGerman ISBN-13: 978-3958454224<br>\nJapanese ISBN-13: 978-4844380603<br>\nItalian ISBN-13: 978-8850333974<br>\nChinese (traditional) ISBN-13: 978-9864341405<br>\nChinese (mainland) ISBN-13: 978-7111558804<br>\nKorean ISBN-13: 979-1187497035<br>\nRussian ISBN-13: 978-5970604090<br>\n\n\n\n## Table of Contents and Code Notebooks\n\n\nSimply click on the `ipynb`/`nbviewer` links next to the chapter headlines to view the code examples (currently, the internal document links are only supported by the NbViewer version).\n**Please note that these are just the code examples accompanying the book, which I uploaded for your convenience; be aware that these notebooks may not be useful without the formulae and descriptive text.**   \n\n\n- Excerpts from the [Foreword](./docs/foreword_ro.pdf) and [Preface](./docs/preface_sr.pdf)\n- [Instructions for setting up Python and the Jupiter Notebook](./code/ch01/README.md)  \n\n<br>\n\n1. Machine Learning - Giving Computers the Ability to Learn from Data [[dir](./code/ch01)] [[ipynb](./code/ch01/ch01.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch01/ch01.ipynb)]\n2. Training Machine Learning Algorithms for Classification [[dir](./code/ch02)] [[ipynb](./code/ch02/ch02.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch02/ch02.ipynb)]\n3. A Tour of Machine Learning Classifiers Using Scikit-Learn [[dir](./code/ch03)] [[ipynb](./code/ch03/ch03.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch03/ch03.ipynb)]\n4. Building Good Training Sets \xe2\x80\x93 Data Pre-Processing [[dir](./code/ch04)] [[ipynb](./code/ch04/ch04.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch04/ch04.ipynb)]\n5. Compressing Data via Dimensionality Reduction [[dir](./code/ch05)] [[ipynb](./code/ch05/ch05.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch05/ch05.ipynb)]\n6. Learning Best Practices for Model Evaluation and Hyperparameter Optimization [[dir](./code/ch06)] [[ipynb](./code/ch06/ch06.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch06/ch06.ipynb)]\n7. Combining Different Models for Ensemble Learning [[dir](./code/ch07)] [[ipynb](./code/ch07/ch07.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch07/ch07.ipynb)]\n8. Applying Machine Learning to Sentiment Analysis [[dir](./code/ch08)] [[ipynb](./code/ch08/ch08.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch08/ch08.ipynb)]\n9. Embedding a Machine Learning Model into a Web Application [[dir](./code/ch09)] [[ipynb](./code/ch09/ch09.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch09/ch09.ipynb)]\n10. Predicting Continuous Target Variables with Regression Analysis [[dir](./code/ch10)] [[ipynb](./code/ch10/ch10.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch10/ch10.ipynb)]\n11. Working with Unlabeled Data \xe2\x80\x93 Clustering Analysis [[dir](./code/ch11)] [[ipynb](./code/ch11/ch11.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch11/ch11.ipynb)]\n12. Training Artificial Neural Networks for Image Recognition [[dir](./code/ch12)] [[ipynb](./code/ch12/ch12.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch12/ch12.ipynb)]\n13. Parallelizing Neural Network Training via Theano [[dir](./code/ch13)] [[ipynb](./code/ch13/ch13.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch13/ch13.ipynb)]\n\n<br>\n\n#### Equation Reference\n\n<a href=""https://github.com/rasbt/python-machine-learning-book/tree/master/docs/equations""><img src=""images/equation-ref-logo.png"" width=""200"" height=""200"" /></a>\n\n[[PDF](./docs/equations/pymle-equations.pdf)] [[TEX](./docs/equations/pymle-equations.tex)]\n\n#### Slides for Teaching\n\nA big thanks to [Dmitriy Dligach](dmitriydligach) for sharing his slides from his machine learning course that is currently offered at [Loyola University Chicago](http://www.luc.edu/cs/). \n\n- [https://github.com/dmitriydligach/PyMLSlides](https://github.com/dmitriydligach/PyMLSlides)\n- \n\n\n\n#### Additional Math and NumPy Resources\n\nSome readers were asking about Math and NumPy primers, since they were not included due to length limitations. However, I recently put together such resources for another book, but I made these *chapters* freely available online in hope that they also serve as helpful background material for this book:\n\n\n- Algebra Basics [[PDF](https://sebastianraschka.com/pdf/books/dlb/appendix_b_algebra.pdf)] [[EPUB](https://sebastianraschka.com/pdf/books/dlb/appendix_b_algebra.epub)]\n\n- A Calculus and Differentiation Primer [[PDF](https://sebastianraschka.com/pdf/books/dlb/appendix_d_calculus.pdf)] [[EPUB](https://sebastianraschka.com/pdf/books/dlb/appendix_d_calculus.epub)]\n\n- Introduction to NumPy [[PDF](https://sebastianraschka.com/pdf/books/dlb/appendix_f_numpy-intro.pdf)] [[EPUB](https://sebastianraschka.com/pdf/books/dlb/appendix_f_numpy-intro.epub)] [[Code Notebook](https://github.com/rasbt/deep-learning-book/blob/master/code/appendix_f_numpy-intro/appendix_f_numpy-intro.ipynb)]\n\n\n\n---\n\n#### Citing this Book\n\nYou are very welcome to re-use the code snippets or other contents from this book\nin scientific publications and other works;\nin this case, I would appreciate citations to the original source:\n\n**BibTeX**:\n\n```\n@Book{raschka2015python,\n author = {Raschka, Sebastian},\n title = {Python Machine Learning},\n publisher = {Packt Publishing},\n year = {2015},\n address = {Birmingham, UK},\n isbn = {1783555130}\n }\n```\n\n\n**MLA**:\n\n\nRaschka, Sebastian. *Python machine learning*. Birmingham, UK: Packt Publishing, 2015. Print.\n\n---\n\n### [Feedback & Reviews](./docs/feedback.md)\n\n#### [Short review snippets](./docs/feedback.md)\n\n[![](./images/pymle_amzn.png)](https://www.amazon.com/Python-Machine-Learning-Sebastian-Raschka/dp/1783555130/ref=sr_1_1?ie=UTF8&qid=1472342570&sr=8-1&keywords=sebastian+raschka)\n\n---\n> *Sebastian Raschka\xe2\x80\x99s new book, Python Machine Learning, has just been released. I got a chance to read a review copy and it\xe2\x80\x99s just as I expected - really great! It\xe2\x80\x99s well organized, super easy to follow, and it not only offers a good foundation for smart, non-experts, practitioners will get some ideas and learn new tricks here as well.*  \n\xe2\x80\x93 Lon Riesberg at [Data Elixir](http://dataelixir.com/issues/55#start)\n\n> *Superb job! Thus far, for me it seems to have hit the right balance of theory and practice\xe2\x80\xa6math and code!*   \n\xe2\x80\x93 [Brian Thomas](http://sebastianraschka.com/blog/2015/writing-pymle.html#comment-2295668894)\n\n> *I\'ve read (virtually) every Machine Learning title based around Scikit-learn and this is hands-down the best one out there.*    \n\xe2\x80\x93 [Jason Wolosonovich](https://www.linkedin.com/pulse/python-machine-learning-sebastian-raschka-review-jason-wolosonovich?trk=prof-post)\n\n> *The best book I\'ve seen to come out of PACKT Publishing. This is a very well written introduction to machine learning with Python. As others have noted, a perfect mixture of theory and application.*    \n\xe2\x80\x93 [Josh D.](https://www.amazon.com/gp/customer-reviews/R27WB1GWTNGIR2/ref=cm_cr_getr_d_rvw_ttl?ie=UTF8&ASIN=1783555130)\n\n> *A book with a blend of qualities that is hard to come by: combines the needed mathematics to control the theory with the applied coding in Python. Also great to see it doesn\'t waste paper in giving a primer on Python as many other books do just to appeal to the greater audience. You can tell it\'s been written by knowledgeable writers and not just DIY geeks.*    \n\xe2\x80\x93 [Amazon Customer](https://www.amazon.com/gp/customer-reviews/RZWY4TF66Z6V0/ref=cm_cr_getr_d_rvw_ttl?ie=UTF8&ASIN=1783555130)\n\n> *Sebastian Raschka created an amazing machine learning tutorial which combines theory with practice. The book explains machine learning from a theoretical perspective and has tons of coded examples to show how you would actually use the machine learning technique. It can be read by a beginner or advanced programmer.*\n- William P. Ross, [7 Must Read Python Books](http://williampross.com/7-must-read-python-books/)\n\n#### Longer reviews\n\nIf you need help to decide whether this book is for you, check out some of the ""longer"" reviews linked below. (If you wrote a review, please let me know, and I\'d be happy to add it to the list).\n\n- [Python Machine Learning Review](http://www.bcs.org/content/conWebDoc/55586) by Patrick Hill at the Chartered Institute for IT\n- [Book Review: Python Machine Learning by Sebastian Raschka](http://whatpixel.com/python-machine-learning-book-review/) by Alex Turner at WhatPixel\n\n---\n\n## Links\n\n- ebook and paperback at [Amazon.com](http://www.amazon.com/Python-Machine-Learning-Sebastian-Raschka/dp/1783555130/ref=sr_1_2?ie=UTF8&qid=1437754343&sr=8-2&keywords=python+machine+learning+essentials), [Amazon.co.uk](http://www.amazon.co.uk/Python-Machine-Learning-Sebastian-Raschka/dp/1783555130), [Amazon.de](http://www.amazon.de/s/ref=nb_sb_noss_2?__mk_de_DE=\xc3\x85M\xc3\x85\xc5\xbd\xc3\x95\xc3\x91&url=search-alias%3Daps&field-keywords=python+machine+learning)\n- [ebook and paperback](https://www.packtpub.com/big-data-and-business-intelligence/python-machine-learning) from Packt (the publisher)\n- at other book stores: [Google Books](https://books.google.com/books?id=GOVOCwAAQBAJ&source=gbs_slider_cls_metadata_7_mylibrary), [O\'Reilly](http://shop.oreilly.com/product/9781783555130.do), [Safari](https://www.safaribooksonline.com/library/view/python-machine-learning/9781783555130/), [Barnes & Noble](http://www.barnesandnoble.com/w/python-machine-learning-essentials-sebastian-raschka/1121999969?ean=9781783555130), [Apple iBooks](https://itunes.apple.com/us/book/python-machine-learning/id1028207310?mt=11), ...\n- social platforms: [Goodreads](https://www.goodreads.com/book/show/25545994-python-machine-learning)\n\n#### Translations\n\n- [Italian translation](https://www.amazon.it/learning-Costruire-algoritmi-generare-conoscenza/dp/8850333978/) via ""Apogeo""\n- [German translation](https://www.amazon.de/Machine-Learning-Python-mitp-Professional/dp/3958454224/) via ""mitp Verlag""\n- [Japanese translation](http://www.amazon.co.jp/gp/product/4844380605/) via ""Impress Top Gear""\n- [Chinese translation (traditional Chinese)](https://taiwan.kinokuniya.com/bw/9789864341405)\n- [Chinese translation (simple Chinese)](https://book.douban.com/subject/27000110/)\n- [Korean translation](http://www.kyobobook.co.kr/product/detailViewKor.laf?mallGb=KOR&ejkGb=KOR&barcode=9791187497035) via ""Kyobo""\n- [Polish translation](https://www.amazon.de/Python-Uczenie-maszynowe-Sebastian-Raschka/dp/8328336138/ref=sr_1_11?ie=UTF8&qid=1513601461&sr=8-11&keywords=sebastian+raschka) via ""Helion""\n\n---\n\n### [Literature References & Further Reading Resources](./docs/references.md)\n\n### [Errata](./docs/errata.md)\n\n\n---\n\n### Bonus Notebooks (not in the book)\n\n- Logistic Regression Implementation [[dir](./code/bonus)] [[ipynb](./code/bonus/logistic_regression.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/bonus/logistic_regression.ipynb)]\n- A Basic Pipeline and Grid Search Setup [[dir](./code/bonus)] [[ipynb](./code/bonus/svm_iris_pipeline_and_gridsearch.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/bonus/svm_iris_pipeline_and_gridsearch.ipynb)]\n- An Extended Nested Cross-Validation Example [[dir](./code/bonus)] [[ipynb](./code/bonus/nested_cross_validation.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/bonus/nested_cross_validation.ipynb)]\n- A Simple Barebones Flask Webapp Template [[view directory](./code/bonus/flask_webapp_ex01)][[download as zip-file](https://github.com/rasbt/python-machine-learning-book/raw/master/code/bonus/flask_webapp_ex01/flask_webapp_ex01.zip)]\n- Reading handwritten digits from MNIST into NumPy arrays [[GitHub ipynb](./code/bonus/reading_mnist.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/bonus/reading_mnist.ipynb)]\n- Scikit-learn Model Persistence using JSON [[GitHub ipynb](./code/bonus/scikit-model-to-json.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/bonus/scikit-model-to-json.ipynb)]\n- Multinomial logistic regression / softmax regression [[GitHub ipynb](./code/bonus/softmax-regression.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/bonus/softmax-regression.ipynb)]\n\n<hr>\n\n**""Related Content"" (not in the book)**\n\n- [Model evaluation, model selection, and algorithm selection in machine learning - Part I](http://sebastianraschka.com/blog/2016/model-evaluation-selection-part1.html)\n- [Model evaluation, model selection, and algorithm selection in machine learning - Part II](http://sebastianraschka.com/blog/2016/model-evaluation-selection-part2.html)\n- [Model evaluation, model selection, and algorithm selection in machine learning - Part III](http://sebastianraschka.com/blog/2016/model-evaluation-selection-part3.html)\n\n---\n\n#### SciPy 2016\n\nWe had such a great time at [SciPy 2016](http://scipy2016.scipy.org/ehome/index.php?eventid=146062&tabid=332930&) in Austin! It was a real pleasure to meet and chat with so many readers of my book. Thanks so much for all the nice words and feedback! And in case you missed it, Andreas Mueller and I gave an **Introduction to Machine Learning with Scikit-learn**; if you are interested, the video recordings of [Part I](https://www.youtube.com/watch?v=OB1reY6IX-o&index=91&list=PLYx7XA2nY5Gf37zYZMw6OqGFRPjB1jCy6) and [Part II](https://www.youtube.com/watch?v=Cte8FYCpylk&list=PLYx7XA2nY5Gf37zYZMw6OqGFRPjB1jCy6&index=90) are now online!\n\n[![](images/scipy2016.jpg)](https://www.youtube.com/watch?v=OB1reY6IX-o&index=91&list=PLYx7XA2nY5Gf37zYZMw6OqGFRPjB1jCy6)\n\n#### PyData Chicago 2016\n\nI attempted the rather challenging task of introducing scikit-learn & machine learning in *just* 90 minutes at PyData Chicago 2016. The slides and tutorial material are available at ""[Learning scikit-learn -- An Introduction to Machine Learning in Python](https://github.com/rasbt/pydata-chicago2016-ml-tutorial).""\n\n\n---\n\n**Note**\n\nI have set up a separate library, [`mlxtend`](http://rasbt.github.io/mlxtend/), containing additional implementations of machine learning (and general ""data science"") algorithms. I also added implementations from this book (for example, the decision region plot, the artificial neural network, and sequential feature selection algorithms) with additional functionality.\n\n[![](./images/mlxtend_logo.png)](http://rasbt.github.io/mlxtend/)\n\n\n<br>\n\n<hr>\n\n### Translations\n\n[![](./images/pymle-cover_it.jpg)](https://www.amazon.it/learning-Costruire-algoritmi-generare-conoscenza/dp/8850333978/)\n[![](./images/pymle-cover_de.jpg)](https://www.amazon.de/Machine-Learning-Python-mitp-Professional/dp/3958454224/)\n[![](./images/pymle-cover_jp.jpg)](http://www.amazon.co.jp/gp/product/4844380605/)\n[![](./images/pymle-cover_cn.jpg)](https://taiwan.kinokuniya.com/bw/9789864341405)\n[![](./images/pymle-cover_cn_mainland.jpg)](https://book.douban.com/subject/27000110/)\n[![](./images/pymle-cover_kr.jpg)](http://www.kyobobook.co.kr/product/detailViewKor.laf?ejkGb=KOR&mallGb=KOR&barcode=9791187497035&orderClick=LEA&Kc=)\n[![](./images/pymle-cover_ru.jpg)](http://www.ozon.ru/context/detail/id/140152222/)\n[![](./images/pymle-cover_pl.jpg)](https://www.amazon.de/Python-Uczenie-maszynowe-Sebastian-Raschka/dp/8328336138/ref=sr_1_11?ie=UTF8&qid=1513601461&sr=8-11&keywords=sebastian+raschka)\n\n<hr>\n\n---\n\n***Dear readers***,  \nfirst of all, I want to thank all of you for the great support! I am really happy about all the great feedback you sent me so far, and I am glad that the book has been so useful to a broad audience.\n\nOver the last couple of months, I received hundreds of emails, and I tried to answer as many as possible in the available time I have. To make them useful to other readers as well, I collected many of my answers in the FAQ section (below).\n\nIn addition, some of you asked me about a platform for readers to discuss the contents of the book. I hope that this would provide an opportunity for you to discuss and share your knowledge with other readers:\n\n#### [Google Groups Discussion Board](https://groups.google.com/forum/#!forum/python-machine-learning-reader-discussion-board)\n\n(And I will try my best to answer questions myself if time allows! :))\n\n> The only thing to do with good advice is to pass it on. It is never of any use to oneself.  \n\xe2\x80\x94 Oscar Wilde\n\n---\n\n## Examples and Applications by Readers\n\nOnce again, I have to say (big!) THANKS for all the nice feedback about the book. I\'ve received many emails from readers, who\nput the concepts and examples from this book out into the real world and make good use of them in their projects. In this section, I am\nstarting to gather some of these great applications, and I\'d be more than happy to add your project to this list -- just shoot me a quick mail!\n\n- [40 scripts on Optical Character Recognition](https://github.com/rrlyman/PythonMachineLearingExamples) by [Richard Lyman](https://github.com/rrlyman)\n- [Code experiments](https://github.com/jeremyn/python-machine-learning-book) by [Jeremy Nation](https://github.com/jeremyn)\n- [What I Learned Implementing a Classifier from Scratch in Python](http://www.jeannicholashould.com) by [Jean-Nicholas Hould](http://www.jeannicholashould.com)\n\n## FAQ\n\n### General Questions\n\n- [What are machine learning and data science?](./faq/datascience-ml.md)\n- [Why do you and other people sometimes implement machine learning algorithms from scratch?](./faq/implementing-from-scratch.md)\n- [What learning path/discipline in data science I should focus on?](./faq/data-science-career.md)\n- [At what point should one start contributing to open source?](./faq/open-source.md)\n- [How important do you think having a mentor is to the learning process?](./faq/mentor.md)\n- [Where are the best online communities centered around data science/machine learning or python?](./faq/ml-python-communities.md)\n- [How would you explain machine learning to a software engineer?](./faq/ml-to-a-programmer.md)\n- [How would your curriculum for a machine learning beginner look like?](./faq/ml-curriculum.md)\n- [What is the Definition of Data Science?](./faq/definition_data-science.md)\n- [How do Data Scientists perform model selection? Is it different from Kaggle?](./faq/model-selection-in-datascience.md)\n\n### Questions about the Machine Learning Field\n\n- [How are Artificial Intelligence and Machine Learning related?](./faq/ai-and-ml.md)\n- [What are some real-world examples of applications of machine learning in the field?](./faq/ml-examples.md)\n- [What are the different fields of study in data mining?](./faq/datamining-overview.md)\n- [What are differences in research nature between the two fields: machine learning & data mining?](./faq/datamining-vs-ml.md)\n- [How do I know if the problem is solvable through machine learning?](./faq/ml-solvable.md)\n- [What are the origins of machine learning?](./faq/ml-origins.md)\n- [How was classification, as a learning machine, developed?](./faq/classifier-history.md)\n- [Which machine learning algorithms can be considered as among the best?](./faq/best-ml-algo.md)\n- [What are the broad categories of classifiers?](./faq/classifier-categories.md)\n- [What is the difference between a classifier and a model?](./faq/difference_classifier_model.md)\n- [What is the difference between a parametric learning algorithm and a nonparametric learning algorithm?](./faq/parametric_vs_nonparametric.md)\n- [What is the difference between a cost function and a loss function in machine learning?](./faq/cost-vs-loss.md)\n\n### Questions about ML Concepts and Statistics\n\n##### Cost Functions and Optimization\n\n- [Fitting a model via closed-form equations vs. Gradient Descent vs Stochastic Gradient Descent vs Mini-Batch Learning -- what is the difference?](./faq/closed-form-vs-gd.md)\n- [How do you derive the Gradient Descent rule for Linear Regression and Adaline?](./faq/linear-gradient-derivative.md)\n\n##### Regression Analysis\n\n- [What is the difference between Pearson R and Simple Linear Regression?](./faq/pearson-r-vs-linear-regr.md)\n\n##### Tree models\n\n- [How does the random forest model work? How is it different from bagging and boosting in ensemble models?](./faq/bagging-boosting-rf.md)\n- [What are the disadvantages of using classic decision tree algorithm for a large dataset?](./faq/decision-tree-disadvantages.md)\n- [Why are implementations of decision tree algorithms usually binary, and what are the advantages of the different impurity metrics?](./faq/decision-tree-binary.md)\n- [Why are we growing decision trees via entropy instead of the classification error?](./faq/decisiontree-error-vs-entropy.md)\n- [When can a random forest perform terribly?](./faq/random-forest-perform-terribly.md)\n\n##### Model evaluation\n\n- [What is overfitting?](./faq/overfitting.md)\n- [How can I avoid overfitting?](./faq/avoid-overfitting.md)\n- [Is it always better to have the largest possible number of folds when performing cross validation?](./faq/number-of-kfolds.md)\n- [When training an SVM classifier, is it better to have a large or small number of support vectors?](./faq/num-support-vectors.md)\n- [How do I evaluate a model?](./faq/evaluate-a-model.md)\n- [What is the best validation metric for multi-class classification?](./faq/multiclass-metric.md)\n- [What factors should I consider when choosing a predictive model technique?](./faq/choosing-technique.md)\n- [What are the best toy datasets to help visualize and understand classifier behavior?](./faq/clf-behavior-data.md)\n- [How do I select SVM kernels?](./faq/select_svm_kernels.md)\n- [Interlude: Comparing and Computing Performance Metrics in Cross-Validation -- Imbalanced Class Problems and 3 Different Ways to Compute the F1 Score](./faq/computing-the-f1-score.md)\n\n##### Logistic Regression\n\n- [What is Softmax regression and how is it related to Logistic regression?](./faq/softmax_regression.md)\n- [Why is logistic regression considered a linear model?](./faq/logistic_regression_linear.md)\n- [What is the probabilistic interpretation of regularized logistic regression?](./faq/probablistic-logistic-regression.md)\n- [Does regularization in logistic regression always results in better fit and better generalization?](./faq/regularized-logistic-regression-performance.md)\n- [What is the major difference between naive Bayes and logistic regression?](./faq/naive-bayes-vs-logistic-regression.md)\n- [What exactly is the ""softmax and the multinomial logistic loss"" in the context of machine learning?](./faq/softmax.md)\n- [What is the relation between Loigistic Regression and Neural Networks and when to use which?](./faq/logisticregr-neuralnet.md)\n- [Logistic Regression: Why sigmoid function?](./faq/logistic-why-sigmoid.md)\n- [Is there an analytical solution to Logistic Regression similar to the Normal Equation for Linear Regression?](./faq/logistic-analytical.md)\n\n\n##### Neural Networks and Deep Learning\n\n- [What is the difference between deep learning and usual machine learning?](./faq/difference-deep-and-normal-learning.md)\n- [Can you give a visual explanation for the back propagation algorithm for neural networks?](./faq/visual-backpropagation.md)\n- [Why did it take so long for deep networks to be invented?](./faq/inventing-deeplearning.md)\n- [What are some good books/papers for learning deep learning?](./faq/deep-learning-resources.md)\n- [Why are there so many deep learning libraries?](./faq/many-deeplearning-libs.md)\n- [Why do some people hate neural networks/deep learning?](./faq/deeplearning-criticism.md)\n- [How can I know if Deep Learning works better for a specific problem than SVM or random forest?](./faq/deeplearn-vs-svm-randomforest.md)\n- [What is wrong when my neural network\'s error increases?](./faq/neuralnet-error.md)\n- [How do I debug an artificial neural network algorithm?](./faq/nnet-debugging-checklist.md)\n- [What is the difference between a Perceptron, Adaline, and neural network model?](./faq/diff-perceptron-adaline-neuralnet.md)\n- [What is the basic idea behind the dropout technique?](./faq/dropout.md)\n\n\n##### Other Algorithms for Supervised Learning\n\n- [Why is Nearest Neighbor a Lazy Algorithm?](./faq/lazy-knn.md)\n\n##### Unsupervised Learning\n\n- [What are some of the issues with clustering?](./faq/issues-with-clustering.md)\n\n##### Semi-Supervised Learning\n\n- [What are the advantages of semi-supervised learning over supervised and unsupervised learning?](./faq/semi-vs-supervised.md)\n\n##### Ensemble Methods\n\n- [Is Combining Classifiers with Stacking Better than Selecting the Best One?](./faq/logistic-boosting.md)\n\n##### Preprocessing, Feature Selection and Extraction\n\n- [Why do we need to re-use training parameters to transform test data?](./faq/scale-training-test.md)\n- [What are the different dimensionality reduction methods in machine learning?](./faq/dimensionality-reduction.md)\n- [What is the difference between LDA and PCA for dimensionality reduction?](./faq/lda-vs-pca.md)\n- [When should I apply data normalization/standardization?](./faq/when-to-standardize.md)\n- [Does mean centering or feature scaling affect a Principal Component Analysis?](./faq/pca-scaling.md)\n- [How do you attack a machine learning problem with a large number of features?](./faq/large-num-features.md)\n- [What are some common approaches for dealing with missing data?](./faq/missing-data.md)\n- [What is the difference between filter, wrapper, and embedded methods for feature selection?](./faq/feature_sele_categories.md)\n- [Should data preparation/pre-processing step be considered one part of feature engineering? Why or why not?](./faq/dataprep-vs-dataengin.md)\n- [Is a bag of words feature representation for text classification considered as a sparse matrix?](./faq/bag-of-words-sparsity.md)\n\n##### Naive Bayes\n\n- [Why is the Naive Bayes Classifier naive?](./faq/naive-naive-bayes.md)\n- [What is the decision boundary for Naive Bayes?](./faq/naive-bayes-boundary.md)\n- [Can I use Naive Bayes classifiers for mixed variable types?](./faq/naive-bayes-vartypes.md)\n- [Is it possible to mix different variable types in Naive Bayes, for example, binary and continues features?](./naive-bayes-vartypes.md)\n\n##### Other\n\n- [What is Euclidean distance in terms of machine learning?](./faq/euclidean-distance.md)\n- [When should one use median, as opposed to the mean or average?](./faq/median-vs-mean.md)\n\n##### Programming Languages and Libraries for Data Science and Machine Learning\n\n- [Is R used extensively today in data science?](./faq/r-in-datascience.md)\n- [What is the main difference between TensorFlow and scikit-learn?](./faq/tensorflow-vs-scikitlearn.md)\n\n<br>\n\n\n\n\n\n### Questions about the Book\n\n- [Can I use paragraphs and images from the book in presentations or my blog?](./faq/copyright.md)\n- [How is this different from other machine learning books?](./faq/different.md)\n- [Which version of Python was used in the code examples?](./faq/py2py3.md)\n- [Which technologies and libraries are being used?](./faq/technologies.md)\n- [Which book version/format would you recommend?](./faq/version.md)\n- [Why did you choose Python for machine learning?](./faq/why-python.md)\n- [Why do you use so many leading and trailing underscores in the code examples?](./faq/underscore-convention.md)\n- [What is the purpose of the `return self` idioms in your code examples?](./faq/return_self_idiom.md)\n- [Are there any prerequisites and recommended pre-readings?](./faq/prerequisites.md)\n- [How can I apply SVM to categorical data?](./faq/svm_for_categorical.md)\n\n\n## Contact\n\nI am happy to answer questions! Just write me an [email](mailto:mail@sebastianraschka.com)\nor consider asking the question on the [Google Groups Email List](https://groups.google.com/forum/#!forum/python-machine-learning-book).\n\nIf you are interested in keeping in touch, I have quite a lively twitter stream ([@rasbt](https://twitter.com/rasbt)) all about data science and machine learning. I also maintain a [blog](http://sebastianraschka.com/articles.html) where I post all of the things I am particularly excited about.\n'"
5,lazyprogrammer/machine_learning_examples,lazyprogrammer,A collection of machine learning examples and tutorials.,2014-07-31 23:40:45,2020-06-18 18:10:27,Python,4700,5140,"b'machine_learning_examples\n=========================\n\nA collection of machine learning examples and tutorials.\n\nFind associated tutorials at https://lazyprogrammer.me\n\nFind associated courses at https://deeplearningcourses.com\n\nPlease note that not all code from all courses will be found in this repository. Some newer code examples (e.g. everything from Tensorflow 2.0) were done in Google Colab. Therefore, you should check the instructions given in the lectures for the course you are taking.\n\n\nWhy you should not fork this repo\n=================================\n\nI\'ve noticed that many people have out-of-date forks. Thus, I recommend not forking this repository if you take one of my courses. I am constantly updating my courses, and your fork will soon become out-of-date. You should clone the repository instead to make it easy to get updates (i.e. just ""git pull"" randomly and frequently).\n\n\nDirect Course Links\n===================\n\nPyTorch: Deep Learning and Artificial Intelligence (special discount link for full VIP course as of Apr 2020)\nhttps://www.udemy.com/course/pytorch-deep-learning/?couponCode=PYTORCHVIP\n\n\nTensorflow 2.0: Deep Learning and Artificial Intelligence\n(Main Course - special discount link)\nhttps://www.udemy.com/course/deep-learning-tensorflow-2/?referralCode=E10B72D3848AB70FE1B8\n\nTensorflow 2.0: Deep Learning and Artificial Intelligence (VIP Content)\nhttps://deeplearningcourses.com/c/deep-learning-tensorflow-2\n\nCutting-Edge AI: Deep Reinforcement Learning in Python\nhttps://deeplearningcourses.com/c/cutting-edge-artificial-intelligence\n\nRecommender Systems and Deep Learning in Python\nhttps://deeplearningcourses.com/c/recommender-systems\n\nMachine Learning and AI: Support Vector Machines in Python\nhttps://deeplearningcourses.com/c/support-vector-machines-in-python\n\nDeep Learning: Advanced Computer Vision\nhttps://deeplearningcourses.com/c/advanced-computer-vision\n\nDeep Learning: Advanced NLP and RNNs\nhttps://deeplearningcourses.com/c/deep-learning-advanced-nlp\n\nDeep Learning: GANs and Variational Autoencoders\nhttps://deeplearningcourses.com/c/deep-learning-gans-and-variational-autoencoders\n\nAdvanced AI: Deep Reinforcement Learning in Python\nhttps://deeplearningcourses.com/c/deep-reinforcement-learning-in-python\n\nArtificial Intelligence: Reinforcement Learning in Python\nhttps://deeplearningcourses.com/c/artificial-intelligence-reinforcement-learning-in-python\n\nNatural Language Processing with Deep Learning in Python\nhttps://deeplearningcourses.com/c/natural-language-processing-with-deep-learning-in-python\n\nDeep Learning: Recurrent Neural Networks in Python\nhttps://deeplearningcourses.com/c/deep-learning-recurrent-neural-networks-in-python\n\nUnsupervised Machine Learning: Hidden Markov Models in Python\nhttps://deeplearningcourses.com/c/unsupervised-machine-learning-hidden-markov-models-in-python\n\nDeep Learning Prerequisites: The Numpy Stack in Python\nhttps://deeplearningcourses.com/c/deep-learning-prerequisites-the-numpy-stack-in-python\n\nDeep Learning Prerequisites: Linear Regression in Python\nhttps://deeplearningcourses.com/c/data-science-linear-regression-in-python\n\nDeep Learning Prerequisites: Logistic Regression in Python\nhttps://deeplearningcourses.com/c/data-science-logistic-regression-in-python\n\nDeep Learning in Python\nhttps://deeplearningcourses.com/c/data-science-deep-learning-in-python\n\nCluster Analysis and Unsupervised Machine Learning in Python\nhttps://deeplearningcourses.com/c/cluster-analysis-unsupervised-machine-learning-python\n\nData Science: Supervised Machine Learning in Python\nhttps://deeplearningcourses.com/c/data-science-supervised-machine-learning-in-python\n\nBayesian Machine Learning in Python: A/B Testing\nhttps://deeplearningcourses.com/c/bayesian-machine-learning-in-python-ab-testing\n\nEasy Natural Language Processing in Python\nhttps://deeplearningcourses.com/c/data-science-natural-language-processing-in-python\n\nPractical Deep Learning in Theano and TensorFlow\nhttps://deeplearningcourses.com/c/data-science-deep-learning-in-theano-tensorflow\n\nEnsemble Machine Learning in Python: Random Forest and AdaBoost\nhttps://deeplearningcourses.com/c/machine-learning-in-python-random-forest-adaboost\n\nDeep Learning: Convolutional Neural Networks in Python\nhttps://deeplearningcourses.com/c/deep-learning-convolutional-neural-networks-theano-tensorflow\n\nUnsupervised Deep Learning in Python\nhttps://deeplearningcourses.com/c/unsupervised-deep-learning-in-python\n'"
6,lawlite19/MachineLearning_Python,lawlite19,机器学习算法python实现,2016-10-17 15:44:59,2020-06-18 16:30:18,Python,1490,3051,"b'\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xae\x97\xe6\xb3\x95Python\xe5\xae\x9e\xe7\x8e\xb0\n=========\n\n[![MIT license](https://img.shields.io/dub/l/vibe-d.svg)](https://github.com/lawlite19/MachineLearning_Python/blob/master/LICENSE)\n\n## \xe7\x9b\xae\xe5\xbd\x95\n* [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xae\x97\xe6\xb3\x95Python\xe5\xae\x9e\xe7\x8e\xb0](#\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xae\x97\xe6\xb3\x95python\xe5\xae\x9e\xe7\x8e\xb0)\n\t* [\xe4\xb8\x80\xe3\x80\x81\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92](#\xe4\xb8\x80\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92)\n\t\t* [1\xe3\x80\x81\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0](#1\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0)\n\t\t* [2\xe3\x80\x81\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xe7\xae\x97\xe6\xb3\x95](#2\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xe7\xae\x97\xe6\xb3\x95)\n\t\t* [3\xe3\x80\x81\xe5\x9d\x87\xe5\x80\xbc\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96](#3\xe5\x9d\x87\xe5\x80\xbc\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96)\n\t\t* [4\xe3\x80\x81\xe6\x9c\x80\xe7\xbb\x88\xe8\xbf\x90\xe8\xa1\x8c\xe7\xbb\x93\xe6\x9e\x9c](#4\xe6\x9c\x80\xe7\xbb\x88\xe8\xbf\x90\xe8\xa1\x8c\xe7\xbb\x93\xe6\x9e\x9c)\n\t\t* [5\xe3\x80\x81\xe4\xbd\xbf\xe7\x94\xa8scikit-learn\xe5\xba\x93\xe4\xb8\xad\xe7\x9a\x84\xe7\xba\xbf\xe6\x80\xa7\xe6\xa8\xa1\xe5\x9e\x8b\xe5\xae\x9e\xe7\x8e\xb0](#5\xe4\xbd\xbf\xe7\x94\xa8scikit-learn\xe5\xba\x93\xe4\xb8\xad\xe7\x9a\x84\xe7\xba\xbf\xe6\x80\xa7\xe6\xa8\xa1\xe5\x9e\x8b\xe5\xae\x9e\xe7\x8e\xb0)\n\t* [\xe4\xba\x8c\xe3\x80\x81\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92](#\xe4\xba\x8c\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92)\n\t\t* [1\xe3\x80\x81\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0](#1\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0)\n\t\t* [2\xe3\x80\x81\xe6\xa2\xaf\xe5\xba\xa6](#2\xe6\xa2\xaf\xe5\xba\xa6)\n\t\t* [3\xe3\x80\x81\xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96](#3\xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96)\n\t\t* [4\xe3\x80\x81S\xe5\x9e\x8b\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x88\xe5\x8d\xb3\xef\xbc\x89](#4s\xe5\x9e\x8b\xe5\x87\xbd\xe6\x95\xb0\xe5\x8d\xb3)\n\t\t* [5\xe3\x80\x81\xe6\x98\xa0\xe5\xb0\x84\xe4\xb8\xba\xe5\xa4\x9a\xe9\xa1\xb9\xe5\xbc\x8f](#5\xe6\x98\xa0\xe5\xb0\x84\xe4\xb8\xba\xe5\xa4\x9a\xe9\xa1\xb9\xe5\xbc\x8f)\n\t\t* [6\xe3\x80\x81\xe4\xbd\xbf\xe7\x94\xa8\xe7\x9a\x84\xe4\xbc\x98\xe5\x8c\x96\xe6\x96\xb9\xe6\xb3\x95](#6\xe4\xbd\xbf\xe7\x94\xa8scipy\xe7\x9a\x84\xe4\xbc\x98\xe5\x8c\x96\xe6\x96\xb9\xe6\xb3\x95)\n\t\t* [7\xe3\x80\x81\xe8\xbf\x90\xe8\xa1\x8c\xe7\xbb\x93\xe6\x9e\x9c](#7\xe8\xbf\x90\xe8\xa1\x8c\xe7\xbb\x93\xe6\x9e\x9c)\n\t\t* [8\xe3\x80\x81\xe4\xbd\xbf\xe7\x94\xa8scikit-learn\xe5\xba\x93\xe4\xb8\xad\xe7\x9a\x84\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92\xe6\xa8\xa1\xe5\x9e\x8b\xe5\xae\x9e\xe7\x8e\xb0](#8\xe4\xbd\xbf\xe7\x94\xa8scikit-learn\xe5\xba\x93\xe4\xb8\xad\xe7\x9a\x84\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92\xe6\xa8\xa1\xe5\x9e\x8b\xe5\xae\x9e\xe7\x8e\xb0)\n\t* [\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92_\xe6\x89\x8b\xe5\x86\x99\xe6\x95\xb0\xe5\xad\x97\xe8\xaf\x86\xe5\x88\xab_OneVsAll](#\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92_\xe6\x89\x8b\xe5\x86\x99\xe6\x95\xb0\xe5\xad\x97\xe8\xaf\x86\xe5\x88\xab_onevsall)\n\t\t* [1\xe3\x80\x81\xe9\x9a\x8f\xe6\x9c\xba\xe6\x98\xbe\xe7\xa4\xba100\xe4\xb8\xaa\xe6\x95\xb0\xe5\xad\x97](#1\xe9\x9a\x8f\xe6\x9c\xba\xe6\x98\xbe\xe7\xa4\xba100\xe4\xb8\xaa\xe6\x95\xb0\xe5\xad\x97)\n\t\t* [2\xe3\x80\x81OneVsAll](#2onevsall)\n\t\t* [3\xe3\x80\x81\xe6\x89\x8b\xe5\x86\x99\xe6\x95\xb0\xe5\xad\x97\xe8\xaf\x86\xe5\x88\xab](#3\xe6\x89\x8b\xe5\x86\x99\xe6\x95\xb0\xe5\xad\x97\xe8\xaf\x86\xe5\x88\xab)\n\t\t* [4\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b](#4\xe9\xa2\x84\xe6\xb5\x8b)\n\t\t* [5\xe3\x80\x81\xe8\xbf\x90\xe8\xa1\x8c\xe7\xbb\x93\xe6\x9e\x9c](#5\xe8\xbf\x90\xe8\xa1\x8c\xe7\xbb\x93\xe6\x9e\x9c)\n\t\t* [6\xe3\x80\x81\xe4\xbd\xbf\xe7\x94\xa8scikit-learn\xe5\xba\x93\xe4\xb8\xad\xe7\x9a\x84\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92\xe6\xa8\xa1\xe5\x9e\x8b\xe5\xae\x9e\xe7\x8e\xb0](#6\xe4\xbd\xbf\xe7\x94\xa8scikit-learn\xe5\xba\x93\xe4\xb8\xad\xe7\x9a\x84\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92\xe6\xa8\xa1\xe5\x9e\x8b\xe5\xae\x9e\xe7\x8e\xb0)\n\t* [\xe4\xb8\x89\xe3\x80\x81BP\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c](#\xe4\xb8\x89bp\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c)\n\t\t* [1\xe3\x80\x81\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9cmodel](#1\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9cmodel)\n\t\t* [2\xe3\x80\x81\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0](#2\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0)\n\t\t* [3\xe3\x80\x81\xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96](#3\xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96)\n\t\t* [4\xe3\x80\x81\xe5\x8f\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xadBP](#4\xe5\x8f\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xadbp)\n\t\t* [5\xe3\x80\x81BP\xe5\x8f\xaf\xe4\xbb\xa5\xe6\xb1\x82\xe6\xa2\xaf\xe5\xba\xa6\xe7\x9a\x84\xe5\x8e\x9f\xe5\x9b\xa0](#5bp\xe5\x8f\xaf\xe4\xbb\xa5\xe6\xb1\x82\xe6\xa2\xaf\xe5\xba\xa6\xe7\x9a\x84\xe5\x8e\x9f\xe5\x9b\xa0)\n\t\t* [6\xe3\x80\x81\xe6\xa2\xaf\xe5\xba\xa6\xe6\xa3\x80\xe6\x9f\xa5](#6\xe6\xa2\xaf\xe5\xba\xa6\xe6\xa3\x80\xe6\x9f\xa5)\n\t\t* [7\xe3\x80\x81\xe6\x9d\x83\xe9\x87\x8d\xe7\x9a\x84\xe9\x9a\x8f\xe6\x9c\xba\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96](#7\xe6\x9d\x83\xe9\x87\x8d\xe7\x9a\x84\xe9\x9a\x8f\xe6\x9c\xba\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96)\n\t\t* [8\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b](#8\xe9\xa2\x84\xe6\xb5\x8b)\n\t\t* [9\xe3\x80\x81\xe8\xbe\x93\xe5\x87\xba\xe7\xbb\x93\xe6\x9e\x9c](#9\xe8\xbe\x93\xe5\x87\xba\xe7\xbb\x93\xe6\x9e\x9c)\n\t* [\xe5\x9b\x9b\xe3\x80\x81SVM\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba](#\xe5\x9b\x9bsvm\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba)\n\t\t* [1\xe3\x80\x81\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0](#1\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0)\n\t\t* [2\xe3\x80\x81Large Margin](#2large-margin)\n\t\t* [3\xe3\x80\x81SVM Kernel\xef\xbc\x88\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x89](#3svm-kernel\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0)\n\t\t* [4\xe3\x80\x81\xe4\xbd\xbf\xe7\x94\xa8\xe4\xb8\xad\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xbb\xa3\xe7\xa0\x81](#4\xe4\xbd\xbf\xe7\x94\xa8scikit-learn\xe4\xb8\xad\xe7\x9a\x84svm\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xbb\xa3\xe7\xa0\x81)\n\t\t* [5\xe3\x80\x81\xe8\xbf\x90\xe8\xa1\x8c\xe7\xbb\x93\xe6\x9e\x9c](#5\xe8\xbf\x90\xe8\xa1\x8c\xe7\xbb\x93\xe6\x9e\x9c)\n\t* [\xe4\xba\x94\xe3\x80\x81K-Means\xe8\x81\x9a\xe7\xb1\xbb\xe7\xae\x97\xe6\xb3\x95](#\xe4\xba\x94k-means\xe8\x81\x9a\xe7\xb1\xbb\xe7\xae\x97\xe6\xb3\x95)\n\t\t* [1\xe3\x80\x81\xe8\x81\x9a\xe7\xb1\xbb\xe8\xbf\x87\xe7\xa8\x8b](#1\xe8\x81\x9a\xe7\xb1\xbb\xe8\xbf\x87\xe7\xa8\x8b)\n\t\t* [2\xe3\x80\x81\xe7\x9b\xae\xe6\xa0\x87\xe5\x87\xbd\xe6\x95\xb0](#2\xe7\x9b\xae\xe6\xa0\x87\xe5\x87\xbd\xe6\x95\xb0)\n\t\t* [3\xe3\x80\x81\xe8\x81\x9a\xe7\xb1\xbb\xe4\xb8\xad\xe5\xbf\x83\xe7\x9a\x84\xe9\x80\x89\xe6\x8b\xa9](#3\xe8\x81\x9a\xe7\xb1\xbb\xe4\xb8\xad\xe5\xbf\x83\xe7\x9a\x84\xe9\x80\x89\xe6\x8b\xa9)\n\t\t* [4\xe3\x80\x81\xe8\x81\x9a\xe7\xb1\xbb\xe4\xb8\xaa\xe6\x95\xb0K\xe7\x9a\x84\xe9\x80\x89\xe6\x8b\xa9](#4\xe8\x81\x9a\xe7\xb1\xbb\xe4\xb8\xaa\xe6\x95\xb0k\xe7\x9a\x84\xe9\x80\x89\xe6\x8b\xa9)\n\t\t* [5\xe3\x80\x81\xe5\xba\x94\xe7\x94\xa8\xe2\x80\x94\xe2\x80\x94\xe5\x9b\xbe\xe7\x89\x87\xe5\x8e\x8b\xe7\xbc\xa9](#5\xe5\xba\x94\xe7\x94\xa8\xe5\x9b\xbe\xe7\x89\x87\xe5\x8e\x8b\xe7\xbc\xa9)\n\t\t* [6\xe3\x80\x81\xe4\xbd\xbf\xe7\x94\xa8scikit-learn\xe5\xba\x93\xe4\xb8\xad\xe7\x9a\x84\xe7\xba\xbf\xe6\x80\xa7\xe6\xa8\xa1\xe5\x9e\x8b\xe5\xae\x9e\xe7\x8e\xb0\xe8\x81\x9a\xe7\xb1\xbb](#6\xe4\xbd\xbf\xe7\x94\xa8scikit-learn\xe5\xba\x93\xe4\xb8\xad\xe7\x9a\x84\xe7\xba\xbf\xe6\x80\xa7\xe6\xa8\xa1\xe5\x9e\x8b\xe5\xae\x9e\xe7\x8e\xb0\xe8\x81\x9a\xe7\xb1\xbb)\n\t\t* [7\xe3\x80\x81\xe8\xbf\x90\xe8\xa1\x8c\xe7\xbb\x93\xe6\x9e\x9c](#7\xe8\xbf\x90\xe8\xa1\x8c\xe7\xbb\x93\xe6\x9e\x9c)\n\t* [\xe5\x85\xad\xe3\x80\x81PCA\xe4\xb8\xbb\xe6\x88\x90\xe5\x88\x86\xe5\x88\x86\xe6\x9e\x90\xef\xbc\x88\xe9\x99\x8d\xe7\xbb\xb4\xef\xbc\x89](#\xe5\x85\xadpca\xe4\xb8\xbb\xe6\x88\x90\xe5\x88\x86\xe5\x88\x86\xe6\x9e\x90\xe9\x99\x8d\xe7\xbb\xb4)\n\t\t* [1\xe3\x80\x81\xe7\x94\xa8\xe5\xa4\x84](#1\xe7\x94\xa8\xe5\xa4\x84)\n\t\t* [2\xe3\x80\x812D-->1D\xef\xbc\x8cnD-->kD](#22d--1dnd--kd)\n\t\t* [3\xe3\x80\x81\xe4\xb8\xbb\xe6\x88\x90\xe5\x88\x86\xe5\x88\x86\xe6\x9e\x90PCA\xe4\xb8\x8e\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9a\x84\xe5\x8c\xba\xe5\x88\xab](#3\xe4\xb8\xbb\xe6\x88\x90\xe5\x88\x86\xe5\x88\x86\xe6\x9e\x90pca\xe4\xb8\x8e\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9a\x84\xe5\x8c\xba\xe5\x88\xab)\n\t\t* [4\xe3\x80\x81PCA\xe9\x99\x8d\xe7\xbb\xb4\xe8\xbf\x87\xe7\xa8\x8b](#4pca\xe9\x99\x8d\xe7\xbb\xb4\xe8\xbf\x87\xe7\xa8\x8b)\n\t\t* [5\xe3\x80\x81\xe6\x95\xb0\xe6\x8d\xae\xe6\x81\xa2\xe5\xa4\x8d](#5\xe6\x95\xb0\xe6\x8d\xae\xe6\x81\xa2\xe5\xa4\x8d)\n\t\t* [6\xe3\x80\x81\xe4\xb8\xbb\xe6\x88\x90\xe5\x88\x86\xe4\xb8\xaa\xe6\x95\xb0\xe7\x9a\x84\xe9\x80\x89\xe6\x8b\xa9\xef\xbc\x88\xe5\x8d\xb3\xe8\xa6\x81\xe9\x99\x8d\xe7\x9a\x84\xe7\xbb\xb4\xe5\xba\xa6\xef\xbc\x89](#6\xe4\xb8\xbb\xe6\x88\x90\xe5\x88\x86\xe4\xb8\xaa\xe6\x95\xb0\xe7\x9a\x84\xe9\x80\x89\xe6\x8b\xa9\xe5\x8d\xb3\xe8\xa6\x81\xe9\x99\x8d\xe7\x9a\x84\xe7\xbb\xb4\xe5\xba\xa6)\n\t\t* [7\xe3\x80\x81\xe4\xbd\xbf\xe7\x94\xa8\xe5\xbb\xba\xe8\xae\xae](#7\xe4\xbd\xbf\xe7\x94\xa8\xe5\xbb\xba\xe8\xae\xae)\n\t\t* [8\xe3\x80\x81\xe8\xbf\x90\xe8\xa1\x8c\xe7\xbb\x93\xe6\x9e\x9c](#8\xe8\xbf\x90\xe8\xa1\x8c\xe7\xbb\x93\xe6\x9e\x9c)\n\t\t* [9\xe3\x80\x81\xe4\xbd\xbf\xe7\x94\xa8scikit-learn\xe5\xba\x93\xe4\xb8\xad\xe7\x9a\x84PCA\xe5\xae\x9e\xe7\x8e\xb0\xe9\x99\x8d\xe7\xbb\xb4](#9\xe4\xbd\xbf\xe7\x94\xa8scikit-learn\xe5\xba\x93\xe4\xb8\xad\xe7\x9a\x84pca\xe5\xae\x9e\xe7\x8e\xb0\xe9\x99\x8d\xe7\xbb\xb4)\n\t* [\xe4\xb8\x83\xe3\x80\x81\xe5\xbc\x82\xe5\xb8\xb8\xe6\xa3\x80\xe6\xb5\x8b Anomaly Detection](#\xe4\xb8\x83\xe5\xbc\x82\xe5\xb8\xb8\xe6\xa3\x80\xe6\xb5\x8b-anomaly-detection)\n\t\t* [1\xe3\x80\x81\xe9\xab\x98\xe6\x96\xaf\xe5\x88\x86\xe5\xb8\x83\xef\xbc\x88\xe6\xad\xa3\xe6\x80\x81\xe5\x88\x86\xe5\xb8\x83\xef\xbc\x89](#1\xe9\xab\x98\xe6\x96\xaf\xe5\x88\x86\xe5\xb8\x83\xe6\xad\xa3\xe6\x80\x81\xe5\x88\x86\xe5\xb8\x83gaussian-distribution)\n\t\t* [2\xe3\x80\x81\xe5\xbc\x82\xe5\xb8\xb8\xe6\xa3\x80\xe6\xb5\x8b\xe7\xae\x97\xe6\xb3\x95](#2\xe5\xbc\x82\xe5\xb8\xb8\xe6\xa3\x80\xe6\xb5\x8b\xe7\xae\x97\xe6\xb3\x95)\n\t\t* [3\xe3\x80\x81\xe8\xaf\x84\xe4\xbb\xb7\xe7\x9a\x84\xe5\xa5\xbd\xe5\x9d\x8f\xef\xbc\x8c\xe4\xbb\xa5\xe5\x8f\x8a\xe7\x9a\x84\xe9\x80\x89\xe5\x8f\x96](#3\xe8\xaf\x84\xe4\xbb\xb7px\xe7\x9a\x84\xe5\xa5\xbd\xe5\x9d\x8f\xe4\xbb\xa5\xe5\x8f\x8a\xce\xb5\xe7\x9a\x84\xe9\x80\x89\xe5\x8f\x96)\n\t\t* [4\xe3\x80\x81\xe9\x80\x89\xe6\x8b\xa9\xe4\xbd\xbf\xe7\x94\xa8\xe4\xbb\x80\xe4\xb9\x88\xe6\xa0\xb7\xe7\x9a\x84feature\xef\xbc\x88\xe5\x8d\x95\xe5\x85\x83\xe9\xab\x98\xe6\x96\xaf\xe5\x88\x86\xe5\xb8\x83\xef\xbc\x89](#4\xe9\x80\x89\xe6\x8b\xa9\xe4\xbd\xbf\xe7\x94\xa8\xe4\xbb\x80\xe4\xb9\x88\xe6\xa0\xb7\xe7\x9a\x84feature\xe5\x8d\x95\xe5\x85\x83\xe9\xab\x98\xe6\x96\xaf\xe5\x88\x86\xe5\xb8\x83)\n\t\t* [5\xe3\x80\x81\xe5\xa4\x9a\xe5\x85\x83\xe9\xab\x98\xe6\x96\xaf\xe5\x88\x86\xe5\xb8\x83](#5\xe5\xa4\x9a\xe5\x85\x83\xe9\xab\x98\xe6\x96\xaf\xe5\x88\x86\xe5\xb8\x83)\n\t\t* [6\xe3\x80\x81\xe5\x8d\x95\xe5\x85\x83\xe5\x92\x8c\xe5\xa4\x9a\xe5\x85\x83\xe9\xab\x98\xe6\x96\xaf\xe5\x88\x86\xe5\xb8\x83\xe7\x89\xb9\xe7\x82\xb9](#6\xe5\x8d\x95\xe5\x85\x83\xe5\x92\x8c\xe5\xa4\x9a\xe5\x85\x83\xe9\xab\x98\xe6\x96\xaf\xe5\x88\x86\xe5\xb8\x83\xe7\x89\xb9\xe7\x82\xb9)\n\t\t* [7\xe3\x80\x81\xe7\xa8\x8b\xe5\xba\x8f\xe8\xbf\x90\xe8\xa1\x8c\xe7\xbb\x93\xe6\x9e\x9c](#7\xe7\xa8\x8b\xe5\xba\x8f\xe8\xbf\x90\xe8\xa1\x8c\xe7\xbb\x93\xe6\x9e\x9c)\n\n## \xe4\xb8\x80\xe3\x80\x81[\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92](/LinearRegression)\n- [\xe5\x85\xa8\xe9\x83\xa8\xe4\xbb\xa3\xe7\xa0\x81](/LinearRegression/LinearRegression.py)\n\n### 1\xe3\x80\x81\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0\n- ![J(\\theta ) = \\frac{1}{{2{\\text{m}}}}\\sum\\limits_{i = 1}^m {{{({h_\\theta }({x^{(i)}}) - {y^{(i)}})}^2}} ](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=J%28%5Ctheta%20%29%20%3D%20%5Cfrac%7B1%7D%7B%7B2%7B%5Ctext%7Bm%7D%7D%7D%7D%5Csum%5Climits_%7Bi%20%3D%201%7D%5Em%20%7B%7B%7B%28%7Bh_%5Ctheta%20%7D%28%7Bx%5E%7B%28i%29%7D%7D%29%20-%20%7By%5E%7B%28i%29%7D%7D%29%7D%5E2%7D%7D%20)\n- \xe5\x85\xb6\xe4\xb8\xad\xef\xbc\x9a\n![{h_\\theta }(x) = {\\theta _0} + {\\theta _1}{x_1} + {\\theta _2}{x_2} + ...](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7Bh_%5Ctheta%20%7D%28x%29%20%3D%20%7B%5Ctheta%20_0%7D%20%2B%20%7B%5Ctheta%20_1%7D%7Bx_1%7D%20%2B%20%7B%5Ctheta%20_2%7D%7Bx_2%7D%20%2B%20...)\n\n- \xe4\xb8\x8b\xe9\x9d\xa2\xe5\xb0\xb1\xe6\x98\xaf\xe8\xa6\x81\xe6\xb1\x82\xe5\x87\xbatheta\xef\xbc\x8c\xe4\xbd\xbf\xe4\xbb\xa3\xe4\xbb\xb7\xe6\x9c\x80\xe5\xb0\x8f\xef\xbc\x8c\xe5\x8d\xb3\xe4\xbb\xa3\xe8\xa1\xa8\xe6\x88\x91\xe4\xbb\xac\xe6\x8b\x9f\xe5\x90\x88\xe5\x87\xba\xe6\x9d\xa5\xe7\x9a\x84\xe6\x96\xb9\xe7\xa8\x8b\xe8\xb7\x9d\xe7\xa6\xbb\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe6\x9c\x80\xe8\xbf\x91\n- \xe5\x85\xb1\xe6\x9c\x89m\xe6\x9d\xa1\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe5\x85\xb6\xe4\xb8\xad![{{{({h_\\theta }({x^{(i)}}) - {y^{(i)}})}^2}}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7B%7B%7B%28%7Bh_%5Ctheta%20%7D%28%7Bx%5E%7B%28i%29%7D%7D%29%20-%20%7By%5E%7B%28i%29%7D%7D%29%7D%5E2%7D%7D)\xe4\xbb\xa3\xe8\xa1\xa8\xe6\x88\x91\xe4\xbb\xac\xe8\xa6\x81\xe6\x8b\x9f\xe5\x90\x88\xe5\x87\xba\xe6\x9d\xa5\xe7\x9a\x84\xe6\x96\xb9\xe7\xa8\x8b\xe5\x88\xb0\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe8\xb7\x9d\xe7\xa6\xbb\xe7\x9a\x84\xe5\xb9\xb3\xe6\x96\xb9\xef\xbc\x8c\xe5\xb9\xb3\xe6\x96\xb9\xe7\x9a\x84\xe5\x8e\x9f\xe5\x9b\xa0\xe6\x98\xaf\xe5\x9b\xa0\xe4\xb8\xba\xe5\x8f\xaf\xe8\x83\xbd\xe6\x9c\x89\xe8\xb4\x9f\xe5\x80\xbc\xef\xbc\x8c\xe6\xad\xa3\xe8\xb4\x9f\xe5\x8f\xaf\xe8\x83\xbd\xe4\xbc\x9a\xe6\x8a\xb5\xe6\xb6\x88\n- \xe5\x89\x8d\xe9\x9d\xa2\xe6\x9c\x89\xe7\xb3\xbb\xe6\x95\xb0`2`\xe7\x9a\x84\xe5\x8e\x9f\xe5\x9b\xa0\xe6\x98\xaf\xe4\xb8\x8b\xe9\x9d\xa2\xe6\xb1\x82\xe6\xa2\xaf\xe5\xba\xa6\xe6\x98\xaf\xe5\xaf\xb9\xe6\xaf\x8f\xe4\xb8\xaa\xe5\x8f\x98\xe9\x87\x8f\xe6\xb1\x82\xe5\x81\x8f\xe5\xaf\xbc\xef\xbc\x8c`2`\xe5\x8f\xaf\xe4\xbb\xa5\xe6\xb6\x88\xe5\x8e\xbb\n\n- \xe5\xae\x9e\xe7\x8e\xb0\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a\n```\n# \xe8\xae\xa1\xe7\xae\x97\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0\ndef computerCost(X,y,theta):\n    m = len(y)\n    J = 0\n    \n    J = (np.transpose(X*theta-y))*(X*theta-y)/(2*m) #\xe8\xae\xa1\xe7\xae\x97\xe4\xbb\xa3\xe4\xbb\xb7J\n    return J\n```\n - \xe6\xb3\xa8\xe6\x84\x8f\xe8\xbf\x99\xe9\x87\x8c\xe7\x9a\x84X\xe6\x98\xaf\xe7\x9c\x9f\xe5\xae\x9e\xe6\x95\xb0\xe6\x8d\xae\xe5\x89\x8d\xe5\x8a\xa0\xe4\xba\x86\xe4\xb8\x80\xe5\x88\x971\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xba\xe6\x9c\x89theta(0)\n\n### 2\xe3\x80\x81\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xe7\xae\x97\xe6\xb3\x95\n- \xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0\xe5\xaf\xb9![{{\\theta _j}}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7B%7B%5Ctheta%20_j%7D%7D)\xe6\xb1\x82\xe5\x81\x8f\xe5\xaf\xbc\xe5\xbe\x97\xe5\x88\xb0\xef\xbc\x9a   \n![\\frac{{\\partial J(\\theta )}}{{\\partial {\\theta _j}}} = \\frac{1}{m}\\sum\\limits_{i = 1}^m {[({h_\\theta }({x^{(i)}}) - {y^{(i)}})x_j^{(i)}]} ](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%5Cfrac%7B%7B%5Cpartial%20J%28%5Ctheta%20%29%7D%7D%7B%7B%5Cpartial%20%7B%5Ctheta%20_j%7D%7D%7D%20%3D%20%5Cfrac%7B1%7D%7Bm%7D%5Csum%5Climits_%7Bi%20%3D%201%7D%5Em%20%7B%5B%28%7Bh_%5Ctheta%20%7D%28%7Bx%5E%7B%28i%29%7D%7D%29%20-%20%7By%5E%7B%28i%29%7D%7D%29x_j%5E%7B%28i%29%7D%5D%7D%20)\n- \xe6\x89\x80\xe4\xbb\xa5\xe5\xaf\xb9theta\xe7\x9a\x84\xe6\x9b\xb4\xe6\x96\xb0\xe5\x8f\xaf\xe4\xbb\xa5\xe5\x86\x99\xe4\xb8\xba\xef\xbc\x9a   \n![{\\theta _j} = {\\theta _j} - \\alpha \\frac{1}{m}\\sum\\limits_{i = 1}^m {[({h_\\theta }({x^{(i)}}) - {y^{(i)}})x_j^{(i)}]} ](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7B%5Ctheta%20_j%7D%20%3D%20%7B%5Ctheta%20_j%7D%20-%20%5Calpha%20%5Cfrac%7B1%7D%7Bm%7D%5Csum%5Climits_%7Bi%20%3D%201%7D%5Em%20%7B%5B%28%7Bh_%5Ctheta%20%7D%28%7Bx%5E%7B%28i%29%7D%7D%29%20-%20%7By%5E%7B%28i%29%7D%7D%29x_j%5E%7B%28i%29%7D%5D%7D%20)\n- \xe5\x85\xb6\xe4\xb8\xad![\\alpha ](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%5Calpha%20)\xe4\xb8\xba\xe5\xad\xa6\xe4\xb9\xa0\xe9\x80\x9f\xe7\x8e\x87\xef\xbc\x8c\xe6\x8e\xa7\xe5\x88\xb6\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xe7\x9a\x84\xe9\x80\x9f\xe5\xba\xa6\xef\xbc\x8c\xe4\xb8\x80\xe8\x88\xac\xe5\x8f\x96**0.01,0.03,0.1,0.3.....**\n- \xe4\xb8\xba\xe4\xbb\x80\xe4\xb9\x88\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xe5\x8f\xaf\xe4\xbb\xa5\xe9\x80\x90\xe6\xad\xa5\xe5\x87\x8f\xe5\xb0\x8f\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0\n - \xe5\x81\x87\xe8\xae\xbe\xe5\x87\xbd\xe6\x95\xb0`f(x)`\n - \xe6\xb3\xb0\xe5\x8b\x92\xe5\xb1\x95\xe5\xbc\x80\xef\xbc\x9a`f(x+\xe2\x96\xb3x)=f(x)+f\'(x)*\xe2\x96\xb3x+o(\xe2\x96\xb3x)`\n - \xe4\xbb\xa4\xef\xbc\x9a`\xe2\x96\xb3x=-\xce\xb1*f\'(x)`   ,\xe5\x8d\xb3\xe8\xb4\x9f\xe6\xa2\xaf\xe5\xba\xa6\xe6\x96\xb9\xe5\x90\x91\xe4\xb9\x98\xe4\xbb\xa5\xe4\xb8\x80\xe4\xb8\xaa\xe5\xbe\x88\xe5\xb0\x8f\xe7\x9a\x84\xe6\xad\xa5\xe9\x95\xbf`\xce\xb1`\n - \xe5\xb0\x86`\xe2\x96\xb3x`\xe4\xbb\xa3\xe5\x85\xa5\xe6\xb3\xb0\xe5\x8b\x92\xe5\xb1\x95\xe5\xbc\x80\xe5\xbc\x8f\xe4\xb8\xad\xef\xbc\x9a`f(x+\xe2\x96\xb3x)=f(x)-\xce\xb1*[f\'(x)]\xc2\xb2+o(\xe2\x96\xb3x)`\n - \xe5\x8f\xaf\xe4\xbb\xa5\xe7\x9c\x8b\xe5\x87\xba\xef\xbc\x8c`\xce\xb1`\xe6\x98\xaf\xe5\x8f\x96\xe5\xbe\x97\xe5\xbe\x88\xe5\xb0\x8f\xe7\x9a\x84\xe6\xad\xa3\xe6\x95\xb0\xef\xbc\x8c`[f\'(x)]\xc2\xb2`\xe4\xb9\x9f\xe6\x98\xaf\xe6\xad\xa3\xe6\x95\xb0\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xe5\x8f\xaf\xe4\xbb\xa5\xe5\xbe\x97\xe5\x87\xba\xef\xbc\x9a`f(x+\xe2\x96\xb3x)<=f(x)`\n - \xe6\x89\x80\xe4\xbb\xa5\xe6\xb2\xbf\xe7\x9d\x80**\xe8\xb4\x9f\xe6\xa2\xaf\xe5\xba\xa6**\xe6\x94\xbe\xe4\xb8\x8b\xef\xbc\x8c\xe5\x87\xbd\xe6\x95\xb0\xe5\x9c\xa8\xe5\x87\x8f\xe5\xb0\x8f\xef\xbc\x8c\xe5\xa4\x9a\xe7\xbb\xb4\xe6\x83\x85\xe5\x86\xb5\xe4\xb8\x80\xe6\xa0\xb7\xe3\x80\x82\n- \xe5\xae\x9e\xe7\x8e\xb0\xe4\xbb\xa3\xe7\xa0\x81\n```\n# \xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xe7\xae\x97\xe6\xb3\x95\ndef gradientDescent(X,y,theta,alpha,num_iters):\n    m = len(y)      \n    n = len(theta)\n    \n    temp = np.matrix(np.zeros((n,num_iters)))   # \xe6\x9a\x82\xe5\xad\x98\xe6\xaf\x8f\xe6\xac\xa1\xe8\xbf\xad\xe4\xbb\xa3\xe8\xae\xa1\xe7\xae\x97\xe7\x9a\x84theta\xef\xbc\x8c\xe8\xbd\xac\xe5\x8c\x96\xe4\xb8\xba\xe7\x9f\xa9\xe9\x98\xb5\xe5\xbd\xa2\xe5\xbc\x8f\n    \n    \n    J_history = np.zeros((num_iters,1)) #\xe8\xae\xb0\xe5\xbd\x95\xe6\xaf\x8f\xe6\xac\xa1\xe8\xbf\xad\xe4\xbb\xa3\xe8\xae\xa1\xe7\xae\x97\xe7\x9a\x84\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x80\xbc\n    \n    for i in range(num_iters):  # \xe9\x81\x8d\xe5\x8e\x86\xe8\xbf\xad\xe4\xbb\xa3\xe6\xac\xa1\xe6\x95\xb0    \n        h = np.dot(X,theta)     # \xe8\xae\xa1\xe7\xae\x97\xe5\x86\x85\xe7\xa7\xaf\xef\xbc\x8cmatrix\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x9b\xb4\xe6\x8e\xa5\xe4\xb9\x98\n        temp[:,i] = theta - ((alpha/m)*(np.dot(np.transpose(X),h-y)))   #\xe6\xa2\xaf\xe5\xba\xa6\xe7\x9a\x84\xe8\xae\xa1\xe7\xae\x97\n        theta = temp[:,i]\n        J_history[i] = computerCost(X,y,theta)      #\xe8\xb0\x83\xe7\x94\xa8\xe8\xae\xa1\xe7\xae\x97\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0\n        print \'.\',      \n    return theta,J_history  \n```\n\n### 3\xe3\x80\x81\xe5\x9d\x87\xe5\x80\xbc\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\n- \xe7\x9b\xae\xe7\x9a\x84\xe6\x98\xaf\xe4\xbd\xbf\xe6\x95\xb0\xe6\x8d\xae\xe9\x83\xbd\xe7\xbc\xa9\xe6\x94\xbe\xe5\x88\xb0\xe4\xb8\x80\xe4\xb8\xaa\xe8\x8c\x83\xe5\x9b\xb4\xe5\x86\x85\xef\xbc\x8c\xe4\xbe\xbf\xe4\xba\x8e\xe4\xbd\xbf\xe7\x94\xa8\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xe7\xae\x97\xe6\xb3\x95\n- ![{x_i} = \\frac{{{x_i} - {\\mu _i}}}{{{s_i}}}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7Bx_i%7D%20%3D%20%5Cfrac%7B%7B%7Bx_i%7D%20-%20%7B%5Cmu%20_i%7D%7D%7D%7B%7B%7Bs_i%7D%7D%7D)\n- \xe5\x85\xb6\xe4\xb8\xad ![{{\\mu _i}}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7B%7B%5Cmu%20_i%7D%7D) \xe4\xb8\xba\xe6\x89\x80\xe6\x9c\x89\xe6\xad\xa4feture\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\xb9\xb3\xe5\x9d\x87\xe5\x80\xbc\n- ![{{s_i}}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7B%7Bs_i%7D%7D)\xe5\x8f\xaf\xe4\xbb\xa5\xe6\x98\xaf**\xe6\x9c\x80\xe5\xa4\xa7\xe5\x80\xbc-\xe6\x9c\x80\xe5\xb0\x8f\xe5\x80\xbc**\xef\xbc\x8c\xe4\xb9\x9f\xe5\x8f\xaf\xe4\xbb\xa5\xe6\x98\xaf\xe8\xbf\x99\xe4\xb8\xaafeature\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84**\xe6\xa0\x87\xe5\x87\x86\xe5\xb7\xae**\n- \xe5\xae\x9e\xe7\x8e\xb0\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a\n```\n# \xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96feature\ndef featureNormaliza(X):\n    X_norm = np.array(X)            #\xe5\xb0\x86X\xe8\xbd\xac\xe5\x8c\x96\xe4\xb8\xbanumpy\xe6\x95\xb0\xe7\xbb\x84\xe5\xaf\xb9\xe8\xb1\xa1\xef\xbc\x8c\xe6\x89\x8d\xe5\x8f\xaf\xe4\xbb\xa5\xe8\xbf\x9b\xe8\xa1\x8c\xe7\x9f\xa9\xe9\x98\xb5\xe7\x9a\x84\xe8\xbf\x90\xe7\xae\x97\n    #\xe5\xae\x9a\xe4\xb9\x89\xe6\x89\x80\xe9\x9c\x80\xe5\x8f\x98\xe9\x87\x8f\n    mu = np.zeros((1,X.shape[1]))   \n    sigma = np.zeros((1,X.shape[1]))\n    \n    mu = np.mean(X_norm,0)          # \xe6\xb1\x82\xe6\xaf\x8f\xe4\xb8\x80\xe5\x88\x97\xe7\x9a\x84\xe5\xb9\xb3\xe5\x9d\x87\xe5\x80\xbc\xef\xbc\x880\xe6\x8c\x87\xe5\xae\x9a\xe4\xb8\xba\xe5\x88\x97\xef\xbc\x8c1\xe4\xbb\xa3\xe8\xa1\xa8\xe8\xa1\x8c\xef\xbc\x89\n    sigma = np.std(X_norm,0)        # \xe6\xb1\x82\xe6\xaf\x8f\xe4\xb8\x80\xe5\x88\x97\xe7\x9a\x84\xe6\xa0\x87\xe5\x87\x86\xe5\xb7\xae\n    for i in range(X.shape[1]):     # \xe9\x81\x8d\xe5\x8e\x86\xe5\x88\x97\n        X_norm[:,i] = (X_norm[:,i]-mu[i])/sigma[i]  # \xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\n    \n    return X_norm,mu,sigma\n```\n- \xe6\xb3\xa8\xe6\x84\x8f\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe6\x97\xb6\xe5\x80\x99\xe4\xb9\x9f\xe9\x9c\x80\xe8\xa6\x81\xe5\x9d\x87\xe5\x80\xbc\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe6\x95\xb0\xe6\x8d\xae\n\n### 4\xe3\x80\x81\xe6\x9c\x80\xe7\xbb\x88\xe8\xbf\x90\xe8\xa1\x8c\xe7\xbb\x93\xe6\x9e\x9c\n- \xe4\xbb\xa3\xe4\xbb\xb7\xe9\x9a\x8f\xe8\xbf\xad\xe4\xbb\xa3\xe6\xac\xa1\xe6\x95\xb0\xe7\x9a\x84\xe5\x8f\x98\xe5\x8c\x96   \n![enter description here][1]\n\n\n### 5\xe3\x80\x81[\xe4\xbd\xbf\xe7\x94\xa8scikit-learn\xe5\xba\x93\xe4\xb8\xad\xe7\x9a\x84\xe7\xba\xbf\xe6\x80\xa7\xe6\xa8\xa1\xe5\x9e\x8b\xe5\xae\x9e\xe7\x8e\xb0](/LinearRegression/LinearRegression_scikit-learn.py)\n- \xe5\xaf\xbc\xe5\x85\xa5\xe5\x8c\x85\n```\nfrom sklearn import linear_model\nfrom sklearn.preprocessing import StandardScaler    #\xe5\xbc\x95\xe5\x85\xa5\xe7\xbc\xa9\xe6\x94\xbe\xe7\x9a\x84\xe5\x8c\x85\n```\n- \xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\n```\n    # \xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe6\x93\x8d\xe4\xbd\x9c\n    scaler = StandardScaler()   \n    scaler.fit(X)\n    x_train = scaler.transform(X)\n    x_test = scaler.transform(np.array([1650,3]))\n```\n- \xe7\xba\xbf\xe6\x80\xa7\xe6\xa8\xa1\xe5\x9e\x8b\xe6\x8b\x9f\xe5\x90\x88\n```\n    # \xe7\xba\xbf\xe6\x80\xa7\xe6\xa8\xa1\xe5\x9e\x8b\xe6\x8b\x9f\xe5\x90\x88\n    model = linear_model.LinearRegression()\n    model.fit(x_train, y)\n``` \n- \xe9\xa2\x84\xe6\xb5\x8b\n```\n    #\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\n    result = model.predict(x_test)\n```\n\n-------------------\n\n  \n## \xe4\xba\x8c\xe3\x80\x81[\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92](/LogisticRegression)\n- [\xe5\x85\xa8\xe9\x83\xa8\xe4\xbb\xa3\xe7\xa0\x81](/LogisticRegression/LogisticRegression.py)\n\n### 1\xe3\x80\x81\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0\n- ![\\left\\{ \\begin{gathered}\n  J(\\theta ) = \\frac{1}{m}\\sum\\limits_{i = 1}^m {\\cos t({h_\\theta }({x^{(i)}}),{y^{(i)}})}  \\hfill \\\\\n  \\cos t({h_\\theta }(x),y) = \\left\\{ {\\begin{array}{c}    { - \\log ({h_\\theta }(x))} \\\\    { - \\log (1 - {h_\\theta }(x))}  \\end{array} \\begin{array}{c}    {y = 1} \\\\    {y = 0}  \\end{array} } \\right. \\hfill \\\\ \n\\end{gathered}  \\right.](http://latex.codecogs.com/gif.latex?%5Clarge%20%5Cleft%5C%7B%20%5Cbegin%7Bgathered%7D%20J%28%5Ctheta%20%29%20%3D%20%5Cfrac%7B1%7D%7Bm%7D%5Csum%5Climits_%7Bi%20%3D%201%7D%5Em%20%7B%5Ccos%20t%28%7Bh_%5Ctheta%20%7D%28%7Bx%5E%7B%28i%29%7D%7D%29%2C%7By%5E%7B%28i%29%7D%7D%29%7D%20%5Chfill%20%5C%5C%20%5Ccos%20t%28%7Bh_%5Ctheta%20%7D%28x%29%2Cy%29%20%3D%20%5Cleft%5C%7B%20%7B%5Cbegin%7Barray%7D%7Bc%7D%20%7B%20-%20%5Clog%20%28%7Bh_%5Ctheta%20%7D%28x%29%29%7D%20%5C%5C%20%7B%20-%20%5Clog%20%281%20-%20%7Bh_%5Ctheta%20%7D%28x%29%29%7D%20%5Cend%7Barray%7D%20%5Cbegin%7Barray%7D%7Bc%7D%20%7By%20%3D%201%7D%20%5C%5C%20%7By%20%3D%200%7D%20%5Cend%7Barray%7D%20%7D%20%5Cright.%20%5Chfill%20%5C%5C%20%5Cend%7Bgathered%7D%20%5Cright.)\n- \xe5\x8f\xaf\xe4\xbb\xa5\xe7\xbb\xbc\xe5\x90\x88\xe8\xb5\xb7\xe6\x9d\xa5\xe4\xb8\xba\xef\xbc\x9a\n![J(\\theta ) =  - \\frac{1}{m}\\sum\\limits_{i = 1}^m {[{y^{(i)}}\\log ({h_\\theta }({x^{(i)}}) + (1 - } {y^{(i)}})\\log (1 - {h_\\theta }({x^{(i)}})]](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=J%28%5Ctheta%20%29%20%3D%20%20-%20%5Cfrac%7B1%7D%7Bm%7D%5Csum%5Climits_%7Bi%20%3D%201%7D%5Em%20%7B%5B%7By%5E%7B%28i%29%7D%7D%5Clog%20%28%7Bh_%5Ctheta%20%7D%28%7Bx%5E%7B%28i%29%7D%7D%29%20%2B%20%281%20-%20%7D%20%7By%5E%7B%28i%29%7D%7D%29%5Clog%20%281%20-%20%7Bh_%5Ctheta%20%7D%28%7Bx%5E%7B%28i%29%7D%7D%29%5D)\n\xe5\x85\xb6\xe4\xb8\xad\xef\xbc\x9a\n![{h_\\theta }(x) = \\frac{1}{{1 + {e^{ - x}}}}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7Bh_%5Ctheta%20%7D%28x%29%20%3D%20%5Cfrac%7B1%7D%7B%7B1%20%2B%20%7Be%5E%7B%20-%20x%7D%7D%7D%7D)\n- \xe4\xb8\xba\xe4\xbb\x80\xe4\xb9\x88\xe4\xb8\x8d\xe7\x94\xa8\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9a\x84\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0\xe8\xa1\xa8\xe7\xa4\xba\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xba\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9a\x84\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0\xe5\x8f\xaf\xe8\x83\xbd\xe6\x98\xaf\xe9\x9d\x9e\xe5\x87\xb8\xe7\x9a\x84\xef\xbc\x8c\xe5\xaf\xb9\xe4\xba\x8e\xe5\x88\x86\xe7\xb1\xbb\xe9\x97\xae\xe9\xa2\x98\xef\xbc\x8c\xe4\xbd\xbf\xe7\x94\xa8\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xe5\xbe\x88\xe9\x9a\xbe\xe5\xbe\x97\xe5\x88\xb0\xe6\x9c\x80\xe5\xb0\x8f\xe5\x80\xbc\xef\xbc\x8c\xe4\xb8\x8a\xe9\x9d\xa2\xe7\x9a\x84\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0\xe6\x98\xaf\xe5\x87\xb8\xe5\x87\xbd\xe6\x95\xb0\n- ![{ - \\log ({h_\\theta }(x))}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7B%20-%20%5Clog%20%28%7Bh_%5Ctheta%20%7D%28x%29%29%7D)\xe7\x9a\x84\xe5\x9b\xbe\xe5\x83\x8f\xe5\xa6\x82\xe4\xb8\x8b\xef\xbc\x8c\xe5\x8d\xb3`y=1`\xe6\x97\xb6\xef\xbc\x9a\n![enter description here][2]\n\n\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x9c\x8b\xe5\x87\xba\xef\xbc\x8c\xe5\xbd\x93![{{h_\\theta }(x)}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7B%7Bh_%5Ctheta%20%7D%28x%29%7D)\xe8\xb6\x8b\xe4\xba\x8e`1`\xef\xbc\x8c`y=1`,\xe4\xb8\x8e\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe4\xb8\x80\xe8\x87\xb4\xef\xbc\x8c\xe6\xad\xa4\xe6\x97\xb6\xe4\xbb\x98\xe5\x87\xba\xe7\x9a\x84\xe4\xbb\xa3\xe4\xbb\xb7`cost`\xe8\xb6\x8b\xe4\xba\x8e`0`\xef\xbc\x8c\xe8\x8b\xa5![{{h_\\theta }(x)}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7B%7Bh_%5Ctheta%20%7D%28x%29%7D)\xe8\xb6\x8b\xe4\xba\x8e`0`\xef\xbc\x8c`y=1`,\xe6\xad\xa4\xe6\x97\xb6\xe7\x9a\x84\xe4\xbb\xa3\xe4\xbb\xb7`cost`\xe5\x80\xbc\xe9\x9d\x9e\xe5\xb8\xb8\xe5\xa4\xa7\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe7\x9b\xae\xe7\x9a\x84\xe6\x98\xaf\xe6\x9c\x80\xe5\xb0\x8f\xe5\x8c\x96\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x80\xbc\n- \xe5\x90\x8c\xe7\x90\x86![{ - \\log (1 - {h_\\theta }(x))}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7B%20-%20%5Clog%20%281%20-%20%7Bh_%5Ctheta%20%7D%28x%29%29%7D)\xe7\x9a\x84\xe5\x9b\xbe\xe5\x83\x8f\xe5\xa6\x82\xe4\xb8\x8b\xef\xbc\x88`y=0`\xef\xbc\x89\xef\xbc\x9a   \n![enter description here][3]\n\n### 2\xe3\x80\x81\xe6\xa2\xaf\xe5\xba\xa6\n- \xe5\x90\x8c\xe6\xa0\xb7\xe5\xaf\xb9\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0\xe6\xb1\x82\xe5\x81\x8f\xe5\xaf\xbc\xef\xbc\x9a\n![\\frac{{\\partial J(\\theta )}}{{\\partial {\\theta _j}}} = \\frac{1}{m}\\sum\\limits_{i = 1}^m {[({h_\\theta }({x^{(i)}}) - {y^{(i)}})x_j^{(i)}]} ](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%5Cfrac%7B%7B%5Cpartial%20J%28%5Ctheta%20%29%7D%7D%7B%7B%5Cpartial%20%7B%5Ctheta%20_j%7D%7D%7D%20%3D%20%5Cfrac%7B1%7D%7Bm%7D%5Csum%5Climits_%7Bi%20%3D%201%7D%5Em%20%7B%5B%28%7Bh_%5Ctheta%20%7D%28%7Bx%5E%7B%28i%29%7D%7D%29%20-%20%7By%5E%7B%28i%29%7D%7D%29x_j%5E%7B%28i%29%7D%5D%7D%20)   \n\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x9c\x8b\xe5\x87\xba\xe4\xb8\x8e\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9a\x84\xe5\x81\x8f\xe5\xaf\xbc\xe6\x95\xb0\xe4\xb8\x80\xe8\x87\xb4\n- \xe6\x8e\xa8\xe5\x88\xb0\xe8\xbf\x87\xe7\xa8\x8b\n![enter description here][4]\n\n### 3\xe3\x80\x81\xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96\n- \xe7\x9b\xae\xe7\x9a\x84\xe6\x98\xaf\xe4\xb8\xba\xe4\xba\x86\xe9\x98\xb2\xe6\xad\xa2\xe8\xbf\x87\xe6\x8b\x9f\xe5\x90\x88\n- \xe5\x9c\xa8\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0\xe4\xb8\xad\xe5\x8a\xa0\xe4\xb8\x8a\xe4\xb8\x80\xe9\xa1\xb9![J(\\theta ) =  - \\frac{1}{m}\\sum\\limits_{i = 1}^m {[{y^{(i)}}\\log ({h_\\theta }({x^{(i)}}) + (1 - } {y^{(i)}})\\log (1 - {h_\\theta }({x^{(i)}})] + \\frac{\\lambda }{{2m}}\\sum\\limits_{j = 1}^n {\\theta _j^2} ](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=J%28%5Ctheta%20%29%20%3D%20%20-%20%5Cfrac%7B1%7D%7Bm%7D%5Csum%5Climits_%7Bi%20%3D%201%7D%5Em%20%7B%5B%7By%5E%7B%28i%29%7D%7D%5Clog%20%28%7Bh_%5Ctheta%20%7D%28%7Bx%5E%7B%28i%29%7D%7D%29%20%2B%20%281%20-%20%7D%20%7By%5E%7B%28i%29%7D%7D%29%5Clog%20%281%20-%20%7Bh_%5Ctheta%20%7D%28%7Bx%5E%7B%28i%29%7D%7D%29%5D%20%2B%20%5Cfrac%7B%5Clambda%20%7D%7B%7B2m%7D%7D%5Csum%5Climits_%7Bj%20%3D%201%7D%5En%20%7B%5Ctheta%20_j%5E2%7D%20)\n- \xe6\xb3\xa8\xe6\x84\x8fj\xe6\x98\xaf\xe9\x87\x8d1\xe5\xbc\x80\xe5\xa7\x8b\xe7\x9a\x84\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xbatheta(0)\xe4\xb8\xba\xe4\xb8\x80\xe4\xb8\xaa\xe5\xb8\xb8\xe6\x95\xb0\xe9\xa1\xb9\xef\xbc\x8cX\xe4\xb8\xad\xe6\x9c\x80\xe5\x89\x8d\xe9\x9d\xa2\xe4\xb8\x80\xe5\x88\x97\xe4\xbc\x9a\xe5\x8a\xa0\xe4\xb8\x8a1\xe5\x88\x971\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xe4\xb9\x98\xe7\xa7\xaf\xe8\xbf\x98\xe6\x98\xaftheta(0),feature\xe6\xb2\xa1\xe6\x9c\x89\xe5\x85\xb3\xe7\xb3\xbb\xef\xbc\x8c\xe6\xb2\xa1\xe6\x9c\x89\xe5\xbf\x85\xe8\xa6\x81\xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96\n- \xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96\xe5\x90\x8e\xe7\x9a\x84\xe4\xbb\xa3\xe4\xbb\xb7\xef\xbc\x9a\n```\n# \xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0\ndef costFunction(initial_theta,X,y,inital_lambda):\n    m = len(y)\n    J = 0\n    \n    h = sigmoid(np.dot(X,initial_theta))    # \xe8\xae\xa1\xe7\xae\x97h(z)\n    theta1 = initial_theta.copy()           # \xe5\x9b\xa0\xe4\xb8\xba\xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96j=1\xe4\xbb\x8e1\xe5\xbc\x80\xe5\xa7\x8b\xef\xbc\x8c\xe4\xb8\x8d\xe5\x8c\x85\xe5\x90\xab0\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xe5\xa4\x8d\xe5\x88\xb6\xe4\xb8\x80\xe4\xbb\xbd\xef\xbc\x8c\xe5\x89\x8dtheta(0)\xe5\x80\xbc\xe4\xb8\xba0 \n    theta1[0] = 0   \n    \n    temp = np.dot(np.transpose(theta1),theta1)\n    J = (-np.dot(np.transpose(y),np.log(h))-np.dot(np.transpose(1-y),np.log(1-h))+temp*inital_lambda/2)/m   # \xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96\xe7\x9a\x84\xe4\xbb\xa3\xe4\xbb\xb7\xe6\x96\xb9\xe7\xa8\x8b\n    return J\n```\n- \xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96\xe5\x90\x8e\xe7\x9a\x84\xe4\xbb\xa3\xe4\xbb\xb7\xe7\x9a\x84\xe6\xa2\xaf\xe5\xba\xa6\n```\n# \xe8\xae\xa1\xe7\xae\x97\xe6\xa2\xaf\xe5\xba\xa6\ndef gradient(initial_theta,X,y,inital_lambda):\n    m = len(y)\n    grad = np.zeros((initial_theta.shape[0]))\n    \n    h = sigmoid(np.dot(X,initial_theta))# \xe8\xae\xa1\xe7\xae\x97h(z)\n    theta1 = initial_theta.copy()\n    theta1[0] = 0\n\n    grad = np.dot(np.transpose(X),h-y)/m+inital_lambda/m*theta1 #\xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96\xe7\x9a\x84\xe6\xa2\xaf\xe5\xba\xa6\n    return grad  \n```\n\n### 4\xe3\x80\x81S\xe5\x9e\x8b\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x88\xe5\x8d\xb3![{{h_\\theta }(x)}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7B%7Bh_%5Ctheta%20%7D%28x%29%7D)\xef\xbc\x89\n- \xe5\xae\x9e\xe7\x8e\xb0\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a\n```\n# S\xe5\x9e\x8b\xe5\x87\xbd\xe6\x95\xb0    \ndef sigmoid(z):\n    h = np.zeros((len(z),1))    # \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xef\xbc\x8c\xe4\xb8\x8ez\xe7\x9a\x84\xe9\x95\xbf\xe5\xba\xa6\xe4\xb8\x80\xe7\xbd\xae\n    \n    h = 1.0/(1.0+np.exp(-z))\n    return h\n```\n\n### 5\xe3\x80\x81\xe6\x98\xa0\xe5\xb0\x84\xe4\xb8\xba\xe5\xa4\x9a\xe9\xa1\xb9\xe5\xbc\x8f\n- \xe5\x9b\xa0\xe4\xb8\xba\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84feture\xe5\x8f\xaf\xe8\x83\xbd\xe5\xbe\x88\xe5\xb0\x91\xef\xbc\x8c\xe5\xaf\xbc\xe8\x87\xb4\xe5\x81\x8f\xe5\xb7\xae\xe5\xa4\xa7\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xe5\x88\x9b\xe9\x80\xa0\xe5\x87\xba\xe4\xb8\x80\xe4\xba\x9bfeture\xe7\xbb\x93\xe5\x90\x88\n- eg:\xe6\x98\xa0\xe5\xb0\x84\xe4\xb8\xba2\xe6\xac\xa1\xe6\x96\xb9\xe7\x9a\x84\xe5\xbd\xa2\xe5\xbc\x8f:![1 + {x_1} + {x_2} + x_1^2 + {x_1}{x_2} + x_2^2](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=1%20%2B%20%7Bx_1%7D%20%2B%20%7Bx_2%7D%20%2B%20x_1%5E2%20%2B%20%7Bx_1%7D%7Bx_2%7D%20%2B%20x_2%5E2)\n- \xe5\xae\x9e\xe7\x8e\xb0\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a\n```\n# \xe6\x98\xa0\xe5\xb0\x84\xe4\xb8\xba\xe5\xa4\x9a\xe9\xa1\xb9\xe5\xbc\x8f \ndef mapFeature(X1,X2):\n    degree = 3;                     # \xe6\x98\xa0\xe5\xb0\x84\xe7\x9a\x84\xe6\x9c\x80\xe9\xab\x98\xe6\xac\xa1\xe6\x96\xb9\n    out = np.ones((X1.shape[0],1))  # \xe6\x98\xa0\xe5\xb0\x84\xe5\x90\x8e\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe6\x95\xb0\xe7\xbb\x84\xef\xbc\x88\xe5\x8f\x96\xe4\xbb\xa3X\xef\xbc\x89\n    \'\'\'\n    \xe8\xbf\x99\xe9\x87\x8c\xe4\xbb\xa5degree=2\xe4\xb8\xba\xe4\xbe\x8b\xef\xbc\x8c\xe6\x98\xa0\xe5\xb0\x84\xe4\xb8\xba1,x1,x2,x1^2,x1,x2,x2^2\n    \'\'\'\n    for i in np.arange(1,degree+1): \n        for j in range(i+1):\n            temp = X1**(i-j)*(X2**j)    #\xe7\x9f\xa9\xe9\x98\xb5\xe7\x9b\xb4\xe6\x8e\xa5\xe4\xb9\x98\xe7\x9b\xb8\xe5\xbd\x93\xe4\xba\x8ematlab\xe4\xb8\xad\xe7\x9a\x84\xe7\x82\xb9\xe4\xb9\x98.*\n            out = np.hstack((out, temp.reshape(-1,1)))\n    return out\n```\n\n### 6\xe3\x80\x81\xe4\xbd\xbf\xe7\x94\xa8`scipy`\xe7\x9a\x84\xe4\xbc\x98\xe5\x8c\x96\xe6\x96\xb9\xe6\xb3\x95\n- \xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xe4\xbd\xbf\xe7\x94\xa8`scipy`\xe4\xb8\xad`optimize`\xe4\xb8\xad\xe7\x9a\x84`fmin_bfgs`\xe5\x87\xbd\xe6\x95\xb0\n- \xe8\xb0\x83\xe7\x94\xa8scipy\xe4\xb8\xad\xe7\x9a\x84\xe4\xbc\x98\xe5\x8c\x96\xe7\xae\x97\xe6\xb3\x95fmin_bfgs\xef\xbc\x88\xe6\x8b\x9f\xe7\x89\x9b\xe9\xa1\xbf\xe6\xb3\x95Broyden-Fletcher-Goldfarb-Shanno\n - costFunction\xe6\x98\xaf\xe8\x87\xaa\xe5\xb7\xb1\xe5\xae\x9e\xe7\x8e\xb0\xe7\x9a\x84\xe4\xb8\x80\xe4\xb8\xaa\xe6\xb1\x82\xe4\xbb\xa3\xe4\xbb\xb7\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x8c\n - initial_theta\xe8\xa1\xa8\xe7\xa4\xba\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe7\x9a\x84\xe5\x80\xbc,\n - fprime\xe6\x8c\x87\xe5\xae\x9acostFunction\xe7\x9a\x84\xe6\xa2\xaf\xe5\xba\xa6\n - args\xe6\x98\xaf\xe5\x85\xb6\xe4\xbd\x99\xe6\xb5\x8b\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x8c\xe4\xbb\xa5\xe5\x85\x83\xe7\xbb\x84\xe7\x9a\x84\xe5\xbd\xa2\xe5\xbc\x8f\xe4\xbc\xa0\xe5\x85\xa5\xef\xbc\x8c\xe6\x9c\x80\xe5\x90\x8e\xe4\xbc\x9a\xe5\xb0\x86\xe6\x9c\x80\xe5\xb0\x8f\xe5\x8c\x96costFunction\xe7\x9a\x84theta\xe8\xbf\x94\xe5\x9b\x9e \n```\n    result = optimize.fmin_bfgs(costFunction, initial_theta, fprime=gradient, args=(X,y,initial_lambda))    \n```   \n\n### 7\xe3\x80\x81\xe8\xbf\x90\xe8\xa1\x8c\xe7\xbb\x93\xe6\x9e\x9c\n- data1\xe5\x86\xb3\xe7\xad\x96\xe8\xbe\xb9\xe7\x95\x8c\xe5\x92\x8c\xe5\x87\x86\xe7\xa1\xae\xe5\xba\xa6  \n![enter description here][5]\n![enter description here][6]\n- data2\xe5\x86\xb3\xe7\xad\x96\xe8\xbe\xb9\xe7\x95\x8c\xe5\x92\x8c\xe5\x87\x86\xe7\xa1\xae\xe5\xba\xa6  \n![enter description here][7]\n![enter description here][8]\n\n### 8\xe3\x80\x81[\xe4\xbd\xbf\xe7\x94\xa8scikit-learn\xe5\xba\x93\xe4\xb8\xad\xe7\x9a\x84\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92\xe6\xa8\xa1\xe5\x9e\x8b\xe5\xae\x9e\xe7\x8e\xb0](/LogisticRegression/LogisticRegression_scikit-learn.py)\n- \xe5\xaf\xbc\xe5\x85\xa5\xe5\x8c\x85\n```\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cross_validation import train_test_split\nimport numpy as np\n```\n- \xe5\x88\x92\xe5\x88\x86\xe8\xae\xad\xe7\xbb\x83\xe9\x9b\x86\xe5\x92\x8c\xe6\xb5\x8b\xe8\xaf\x95\xe9\x9b\x86\n```\n    # \xe5\x88\x92\xe5\x88\x86\xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe9\x9b\x86\xe5\x92\x8c\xe6\xb5\x8b\xe8\xaf\x95\xe9\x9b\x86\n    x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\n```\n- \xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\n```\n    # \xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\n    scaler = StandardScaler()\n    x_train = scaler.fit_transform(x_train)\n    x_test = scaler.fit_transform(x_test)\n```\n- \xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92\n```\n    #\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92\n    model = LogisticRegression()\n    model.fit(x_train,y_train)\n``` \n- \xe9\xa2\x84\xe6\xb5\x8b\n```\n    # \xe9\xa2\x84\xe6\xb5\x8b\n    predict = model.predict(x_test)\n    right = sum(predict == y_test)\n    \n    predict = np.hstack((predict.reshape(-1,1),y_test.reshape(-1,1)))   # \xe5\xb0\x86\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe5\x92\x8c\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe6\x94\xbe\xe5\x9c\xa8\xe4\xb8\x80\xe5\x9d\x97\xef\xbc\x8c\xe5\xa5\xbd\xe8\xa7\x82\xe5\xaf\x9f\n    print predict\n    print (\'\xe6\xb5\x8b\xe8\xaf\x95\xe9\x9b\x86\xe5\x87\x86\xe7\xa1\xae\xe7\x8e\x87\xef\xbc\x9a%f%%\'%(right*100.0/predict.shape[0]))          #\xe8\xae\xa1\xe7\xae\x97\xe5\x9c\xa8\xe6\xb5\x8b\xe8\xaf\x95\xe9\x9b\x86\xe4\xb8\x8a\xe7\x9a\x84\xe5\x87\x86\xe7\xa1\xae\xe5\xba\xa6\n```\n\n\n-------------\n\n## [\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92_\xe6\x89\x8b\xe5\x86\x99\xe6\x95\xb0\xe5\xad\x97\xe8\xaf\x86\xe5\x88\xab_OneVsAll](/LogisticRegression)\n- [\xe5\x85\xa8\xe9\x83\xa8\xe4\xbb\xa3\xe7\xa0\x81](/LogisticRegression/LogisticRegression_OneVsAll.py)\n\n### 1\xe3\x80\x81\xe9\x9a\x8f\xe6\x9c\xba\xe6\x98\xbe\xe7\xa4\xba100\xe4\xb8\xaa\xe6\x95\xb0\xe5\xad\x97\n- \xe6\x88\x91\xe6\xb2\xa1\xe6\x9c\x89\xe4\xbd\xbf\xe7\x94\xa8scikit-learn\xe4\xb8\xad\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xef\xbc\x8c\xe5\x83\x8f\xe7\xb4\xa0\xe6\x98\xaf20*20px\xef\xbc\x8c\xe5\xbd\xa9\xe8\x89\xb2\xe5\x9b\xbe\xe5\xa6\x82\xe4\xb8\x8b\n![enter description here][9]\n\xe7\x81\xb0\xe5\xba\xa6\xe5\x9b\xbe\xef\xbc\x9a\n![enter description here][10]\n- \xe5\xae\x9e\xe7\x8e\xb0\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a\n```\n# \xe6\x98\xbe\xe7\xa4\xba100\xe4\xb8\xaa\xe6\x95\xb0\xe5\xad\x97\ndef display_data(imgData):\n    sum = 0\n    \'\'\'\n    \xe6\x98\xbe\xe7\xa4\xba100\xe4\xb8\xaa\xe6\x95\xb0\xef\xbc\x88\xe8\x8b\xa5\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe4\xb8\x80\xe4\xb8\xaa\xe7\xbb\x98\xe5\x88\xb6\xe5\xb0\x86\xe4\xbc\x9a\xe9\x9d\x9e\xe5\xb8\xb8\xe6\x85\xa2\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe5\xb0\x86\xe8\xa6\x81\xe7\x94\xbb\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\x97\xe6\x95\xb4\xe7\x90\x86\xe5\xa5\xbd\xef\xbc\x8c\xe6\x94\xbe\xe5\x88\xb0\xe4\xb8\x80\xe4\xb8\xaa\xe7\x9f\xa9\xe9\x98\xb5\xe4\xb8\xad\xef\xbc\x8c\xe6\x98\xbe\xe7\xa4\xba\xe8\xbf\x99\xe4\xb8\xaa\xe7\x9f\xa9\xe9\x98\xb5\xe5\x8d\xb3\xe5\x8f\xaf\xef\xbc\x89\n    - \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe4\xb8\x80\xe4\xb8\xaa\xe4\xba\x8c\xe7\xbb\xb4\xe6\x95\xb0\xe7\xbb\x84\n    - \xe5\xb0\x86\xe6\xaf\x8f\xe8\xa1\x8c\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe8\xb0\x83\xe6\x95\xb4\xe6\x88\x90\xe5\x9b\xbe\xe5\x83\x8f\xe7\x9a\x84\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x8c\xe6\x94\xbe\xe8\xbf\x9b\xe4\xba\x8c\xe7\xbb\xb4\xe6\x95\xb0\xe7\xbb\x84\n    - \xe6\x98\xbe\xe7\xa4\xba\xe5\x8d\xb3\xe5\x8f\xaf\n    \'\'\'\n    pad = 1\n    display_array = -np.ones((pad+10*(20+pad),pad+10*(20+pad)))\n    for i in range(10):\n        for j in range(10):\n            display_array[pad+i*(20+pad):pad+i*(20+pad)+20,pad+j*(20+pad):pad+j*(20+pad)+20] = (imgData[sum,:].reshape(20,20,order=""F""))    # order=F\xe6\x8c\x87\xe5\xae\x9a\xe4\xbb\xa5\xe5\x88\x97\xe4\xbc\x98\xe5\x85\x88\xef\xbc\x8c\xe5\x9c\xa8matlab\xe4\xb8\xad\xe6\x98\xaf\xe8\xbf\x99\xe6\xa0\xb7\xe7\x9a\x84\xef\xbc\x8cpython\xe4\xb8\xad\xe9\x9c\x80\xe8\xa6\x81\xe6\x8c\x87\xe5\xae\x9a\xef\xbc\x8c\xe9\xbb\x98\xe8\xae\xa4\xe4\xbb\xa5\xe8\xa1\x8c\n            sum += 1\n            \n    plt.imshow(display_array,cmap=\'gray\')   #\xe6\x98\xbe\xe7\xa4\xba\xe7\x81\xb0\xe5\xba\xa6\xe5\x9b\xbe\xe5\x83\x8f\n    plt.axis(\'off\')\n    plt.show()\n```\n\n### 2\xe3\x80\x81OneVsAll\n- \xe5\xa6\x82\xe4\xbd\x95\xe5\x88\xa9\xe7\x94\xa8\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92\xe8\xa7\xa3\xe5\x86\xb3\xe5\xa4\x9a\xe5\x88\x86\xe7\xb1\xbb\xe7\x9a\x84\xe9\x97\xae\xe9\xa2\x98\xef\xbc\x8cOneVsAll\xe5\xb0\xb1\xe6\x98\xaf\xe6\x8a\x8a\xe5\xbd\x93\xe5\x89\x8d\xe6\x9f\x90\xe4\xb8\x80\xe7\xb1\xbb\xe7\x9c\x8b\xe6\x88\x90\xe4\xb8\x80\xe7\xb1\xbb\xef\xbc\x8c\xe5\x85\xb6\xe4\xbb\x96\xe6\x89\x80\xe6\x9c\x89\xe7\xb1\xbb\xe5\x88\xab\xe7\x9c\x8b\xe4\xbd\x9c\xe4\xb8\x80\xe7\xb1\xbb\xef\xbc\x8c\xe8\xbf\x99\xe6\xa0\xb7\xe6\x9c\x89\xe6\x88\x90\xe4\xba\x86\xe4\xba\x8c\xe5\x88\x86\xe7\xb1\xbb\xe7\x9a\x84\xe9\x97\xae\xe9\xa2\x98\xe4\xba\x86\n- \xe5\xa6\x82\xe4\xb8\x8b\xe5\x9b\xbe\xef\xbc\x8c\xe6\x8a\x8a\xe9\x80\x94\xe4\xb8\xad\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe6\x88\x90\xe4\xb8\x89\xe7\xb1\xbb\xef\xbc\x8c\xe5\x85\x88\xe6\x8a\x8a\xe7\xba\xa2\xe8\x89\xb2\xe7\x9a\x84\xe7\x9c\x8b\xe6\x88\x90\xe4\xb8\x80\xe7\xb1\xbb\xef\xbc\x8c\xe6\x8a\x8a\xe5\x85\xb6\xe4\xbb\x96\xe7\x9a\x84\xe7\x9c\x8b\xe4\xbd\x9c\xe5\x8f\xa6\xe5\xa4\x96\xe4\xb8\x80\xe7\xb1\xbb\xef\xbc\x8c\xe8\xbf\x9b\xe8\xa1\x8c\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92\xef\xbc\x8c\xe7\x84\xb6\xe5\x90\x8e\xe6\x8a\x8a\xe8\x93\x9d\xe8\x89\xb2\xe7\x9a\x84\xe7\x9c\x8b\xe6\x88\x90\xe4\xb8\x80\xe7\xb1\xbb\xef\xbc\x8c\xe5\x85\xb6\xe4\xbb\x96\xe7\x9a\x84\xe5\x86\x8d\xe7\x9c\x8b\xe6\x88\x90\xe4\xb8\x80\xe7\xb1\xbb\xef\xbc\x8c\xe4\xbb\xa5\xe6\xad\xa4\xe7\xb1\xbb\xe6\x8e\xa8...\n![enter description here][11]\n- \xe5\x8f\xaf\xe4\xbb\xa5\xe7\x9c\x8b\xe5\x87\xba\xe5\xa4\xa7\xe4\xba\x8e2\xe7\xb1\xbb\xe7\x9a\x84\xe6\x83\x85\xe5\x86\xb5\xe4\xb8\x8b\xef\xbc\x8c\xe6\x9c\x89\xe5\xa4\x9a\xe5\xb0\x91\xe7\xb1\xbb\xe5\xb0\xb1\xe8\xa6\x81\xe8\xbf\x9b\xe8\xa1\x8c\xe5\xa4\x9a\xe5\xb0\x91\xe6\xac\xa1\xe7\x9a\x84\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92\xe5\x88\x86\xe7\xb1\xbb\n\n### 3\xe3\x80\x81\xe6\x89\x8b\xe5\x86\x99\xe6\x95\xb0\xe5\xad\x97\xe8\xaf\x86\xe5\x88\xab\n- \xe5\x85\xb1\xe6\x9c\x890-9\xef\xbc\x8c10\xe4\xb8\xaa\xe6\x95\xb0\xe5\xad\x97\xef\xbc\x8c\xe9\x9c\x80\xe8\xa6\x8110\xe6\xac\xa1\xe5\x88\x86\xe7\xb1\xbb\n- \xe7\x94\xb1\xe4\xba\x8e**\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86y**\xe7\xbb\x99\xe5\x87\xba\xe7\x9a\x84\xe6\x98\xaf`0,1,2...9`\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\x97\xef\xbc\x8c\xe8\x80\x8c\xe8\xbf\x9b\xe8\xa1\x8c\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92\xe9\x9c\x80\xe8\xa6\x81`0/1`\xe7\x9a\x84label\xe6\xa0\x87\xe8\xae\xb0\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xe9\x9c\x80\xe8\xa6\x81\xe5\xaf\xb9y\xe5\xa4\x84\xe7\x90\x86\n- \xe8\xaf\xb4\xe4\xb8\x80\xe4\xb8\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xef\xbc\x8c\xe5\x89\x8d`500`\xe4\xb8\xaa\xe6\x98\xaf`0`,`500-1000`\xe6\x98\xaf`1`,`...`,\xe6\x89\x80\xe4\xbb\xa5\xe5\xa6\x82\xe4\xb8\x8b\xe5\x9b\xbe\xef\xbc\x8c\xe5\xa4\x84\xe7\x90\x86\xe5\x90\x8e\xe7\x9a\x84`y`\xef\xbc\x8c**\xe5\x89\x8d500\xe8\xa1\x8c\xe7\x9a\x84\xe7\xac\xac\xe4\xb8\x80\xe5\x88\x97\xe6\x98\xaf1\xef\xbc\x8c\xe5\x85\xb6\xe4\xbd\x99\xe9\x83\xbd\xe6\x98\xaf0,500-1000\xe8\xa1\x8c\xe7\xac\xac\xe4\xba\x8c\xe5\x88\x97\xe6\x98\xaf1\xef\xbc\x8c\xe5\x85\xb6\xe4\xbd\x99\xe9\x83\xbd\xe6\x98\xaf0....**\n![enter description here][12]\n- \xe7\x84\xb6\xe5\x90\x8e\xe8\xb0\x83\xe7\x94\xa8**\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xe7\xae\x97\xe6\xb3\x95**\xe6\xb1\x82\xe8\xa7\xa3`theta`\n- \xe5\xae\x9e\xe7\x8e\xb0\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a\n```\n# \xe6\xb1\x82\xe6\xaf\x8f\xe4\xb8\xaa\xe5\x88\x86\xe7\xb1\xbb\xe7\x9a\x84theta\xef\xbc\x8c\xe6\x9c\x80\xe5\x90\x8e\xe8\xbf\x94\xe5\x9b\x9e\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84all_theta    \ndef oneVsAll(X,y,num_labels,Lambda):\n    # \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe5\x8f\x98\xe9\x87\x8f\n    m,n = X.shape\n    all_theta = np.zeros((n+1,num_labels))  # \xe6\xaf\x8f\xe4\xb8\x80\xe5\x88\x97\xe5\xaf\xb9\xe5\xba\x94\xe7\x9b\xb8\xe5\xba\x94\xe5\x88\x86\xe7\xb1\xbb\xe7\x9a\x84theta,\xe5\x85\xb110\xe5\x88\x97\n    X = np.hstack((np.ones((m,1)),X))       # X\xe5\x89\x8d\xe8\xa1\xa5\xe4\xb8\x8a\xe4\xb8\x80\xe5\x88\x971\xe7\x9a\x84\xe5\x81\x8f\xe7\xbd\xaebias\n    class_y = np.zeros((m,num_labels))      # \xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84y\xe5\xaf\xb9\xe5\xba\x940-9\xef\xbc\x8c\xe9\x9c\x80\xe8\xa6\x81\xe6\x98\xa0\xe5\xb0\x84\xe4\xb8\xba0/1\xe7\x9a\x84\xe5\x85\xb3\xe7\xb3\xbb\n    initial_theta = np.zeros((n+1,1))       # \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe4\xb8\x80\xe4\xb8\xaa\xe5\x88\x86\xe7\xb1\xbb\xe7\x9a\x84theta\n    \n    # \xe6\x98\xa0\xe5\xb0\x84y\n    for i in range(num_labels):\n        class_y[:,i] = np.int32(y==i).reshape(1,-1) # \xe6\xb3\xa8\xe6\x84\x8freshape(1,-1)\xe6\x89\x8d\xe5\x8f\xaf\xe4\xbb\xa5\xe8\xb5\x8b\xe5\x80\xbc\n    \n    #np.savetxt(""class_y.csv"", class_y[0:600,:], delimiter=\',\')    \n    \n    \'\'\'\xe9\x81\x8d\xe5\x8e\x86\xe6\xaf\x8f\xe4\xb8\xaa\xe5\x88\x86\xe7\xb1\xbb\xef\xbc\x8c\xe8\xae\xa1\xe7\xae\x97\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84theta\xe5\x80\xbc\'\'\'\n    for i in range(num_labels):\n        result = optimize.fmin_bfgs(costFunction, initial_theta, fprime=gradient, args=(X,class_y[:,i],Lambda)) # \xe8\xb0\x83\xe7\x94\xa8\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xe7\x9a\x84\xe4\xbc\x98\xe5\x8c\x96\xe6\x96\xb9\xe6\xb3\x95\n        all_theta[:,i] = result.reshape(1,-1)   # \xe6\x94\xbe\xe5\x85\xa5all_theta\xe4\xb8\xad\n        \n    all_theta = np.transpose(all_theta) \n    return all_theta\n```\n\n### 4\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\n- \xe4\xb9\x8b\xe5\x89\x8d\xe8\xaf\xb4\xe8\xbf\x87\xef\xbc\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa**\xe6\xa6\x82\xe7\x8e\x87\xe5\x80\xbc**\xef\xbc\x8c\xe5\x88\xa9\xe7\x94\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x87\xba\xe6\x9d\xa5\xe7\x9a\x84`theta`\xe4\xbb\xa3\xe5\x85\xa5\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84**S\xe5\x9e\x8b\xe5\x87\xbd\xe6\x95\xb0**\xe4\xb8\xad\xef\xbc\x8c\xe6\xaf\x8f\xe8\xa1\x8c\xe7\x9a\x84\xe6\x9c\x80\xe5\xa4\xa7\xe5\x80\xbc\xe5\xb0\xb1\xe6\x98\xaf\xe6\x98\xaf\xe6\x9f\x90\xe4\xb8\xaa\xe6\x95\xb0\xe5\xad\x97\xe7\x9a\x84\xe6\x9c\x80\xe5\xa4\xa7\xe6\xa6\x82\xe7\x8e\x87\xef\xbc\x8c\xe6\x89\x80\xe5\x9c\xa8\xe7\x9a\x84**\xe5\x88\x97\xe5\x8f\xb7**\xe5\xb0\xb1\xe6\x98\xaf\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\x97\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc,\xe5\x9b\xa0\xe4\xb8\xba\xe5\x9c\xa8\xe5\x88\x86\xe7\xb1\xbb\xe6\x97\xb6\xef\xbc\x8c\xe6\x89\x80\xe6\x9c\x89\xe4\xb8\xba`0`\xe7\x9a\x84\xe5\xb0\x86`y`\xe6\x98\xa0\xe5\xb0\x84\xe5\x9c\xa8\xe7\xac\xac\xe4\xb8\x80\xe5\x88\x97\xef\xbc\x8c\xe4\xb8\xba1\xe7\x9a\x84\xe6\x98\xa0\xe5\xb0\x84\xe5\x9c\xa8\xe7\xac\xac\xe4\xba\x8c\xe5\x88\x97\xef\xbc\x8c\xe4\xbe\x9d\xe6\xac\xa1\xe7\xb1\xbb\xe6\x8e\xa8\n- \xe5\xae\x9e\xe7\x8e\xb0\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a\n```\n# \xe9\xa2\x84\xe6\xb5\x8b\ndef predict_oneVsAll(all_theta,X):\n    m = X.shape[0]\n    num_labels = all_theta.shape[0]\n    p = np.zeros((m,1))\n    X = np.hstack((np.ones((m,1)),X))   #\xe5\x9c\xa8X\xe6\x9c\x80\xe5\x89\x8d\xe9\x9d\xa2\xe5\x8a\xa0\xe4\xb8\x80\xe5\x88\x971\n    \n    h = sigmoid(np.dot(X,np.transpose(all_theta)))  #\xe9\xa2\x84\xe6\xb5\x8b\n\n    \'\'\'\n    \xe8\xbf\x94\xe5\x9b\x9eh\xe4\xb8\xad\xe6\xaf\x8f\xe4\xb8\x80\xe8\xa1\x8c\xe6\x9c\x80\xe5\xa4\xa7\xe5\x80\xbc\xe6\x89\x80\xe5\x9c\xa8\xe7\x9a\x84\xe5\x88\x97\xe5\x8f\xb7\n    - np.max(h, axis=1)\xe8\xbf\x94\xe5\x9b\x9eh\xe4\xb8\xad\xe6\xaf\x8f\xe4\xb8\x80\xe8\xa1\x8c\xe7\x9a\x84\xe6\x9c\x80\xe5\xa4\xa7\xe5\x80\xbc\xef\xbc\x88\xe6\x98\xaf\xe6\x9f\x90\xe4\xb8\xaa\xe6\x95\xb0\xe5\xad\x97\xe7\x9a\x84\xe6\x9c\x80\xe5\xa4\xa7\xe6\xa6\x82\xe7\x8e\x87\xef\xbc\x89\n    - \xe6\x9c\x80\xe5\x90\x8ewhere\xe6\x89\xbe\xe5\x88\xb0\xe7\x9a\x84\xe6\x9c\x80\xe5\xa4\xa7\xe6\xa6\x82\xe7\x8e\x87\xe6\x89\x80\xe5\x9c\xa8\xe7\x9a\x84\xe5\x88\x97\xe5\x8f\xb7\xef\xbc\x88\xe5\x88\x97\xe5\x8f\xb7\xe5\x8d\xb3\xe6\x98\xaf\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\x97\xef\xbc\x89\n    \'\'\'\n    p = np.array(np.where(h[0,:] == np.max(h, axis=1)[0]))  \n    for i in np.arange(1, m):\n        t = np.array(np.where(h[i,:] == np.max(h, axis=1)[i]))\n        p = np.vstack((p,t))\n    return p\n```\n\n### 5\xe3\x80\x81\xe8\xbf\x90\xe8\xa1\x8c\xe7\xbb\x93\xe6\x9e\x9c\n- 10\xe6\xac\xa1\xe5\x88\x86\xe7\xb1\xbb\xef\xbc\x8c\xe5\x9c\xa8\xe8\xae\xad\xe7\xbb\x83\xe9\x9b\x86\xe4\xb8\x8a\xe7\x9a\x84\xe5\x87\x86\xe7\xa1\xae\xe5\xba\xa6\xef\xbc\x9a   \n![enter description here][13]\n\n### 6\xe3\x80\x81[\xe4\xbd\xbf\xe7\x94\xa8scikit-learn\xe5\xba\x93\xe4\xb8\xad\xe7\x9a\x84\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92\xe6\xa8\xa1\xe5\x9e\x8b\xe5\xae\x9e\xe7\x8e\xb0](/LogisticRegression/LogisticRegression_OneVsAll_scikit-learn.py)\n- 1\xe3\x80\x81\xe5\xaf\xbc\xe5\x85\xa5\xe5\x8c\x85\n```\nfrom scipy import io as spio\nimport numpy as np\nfrom sklearn import svm\nfrom sklearn.linear_model import LogisticRegression\n```\n- 2\xe3\x80\x81\xe5\x8a\xa0\xe8\xbd\xbd\xe6\x95\xb0\xe6\x8d\xae\n```\n    data = loadmat_data(""data_digits.mat"") \n    X = data[\'X\']   # \xe8\x8e\xb7\xe5\x8f\x96X\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe6\xaf\x8f\xe4\xb8\x80\xe8\xa1\x8c\xe5\xaf\xb9\xe5\xba\x94\xe4\xb8\x80\xe4\xb8\xaa\xe6\x95\xb0\xe5\xad\x9720x20px\n    y = data[\'y\']   # \xe8\xbf\x99\xe9\x87\x8c\xe8\xaf\xbb\xe5\x8f\x96mat\xe6\x96\x87\xe4\xbb\xb6y\xe7\x9a\x84shape=(5000, 1)\n    y = np.ravel(y) # \xe8\xb0\x83\xe7\x94\xa8sklearn\xe9\x9c\x80\xe8\xa6\x81\xe8\xbd\xac\xe5\x8c\x96\xe6\x88\x90\xe4\xb8\x80\xe7\xbb\xb4\xe7\x9a\x84(5000,)\n```\n- 3\xe3\x80\x81\xe6\x8b\x9f\xe5\x90\x88\xe6\xa8\xa1\xe5\x9e\x8b\n```\n    model = LogisticRegression()\n    model.fit(X, y) # \xe6\x8b\x9f\xe5\x90\x88\n```\n- 4\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\n```\n    predict = model.predict(X) #\xe9\xa2\x84\xe6\xb5\x8b\n    \n    print u""\xe9\xa2\x84\xe6\xb5\x8b\xe5\x87\x86\xe7\xa1\xae\xe5\xba\xa6\xe4\xb8\xba\xef\xbc\x9a%f%%""%np.mean(np.float64(predict == y)*100)\n```\n- 5\xe3\x80\x81\xe8\xbe\x93\xe5\x87\xba\xe7\xbb\x93\xe6\x9e\x9c\xef\xbc\x88\xe5\x9c\xa8\xe8\xae\xad\xe7\xbb\x83\xe9\x9b\x86\xe4\xb8\x8a\xe7\x9a\x84\xe5\x87\x86\xe7\xa1\xae\xe5\xba\xa6\xef\xbc\x89\n![enter description here][14]\n\n\n----------\n\n## \xe4\xb8\x89\xe3\x80\x81BP\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\n- [\xe5\x85\xa8\xe9\x83\xa8\xe4\xbb\xa3\xe7\xa0\x81](/NeuralNetwok/NeuralNetwork.py)\n\n### 1\xe3\x80\x81\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9cmodel\n- \xe5\x85\x88\xe4\xbb\x8b\xe7\xbb\x8d\xe4\xb8\xaa\xe4\xb8\x89\xe5\xb1\x82\xe7\x9a\x84\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xef\xbc\x8c\xe5\xa6\x82\xe4\xb8\x8b\xe5\x9b\xbe\xe6\x89\x80\xe7\xa4\xba\n - \xe8\xbe\x93\xe5\x85\xa5\xe5\xb1\x82\xef\xbc\x88input layer\xef\xbc\x89\xe6\x9c\x89\xe4\xb8\x89\xe4\xb8\xaaunits\xef\xbc\x88![{x_0}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7Bx_0%7D)\xe4\xb8\xba\xe8\xa1\xa5\xe4\xb8\x8a\xe7\x9a\x84bias\xef\xbc\x8c\xe9\x80\x9a\xe5\xb8\xb8\xe8\xae\xbe\xe4\xb8\xba`1`\xef\xbc\x89\n - ![a_i^{(j)}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=a_i%5E%7B%28j%29%7D)\xe8\xa1\xa8\xe7\xa4\xba\xe7\xac\xac`j`\xe5\xb1\x82\xe7\x9a\x84\xe7\xac\xac`i`\xe4\xb8\xaa\xe6\xbf\x80\xe5\x8a\xb1\xef\xbc\x8c\xe4\xb9\x9f\xe7\xa7\xb0\xe4\xb8\xba\xe4\xb8\xba\xe5\x8d\x95\xe5\x85\x83unit\n - ![{\\theta ^{(j)}}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7B%5Ctheta%20%5E%7B%28j%29%7D%7D)\xe4\xb8\xba\xe7\xac\xac`j`\xe5\xb1\x82\xe5\x88\xb0\xe7\xac\xac`j+1`\xe5\xb1\x82\xe6\x98\xa0\xe5\xb0\x84\xe7\x9a\x84\xe6\x9d\x83\xe9\x87\x8d\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x8c\xe5\xb0\xb1\xe6\x98\xaf\xe6\xaf\x8f\xe6\x9d\xa1\xe8\xbe\xb9\xe7\x9a\x84\xe6\x9d\x83\xe9\x87\x8d\n![enter description here][15]\n\n- \xe6\x89\x80\xe4\xbb\xa5\xe5\x8f\xaf\xe4\xbb\xa5\xe5\xbe\x97\xe5\x88\xb0\xef\xbc\x9a\n - \xe9\x9a\x90\xe5\x90\xab\xe5\xb1\x82\xef\xbc\x9a  \n![a_1^{(2)} = g(\\theta _{10}^{(1)}{x_0} + \\theta _{11}^{(1)}{x_1} + \\theta _{12}^{(1)}{x_2} + \\theta _{13}^{(1)}{x_3})](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=a_1%5E%7B%282%29%7D%20%3D%20g%28%5Ctheta%20_%7B10%7D%5E%7B%281%29%7D%7Bx_0%7D%20%2B%20%5Ctheta%20_%7B11%7D%5E%7B%281%29%7D%7Bx_1%7D%20%2B%20%5Ctheta%20_%7B12%7D%5E%7B%281%29%7D%7Bx_2%7D%20%2B%20%5Ctheta%20_%7B13%7D%5E%7B%281%29%7D%7Bx_3%7D%29)   \n![a_2^{(2)} = g(\\theta _{20}^{(1)}{x_0} + \\theta _{21}^{(1)}{x_1} + \\theta _{22}^{(1)}{x_2} + \\theta _{23}^{(1)}{x_3})](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=a_2%5E%7B%282%29%7D%20%3D%20g%28%5Ctheta%20_%7B20%7D%5E%7B%281%29%7D%7Bx_0%7D%20%2B%20%5Ctheta%20_%7B21%7D%5E%7B%281%29%7D%7Bx_1%7D%20%2B%20%5Ctheta%20_%7B22%7D%5E%7B%281%29%7D%7Bx_2%7D%20%2B%20%5Ctheta%20_%7B23%7D%5E%7B%281%29%7D%7Bx_3%7D%29)   \n![a_3^{(2)} = g(\\theta _{30}^{(1)}{x_0} + \\theta _{31}^{(1)}{x_1} + \\theta _{32}^{(1)}{x_2} + \\theta _{33}^{(1)}{x_3})](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=a_3%5E%7B%282%29%7D%20%3D%20g%28%5Ctheta%20_%7B30%7D%5E%7B%281%29%7D%7Bx_0%7D%20%2B%20%5Ctheta%20_%7B31%7D%5E%7B%281%29%7D%7Bx_1%7D%20%2B%20%5Ctheta%20_%7B32%7D%5E%7B%281%29%7D%7Bx_2%7D%20%2B%20%5Ctheta%20_%7B33%7D%5E%7B%281%29%7D%7Bx_3%7D%29)\n - \xe8\xbe\x93\xe5\x87\xba\xe5\xb1\x82   \n![{h_\\theta }(x) = a_1^{(3)} = g(\\theta _{10}^{(2)}a_0^{(2)} + \\theta _{11}^{(2)}a_1^{(2)} + \\theta _{12}^{(2)}a_2^{(2)} + \\theta _{13}^{(2)}a_3^{(2)})](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7Bh_%5Ctheta%20%7D%28x%29%20%3D%20a_1%5E%7B%283%29%7D%20%3D%20g%28%5Ctheta%20_%7B10%7D%5E%7B%282%29%7Da_0%5E%7B%282%29%7D%20%2B%20%5Ctheta%20_%7B11%7D%5E%7B%282%29%7Da_1%5E%7B%282%29%7D%20%2B%20%5Ctheta%20_%7B12%7D%5E%7B%282%29%7Da_2%5E%7B%282%29%7D%20%2B%20%5Ctheta%20_%7B13%7D%5E%7B%282%29%7Da_3%5E%7B%282%29%7D%29) \xe5\x85\xb6\xe4\xb8\xad\xef\xbc\x8c**S\xe5\x9e\x8b\xe5\x87\xbd\xe6\x95\xb0**![g(z) = \\frac{1}{{1 + {e^{ - z}}}}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=g%28z%29%20%3D%20%5Cfrac%7B1%7D%7B%7B1%20%2B%20%7Be%5E%7B%20-%20z%7D%7D%7D%7D)\xef\xbc\x8c\xe4\xb9\x9f\xe6\x88\x90\xe4\xb8\xba**\xe6\xbf\x80\xe5\x8a\xb1\xe5\x87\xbd\xe6\x95\xb0**\n- \xe5\x8f\xaf\xe4\xbb\xa5\xe7\x9c\x8b\xe5\x87\xba![{\\theta ^{(1)}}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7B%5Ctheta%20%5E%7B%281%29%7D%7D) \xe4\xb8\xba3x4\xe7\x9a\x84\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x8c![{\\theta ^{(2)}}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7B%5Ctheta%20%5E%7B%282%29%7D%7D)\xe4\xb8\xba1x4\xe7\x9a\x84\xe7\x9f\xa9\xe9\x98\xb5\n - ![{\\theta ^{(j)}}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7B%5Ctheta%20%5E%7B%28j%29%7D%7D) ==\xe3\x80\x8b`j+1`\xe7\x9a\x84\xe5\x8d\x95\xe5\x85\x83\xe6\x95\xb0x\xef\xbc\x88`j`\xe5\xb1\x82\xe7\x9a\x84\xe5\x8d\x95\xe5\x85\x83\xe6\x95\xb0+1\xef\xbc\x89\n\n### 2\xe3\x80\x81\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0\n- \xe5\x81\x87\xe8\xae\xbe\xe6\x9c\x80\xe5\x90\x8e\xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84![{h_\\Theta }(x) \\in {R^K}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7Bh_%5CTheta%20%7D%28x%29%20%5Cin%20%7BR%5EK%7D)\xef\xbc\x8c\xe5\x8d\xb3\xe4\xbb\xa3\xe8\xa1\xa8\xe8\xbe\x93\xe5\x87\xba\xe5\xb1\x82\xe6\x9c\x89K\xe4\xb8\xaa\xe5\x8d\x95\xe5\x85\x83\n- ![J(\\Theta ) =  - \\frac{1}{m}\\sum\\limits_{i = 1}^m {\\sum\\limits_{k = 1}^K {[y_k^{(i)}\\log {{({h_\\Theta }({x^{(i)}}))}_k}} }  + (1 - y_k^{(i)})\\log {(1 - {h_\\Theta }({x^{(i)}}))_k}]](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=J%28%5CTheta%20%29%20%3D%20%20-%20%5Cfrac%7B1%7D%7Bm%7D%5Csum%5Climits_%7Bi%20%3D%201%7D%5Em%20%7B%5Csum%5Climits_%7Bk%20%3D%201%7D%5EK%20%7B%5By_k%5E%7B%28i%29%7D%5Clog%20%7B%7B%28%7Bh_%5CTheta%20%7D%28%7Bx%5E%7B%28i%29%7D%7D%29%29%7D_k%7D%7D%20%7D%20%20%2B%20%281%20-%20y_k%5E%7B%28i%29%7D%29%5Clog%20%7B%281%20-%20%7Bh_%5CTheta%20%7D%28%7Bx%5E%7B%28i%29%7D%7D%29%29_k%7D%5D) \xe5\x85\xb6\xe4\xb8\xad\xef\xbc\x8c![{({h_\\Theta }(x))_i}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7B%28%7Bh_%5CTheta%20%7D%28x%29%29_i%7D)\xe4\xbb\xa3\xe8\xa1\xa8\xe7\xac\xac`i`\xe4\xb8\xaa\xe5\x8d\x95\xe5\x85\x83\xe8\xbe\x93\xe5\x87\xba\n- \xe4\xb8\x8e\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9a\x84\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0![J(\\theta ) =  - \\frac{1}{m}\\sum\\limits_{i = 1}^m {[{y^{(i)}}\\log ({h_\\theta }({x^{(i)}}) + (1 - } {y^{(i)}})\\log (1 - {h_\\theta }({x^{(i)}})]](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=J%28%5Ctheta%20%29%20%3D%20%20-%20%5Cfrac%7B1%7D%7Bm%7D%5Csum%5Climits_%7Bi%20%3D%201%7D%5Em%20%7B%5B%7By%5E%7B%28i%29%7D%7D%5Clog%20%28%7Bh_%5Ctheta%20%7D%28%7Bx%5E%7B%28i%29%7D%7D%29%20%2B%20%281%20-%20%7D%20%7By%5E%7B%28i%29%7D%7D%29%5Clog%20%281%20-%20%7Bh_%5Ctheta%20%7D%28%7Bx%5E%7B%28i%29%7D%7D%29%5D)\xe5\xb7\xae\xe4\xb8\x8d\xe5\xa4\x9a\xef\xbc\x8c\xe5\xb0\xb1\xe6\x98\xaf\xe7\xb4\xaf\xe5\x8a\xa0\xe4\xb8\x8a\xe6\xaf\x8f\xe4\xb8\xaa\xe8\xbe\x93\xe5\x87\xba\xef\xbc\x88\xe5\x85\xb1\xe6\x9c\x89K\xe4\xb8\xaa\xe8\xbe\x93\xe5\x87\xba\xef\xbc\x89\n\n\n\n### 3\xe3\x80\x81\xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96\n- `L`-->\xe6\x89\x80\xe6\x9c\x89\xe5\xb1\x82\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\n- ![{S_l}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7BS_l%7D)-->\xe7\xac\xac`l`\xe5\xb1\x82unit\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\n- \xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96\xe5\x90\x8e\xe7\x9a\x84**\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0**\xe4\xb8\xba  \n![enter description here][16]\n - ![\\theta ](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%5Ctheta%20)\xe5\x85\xb1\xe6\x9c\x89`L-1`\xe5\xb1\x82\xef\xbc\x8c\n - \xe7\x84\xb6\xe5\x90\x8e\xe6\x98\xaf\xe7\xb4\xaf\xe5\x8a\xa0\xe5\xaf\xb9\xe5\xba\x94\xe6\xaf\x8f\xe4\xb8\x80\xe5\xb1\x82\xe7\x9a\x84theta\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x8c\xe6\xb3\xa8\xe6\x84\x8f\xe4\xb8\x8d\xe5\x8c\x85\xe5\x90\xab\xe5\x8a\xa0\xe4\xb8\x8a\xe5\x81\x8f\xe7\xbd\xae\xe9\xa1\xb9\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84theta(0)\n- \xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96\xe5\x90\x8e\xe7\x9a\x84\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0\xe5\xae\x9e\xe7\x8e\xb0\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a\n```\n# \xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0\ndef nnCostFunction(nn_params,input_layer_size,hidden_layer_size,num_labels,X,y,Lambda):\n    length = nn_params.shape[0] # theta\xe7\x9a\x84\xe4\xb8\xad\xe9\x95\xbf\xe5\xba\xa6\n    # \xe8\xbf\x98\xe5\x8e\x9ftheta1\xe5\x92\x8ctheta2\n    Theta1 = nn_params[0:hidden_layer_size*(input_layer_size+1)].reshape(hidden_layer_size,input_layer_size+1)\n    Theta2 = nn_params[hidden_layer_size*(input_layer_size+1):length].reshape(num_labels,hidden_layer_size+1)\n    \n    # np.savetxt(""Theta1.csv"",Theta1,delimiter=\',\')\n    \n    m = X.shape[0]\n    class_y = np.zeros((m,num_labels))      # \xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84y\xe5\xaf\xb9\xe5\xba\x940-9\xef\xbc\x8c\xe9\x9c\x80\xe8\xa6\x81\xe6\x98\xa0\xe5\xb0\x84\xe4\xb8\xba0/1\xe7\x9a\x84\xe5\x85\xb3\xe7\xb3\xbb\n    # \xe6\x98\xa0\xe5\xb0\x84y\n    for i in range(num_labels):\n        class_y[:,i] = np.int32(y==i).reshape(1,-1) # \xe6\xb3\xa8\xe6\x84\x8freshape(1,-1)\xe6\x89\x8d\xe5\x8f\xaf\xe4\xbb\xa5\xe8\xb5\x8b\xe5\x80\xbc\n     \n    \'\'\'\xe5\x8e\xbb\xe6\x8e\x89theta1\xe5\x92\x8ctheta2\xe7\x9a\x84\xe7\xac\xac\xe4\xb8\x80\xe5\x88\x97\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xba\xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96\xe6\x97\xb6\xe4\xbb\x8e1\xe5\xbc\x80\xe5\xa7\x8b\'\'\'    \n    Theta1_colCount = Theta1.shape[1]    \n    Theta1_x = Theta1[:,1:Theta1_colCount]\n    Theta2_colCount = Theta2.shape[1]    \n    Theta2_x = Theta2[:,1:Theta2_colCount]\n    # \xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96\xe5\x90\x91theta^2\n    term = np.dot(np.transpose(np.vstack((Theta1_x.reshape(-1,1),Theta2_x.reshape(-1,1)))),np.vstack((Theta1_x.reshape(-1,1),Theta2_x.reshape(-1,1))))\n    \n    \'\'\'\xe6\xad\xa3\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad,\xe6\xaf\x8f\xe6\xac\xa1\xe9\x9c\x80\xe8\xa6\x81\xe8\xa1\xa5\xe4\xb8\x8a\xe4\xb8\x80\xe5\x88\x971\xe7\x9a\x84\xe5\x81\x8f\xe7\xbd\xaebias\'\'\'\n    a1 = np.hstack((np.ones((m,1)),X))      \n    z2 = np.dot(a1,np.transpose(Theta1))    \n    a2 = sigmoid(z2)\n    a2 = np.hstack((np.ones((m,1)),a2))\n    z3 = np.dot(a2,np.transpose(Theta2))\n    h  = sigmoid(z3)    \n    \'\'\'\xe4\xbb\xa3\xe4\xbb\xb7\'\'\'    \n    J = -(np.dot(np.transpose(class_y.reshape(-1,1)),np.log(h.reshape(-1,1)))+np.dot(np.transpose(1-class_y.reshape(-1,1)),np.log(1-h.reshape(-1,1)))-Lambda*term/2)/m   \n    \n    return np.ravel(J)\n```\n\n### 4\xe3\x80\x81\xe5\x8f\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xadBP\n- \xe4\xb8\x8a\xe9\x9d\xa2\xe6\xad\xa3\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\xe5\x8f\xaf\xe4\xbb\xa5\xe8\xae\xa1\xe7\xae\x97\xe5\xbe\x97\xe5\x88\xb0`J(\xce\xb8)`,\xe4\xbd\xbf\xe7\x94\xa8\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xe6\xb3\x95\xe8\xbf\x98\xe9\x9c\x80\xe8\xa6\x81\xe6\xb1\x82\xe5\xae\x83\xe7\x9a\x84\xe6\xa2\xaf\xe5\xba\xa6\n- BP\xe5\x8f\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\xe7\x9a\x84\xe7\x9b\xae\xe7\x9a\x84\xe5\xb0\xb1\xe6\x98\xaf\xe6\xb1\x82\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84\xe6\xa2\xaf\xe5\xba\xa6\n- \xe5\x81\x87\xe8\xae\xbe4\xe5\xb1\x82\xe7\x9a\x84\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c,![\\delta _{\\text{j}}^{(l)}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%5Cdelta%20_%7B%5Ctext%7Bj%7D%7D%5E%7B%28l%29%7D)\xe8\xae\xb0\xe4\xb8\xba-->`l`\xe5\xb1\x82\xe7\xac\xac`j`\xe4\xb8\xaa\xe5\x8d\x95\xe5\x85\x83\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\n - ![\\delta _{\\text{j}}^{(4)} = a_j^{(4)} - {y_i}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%5Cdelta%20_%7B%5Ctext%7Bj%7D%7D%5E%7B%284%29%7D%20%3D%20a_j%5E%7B%284%29%7D%20-%20%7By_i%7D)\xe3\x80\x8a===\xe3\x80\x8b![{\\delta ^{(4)}} = {a^{(4)}} - y](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7B%5Cdelta%20%5E%7B%284%29%7D%7D%20%3D%20%7Ba%5E%7B%284%29%7D%7D%20-%20y)\xef\xbc\x88\xe5\x90\x91\xe9\x87\x8f\xe5\x8c\x96\xef\xbc\x89\n - ![{\\delta ^{(3)}} = {({\\theta ^{(3)}})^T}{\\delta ^{(4)}}.*{g^}({a^{(3)}})](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7B%5Cdelta%20%5E%7B%283%29%7D%7D%20%3D%20%7B%28%7B%5Ctheta%20%5E%7B%283%29%7D%7D%29%5ET%7D%7B%5Cdelta%20%5E%7B%284%29%7D%7D.%2A%7Bg%5E%7D%28%7Ba%5E%7B%283%29%7D%7D%29)\n - ![{\\delta ^{(2)}} = {({\\theta ^{(2)}})^T}{\\delta ^{(3)}}.*{g^}({a^{(2)}})](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7B%5Cdelta%20%5E%7B%282%29%7D%7D%20%3D%20%7B%28%7B%5Ctheta%20%5E%7B%282%29%7D%7D%29%5ET%7D%7B%5Cdelta%20%5E%7B%283%29%7D%7D.%2A%7Bg%5E%7D%28%7Ba%5E%7B%282%29%7D%7D%29)\n - \xe6\xb2\xa1\xe6\x9c\x89![{\\delta ^{(1)}}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7B%5Cdelta%20%5E%7B%281%29%7D%7D)\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xba\xe5\xaf\xb9\xe4\xba\x8e\xe8\xbe\x93\xe5\x85\xa5\xe6\xb2\xa1\xe6\x9c\x89\xe8\xaf\xaf\xe5\xb7\xae\n- \xe5\x9b\xa0\xe4\xb8\xbaS\xe5\x9e\x8b\xe5\x87\xbd\xe6\x95\xb0![{\\text{g(z)}}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7B%5Ctext%7Bg%28z%29%7D%7D)\xe7\x9a\x84\xe5\xaf\xbc\xe6\x95\xb0\xe4\xb8\xba\xef\xbc\x9a![{g^}(z){\\text{ = g(z)(1 - g(z))}}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7Bg%5E%7D%28z%29%7B%5Ctext%7B%20%3D%20g%28z%29%281%20-%20g%28z%29%29%7D%7D)\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xe4\xb8\x8a\xe9\x9d\xa2\xe7\x9a\x84![{g^}({a^{(3)}})](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7Bg%5E%7D%28%7Ba%5E%7B%283%29%7D%7D%29)\xe5\x92\x8c![{g^}({a^{(2)}})](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7Bg%5E%7D%28%7Ba%5E%7B%282%29%7D%7D%29)\xe5\x8f\xaf\xe4\xbb\xa5\xe5\x9c\xa8\xe5\x89\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\xe4\xb8\xad\xe8\xae\xa1\xe7\xae\x97\xe5\x87\xba\xe6\x9d\xa5\n\n- \xe5\x8f\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\xe8\xae\xa1\xe7\xae\x97\xe6\xa2\xaf\xe5\xba\xa6\xe7\x9a\x84\xe8\xbf\x87\xe7\xa8\x8b\xe4\xb8\xba\xef\xbc\x9a\n - ![\\Delta _{ij}^{(l)} = 0](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%5CDelta%20_%7Bij%7D%5E%7B%28l%29%7D%20%3D%200)\xef\xbc\x88![\\Delta ](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%5CDelta%20)\xe6\x98\xaf\xe5\xa4\xa7\xe5\x86\x99\xe7\x9a\x84![\\delta ](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%5Cdelta%20)\xef\xbc\x89\n - for i=1-m:     \n -![{a^{(1)}} = {x^{(i)}}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7Ba%5E%7B%281%29%7D%7D%20%3D%20%7Bx%5E%7B%28i%29%7D%7D)       \n-\xe6\xad\xa3\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\xe8\xae\xa1\xe7\xae\x97![{a^{(l)}}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7Ba%5E%7B%28l%29%7D%7D)\xef\xbc\x88l=2,3,4...L\xef\xbc\x89      \n-\xe5\x8f\x8d\xe5\x90\x91\xe8\xae\xa1\xe7\xae\x97![{\\delta ^{(L)}}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7B%5Cdelta%20%5E%7B%28L%29%7D%7D)\xe3\x80\x81![{\\delta ^{(L - 1)}}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7B%5Cdelta%20%5E%7B%28L%20-%201%29%7D%7D)...![{\\delta ^{(2)}}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7B%5Cdelta%20%5E%7B%282%29%7D%7D)\xef\xbc\x9b       \n-![\\Delta _{ij}^{(l)} = \\Delta _{ij}^{(l)} + a_j^{(l)}{\\delta ^{(l + 1)}}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%5CDelta%20_%7Bij%7D%5E%7B%28l%29%7D%20%3D%20%5CDelta%20_%7Bij%7D%5E%7B%28l%29%7D%20%2B%20a_j%5E%7B%28l%29%7D%7B%5Cdelta%20%5E%7B%28l%20%2B%201%29%7D%7D)          \n-![D_{ij}^{(l)} = \\frac{1}{m}\\Delta _{ij}^{(l)} + \\lambda \\theta _{ij}^l\\begin{array}{c}    {}&amp; {(j \\ne 0)}  \\end{array} ](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=D_%7Bij%7D%5E%7B%28l%29%7D%20%3D%20%5Cfrac%7B1%7D%7Bm%7D%5CDelta%20_%7Bij%7D%5E%7B%28l%29%7D%20%2B%20%5Clambda%20%5Ctheta%20_%7Bij%7D%5El%5Cbegin%7Barray%7D%7Bc%7D%20%20%20%20%7B%7D%26%20%7B%28j%20%5Cne%200%29%7D%20%20%5Cend%7Barray%7D%20)      \n![D_{ij}^{(l)} = \\frac{1}{m}\\Delta _{ij}^{(l)} + \\lambda \\theta _{ij}^lj = 0\\begin{array}{c}    {}&amp; {j = 0}  \\end{array} ](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=D_%7Bij%7D%5E%7B%28l%29%7D%20%3D%20%5Cfrac%7B1%7D%7Bm%7D%5CDelta%20_%7Bij%7D%5E%7B%28l%29%7D%20%2B%20%5Clambda%20%5Ctheta%20_%7Bij%7D%5Elj%20%3D%200%5Cbegin%7Barray%7D%7Bc%7D%20%20%20%20%7B%7D%26%20%7Bj%20%3D%200%7D%20%20%5Cend%7Barray%7D%20)     \n\n- \xe6\x9c\x80\xe5\x90\x8e![\\frac{{\\partial J(\\Theta )}}{{\\partial \\Theta _{ij}^{(l)}}} = D_{ij}^{(l)}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%5Cfrac%7B%7B%5Cpartial%20J%28%5CTheta%20%29%7D%7D%7B%7B%5Cpartial%20%5CTheta%20_%7Bij%7D%5E%7B%28l%29%7D%7D%7D%20%3D%20D_%7Bij%7D%5E%7B%28l%29%7D)\xef\xbc\x8c\xe5\x8d\xb3\xe5\xbe\x97\xe5\x88\xb0\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84\xe6\xa2\xaf\xe5\xba\xa6\n- \xe5\xae\x9e\xe7\x8e\xb0\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a\n```\n# \xe6\xa2\xaf\xe5\xba\xa6\ndef nnGradient(nn_params,input_layer_size,hidden_layer_size,num_labels,X,y,Lambda):\n    length = nn_params.shape[0]\n    Theta1 = nn_params[0:hidden_layer_size*(input_layer_size+1)].reshape(hidden_layer_size,input_layer_size+1).copy()   # \xe8\xbf\x99\xe9\x87\x8c\xe4\xbd\xbf\xe7\x94\xa8copy\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x8c\xe5\x90\xa6\xe5\x88\x99\xe4\xb8\x8b\xe9\x9d\xa2\xe4\xbf\xae\xe6\x94\xb9Theta\xe7\x9a\x84\xe5\x80\xbc\xef\xbc\x8cnn_params\xe4\xb9\x9f\xe4\xbc\x9a\xe4\xb8\x80\xe8\xb5\xb7\xe4\xbf\xae\xe6\x94\xb9\n    Theta2 = nn_params[hidden_layer_size*(input_layer_size+1):length].reshape(num_labels,hidden_layer_size+1).copy()\n    m = X.shape[0]\n    class_y = np.zeros((m,num_labels))      # \xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84y\xe5\xaf\xb9\xe5\xba\x940-9\xef\xbc\x8c\xe9\x9c\x80\xe8\xa6\x81\xe6\x98\xa0\xe5\xb0\x84\xe4\xb8\xba0/1\xe7\x9a\x84\xe5\x85\xb3\xe7\xb3\xbb    \n    # \xe6\x98\xa0\xe5\xb0\x84y\n    for i in range(num_labels):\n        class_y[:,i] = np.int32(y==i).reshape(1,-1) # \xe6\xb3\xa8\xe6\x84\x8freshape(1,-1)\xe6\x89\x8d\xe5\x8f\xaf\xe4\xbb\xa5\xe8\xb5\x8b\xe5\x80\xbc\n     \n    \'\'\'\xe5\x8e\xbb\xe6\x8e\x89theta1\xe5\x92\x8ctheta2\xe7\x9a\x84\xe7\xac\xac\xe4\xb8\x80\xe5\x88\x97\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xba\xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96\xe6\x97\xb6\xe4\xbb\x8e1\xe5\xbc\x80\xe5\xa7\x8b\'\'\'\n    Theta1_colCount = Theta1.shape[1]    \n    Theta1_x = Theta1[:,1:Theta1_colCount]\n    Theta2_colCount = Theta2.shape[1]    \n    Theta2_x = Theta2[:,1:Theta2_colCount]\n    \n    Theta1_grad = np.zeros((Theta1.shape))  #\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe5\x88\xb0\xe7\xac\xac\xe4\xba\x8c\xe5\xb1\x82\xe7\x9a\x84\xe6\x9d\x83\xe9\x87\x8d\n    Theta2_grad = np.zeros((Theta2.shape))  #\xe7\xac\xac\xe4\xba\x8c\xe5\xb1\x82\xe5\x88\xb0\xe7\xac\xac\xe4\xb8\x89\xe5\xb1\x82\xe7\x9a\x84\xe6\x9d\x83\xe9\x87\x8d\n      \n   \n    \'\'\'\xe6\xad\xa3\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\xef\xbc\x8c\xe6\xaf\x8f\xe6\xac\xa1\xe9\x9c\x80\xe8\xa6\x81\xe8\xa1\xa5\xe4\xb8\x8a\xe4\xb8\x80\xe5\x88\x971\xe7\x9a\x84\xe5\x81\x8f\xe7\xbd\xaebias\'\'\'\n    a1 = np.hstack((np.ones((m,1)),X))\n    z2 = np.dot(a1,np.transpose(Theta1))\n    a2 = sigmoid(z2)\n    a2 = np.hstack((np.ones((m,1)),a2))\n    z3 = np.dot(a2,np.transpose(Theta2))\n    h  = sigmoid(z3)\n    \n    \n    \'\'\'\xe5\x8f\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\xef\xbc\x8cdelta\xe4\xb8\xba\xe8\xaf\xaf\xe5\xb7\xae\xef\xbc\x8c\'\'\'\n    delta3 = np.zeros((m,num_labels))\n    delta2 = np.zeros((m,hidden_layer_size))\n    for i in range(m):\n        #delta3[i,:] = (h[i,:]-class_y[i,:])*sigmoidGradient(z3[i,:])  # \xe5\x9d\x87\xe6\x96\xb9\xe8\xaf\xaf\xe5\xb7\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xe7\x8e\x87\n        delta3[i,:] = h[i,:]-class_y[i,:]                              # \xe4\xba\xa4\xe5\x8f\x89\xe7\x86\xb5\xe8\xaf\xaf\xe5\xb7\xae\xe7\x8e\x87\n        Theta2_grad = Theta2_grad+np.dot(np.transpose(delta3[i,:].reshape(1,-1)),a2[i,:].reshape(1,-1))\n        delta2[i,:] = np.dot(delta3[i,:].reshape(1,-1),Theta2_x)*sigmoidGradient(z2[i,:])\n        Theta1_grad = Theta1_grad+np.dot(np.transpose(delta2[i,:].reshape(1,-1)),a1[i,:].reshape(1,-1))\n    \n    Theta1[:,0] = 0\n    Theta2[:,0] = 0          \n    \'\'\'\xe6\xa2\xaf\xe5\xba\xa6\'\'\'\n    grad = (np.vstack((Theta1_grad.reshape(-1,1),Theta2_grad.reshape(-1,1)))+Lambda*np.vstack((Theta1.reshape(-1,1),Theta2.reshape(-1,1))))/m\n    return np.ravel(grad)\n```\n\n### 5\xe3\x80\x81BP\xe5\x8f\xaf\xe4\xbb\xa5\xe6\xb1\x82\xe6\xa2\xaf\xe5\xba\xa6\xe7\x9a\x84\xe5\x8e\x9f\xe5\x9b\xa0\n- \xe5\xae\x9e\xe9\x99\x85\xe6\x98\xaf\xe5\x88\xa9\xe7\x94\xa8\xe4\xba\x86`\xe9\x93\xbe\xe5\xbc\x8f\xe6\xb1\x82\xe5\xaf\xbc`\xe6\xb3\x95\xe5\x88\x99\n- \xe5\x9b\xa0\xe4\xb8\xba\xe4\xb8\x8b\xe4\xb8\x80\xe5\xb1\x82\xe7\x9a\x84\xe5\x8d\x95\xe5\x85\x83\xe5\x88\xa9\xe7\x94\xa8\xe4\xb8\x8a\xe4\xb8\x80\xe5\xb1\x82\xe7\x9a\x84\xe5\x8d\x95\xe5\x85\x83\xe4\xbd\x9c\xe4\xb8\xba\xe8\xbe\x93\xe5\x85\xa5\xe8\xbf\x9b\xe8\xa1\x8c\xe8\xae\xa1\xe7\xae\x97\n- \xe5\xa4\xa7\xe4\xbd\x93\xe7\x9a\x84\xe6\x8e\xa8\xe5\xaf\xbc\xe8\xbf\x87\xe7\xa8\x8b\xe5\xa6\x82\xe4\xb8\x8b\xef\xbc\x8c\xe6\x9c\x80\xe7\xbb\x88\xe6\x88\x91\xe4\xbb\xac\xe6\x98\xaf\xe6\x83\xb3\xe9\xa2\x84\xe6\xb5\x8b\xe5\x87\xbd\xe6\x95\xb0\xe4\xb8\x8e\xe5\xb7\xb2\xe7\x9f\xa5\xe7\x9a\x84`y`\xe9\x9d\x9e\xe5\xb8\xb8\xe6\x8e\xa5\xe8\xbf\x91\xef\xbc\x8c\xe6\xb1\x82\xe5\x9d\x87\xe6\x96\xb9\xe5\xb7\xae\xe7\x9a\x84\xe6\xa2\xaf\xe5\xba\xa6\xe6\xb2\xbf\xe7\x9d\x80\xe6\xad\xa4\xe6\xa2\xaf\xe5\xba\xa6\xe6\x96\xb9\xe5\x90\x91\xe5\x8f\xaf\xe4\xbd\xbf\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0\xe6\x9c\x80\xe5\xb0\x8f\xe5\x8c\x96\xe3\x80\x82\xe5\x8f\xaf\xe5\xaf\xb9\xe7\x85\xa7\xe4\xb8\x8a\xe9\x9d\xa2\xe6\xb1\x82\xe6\xa2\xaf\xe5\xba\xa6\xe7\x9a\x84\xe8\xbf\x87\xe7\xa8\x8b\xe3\x80\x82\n![enter description here][17]\n- \xe6\xb1\x82\xe8\xaf\xaf\xe5\xb7\xae\xe6\x9b\xb4\xe8\xaf\xa6\xe7\xbb\x86\xe7\x9a\x84\xe6\x8e\xa8\xe5\xaf\xbc\xe8\xbf\x87\xe7\xa8\x8b\xef\xbc\x9a\n![enter description here][18]\n\n### 6\xe3\x80\x81\xe6\xa2\xaf\xe5\xba\xa6\xe6\xa3\x80\xe6\x9f\xa5\n- \xe6\xa3\x80\xe6\x9f\xa5\xe5\x88\xa9\xe7\x94\xa8`BP`\xe6\xb1\x82\xe7\x9a\x84\xe6\xa2\xaf\xe5\xba\xa6\xe6\x98\xaf\xe5\x90\xa6\xe6\xad\xa3\xe7\xa1\xae\n- \xe5\x88\xa9\xe7\x94\xa8\xe5\xaf\xbc\xe6\x95\xb0\xe7\x9a\x84\xe5\xae\x9a\xe4\xb9\x89\xe9\xaa\x8c\xe8\xaf\x81\xef\xbc\x9a\n![\\frac{{dJ(\\theta )}}{{d\\theta }} \\approx \\frac{{J(\\theta  + \\varepsilon ) - J(\\theta  - \\varepsilon )}}{{2\\varepsilon }}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%5Cfrac%7B%7BdJ%28%5Ctheta%20%29%7D%7D%7B%7Bd%5Ctheta%20%7D%7D%20%5Capprox%20%5Cfrac%7B%7BJ%28%5Ctheta%20%20%2B%20%5Cvarepsilon%20%29%20-%20J%28%5Ctheta%20%20-%20%5Cvarepsilon%20%29%7D%7D%7B%7B2%5Cvarepsilon%20%7D%7D)\n- \xe6\xb1\x82\xe5\x87\xba\xe6\x9d\xa5\xe7\x9a\x84\xe6\x95\xb0\xe5\x80\xbc\xe6\xa2\xaf\xe5\xba\xa6\xe5\xba\x94\xe8\xaf\xa5\xe4\xb8\x8eBP\xe6\xb1\x82\xe5\x87\xba\xe7\x9a\x84\xe6\xa2\xaf\xe5\xba\xa6\xe9\x9d\x9e\xe5\xb8\xb8\xe6\x8e\xa5\xe8\xbf\x91\n- \xe9\xaa\x8c\xe8\xaf\x81BP\xe6\xad\xa3\xe7\xa1\xae\xe5\x90\x8e\xe5\xb0\xb1\xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xe5\x86\x8d\xe6\x89\xa7\xe8\xa1\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe6\xa2\xaf\xe5\xba\xa6\xe7\x9a\x84\xe7\xae\x97\xe6\xb3\x95\xe4\xba\x86\n- \xe5\xae\x9e\xe7\x8e\xb0\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a\n```\n# \xe6\xa3\x80\xe9\xaa\x8c\xe6\xa2\xaf\xe5\xba\xa6\xe6\x98\xaf\xe5\x90\xa6\xe8\xae\xa1\xe7\xae\x97\xe6\xad\xa3\xe7\xa1\xae\n# \xe6\xa3\x80\xe9\xaa\x8c\xe6\xa2\xaf\xe5\xba\xa6\xe6\x98\xaf\xe5\x90\xa6\xe8\xae\xa1\xe7\xae\x97\xe6\xad\xa3\xe7\xa1\xae\ndef checkGradient(Lambda = 0):\n    \'\'\'\xe6\x9e\x84\xe9\x80\xa0\xe4\xb8\x80\xe4\xb8\xaa\xe5\xb0\x8f\xe5\x9e\x8b\xe7\x9a\x84\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe9\xaa\x8c\xe8\xaf\x81\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xba\xe6\x95\xb0\xe5\x80\xbc\xe6\xb3\x95\xe8\xae\xa1\xe7\xae\x97\xe6\xa2\xaf\xe5\xba\xa6\xe5\xbe\x88\xe6\xb5\xaa\xe8\xb4\xb9\xe6\x97\xb6\xe9\x97\xb4\xef\xbc\x8c\xe8\x80\x8c\xe4\xb8\x94\xe9\xaa\x8c\xe8\xaf\x81\xe6\xad\xa3\xe7\xa1\xae\xe5\x90\x8e\xe4\xb9\x8b\xe5\x90\x8e\xe5\xb0\xb1\xe4\xb8\x8d\xe5\x86\x8d\xe9\x9c\x80\xe8\xa6\x81\xe9\xaa\x8c\xe8\xaf\x81\xe4\xba\x86\'\'\'\n    input_layer_size = 3\n    hidden_layer_size = 5\n    num_labels = 3\n    m = 5\n    initial_Theta1 = debugInitializeWeights(input_layer_size,hidden_layer_size); \n    initial_Theta2 = debugInitializeWeights(hidden_layer_size,num_labels)\n    X = debugInitializeWeights(input_layer_size-1,m)\n    y = 1+np.transpose(np.mod(np.arange(1,m+1), num_labels))# \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96y\n    \n    y = y.reshape(-1,1)\n    nn_params = np.vstack((initial_Theta1.reshape(-1,1),initial_Theta2.reshape(-1,1)))  #\xe5\xb1\x95\xe5\xbc\x80theta \n    \'\'\'BP\xe6\xb1\x82\xe5\x87\xba\xe6\xa2\xaf\xe5\xba\xa6\'\'\'\n    grad = nnGradient(nn_params, input_layer_size, hidden_layer_size, \n                     num_labels, X, y, Lambda)  \n    \'\'\'\xe4\xbd\xbf\xe7\x94\xa8\xe6\x95\xb0\xe5\x80\xbc\xe6\xb3\x95\xe8\xae\xa1\xe7\xae\x97\xe6\xa2\xaf\xe5\xba\xa6\'\'\'\n    num_grad = np.zeros((nn_params.shape[0]))\n    step = np.zeros((nn_params.shape[0]))\n    e = 1e-4\n    for i in range(nn_params.shape[0]):\n        step[i] = e\n        loss1 = nnCostFunction(nn_params-step.reshape(-1,1), input_layer_size, hidden_layer_size, \n                              num_labels, X, y, \n                              Lambda)\n        loss2 = nnCostFunction(nn_params+step.reshape(-1,1), input_layer_size, hidden_layer_size, \n                              num_labels, X, y, \n                              Lambda)\n        num_grad[i] = (loss2-loss1)/(2*e)\n        step[i]=0\n    # \xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xa4\xe5\x88\x97\xe6\xaf\x94\xe8\xbe\x83\n    res = np.hstack((num_grad.reshape(-1,1),grad.reshape(-1,1)))\n    print res\n```\n\n### 7\xe3\x80\x81\xe6\x9d\x83\xe9\x87\x8d\xe7\x9a\x84\xe9\x9a\x8f\xe6\x9c\xba\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\n- \xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe4\xb8\x8d\xe8\x83\xbd\xe5\x83\x8f\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92\xe9\x82\xa3\xe6\xa0\xb7\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96`theta`\xe4\xb8\xba`0`,\xe5\x9b\xa0\xe4\xb8\xba\xe8\x8b\xa5\xe6\x98\xaf\xe6\xaf\x8f\xe6\x9d\xa1\xe8\xbe\xb9\xe7\x9a\x84\xe6\x9d\x83\xe9\x87\x8d\xe9\x83\xbd\xe4\xb8\xba0\xef\xbc\x8c\xe6\xaf\x8f\xe4\xb8\xaa\xe7\xa5\x9e\xe7\xbb\x8f\xe5\x85\x83\xe9\x83\xbd\xe6\x98\xaf\xe7\x9b\xb8\xe5\x90\x8c\xe7\x9a\x84\xe8\xbe\x93\xe5\x87\xba\xef\xbc\x8c\xe5\x9c\xa8\xe5\x8f\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\xe4\xb8\xad\xe4\xb9\x9f\xe4\xbc\x9a\xe5\xbe\x97\xe5\x88\xb0\xe5\x90\x8c\xe6\xa0\xb7\xe7\x9a\x84\xe6\xa2\xaf\xe5\xba\xa6\xef\xbc\x8c\xe6\x9c\x80\xe7\xbb\x88\xe5\x8f\xaa\xe4\xbc\x9a\xe9\xa2\x84\xe6\xb5\x8b\xe4\xb8\x80\xe7\xa7\x8d\xe7\xbb\x93\xe6\x9e\x9c\xe3\x80\x82\n- \xe6\x89\x80\xe4\xbb\xa5\xe5\xba\x94\xe8\xaf\xa5\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe4\xb8\xba\xe6\x8e\xa5\xe8\xbf\x910\xe7\x9a\x84\xe6\x95\xb0\n- \xe5\xae\x9e\xe7\x8e\xb0\xe4\xbb\xa3\xe7\xa0\x81\n```\n# \xe9\x9a\x8f\xe6\x9c\xba\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe6\x9d\x83\xe9\x87\x8dtheta\ndef randInitializeWeights(L_in,L_out):\n    W = np.zeros((L_out,1+L_in))    # \xe5\xaf\xb9\xe5\xba\x94theta\xe7\x9a\x84\xe6\x9d\x83\xe9\x87\x8d\n    epsilon_init = (6.0/(L_out+L_in))**0.5\n    W = np.random.rand(L_out,1+L_in)*2*epsilon_init-epsilon_init # np.random.rand(L_out,1+L_in)\xe4\xba\xa7\xe7\x94\x9fL_out*(1+L_in)\xe5\xa4\xa7\xe5\xb0\x8f\xe7\x9a\x84\xe9\x9a\x8f\xe6\x9c\xba\xe7\x9f\xa9\xe9\x98\xb5\n    return W\n```\n\n### 8\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\n- \xe6\xad\xa3\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\n- \xe5\xae\x9e\xe7\x8e\xb0\xe4\xbb\xa3\xe7\xa0\x81\n```\n# \xe9\xa2\x84\xe6\xb5\x8b\ndef predict(Theta1,Theta2,X):\n    m = X.shape[0]\n    num_labels = Theta2.shape[0]\n    #p = np.zeros((m,1))\n    \'\'\'\xe6\xad\xa3\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\xef\xbc\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\'\'\'\n    X = np.hstack((np.ones((m,1)),X))\n    h1 = sigmoid(np.dot(X,np.transpose(Theta1)))\n    h1 = np.hstack((np.ones((m,1)),h1))\n    h2 = sigmoid(np.dot(h1,np.transpose(Theta2)))\n    \n    \'\'\'\n    \xe8\xbf\x94\xe5\x9b\x9eh\xe4\xb8\xad\xe6\xaf\x8f\xe4\xb8\x80\xe8\xa1\x8c\xe6\x9c\x80\xe5\xa4\xa7\xe5\x80\xbc\xe6\x89\x80\xe5\x9c\xa8\xe7\x9a\x84\xe5\x88\x97\xe5\x8f\xb7\n    - np.max(h, axis=1)\xe8\xbf\x94\xe5\x9b\x9eh\xe4\xb8\xad\xe6\xaf\x8f\xe4\xb8\x80\xe8\xa1\x8c\xe7\x9a\x84\xe6\x9c\x80\xe5\xa4\xa7\xe5\x80\xbc\xef\xbc\x88\xe6\x98\xaf\xe6\x9f\x90\xe4\xb8\xaa\xe6\x95\xb0\xe5\xad\x97\xe7\x9a\x84\xe6\x9c\x80\xe5\xa4\xa7\xe6\xa6\x82\xe7\x8e\x87\xef\xbc\x89\n    - \xe6\x9c\x80\xe5\x90\x8ewhere\xe6\x89\xbe\xe5\x88\xb0\xe7\x9a\x84\xe6\x9c\x80\xe5\xa4\xa7\xe6\xa6\x82\xe7\x8e\x87\xe6\x89\x80\xe5\x9c\xa8\xe7\x9a\x84\xe5\x88\x97\xe5\x8f\xb7\xef\xbc\x88\xe5\x88\x97\xe5\x8f\xb7\xe5\x8d\xb3\xe6\x98\xaf\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\x97\xef\xbc\x89\n    \'\'\'\n    #np.savetxt(""h2.csv"",h2,delimiter=\',\')\n    p = np.array(np.where(h2[0,:] == np.max(h2, axis=1)[0]))  \n    for i in np.arange(1, m):\n        t = np.array(np.where(h2[i,:] == np.max(h2, axis=1)[i]))\n        p = np.vstack((p,t))\n    return p \n```\n\n### 9\xe3\x80\x81\xe8\xbe\x93\xe5\x87\xba\xe7\xbb\x93\xe6\x9e\x9c\n- \xe6\xa2\xaf\xe5\xba\xa6\xe6\xa3\x80\xe6\x9f\xa5\xef\xbc\x9a     \n![enter description here][19]\n- \xe9\x9a\x8f\xe6\x9c\xba\xe6\x98\xbe\xe7\xa4\xba100\xe4\xb8\xaa\xe6\x89\x8b\xe5\x86\x99\xe6\x95\xb0\xe5\xad\x97     \n![enter description here][20]\n- \xe6\x98\xbe\xe7\xa4\xbatheta1\xe6\x9d\x83\xe9\x87\x8d     \n![enter description here][21]\n- \xe8\xae\xad\xe7\xbb\x83\xe9\x9b\x86\xe9\xa2\x84\xe6\xb5\x8b\xe5\x87\x86\xe7\xa1\xae\xe5\xba\xa6     \n![enter description here][22]\n- \xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe5\x90\x8e\xe8\xae\xad\xe7\xbb\x83\xe9\x9b\x86\xe9\xa2\x84\xe6\xb5\x8b\xe5\x87\x86\xe7\xa1\xae\xe5\xba\xa6     \n![enter description here][23]\n\n--------------------\n\n## \xe5\x9b\x9b\xe3\x80\x81SVM\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba\n\n### 1\xe3\x80\x81\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0\n- \xe5\x9c\xa8\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92\xe4\xb8\xad\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe7\x9a\x84\xe4\xbb\xa3\xe4\xbb\xb7\xe4\xb8\xba\xef\xbc\x9a   \n![\\cos t({h_\\theta }(x),y) = \\left\\{ {\\begin{array}{c}    { - \\log ({h_\\theta }(x))} \\\\    { - \\log (1 - {h_\\theta }(x))}  \\end{array} \\begin{array}{c}    {y = 1} \\\\    {y = 0}  \\end{array} } \\right.](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%5Ccos%20t%28%7Bh_%5Ctheta%20%7D%28x%29%2Cy%29%20%3D%20%5Cleft%5C%7B%20%7B%5Cbegin%7Barray%7D%7Bc%7D%20%20%20%20%7B%20-%20%5Clog%20%28%7Bh_%5Ctheta%20%7D%28x%29%29%7D%20%5C%5C%20%20%20%20%7B%20-%20%5Clog%20%281%20-%20%7Bh_%5Ctheta%20%7D%28x%29%29%7D%20%20%5Cend%7Barray%7D%20%5Cbegin%7Barray%7D%7Bc%7D%20%20%20%20%7By%20%3D%201%7D%20%5C%5C%20%20%20%20%7By%20%3D%200%7D%20%20%5Cend%7Barray%7D%20%7D%20%5Cright.)\xef\xbc\x8c    \n\xe5\x85\xb6\xe4\xb8\xad\xef\xbc\x9a![{h_\\theta }({\\text{z}}) = \\frac{1}{{1 + {e^{ - z}}}}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7Bh_%5Ctheta%20%7D%28%7B%5Ctext%7Bz%7D%7D%29%20%3D%20%5Cfrac%7B1%7D%7B%7B1%20%2B%20%7Be%5E%7B%20-%20z%7D%7D%7D%7D)\xef\xbc\x8c![z = {\\theta ^T}x](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=z%20%3D%20%7B%5Ctheta%20%5ET%7Dx)\n- \xe5\xa6\x82\xe5\x9b\xbe\xe6\x89\x80\xe7\xa4\xba\xef\xbc\x8c\xe5\xa6\x82\xe6\x9e\x9c`y=1`\xef\xbc\x8c`cost`\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0\xe5\xa6\x82\xe5\x9b\xbe\xe6\x89\x80\xe7\xa4\xba    \n![enter description here][24]    \n\xe6\x88\x91\xe4\xbb\xac\xe6\x83\xb3\xe8\xae\xa9![{\\theta ^T}x &gt;  &gt; 0](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7B%5Ctheta%20%5ET%7Dx%20%3E%20%20%3E%200)\xef\xbc\x8c\xe5\x8d\xb3`z>>0`\xef\xbc\x8c\xe8\xbf\x99\xe6\xa0\xb7\xe7\x9a\x84\xe8\xaf\x9d`cost`\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0\xe6\x89\x8d\xe4\xbc\x9a\xe8\xb6\x8b\xe4\xba\x8e\xe6\x9c\x80\xe5\xb0\x8f\xef\xbc\x88\xe8\xbf\x99\xe6\x98\xaf\xe6\x88\x91\xe4\xbb\xac\xe6\x83\xb3\xe8\xa6\x81\xe7\x9a\x84\xef\xbc\x89\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xe7\x94\xa8\xe9\x80\x94\xe4\xb8\xad**\xe7\xba\xa2\xe8\x89\xb2**\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0![\\cos {t_1}(z)](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%5Ccos%20%7Bt_1%7D%28z%29)\xe4\xbb\xa3\xe6\x9b\xbf\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92\xe4\xb8\xad\xe7\x9a\x84cost\n- \xe5\xbd\x93`y=0`\xe6\x97\xb6\xe5\x90\x8c\xe6\xa0\xb7\xef\xbc\x8c\xe7\x94\xa8![\\cos {t_0}(z)](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%5Ccos%20%7Bt_0%7D%28z%29)\xe4\xbb\xa3\xe6\x9b\xbf\n![enter description here][25]\n- \xe6\x9c\x80\xe7\xbb\x88\xe5\xbe\x97\xe5\x88\xb0\xe7\x9a\x84\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0\xe4\xb8\xba\xef\xbc\x9a    \n![J(\\theta ) = C\\sum\\limits_{i = 1}^m {[{y^{(i)}}\\cos {t_1}({\\theta ^T}{x^{(i)}}) + (1 - {y^{(i)}})\\cos {t_0}({\\theta ^T}{x^{(i)}})} ] + \\frac{1}{2}\\sum\\limits_{j = 1}^{\\text{n}} {\\theta _j^2} ](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=J%28%5Ctheta%20%29%20%3D%20C%5Csum%5Climits_%7Bi%20%3D%201%7D%5Em%20%7B%5B%7By%5E%7B%28i%29%7D%7D%5Ccos%20%7Bt_1%7D%28%7B%5Ctheta%20%5ET%7D%7Bx%5E%7B%28i%29%7D%7D%29%20%2B%20%281%20-%20%7By%5E%7B%28i%29%7D%7D%29%5Ccos%20%7Bt_0%7D%28%7B%5Ctheta%20%5ET%7D%7Bx%5E%7B%28i%29%7D%7D%29%7D%20%5D%20%2B%20%5Cfrac%7B1%7D%7B2%7D%5Csum%5Climits_%7Bj%20%3D%201%7D%5E%7B%5Ctext%7Bn%7D%7D%20%7B%5Ctheta%20_j%5E2%7D%20)   \n\xe6\x9c\x80\xe5\x90\x8e\xe6\x88\x91\xe4\xbb\xac\xe6\x83\xb3\xe8\xa6\x81![\\mathop {\\min }\\limits_\\theta  J(\\theta )](http://latex.codecogs.com/gif.latex?%5Clarge%20%5Cmathop%20%7B%5Cmin%20%7D%5Climits_%5Ctheta%20J%28%5Ctheta%20%29)\n- \xe4\xb9\x8b\xe5\x89\x8d\xe6\x88\x91\xe4\xbb\xac\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92\xe4\xb8\xad\xe7\x9a\x84\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0\xe4\xb8\xba\xef\xbc\x9a   \n![J(\\theta ) =  - \\frac{1}{m}\\sum\\limits_{i = 1}^m {[{y^{(i)}}\\log ({h_\\theta }({x^{(i)}}) + (1 - } {y^{(i)}})\\log (1 - {h_\\theta }({x^{(i)}})] + \\frac{\\lambda }{{2m}}\\sum\\limits_{j = 1}^n {\\theta _j^2} ](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=J%28%5Ctheta%20%29%20%3D%20%20-%20%5Cfrac%7B1%7D%7Bm%7D%5Csum%5Climits_%7Bi%20%3D%201%7D%5Em%20%7B%5B%7By%5E%7B%28i%29%7D%7D%5Clog%20%28%7Bh_%5Ctheta%20%7D%28%7Bx%5E%7B%28i%29%7D%7D%29%20%2B%20%281%20-%20%7D%20%7By%5E%7B%28i%29%7D%7D%29%5Clog%20%281%20-%20%7Bh_%5Ctheta%20%7D%28%7Bx%5E%7B%28i%29%7D%7D%29%5D%20%2B%20%5Cfrac%7B%5Clambda%20%7D%7B%7B2m%7D%7D%5Csum%5Climits_%7Bj%20%3D%201%7D%5En%20%7B%5Ctheta%20_j%5E2%7D%20)   \n\xe5\x8f\xaf\xe4\xbb\xa5\xe8\xae\xa4\xe4\xb8\xba\xe8\xbf\x99\xe9\x87\x8c\xe7\x9a\x84![C = \\frac{m}{\\lambda }](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=C%20%3D%20%5Cfrac%7Bm%7D%7B%5Clambda%20%7D)\xef\xbc\x8c\xe5\x8f\xaa\xe6\x98\xaf\xe8\xa1\xa8\xe8\xbe\xbe\xe5\xbd\xa2\xe5\xbc\x8f\xe9\x97\xae\xe9\xa2\x98\xef\xbc\x8c\xe8\xbf\x99\xe9\x87\x8c`C`\xe7\x9a\x84\xe5\x80\xbc\xe8\xb6\x8a\xe5\xa4\xa7\xef\xbc\x8cSVM\xe7\x9a\x84\xe5\x86\xb3\xe7\xad\x96\xe8\xbe\xb9\xe7\x95\x8c\xe7\x9a\x84`margin`\xe4\xb9\x9f\xe8\xb6\x8a\xe5\xa4\xa7\xef\xbc\x8c\xe4\xb8\x8b\xe9\x9d\xa2\xe4\xbc\x9a\xe8\xaf\xb4\xe6\x98\x8e\n\n### 2\xe3\x80\x81Large Margin\n- \xe5\xa6\x82\xe4\xb8\x8b\xe5\x9b\xbe\xe6\x89\x80\xe7\xa4\xba,SVM\xe5\x88\x86\xe7\xb1\xbb\xe4\xbc\x9a\xe4\xbd\xbf\xe7\x94\xa8\xe6\x9c\x80\xe5\xa4\xa7\xe7\x9a\x84`margin`\xe5\xb0\x86\xe5\x85\xb6\xe5\x88\x86\xe5\xbc\x80    \n![enter description here][26]\n- \xe5\x85\x88\xe8\xaf\xb4\xe4\xb8\x80\xe4\xb8\x8b\xe5\x90\x91\xe9\x87\x8f\xe5\x86\x85\xe7\xa7\xaf\n - ![u = \\left[ {\\begin{array}{c}    {{u_1}} \\\\    {{u_2}}  \\end{array} } \\right]](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=u%20%3D%20%5Cleft%5B%20%7B%5Cbegin%7Barray%7D%7Bc%7D%20%20%20%20%7B%7Bu_1%7D%7D%20%5C%5C%20%20%20%20%7B%7Bu_2%7D%7D%20%20%5Cend%7Barray%7D%20%7D%20%5Cright%5D)\xef\xbc\x8c![v = \\left[ {\\begin{array}{c}    {{v_1}} \\\\    {{v_2}}  \\end{array} } \\right]](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=v%20%3D%20%5Cleft%5B%20%7B%5Cbegin%7Barray%7D%7Bc%7D%20%20%20%20%7B%7Bv_1%7D%7D%20%5C%5C%20%20%20%20%7B%7Bv_2%7D%7D%20%20%5Cend%7Barray%7D%20%7D%20%5Cright%5D)    \n - ![||u||](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7C%7Cu%7C%7C)\xe8\xa1\xa8\xe7\xa4\xba`u`\xe7\x9a\x84**\xe6\xac\xa7\xe5\x87\xa0\xe9\x87\x8c\xe5\xbe\x97\xe8\x8c\x83\xe6\x95\xb0**\xef\xbc\x88\xe6\xac\xa7\xe5\xbc\x8f\xe8\x8c\x83\xe6\x95\xb0\xef\xbc\x89\xef\xbc\x8c![||u||{\\text{ = }}\\sqrt {{\\text{u}}_1^2 + u_2^2} ](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7C%7Cu%7C%7C%7B%5Ctext%7B%20%3D%20%7D%7D%5Csqrt%20%7B%7B%5Ctext%7Bu%7D%7D_1%5E2%20%2B%20u_2%5E2%7D%20)\n - `\xe5\x90\x91\xe9\x87\x8fV`\xe5\x9c\xa8`\xe5\x90\x91\xe9\x87\x8fu`\xe4\xb8\x8a\xe7\x9a\x84\xe6\x8a\x95\xe5\xbd\xb1\xe7\x9a\x84\xe9\x95\xbf\xe5\xba\xa6\xe8\xae\xb0\xe4\xb8\xba`p`\xef\xbc\x8c\xe5\x88\x99\xef\xbc\x9a\xe5\x90\x91\xe9\x87\x8f\xe5\x86\x85\xe7\xa7\xaf\xef\xbc\x9a    \n ![{{\\text{u}}^T}v = p||u|| = {u_1}{v_1} + {u_2}{v_2}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7B%7B%5Ctext%7Bu%7D%7D%5ET%7Dv%20%3D%20p%7C%7Cu%7C%7C%20%3D%20%7Bu_1%7D%7Bv_1%7D%20%2B%20%7Bu_2%7D%7Bv_2%7D)      \n ![enter description here][27]  \n\xe6\xa0\xb9\xe6\x8d\xae\xe5\x90\x91\xe9\x87\x8f\xe5\xa4\xb9\xe8\xa7\x92\xe5\x85\xac\xe5\xbc\x8f\xe6\x8e\xa8\xe5\xaf\xbc\xe4\xb8\x80\xe4\xb8\x8b\xe5\x8d\xb3\xe5\x8f\xaf\xef\xbc\x8c![\\cos \\theta  = \\frac{{\\overrightarrow {\\text{u}} \\overrightarrow v }}{{|\\overrightarrow {\\text{u}} ||\\overrightarrow v |}}](http://latex.codecogs.com/gif.latex?%5Clarge%20%5Ccos%20%5Ctheta%20%3D%20%5Cfrac%7B%7B%5Coverrightarrow%20%7B%5Ctext%7Bu%7D%7D%20%5Coverrightarrow%20v%20%7D%7D%7B%7B%7C%5Coverrightarrow%20%7B%5Ctext%7Bu%7D%7D%20%7C%7C%5Coverrightarrow%20v%20%7C%7D%7D)\n\n- \xe5\x89\x8d\xe9\x9d\xa2\xe8\xaf\xb4\xe8\xbf\x87\xef\xbc\x8c\xe5\xbd\x93`C`\xe8\xb6\x8a\xe5\xa4\xa7\xe6\x97\xb6\xef\xbc\x8c`margin`\xe4\xb9\x9f\xe5\xb0\xb1\xe8\xb6\x8a\xe5\xa4\xa7\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe7\x9a\x84\xe7\x9b\xae\xe7\x9a\x84\xe6\x98\xaf\xe6\x9c\x80\xe5\xb0\x8f\xe5\x8c\x96\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0`J(\xce\xb8)`,\xe5\xbd\x93`margin`\xe6\x9c\x80\xe5\xa4\xa7\xe6\x97\xb6\xef\xbc\x8c`C`\xe7\x9a\x84\xe4\xb9\x98\xe7\xa7\xaf\xe9\xa1\xb9![\\sum\\limits_{i = 1}^m {[{y^{(i)}}\\cos {t_1}({\\theta ^T}{x^{(i)}}) + (1 - {y^{(i)}})\\cos {t_0}({\\theta ^T}{x^{(i)}})} ]](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%5Csum%5Climits_%7Bi%20%3D%201%7D%5Em%20%7B%5B%7By%5E%7B%28i%29%7D%7D%5Ccos%20%7Bt_1%7D%28%7B%5Ctheta%20%5ET%7D%7Bx%5E%7B%28i%29%7D%7D%29%20%2B%20%281%20-%20%7By%5E%7B%28i%29%7D%7D%29%5Ccos%20%7Bt_0%7D%28%7B%5Ctheta%20%5ET%7D%7Bx%5E%7B%28i%29%7D%7D%29%7D%20%5D)\xe8\xa6\x81\xe5\xbe\x88\xe5\xb0\x8f\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xe8\xbf\x91\xe4\xbc\xbc\xe4\xb8\xba\xef\xbc\x9a   \n![J(\\theta ) = C0 + \\frac{1}{2}\\sum\\limits_{j = 1}^{\\text{n}} {\\theta _j^2}  = \\frac{1}{2}\\sum\\limits_{j = 1}^{\\text{n}} {\\theta _j^2}  = \\frac{1}{2}(\\theta _1^2 + \\theta _2^2) = \\frac{1}{2}{\\sqrt {\\theta _1^2 + \\theta _2^2} ^2}](http://latex.codecogs.com/gif.latex?%5Clarge%20J%28%5Ctheta%20%29%20%3D%20C0%20&plus;%20%5Cfrac%7B1%7D%7B2%7D%5Csum%5Climits_%7Bj%20%3D%201%7D%5E%7B%5Ctext%7Bn%7D%7D%20%7B%5Ctheta%20_j%5E2%7D%20%3D%20%5Cfrac%7B1%7D%7B2%7D%5Csum%5Climits_%7Bj%20%3D%201%7D%5E%7B%5Ctext%7Bn%7D%7D%20%7B%5Ctheta%20_j%5E2%7D%20%3D%20%5Cfrac%7B1%7D%7B2%7D%28%5Ctheta%20_1%5E2%20&plus;%20%5Ctheta%20_2%5E2%29%20%3D%20%5Cfrac%7B1%7D%7B2%7D%7B%5Csqrt%20%7B%5Ctheta%20_1%5E2%20&plus;%20%5Ctheta%20_2%5E2%7D%20%5E2%7D)\xef\xbc\x8c      \n\xe6\x88\x91\xe4\xbb\xac\xe6\x9c\x80\xe5\x90\x8e\xe7\x9a\x84\xe7\x9b\xae\xe7\x9a\x84\xe5\xb0\xb1\xe6\x98\xaf\xe6\xb1\x82\xe4\xbd\xbf\xe4\xbb\xa3\xe4\xbb\xb7\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84`\xce\xb8`\n- \xe7\x94\xb1   \n![\\left\\{ {\\begin{array}{c}    {{\\theta ^T}{x^{(i)}} \\geqslant 1} \\\\    {{\\theta ^T}{x^{(i)}} \\leqslant  - 1}  \\end{array} } \\right.\\begin{array}{c}    {({y^{(i)}} = 1)} \\\\    {({y^{(i)}} = 0)}  \\end{array} ](http://latex.codecogs.com/gif.latex?%5Clarge%20%5Cleft%5C%7B%20%7B%5Cbegin%7Barray%7D%7Bc%7D%20%7B%7B%5Ctheta%20%5ET%7D%7Bx%5E%7B%28i%29%7D%7D%20%5Cgeqslant%201%7D%20%5C%5C%20%7B%7B%5Ctheta%20%5ET%7D%7Bx%5E%7B%28i%29%7D%7D%20%5Cleqslant%20-%201%7D%20%5Cend%7Barray%7D%20%7D%20%5Cright.%5Cbegin%7Barray%7D%7Bc%7D%20%7B%28%7By%5E%7B%28i%29%7D%7D%20%3D%201%29%7D%20%5C%5C%20%7B%28%7By%5E%7B%28i%29%7D%7D%20%3D%200%29%7D%20%5Cend%7Barray%7D)\xe5\x8f\xaf\xe4\xbb\xa5\xe5\xbe\x97\xe5\x88\xb0\xef\xbc\x9a    \n![\\left\\{ {\\begin{array}{c}    {{p^{(i)}}||\\theta || \\geqslant 1} \\\\    {{p^{(i)}}||\\theta || \\leqslant  - 1}  \\end{array} } \\right.\\begin{array}{c}    {({y^{(i)}} = 1)} \\\\    {({y^{(i)}} = 0)}  \\end{array} ](http://latex.codecogs.com/gif.latex?%5Clarge%20%5Cleft%5C%7B%20%7B%5Cbegin%7Barray%7D%7Bc%7D%20%7B%7Bp%5E%7B%28i%29%7D%7D%7C%7C%5Ctheta%20%7C%7C%20%5Cgeqslant%201%7D%20%5C%5C%20%7B%7Bp%5E%7B%28i%29%7D%7D%7C%7C%5Ctheta%20%7C%7C%20%5Cleqslant%20-%201%7D%20%5Cend%7Barray%7D%20%7D%20%5Cright.%5Cbegin%7Barray%7D%7Bc%7D%20%7B%28%7By%5E%7B%28i%29%7D%7D%20%3D%201%29%7D%20%5C%5C%20%7B%28%7By%5E%7B%28i%29%7D%7D%20%3D%200%29%7D%20%5Cend%7Barray%7D)\xef\xbc\x8c`p`\xe5\x8d\xb3\xe4\xb8\xba`x`\xe5\x9c\xa8`\xce\xb8`\xe4\xb8\x8a\xe7\x9a\x84\xe6\x8a\x95\xe5\xbd\xb1\n- \xe5\xa6\x82\xe4\xb8\x8b\xe5\x9b\xbe\xe6\x89\x80\xe7\xa4\xba\xef\xbc\x8c\xe5\x81\x87\xe8\xae\xbe\xe5\x86\xb3\xe7\xad\x96\xe8\xbe\xb9\xe7\x95\x8c\xe5\xa6\x82\xe5\x9b\xbe\xef\xbc\x8c\xe6\x89\xbe\xe5\x85\xb6\xe4\xb8\xad\xe7\x9a\x84\xe4\xb8\x80\xe4\xb8\xaa\xe7\x82\xb9\xef\xbc\x8c\xe5\x88\xb0`\xce\xb8`\xe4\xb8\x8a\xe7\x9a\x84\xe6\x8a\x95\xe5\xbd\xb1\xe4\xb8\xba`p`,\xe5\x88\x99![p||\\theta || \\geqslant 1](http://latex.codecogs.com/gif.latex?%5Clarge%20p%7C%7C%5Ctheta%20%7C%7C%20%5Cgeqslant%201)\xe6\x88\x96\xe8\x80\x85![p||\\theta || \\leqslant  - 1](http://latex.codecogs.com/gif.latex?%5Clarge%20p%7C%7C%5Ctheta%20%7C%7C%20%5Cleqslant%20-%201)\xef\xbc\x8c\xe8\x8b\xa5\xe6\x98\xaf`p`\xe5\xbe\x88\xe5\xb0\x8f\xef\xbc\x8c\xe5\x88\x99\xe9\x9c\x80\xe8\xa6\x81![||\\theta ||](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7C%7C%5Ctheta%20%7C%7C)\xe5\xbe\x88\xe5\xa4\xa7\xef\xbc\x8c\xe8\xbf\x99\xe4\xb8\x8e\xe6\x88\x91\xe4\xbb\xac\xe8\xa6\x81\xe6\xb1\x82\xe7\x9a\x84`\xce\xb8`\xe4\xbd\xbf![||\\theta || = \\frac{1}{2}\\sqrt {\\theta _1^2 + \\theta _2^2} ](http://latex.codecogs.com/gif.latex?%5Clarge%20%7C%7C%5Ctheta%20%7C%7C%20%3D%20%5Cfrac%7B1%7D%7B2%7D%5Csqrt%20%7B%5Ctheta%20_1%5E2%20&plus;%20%5Ctheta%20_2%5E2%7D)\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9b\xb8\xe8\xbf\x9d\xe8\x83\x8c\xef\xbc\x8c**\xe6\x89\x80\xe4\xbb\xa5**\xe6\x9c\x80\xe5\x90\x8e\xe6\xb1\x82\xe7\x9a\x84\xe6\x98\xaf`large margin`   \n![enter description here][28]\n\n### 3\xe3\x80\x81SVM Kernel\xef\xbc\x88\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x89\n- \xe5\xaf\xb9\xe4\xba\x8e\xe7\xba\xbf\xe6\x80\xa7\xe5\x8f\xaf\xe5\x88\x86\xe7\x9a\x84\xe9\x97\xae\xe9\xa2\x98\xef\xbc\x8c\xe4\xbd\xbf\xe7\x94\xa8**\xe7\xba\xbf\xe6\x80\xa7\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0**\xe5\x8d\xb3\xe5\x8f\xaf\n- \xe5\xaf\xb9\xe4\xba\x8e\xe7\xba\xbf\xe6\x80\xa7\xe4\xb8\x8d\xe5\x8f\xaf\xe5\x88\x86\xe7\x9a\x84\xe9\x97\xae\xe9\xa2\x98\xef\xbc\x8c\xe5\x9c\xa8\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92\xe4\xb8\xad\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe6\x98\xaf\xe5\xb0\x86`feature`\xe6\x98\xa0\xe5\xb0\x84\xe4\xb8\xba\xe4\xbd\xbf\xe7\x94\xa8\xe5\xa4\x9a\xe9\xa1\xb9\xe5\xbc\x8f\xe7\x9a\x84\xe5\xbd\xa2\xe5\xbc\x8f![1 + {x_1} + {x_2} + x_1^2 + {x_1}{x_2} + x_2^2](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=1%20%2B%20%7Bx_1%7D%20%2B%20%7Bx_2%7D%20%2B%20x_1%5E2%20%2B%20%7Bx_1%7D%7Bx_2%7D%20%2B%20x_2%5E2)\xef\xbc\x8c`SVM`\xe4\xb8\xad\xe4\xb9\x9f\xe6\x9c\x89**\xe5\xa4\x9a\xe9\xa1\xb9\xe5\xbc\x8f\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0**\xef\xbc\x8c\xe4\xbd\x86\xe6\x98\xaf\xe6\x9b\xb4\xe5\xb8\xb8\xe7\x94\xa8\xe7\x9a\x84\xe6\x98\xaf**\xe9\xab\x98\xe6\x96\xaf\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0**\xef\xbc\x8c\xe4\xb9\x9f\xe7\xa7\xb0\xe4\xb8\xba**RBF\xe6\xa0\xb8**\n- \xe9\xab\x98\xe6\x96\xaf\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xe4\xb8\xba\xef\xbc\x9a![f(x) = {e^{ - \\frac{{||x - u|{|^2}}}{{2{\\sigma ^2}}}}}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=f%28x%29%20%3D%20%7Be%5E%7B%20-%20%5Cfrac%7B%7B%7C%7Cx%20-%20u%7C%7B%7C%5E2%7D%7D%7D%7B%7B2%7B%5Csigma%20%5E2%7D%7D%7D%7D%7D)     \n\xe5\x81\x87\xe8\xae\xbe\xe5\xa6\x82\xe5\x9b\xbe\xe5\x87\xa0\xe4\xb8\xaa\xe7\x82\xb9\xef\xbc\x8c\n![enter description here][29]\n\xe4\xbb\xa4\xef\xbc\x9a   \n![{f_1} = similarity(x,{l^{(1)}}) = {e^{ - \\frac{{||x - {l^{(1)}}|{|^2}}}{{2{\\sigma ^2}}}}}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7Bf_1%7D%20%3D%20similarity%28x%2C%7Bl%5E%7B%281%29%7D%7D%29%20%3D%20%7Be%5E%7B%20-%20%5Cfrac%7B%7B%7C%7Cx%20-%20%7Bl%5E%7B%281%29%7D%7D%7C%7B%7C%5E2%7D%7D%7D%7B%7B2%7B%5Csigma%20%5E2%7D%7D%7D%7D%7D)   \n![{f_2} = similarity(x,{l^{(2)}}) = {e^{ - \\frac{{||x - {l^{(2)}}|{|^2}}}{{2{\\sigma ^2}}}}}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7Bf_2%7D%20%3D%20similarity%28x%2C%7Bl%5E%7B%282%29%7D%7D%29%20%3D%20%7Be%5E%7B%20-%20%5Cfrac%7B%7B%7C%7Cx%20-%20%7Bl%5E%7B%282%29%7D%7D%7C%7B%7C%5E2%7D%7D%7D%7B%7B2%7B%5Csigma%20%5E2%7D%7D%7D%7D%7D)\n.\n.\n.\n- \xe5\x8f\xaf\xe4\xbb\xa5\xe7\x9c\x8b\xe5\x87\xba\xef\xbc\x8c\xe8\x8b\xa5\xe6\x98\xaf`x`\xe4\xb8\x8e![{l^{(1)}}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7Bl%5E%7B%281%29%7D%7D)\xe8\xb7\x9d\xe7\xa6\xbb\xe8\xbe\x83\xe8\xbf\x91\xef\xbc\x8c==\xe3\x80\x8b![{f_1} \\approx {e^0} = 1](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7Bf_1%7D%20%5Capprox%20%7Be%5E0%7D%20%3D%201)\xef\xbc\x8c\xef\xbc\x88\xe5\x8d\xb3\xe7\x9b\xb8\xe4\xbc\xbc\xe5\xba\xa6\xe8\xbe\x83\xe5\xa4\xa7\xef\xbc\x89   \n\xe8\x8b\xa5\xe6\x98\xaf`x`\xe4\xb8\x8e![{l^{(1)}}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7Bl%5E%7B%281%29%7D%7D)\xe8\xb7\x9d\xe7\xa6\xbb\xe8\xbe\x83\xe8\xbf\x9c\xef\xbc\x8c==\xe3\x80\x8b![{f_2} \\approx {e^{ - \\infty }} = 0](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7Bf_2%7D%20%5Capprox%20%7Be%5E%7B%20-%20%5Cinfty%20%7D%7D%20%3D%200)\xef\xbc\x8c\xef\xbc\x88\xe5\x8d\xb3\xe7\x9b\xb8\xe4\xbc\xbc\xe5\xba\xa6\xe8\xbe\x83\xe4\xbd\x8e\xef\xbc\x89\n- \xe9\xab\x98\xe6\x96\xaf\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84`\xcf\x83`\xe8\xb6\x8a\xe5\xb0\x8f\xef\xbc\x8c`f`\xe4\xb8\x8b\xe9\x99\x8d\xe7\x9a\x84\xe8\xb6\x8a\xe5\xbf\xab      \n![enter description here][30]\n![enter description here][31]\n\n- \xe5\xa6\x82\xe4\xbd\x95\xe9\x80\x89\xe6\x8b\xa9\xe5\x88\x9d\xe5\xa7\x8b\xe7\x9a\x84![{l^{(1)}}{l^{(2)}}{l^{(3)}}...](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7Bl%5E%7B%281%29%7D%7D%7Bl%5E%7B%282%29%7D%7D%7Bl%5E%7B%283%29%7D%7D...)\n - \xe8\xae\xad\xe7\xbb\x83\xe9\x9b\x86\xef\xbc\x9a![(({x^{(1)}},{y^{(1)}}),({x^{(2)}},{y^{(2)}}),...({x^{(m)}},{y^{(m)}}))](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%28%28%7Bx%5E%7B%281%29%7D%7D%2C%7By%5E%7B%281%29%7D%7D%29%2C%28%7Bx%5E%7B%282%29%7D%7D%2C%7By%5E%7B%282%29%7D%7D%29%2C...%28%7Bx%5E%7B%28m%29%7D%7D%2C%7By%5E%7B%28m%29%7D%7D%29%29)\n - \xe9\x80\x89\xe6\x8b\xa9\xef\xbc\x9a![{l^{(1)}} = {x^{(1)}},{l^{(2)}} = {x^{(2)}}...{l^{(m)}} = {x^{(m)}}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7Bl%5E%7B%281%29%7D%7D%20%3D%20%7Bx%5E%7B%281%29%7D%7D%2C%7Bl%5E%7B%282%29%7D%7D%20%3D%20%7Bx%5E%7B%282%29%7D%7D...%7Bl%5E%7B%28m%29%7D%7D%20%3D%20%7Bx%5E%7B%28m%29%7D%7D)\n - \xe5\xaf\xb9\xe4\xba\x8e\xe7\xbb\x99\xe5\x87\xba\xe7\x9a\x84`x`\xef\xbc\x8c\xe8\xae\xa1\xe7\xae\x97`f`,\xe4\xbb\xa4\xef\xbc\x9a![f_0^{(i)} = 1](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=f_0%5E%7B%28i%29%7D%20%3D%201)\xe6\x89\x80\xe4\xbb\xa5\xef\xbc\x9a![{f^{(i)}} \\in {R^{m + 1}}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7Bf%5E%7B%28i%29%7D%7D%20%5Cin%20%7BR%5E%7Bm%20%2B%201%7D%7D)\n - \xe6\x9c\x80\xe5\xb0\x8f\xe5\x8c\x96`J`\xe6\xb1\x82\xe5\x87\xba`\xce\xb8`\xef\xbc\x8c          \n ![J(\\theta ) = C\\sum\\limits_{i = 1}^m {[{y^{(i)}}\\cos {t_1}({\\theta ^T}{f^{(i)}}) + (1 - {y^{(i)}})\\cos {t_0}({\\theta ^T}{f^{(i)}})} ] + \\frac{1}{2}\\sum\\limits_{j = 1}^{\\text{n}} {\\theta _j^2} ](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=J%28%5Ctheta%20%29%20%3D%20C%5Csum%5Climits_%7Bi%20%3D%201%7D%5Em%20%7B%5B%7By%5E%7B%28i%29%7D%7D%5Ccos%20%7Bt_1%7D%28%7B%5Ctheta%20%5ET%7D%7Bf%5E%7B%28i%29%7D%7D%29%20%2B%20%281%20-%20%7By%5E%7B%28i%29%7D%7D%29%5Ccos%20%7Bt_0%7D%28%7B%5Ctheta%20%5ET%7D%7Bf%5E%7B%28i%29%7D%7D%29%7D%20%5D%20%2B%20%5Cfrac%7B1%7D%7B2%7D%5Csum%5Climits_%7Bj%20%3D%201%7D%5E%7B%5Ctext%7Bn%7D%7D%20%7B%5Ctheta%20_j%5E2%7D%20)\n - \xe5\xa6\x82\xe6\x9e\x9c![{\\theta ^T}f \\geqslant 0](http://latex.codecogs.com/gif.latex?%5Clarge%20%7B%5Ctheta%20%5ET%7Df%20%5Cgeqslant%200)\xef\xbc\x8c==\xe3\x80\x8b\xe9\xa2\x84\xe6\xb5\x8b`y=1`\n\n### 4\xe3\x80\x81\xe4\xbd\xbf\xe7\x94\xa8`scikit-learn`\xe4\xb8\xad\xe7\x9a\x84`SVM`\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xbb\xa3\xe7\xa0\x81\n- [\xe5\x85\xa8\xe9\x83\xa8\xe4\xbb\xa3\xe7\xa0\x81](/SVM/SVM_scikit-learn.py)\n- \xe7\xba\xbf\xe6\x80\xa7\xe5\x8f\xaf\xe5\x88\x86\xe7\x9a\x84,\xe6\x8c\x87\xe5\xae\x9a\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xe4\xb8\xba`linear`\xef\xbc\x9a\n```\n    \'\'\'data1\xe2\x80\x94\xe2\x80\x94\xe7\xba\xbf\xe6\x80\xa7\xe5\x88\x86\xe7\xb1\xbb\'\'\'\n    data1 = spio.loadmat(\'data1.mat\')\n    X = data1[\'X\']\n    y = data1[\'y\']\n    y = np.ravel(y)\n    plot_data(X,y)\n    \n    model = svm.SVC(C=1.0,kernel=\'linear\').fit(X,y) # \xe6\x8c\x87\xe5\xae\x9a\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xe4\xb8\xba\xe7\xba\xbf\xe6\x80\xa7\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\n```\n- \xe9\x9d\x9e\xe7\xba\xbf\xe6\x80\xa7\xe5\x8f\xaf\xe5\x88\x86\xe7\x9a\x84\xef\xbc\x8c\xe9\xbb\x98\xe8\xae\xa4\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xe4\xb8\xba`rbf`\n```\n    \'\'\'data2\xe2\x80\x94\xe2\x80\x94\xe9\x9d\x9e\xe7\xba\xbf\xe6\x80\xa7\xe5\x88\x86\xe7\xb1\xbb\'\'\'\n    data2 = spio.loadmat(\'data2.mat\')\n    X = data2[\'X\']\n    y = data2[\'y\']\n    y = np.ravel(y)\n    plt = plot_data(X,y)\n    plt.show()\n    \n    model = svm.SVC(gamma=100).fit(X,y)     # gamma\xe4\xb8\xba\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84\xe7\xb3\xbb\xe6\x95\xb0\xef\xbc\x8c\xe5\x80\xbc\xe8\xb6\x8a\xe5\xa4\xa7\xe6\x8b\x9f\xe5\x90\x88\xe7\x9a\x84\xe8\xb6\x8a\xe5\xa5\xbd\n```\n### 5\xe3\x80\x81\xe8\xbf\x90\xe8\xa1\x8c\xe7\xbb\x93\xe6\x9e\x9c\n- \xe7\xba\xbf\xe6\x80\xa7\xe5\x8f\xaf\xe5\x88\x86\xe7\x9a\x84\xe5\x86\xb3\xe7\xad\x96\xe8\xbe\xb9\xe7\x95\x8c\xef\xbc\x9a    \n![enter description here][32]\n- \xe7\xba\xbf\xe6\x80\xa7\xe4\xb8\x8d\xe5\x8f\xaf\xe5\x88\x86\xe7\x9a\x84\xe5\x86\xb3\xe7\xad\x96\xe8\xbe\xb9\xe7\x95\x8c\xef\xbc\x9a   \n![enter description here][33]\n\n--------------------------\n\n## \xe4\xba\x94\xe3\x80\x81K-Means\xe8\x81\x9a\xe7\xb1\xbb\xe7\xae\x97\xe6\xb3\x95\n- [\xe5\x85\xa8\xe9\x83\xa8\xe4\xbb\xa3\xe7\xa0\x81](/K-Means/K-Menas.py)\n\n### 1\xe3\x80\x81\xe8\x81\x9a\xe7\xb1\xbb\xe8\xbf\x87\xe7\xa8\x8b\n- \xe8\x81\x9a\xe7\xb1\xbb\xe5\xb1\x9e\xe4\xba\x8e\xe6\x97\xa0\xe7\x9b\x91\xe7\x9d\xa3\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x8c\xe4\xb8\x8d\xe7\x9f\xa5\xe9\x81\x93y\xe7\x9a\x84\xe6\xa0\x87\xe8\xae\xb0\xe5\x88\x86\xe4\xb8\xbaK\xe7\xb1\xbb\n- K-Means\xe7\xae\x97\xe6\xb3\x95\xe5\x88\x86\xe4\xb8\xba\xe4\xb8\xa4\xe4\xb8\xaa\xe6\xad\xa5\xe9\xaa\xa4\n - \xe7\xac\xac\xe4\xb8\x80\xe6\xad\xa5\xef\xbc\x9a\xe7\xb0\x87\xe5\x88\x86\xe9\x85\x8d\xef\xbc\x8c\xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89`K`\xe4\xb8\xaa\xe7\x82\xb9\xe4\xbd\x9c\xe4\xb8\xba\xe4\xb8\xad\xe5\xbf\x83\xef\xbc\x8c\xe8\xae\xa1\xe7\xae\x97\xe5\x88\xb0\xe8\xbf\x99`K`\xe4\xb8\xaa\xe7\x82\xb9\xe7\x9a\x84\xe8\xb7\x9d\xe7\xa6\xbb\xef\xbc\x8c\xe5\x88\x86\xe4\xb8\xba`K`\xe4\xb8\xaa\xe7\xb0\x87\n - \xe7\xac\xac\xe4\xba\x8c\xe6\xad\xa5\xef\xbc\x9a\xe7\xa7\xbb\xe5\x8a\xa8\xe8\x81\x9a\xe7\xb1\xbb\xe4\xb8\xad\xe5\xbf\x83\xef\xbc\x9a\xe9\x87\x8d\xe6\x96\xb0\xe8\xae\xa1\xe7\xae\x97\xe6\xaf\x8f\xe4\xb8\xaa**\xe7\xb0\x87**\xe7\x9a\x84\xe4\xb8\xad\xe5\xbf\x83\xef\xbc\x8c\xe7\xa7\xbb\xe5\x8a\xa8\xe4\xb8\xad\xe5\xbf\x83\xef\xbc\x8c\xe9\x87\x8d\xe5\xa4\x8d\xe4\xbb\xa5\xe4\xb8\x8a\xe6\xad\xa5\xe9\xaa\xa4\xe3\x80\x82\n- \xe5\xa6\x82\xe4\xb8\x8b\xe5\x9b\xbe\xe6\x89\x80\xe7\xa4\xba\xef\xbc\x9a\n - \xe9\x9a\x8f\xe6\x9c\xba\xe5\x88\x86\xe9\x85\x8d\xe7\x9a\x84\xe8\x81\x9a\xe7\xb1\xbb\xe4\xb8\xad\xe5\xbf\x83  \n ![enter description here][34]\n - \xe9\x87\x8d\xe6\x96\xb0\xe8\xae\xa1\xe7\xae\x97\xe8\x81\x9a\xe7\xb1\xbb\xe4\xb8\xad\xe5\xbf\x83\xef\xbc\x8c\xe7\xa7\xbb\xe5\x8a\xa8\xe4\xb8\x80\xe6\xac\xa1  \n ![enter description here][35]\n - \xe6\x9c\x80\xe5\x90\x8e`10`\xe6\xad\xa5\xe4\xb9\x8b\xe5\x90\x8e\xe7\x9a\x84\xe8\x81\x9a\xe7\xb1\xbb\xe4\xb8\xad\xe5\xbf\x83  \n ![enter description here][36]\n\n- \xe8\xae\xa1\xe7\xae\x97\xe6\xaf\x8f\xe6\x9d\xa1\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\xb0\xe5\x93\xaa\xe4\xb8\xaa\xe4\xb8\xad\xe5\xbf\x83\xe6\x9c\x80\xe8\xbf\x91\xe5\xae\x9e\xe7\x8e\xb0\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a\n```\n# \xe6\x89\xbe\xe5\x88\xb0\xe6\xaf\x8f\xe6\x9d\xa1\xe6\x95\xb0\xe6\x8d\xae\xe8\xb7\x9d\xe7\xa6\xbb\xe5\x93\xaa\xe4\xb8\xaa\xe7\xb1\xbb\xe4\xb8\xad\xe5\xbf\x83\xe6\x9c\x80\xe8\xbf\x91    \ndef findClosestCentroids(X,initial_centroids):\n    m = X.shape[0]                  # \xe6\x95\xb0\xe6\x8d\xae\xe6\x9d\xa1\xe6\x95\xb0\n    K = initial_centroids.shape[0]  # \xe7\xb1\xbb\xe7\x9a\x84\xe6\x80\xbb\xe6\x95\xb0\n    dis = np.zeros((m,K))           # \xe5\xad\x98\xe5\x82\xa8\xe8\xae\xa1\xe7\xae\x97\xe6\xaf\x8f\xe4\xb8\xaa\xe7\x82\xb9\xe5\x88\x86\xe5\x88\xab\xe5\x88\xb0K\xe4\xb8\xaa\xe7\xb1\xbb\xe7\x9a\x84\xe8\xb7\x9d\xe7\xa6\xbb\n    idx = np.zeros((m,1))           # \xe8\xa6\x81\xe8\xbf\x94\xe5\x9b\x9e\xe7\x9a\x84\xe6\xaf\x8f\xe6\x9d\xa1\xe6\x95\xb0\xe6\x8d\xae\xe5\xb1\x9e\xe4\xba\x8e\xe5\x93\xaa\xe4\xb8\xaa\xe7\xb1\xbb\n    \n    \'\'\'\xe8\xae\xa1\xe7\xae\x97\xe6\xaf\x8f\xe4\xb8\xaa\xe7\x82\xb9\xe5\x88\xb0\xe6\xaf\x8f\xe4\xb8\xaa\xe7\xb1\xbb\xe4\xb8\xad\xe5\xbf\x83\xe7\x9a\x84\xe8\xb7\x9d\xe7\xa6\xbb\'\'\'\n    for i in range(m):\n        for j in range(K):\n            dis[i,j] = np.dot((X[i,:]-initial_centroids[j,:]).reshape(1,-1),(X[i,:]-initial_centroids[j,:]).reshape(-1,1))\n    \n    \'\'\'\xe8\xbf\x94\xe5\x9b\x9edis\xe6\xaf\x8f\xe4\xb8\x80\xe8\xa1\x8c\xe7\x9a\x84\xe6\x9c\x80\xe5\xb0\x8f\xe5\x80\xbc\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe5\x88\x97\xe5\x8f\xb7\xef\xbc\x8c\xe5\x8d\xb3\xe4\xb8\xba\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\n    - np.min(dis, axis=1)\xe8\xbf\x94\xe5\x9b\x9e\xe6\xaf\x8f\xe4\xb8\x80\xe8\xa1\x8c\xe7\x9a\x84\xe6\x9c\x80\xe5\xb0\x8f\xe5\x80\xbc\n    - np.where(dis == np.min(dis, axis=1).reshape(-1,1)) \xe8\xbf\x94\xe5\x9b\x9e\xe5\xaf\xb9\xe5\xba\x94\xe6\x9c\x80\xe5\xb0\x8f\xe5\x80\xbc\xe7\x9a\x84\xe5\x9d\x90\xe6\xa0\x87\n     - \xe6\xb3\xa8\xe6\x84\x8f\xef\xbc\x9a\xe5\x8f\xaf\xe8\x83\xbd\xe6\x9c\x80\xe5\xb0\x8f\xe5\x80\xbc\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe5\x9d\x90\xe6\xa0\x87\xe6\x9c\x89\xe5\xa4\x9a\xe4\xb8\xaa\xef\xbc\x8cwhere\xe9\x83\xbd\xe4\xbc\x9a\xe6\x89\xbe\xe5\x87\xba\xe6\x9d\xa5\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xe8\xbf\x94\xe5\x9b\x9e\xe6\x97\xb6\xe8\xbf\x94\xe5\x9b\x9e\xe5\x89\x8dm\xe4\xb8\xaa\xe9\x9c\x80\xe8\xa6\x81\xe7\x9a\x84\xe5\x8d\xb3\xe5\x8f\xaf\xef\xbc\x88\xe5\x9b\xa0\xe4\xb8\xba\xe5\xaf\xb9\xe4\xba\x8e\xe5\xa4\x9a\xe4\xb8\xaa\xe6\x9c\x80\xe5\xb0\x8f\xe5\x80\xbc\xef\xbc\x8c\xe5\xb1\x9e\xe4\xba\x8e\xe5\x93\xaa\xe4\xb8\xaa\xe7\xb1\xbb\xe5\x88\xab\xe9\x83\xbd\xe5\x8f\xaf\xe4\xbb\xa5\xef\xbc\x89\n    \'\'\'  \n    dummy,idx = np.where(dis == np.min(dis, axis=1).reshape(-1,1))\n    return idx[0:dis.shape[0]]  # \xe6\xb3\xa8\xe6\x84\x8f\xe6\x88\xaa\xe5\x8f\x96\xe4\xb8\x80\xe4\xb8\x8b\n```\n- \xe8\xae\xa1\xe7\xae\x97\xe7\xb1\xbb\xe4\xb8\xad\xe5\xbf\x83\xe5\xae\x9e\xe7\x8e\xb0\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a\n```\n# \xe8\xae\xa1\xe7\xae\x97\xe7\xb1\xbb\xe4\xb8\xad\xe5\xbf\x83\ndef computerCentroids(X,idx,K):\n    n = X.shape[1]\n    centroids = np.zeros((K,n))\n    for i in range(K):\n        centroids[i,:] = np.mean(X[np.ravel(idx==i),:], axis=0).reshape(1,-1)   # \xe7\xb4\xa2\xe5\xbc\x95\xe8\xa6\x81\xe6\x98\xaf\xe4\xb8\x80\xe7\xbb\xb4\xe7\x9a\x84,axis=0\xe4\xb8\xba\xe6\xaf\x8f\xe4\xb8\x80\xe5\x88\x97\xef\xbc\x8cidx==i\xe4\xb8\x80\xe6\xac\xa1\xe6\x89\xbe\xe5\x87\xba\xe5\xb1\x9e\xe4\xba\x8e\xe5\x93\xaa\xe4\xb8\x80\xe7\xb1\xbb\xe7\x9a\x84\xef\xbc\x8c\xe7\x84\xb6\xe5\x90\x8e\xe8\xae\xa1\xe7\xae\x97\xe5\x9d\x87\xe5\x80\xbc\n    return centroids\n```\n\n### 2\xe3\x80\x81\xe7\x9b\xae\xe6\xa0\x87\xe5\x87\xbd\xe6\x95\xb0\n- \xe4\xb9\x9f\xe5\x8f\xab\xe5\x81\x9a**\xe5\xa4\xb1\xe7\x9c\x9f\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0**\n- ![J({c^{(1)}}, \\cdots ,{c^{(m)}},{u_1}, \\cdots ,{u_k}) = \\frac{1}{m}\\sum\\limits_{i = 1}^m {||{x^{(i)}} - {u_{{c^{(i)}}}}|{|^2}} ](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=J%28%7Bc%5E%7B%281%29%7D%7D%2C%20%5Ccdots%20%2C%7Bc%5E%7B%28m%29%7D%7D%2C%7Bu_1%7D%2C%20%5Ccdots%20%2C%7Bu_k%7D%29%20%3D%20%5Cfrac%7B1%7D%7Bm%7D%5Csum%5Climits_%7Bi%20%3D%201%7D%5Em%20%7B%7C%7C%7Bx%5E%7B%28i%29%7D%7D%20-%20%7Bu_%7B%7Bc%5E%7B%28i%29%7D%7D%7D%7D%7C%7B%7C%5E2%7D%7D%20)\n- \xe6\x9c\x80\xe5\x90\x8e\xe6\x88\x91\xe4\xbb\xac\xe6\x83\xb3\xe5\xbe\x97\xe5\x88\xb0\xef\xbc\x9a  \n![enter description here][37]\n- \xe5\x85\xb6\xe4\xb8\xad![{c^{(i)}}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7Bc%5E%7B%28i%29%7D%7D)\xe8\xa1\xa8\xe7\xa4\xba\xe7\xac\xac`i`\xe6\x9d\xa1\xe6\x95\xb0\xe6\x8d\xae\xe8\xb7\x9d\xe7\xa6\xbb\xe5\x93\xaa\xe4\xb8\xaa\xe7\xb1\xbb\xe4\xb8\xad\xe5\xbf\x83\xe6\x9c\x80\xe8\xbf\x91\xef\xbc\x8c\n- \xe5\x85\xb6\xe4\xb8\xad![{u_i}](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=%7Bu_i%7D)\xe5\x8d\xb3\xe4\xb8\xba\xe8\x81\x9a\xe7\xb1\xbb\xe7\x9a\x84\xe4\xb8\xad\xe5\xbf\x83\n\n### 3\xe3\x80\x81\xe8\x81\x9a\xe7\xb1\xbb\xe4\xb8\xad\xe5\xbf\x83\xe7\x9a\x84\xe9\x80\x89\xe6\x8b\xa9\n- \xe9\x9a\x8f\xe6\x9c\xba\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xef\xbc\x8c\xe4\xbb\x8e\xe7\xbb\x99\xe5\xae\x9a\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\xad\xe9\x9a\x8f\xe6\x9c\xba\xe6\x8a\xbd\xe5\x8f\x96K\xe4\xb8\xaa\xe4\xbd\x9c\xe4\xb8\xba\xe8\x81\x9a\xe7\xb1\xbb\xe4\xb8\xad\xe5\xbf\x83\n- \xe9\x9a\x8f\xe6\x9c\xba\xe4\xb8\x80\xe6\xac\xa1\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe5\x8f\xaf\xe8\x83\xbd\xe4\xb8\x8d\xe5\xa5\xbd\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe9\x9a\x8f\xe6\x9c\xba\xe5\xa4\x9a\xe6\xac\xa1\xef\xbc\x8c\xe6\x9c\x80\xe5\x90\x8e\xe5\x8f\x96\xe4\xbd\xbf\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84\xe4\xbd\x9c\xe4\xb8\xba\xe4\xb8\xad\xe5\xbf\x83\n- \xe5\xae\x9e\xe7\x8e\xb0\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a(\xe8\xbf\x99\xe9\x87\x8c\xe9\x9a\x8f\xe6\x9c\xba\xe4\xb8\x80\xe6\xac\xa1)\n```\n# \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe7\xb1\xbb\xe4\xb8\xad\xe5\xbf\x83--\xe9\x9a\x8f\xe6\x9c\xba\xe5\x8f\x96K\xe4\xb8\xaa\xe7\x82\xb9\xe4\xbd\x9c\xe4\xb8\xba\xe8\x81\x9a\xe7\xb1\xbb\xe4\xb8\xad\xe5\xbf\x83\ndef kMeansInitCentroids(X,K):\n    m = X.shape[0]\n    m_arr = np.arange(0,m)      # \xe7\x94\x9f\xe6\x88\x900-m-1\n    centroids = np.zeros((K,X.shape[1]))\n    np.random.shuffle(m_arr)    # \xe6\x89\x93\xe4\xb9\xb1m_arr\xe9\xa1\xba\xe5\xba\x8f    \n    rand_indices = m_arr[:K]    # \xe5\x8f\x96\xe5\x89\x8dK\xe4\xb8\xaa\n    centroids = X[rand_indices,:]\n    return centroids\n```\n\n### 4\xe3\x80\x81\xe8\x81\x9a\xe7\xb1\xbb\xe4\xb8\xaa\xe6\x95\xb0K\xe7\x9a\x84\xe9\x80\x89\xe6\x8b\xa9\n- \xe8\x81\x9a\xe7\xb1\xbb\xe6\x98\xaf\xe4\xb8\x8d\xe7\x9f\xa5\xe9\x81\x93y\xe7\x9a\x84label\xe7\x9a\x84\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xe4\xb8\x8d\xe7\x9f\xa5\xe9\x81\x93\xe7\x9c\x9f\xe6\xad\xa3\xe7\x9a\x84\xe8\x81\x9a\xe7\xb1\xbb\xe4\xb8\xaa\xe6\x95\xb0\n- \xe8\x82\x98\xe9\x83\xa8\xe6\xb3\x95\xe5\x88\x99\xef\xbc\x88Elbow method\xef\xbc\x89\n - \xe4\xbd\x9c\xe4\xbb\xa3\xe4\xbb\xb7\xe5\x87\xbd\xe6\x95\xb0`J`\xe5\x92\x8c`K`\xe7\x9a\x84\xe5\x9b\xbe\xef\xbc\x8c\xe8\x8b\xa5\xe6\x98\xaf\xe5\x87\xba\xe7\x8e\xb0\xe4\xb8\x80\xe4\xb8\xaa\xe6\x8b\x90\xe7\x82\xb9\xef\xbc\x8c\xe5\xa6\x82\xe4\xb8\x8b\xe5\x9b\xbe\xe6\x89\x80\xe7\xa4\xba\xef\xbc\x8c`K`\xe5\xb0\xb1\xe5\x8f\x96\xe6\x8b\x90\xe7\x82\xb9\xe5\xa4\x84\xe7\x9a\x84\xe5\x80\xbc\xef\xbc\x8c\xe4\xb8\x8b\xe5\x9b\xbe\xe6\xad\xa4\xe6\x97\xb6`K=3`\n ![enter description here][38]\n - \xe8\x8b\xa5\xe6\x98\xaf\xe5\xbe\x88\xe5\xb9\xb3\xe6\xbb\x91\xe5\xb0\xb1\xe4\xb8\x8d\xe6\x98\x8e\xe7\xa1\xae\xef\xbc\x8c\xe4\xba\xba\xe4\xb8\xba\xe9\x80\x89\xe6\x8b\xa9\xe3\x80\x82\n- \xe7\xac\xac\xe4\xba\x8c\xe7\xa7\x8d\xe5\xb0\xb1\xe6\x98\xaf\xe4\xba\xba\xe4\xb8\xba\xe8\xa7\x82\xe5\xaf\x9f\xe9\x80\x89\xe6\x8b\xa9\n\n### 5\xe3\x80\x81\xe5\xba\x94\xe7\x94\xa8\xe2\x80\x94\xe2\x80\x94\xe5\x9b\xbe\xe7\x89\x87\xe5\x8e\x8b\xe7\xbc\xa9\n- \xe5\xb0\x86\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe5\x83\x8f\xe7\xb4\xa0\xe5\x88\x86\xe4\xb8\xba\xe8\x8b\xa5\xe5\xb9\xb2\xe7\xb1\xbb\xef\xbc\x8c\xe7\x84\xb6\xe5\x90\x8e\xe7\x94\xa8\xe8\xbf\x99\xe4\xb8\xaa\xe7\xb1\xbb\xe4\xbb\xa3\xe6\x9b\xbf\xe5\x8e\x9f\xe6\x9d\xa5\xe7\x9a\x84\xe5\x83\x8f\xe7\xb4\xa0\xe5\x80\xbc\n- \xe6\x89\xa7\xe8\xa1\x8c\xe8\x81\x9a\xe7\xb1\xbb\xe7\x9a\x84\xe7\xae\x97\xe6\xb3\x95\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a\n```\n# \xe8\x81\x9a\xe7\xb1\xbb\xe7\xae\x97\xe6\xb3\x95\ndef runKMeans(X,initial_centroids,max_iters,plot_process):\n    m,n = X.shape                   # \xe6\x95\xb0\xe6\x8d\xae\xe6\x9d\xa1\xe6\x95\xb0\xe5\x92\x8c\xe7\xbb\xb4\xe5\xba\xa6\n    K = initial_centroids.shape[0]  # \xe7\xb1\xbb\xe6\x95\xb0\n    centroids = initial_centroids   # \xe8\xae\xb0\xe5\xbd\x95\xe5\xbd\x93\xe5\x89\x8d\xe7\xb1\xbb\xe4\xb8\xad\xe5\xbf\x83\n    previous_centroids = centroids  # \xe8\xae\xb0\xe5\xbd\x95\xe4\xb8\x8a\xe4\xb8\x80\xe6\xac\xa1\xe7\xb1\xbb\xe4\xb8\xad\xe5\xbf\x83\n    idx = np.zeros((m,1))           # \xe6\xaf\x8f\xe6\x9d\xa1\xe6\x95\xb0\xe6\x8d\xae\xe5\xb1\x9e\xe4\xba\x8e\xe5\x93\xaa\xe4\xb8\xaa\xe7\xb1\xbb\n    \n    for i in range(max_iters):      # \xe8\xbf\xad\xe4\xbb\xa3\xe6\xac\xa1\xe6\x95\xb0\n        print u\'\xe8\xbf\xad\xe4\xbb\xa3\xe8\xae\xa1\xe7\xae\x97\xe6\xac\xa1\xe6\x95\xb0\xef\xbc\x9a%d\'%(i+1)\n        idx = findClosestCentroids(X, centroids)\n        if plot_process:    # \xe5\xa6\x82\xe6\x9e\x9c\xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe\xe5\x83\x8f\n            plt = plotProcessKMeans(X,centroids,previous_centroids) # \xe7\x94\xbb\xe8\x81\x9a\xe7\xb1\xbb\xe4\xb8\xad\xe5\xbf\x83\xe7\x9a\x84\xe7\xa7\xbb\xe5\x8a\xa8\xe8\xbf\x87\xe7\xa8\x8b\n            previous_centroids = centroids  # \xe9\x87\x8d\xe7\xbd\xae\n        centroids = computerCentroids(X, idx, K)    # \xe9\x87\x8d\xe6\x96\xb0\xe8\xae\xa1\xe7\xae\x97\xe7\xb1\xbb\xe4\xb8\xad\xe5\xbf\x83\n    if plot_process:    # \xe6\x98\xbe\xe7\xa4\xba\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe7\xbb\x98\xe5\x88\xb6\xe7\xbb\x93\xe6\x9e\x9c\n        plt.show()\n    return centroids,idx    # \xe8\xbf\x94\xe5\x9b\x9e\xe8\x81\x9a\xe7\xb1\xbb\xe4\xb8\xad\xe5\xbf\x83\xe5\x92\x8c\xe6\x95\xb0\xe6\x8d\xae\xe5\xb1\x9e\xe4\xba\x8e\xe5\x93\xaa\xe4\xb8\xaa\xe7\xb1\xbb\n```\n\n### 6\xe3\x80\x81[\xe4\xbd\xbf\xe7\x94\xa8scikit-learn\xe5\xba\x93\xe4\xb8\xad\xe7\x9a\x84\xe7\xba\xbf\xe6\x80\xa7\xe6\xa8\xa1\xe5\x9e\x8b\xe5\xae\x9e\xe7\x8e\xb0\xe8\x81\x9a\xe7\xb1\xbb](/K-Means/K-Means_scikit-learn.py)\n\n- \xe5\xaf\xbc\xe5\x85\xa5\xe5\x8c\x85\n```\n    from sklearn.cluster import KMeans\n```\n- \xe4\xbd\xbf\xe7\x94\xa8\xe6\xa8\xa1\xe5\x9e\x8b\xe6\x8b\x9f\xe5\x90\x88\xe6\x95\xb0\xe6\x8d\xae\n```\n    model = KMeans(n_clusters=3).fit(X) # n_clusters\xe6\x8c\x87\xe5\xae\x9a3\xe7\xb1\xbb\xef\xbc\x8c\xe6\x8b\x9f\xe5\x90\x88\xe6\x95\xb0\xe6\x8d\xae\n```\n- \xe8\x81\x9a\xe7\xb1\xbb\xe4\xb8\xad\xe5\xbf\x83\n```\n    centroids = model.cluster_centers_  # \xe8\x81\x9a\xe7\xb1\xbb\xe4\xb8\xad\xe5\xbf\x83\n```\n\n### 7\xe3\x80\x81\xe8\xbf\x90\xe8\xa1\x8c\xe7\xbb\x93\xe6\x9e\x9c\n- \xe4\xba\x8c\xe7\xbb\xb4\xe6\x95\xb0\xe6\x8d\xae\xe7\xb1\xbb\xe4\xb8\xad\xe5\xbf\x83\xe7\x9a\x84\xe7\xa7\xbb\xe5\x8a\xa8  \n![enter description here][39]\n- \xe5\x9b\xbe\xe7\x89\x87\xe5\x8e\x8b\xe7\xbc\xa9  \n![enter description here][40]\n\n\n----------------------\n\n## \xe5\x85\xad\xe3\x80\x81PCA\xe4\xb8\xbb\xe6\x88\x90\xe5\x88\x86\xe5\x88\x86\xe6\x9e\x90\xef\xbc\x88\xe9\x99\x8d\xe7\xbb\xb4\xef\xbc\x89\n- [\xe5\x85\xa8\xe9\x83\xa8\xe4\xbb\xa3\xe7\xa0\x81](/PCA/PCA.py)\n\n### 1\xe3\x80\x81\xe7\x94\xa8\xe5\xa4\x84\n- \xe6\x95\xb0\xe6\x8d\xae\xe5\x8e\x8b\xe7\xbc\xa9\xef\xbc\x88Data Compression\xef\xbc\x89,\xe4\xbd\xbf\xe7\xa8\x8b\xe5\xba\x8f\xe8\xbf\x90\xe8\xa1\x8c\xe6\x9b\xb4\xe5\xbf\xab\n- \xe5\x8f\xaf\xe8\xa7\x86\xe5\x8c\x96\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe4\xbe\x8b\xe5\xa6\x82`3D-->2D`\xe7\xad\x89\n- ......\n\n### 2\xe3\x80\x812D-->1D\xef\xbc\x8cnD-->kD\n- \xe5\xa6\x82\xe4\xb8\x8b\xe5\x9b\xbe\xe6\x89\x80\xe7\xa4\xba\xef\xbc\x8c\xe6\x89\x80\xe6\x9c\x89\xe6\x95\xb0\xe6\x8d\xae\xe7\x82\xb9\xe5\x8f\xaf\xe4\xbb\xa5\xe6\x8a\x95\xe5\xbd\xb1\xe5\x88\xb0\xe4\xb8\x80\xe6\x9d\xa1\xe7\x9b\xb4\xe7\xba\xbf\xef\xbc\x8c\xe6\x98\xaf**\xe6\x8a\x95\xe5\xbd\xb1\xe8\xb7\x9d\xe7\xa6\xbb\xe7\x9a\x84\xe5\xb9\xb3\xe6\x96\xb9\xe5\x92\x8c**\xef\xbc\x88\xe6\x8a\x95\xe5\xbd\xb1\xe8\xaf\xaf\xe5\xb7\xae\xef\xbc\x89\xe6\x9c\x80\xe5\xb0\x8f\n![enter description here][41]\n- \xe6\xb3\xa8\xe6\x84\x8f\xe6\x95\xb0\xe6\x8d\xae\xe9\x9c\x80\xe8\xa6\x81`\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96`\xe5\xa4\x84\xe7\x90\x86\n- \xe6\x80\x9d\xe8\xb7\xaf\xe6\x98\xaf\xe6\x89\xbe`1`\xe4\xb8\xaa`\xe5\x90\x91\xe9\x87\x8fu`,\xe6\x89\x80\xe6\x9c\x89\xe6\x95\xb0\xe6\x8d\xae\xe6\x8a\x95\xe5\xbd\xb1\xe5\x88\xb0\xe4\xb8\x8a\xe9\x9d\xa2\xe4\xbd\xbf\xe6\x8a\x95\xe5\xbd\xb1\xe8\xb7\x9d\xe7\xa6\xbb\xe6\x9c\x80\xe5\xb0\x8f\n- \xe9\x82\xa3\xe4\xb9\x88`nD-->kD`\xe5\xb0\xb1\xe6\x98\xaf\xe6\x89\xbe`k`\xe4\xb8\xaa\xe5\x90\x91\xe9\x87\x8f![$${u^{(1)}},{u^{(2)}} \\ldots {u^{(k)}}$$](http://latex.codecogs.com/gif.latex?%24%24%7Bu%5E%7B%281%29%7D%7D%2C%7Bu%5E%7B%282%29%7D%7D%20%5Cldots%20%7Bu%5E%7B%28k%29%7D%7D%24%24)\xef\xbc\x8c\xe6\x89\x80\xe6\x9c\x89\xe6\x95\xb0\xe6\x8d\xae\xe6\x8a\x95\xe5\xbd\xb1\xe5\x88\xb0\xe4\xb8\x8a\xe9\x9d\xa2\xe4\xbd\xbf\xe6\x8a\x95\xe5\xbd\xb1\xe8\xaf\xaf\xe5\xb7\xae\xe6\x9c\x80\xe5\xb0\x8f\n - eg:3D-->2D,2\xe4\xb8\xaa\xe5\x90\x91\xe9\x87\x8f![$${u^{(1)}},{u^{(2)}}$$](http://latex.codecogs.com/gif.latex?%24%24%7Bu%5E%7B%281%29%7D%7D%2C%7Bu%5E%7B%282%29%7D%7D%24%24)\xe5\xb0\xb1\xe4\xbb\xa3\xe8\xa1\xa8\xe4\xb8\x80\xe4\xb8\xaa\xe5\xb9\xb3\xe9\x9d\xa2\xe4\xba\x86\xef\xbc\x8c\xe6\x89\x80\xe6\x9c\x89\xe7\x82\xb9\xe6\x8a\x95\xe5\xbd\xb1\xe5\x88\xb0\xe8\xbf\x99\xe4\xb8\xaa\xe5\xb9\xb3\xe9\x9d\xa2\xe7\x9a\x84\xe6\x8a\x95\xe5\xbd\xb1\xe8\xaf\xaf\xe5\xb7\xae\xe6\x9c\x80\xe5\xb0\x8f\xe5\x8d\xb3\xe5\x8f\xaf\n\n### 3\xe3\x80\x81\xe4\xb8\xbb\xe6\x88\x90\xe5\x88\x86\xe5\x88\x86\xe6\x9e\x90PCA\xe4\xb8\x8e\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9a\x84\xe5\x8c\xba\xe5\x88\xab\n- \xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe6\x98\xaf\xe6\x89\xbe`x`\xe4\xb8\x8e`y`\xe7\x9a\x84\xe5\x85\xb3\xe7\xb3\xbb\xef\xbc\x8c\xe7\x84\xb6\xe5\x90\x8e\xe7\x94\xa8\xe4\xba\x8e\xe9\xa2\x84\xe6\xb5\x8b`y`\n- `PCA`\xe6\x98\xaf\xe6\x89\xbe\xe4\xb8\x80\xe4\xb8\xaa\xe6\x8a\x95\xe5\xbd\xb1\xe9\x9d\xa2\xef\xbc\x8c\xe6\x9c\x80\xe5\xb0\x8f\xe5\x8c\x96data\xe5\x88\xb0\xe8\xbf\x99\xe4\xb8\xaa\xe6\x8a\x95\xe5\xbd\xb1\xe9\x9d\xa2\xe7\x9a\x84\xe6\x8a\x95\xe5\xbd\xb1\xe8\xaf\xaf\xe5\xb7\xae\n\n### 4\xe3\x80\x81PCA\xe9\x99\x8d\xe7\xbb\xb4\xe8\xbf\x87\xe7\xa8\x8b\n- \xe6\x95\xb0\xe6\x8d\xae\xe9\xa2\x84\xe5\xa4\x84\xe7\x90\x86\xef\xbc\x88\xe5\x9d\x87\xe5\x80\xbc\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xef\xbc\x89\n - \xe5\x85\xac\xe5\xbc\x8f\xef\xbc\x9a![$${\\rm{x}}_j^{(i)} = {{{\\rm{x}}_j^{(i)} - {u_j}} \\over {{s_j}}}$$](http://latex.codecogs.com/gif.latex?%24%24%7B%5Crm%7Bx%7D%7D_j%5E%7B%28i%29%7D%20%3D%20%7B%7B%7B%5Crm%7Bx%7D%7D_j%5E%7B%28i%29%7D%20-%20%7Bu_j%7D%7D%20%5Cover%20%7B%7Bs_j%7D%7D%7D%24%24)\n - \xe5\xb0\xb1\xe6\x98\xaf\xe5\x87\x8f\xe5\x8e\xbb\xe5\xaf\xb9\xe5\xba\x94feature\xe7\x9a\x84\xe5\x9d\x87\xe5\x80\xbc\xef\xbc\x8c\xe7\x84\xb6\xe5\x90\x8e\xe9\x99\xa4\xe4\xbb\xa5\xe5\xaf\xb9\xe5\xba\x94\xe7\x89\xb9\xe5\xbe\x81\xe7\x9a\x84\xe6\xa0\x87\xe5\x87\x86\xe5\xb7\xae\xef\xbc\x88\xe4\xb9\x9f\xe5\x8f\xaf\xe4\xbb\xa5\xe6\x98\xaf\xe6\x9c\x80\xe5\xa4\xa7\xe5\x80\xbc-\xe6\x9c\x80\xe5\xb0\x8f\xe5\x80\xbc\xef\xbc\x89\n - \xe5\xae\x9e\xe7\x8e\xb0\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a\n ```\n     # \xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe6\x95\xb0\xe6\x8d\xae\n    def featureNormalize(X):\n        \'\'\'\xef\xbc\x88\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe6\x95\xb0\xe6\x8d\xae-\xe5\xbd\x93\xe5\x89\x8d\xe5\x88\x97\xe7\x9a\x84\xe5\x9d\x87\xe5\x80\xbc\xef\xbc\x89/\xe5\xbd\x93\xe5\x89\x8d\xe5\x88\x97\xe7\x9a\x84\xe6\xa0\x87\xe5\x87\x86\xe5\xb7\xae\'\'\'\n        n = X.shape[1]\n        mu = np.zeros((1,n));\n        sigma = np.zeros((1,n))\n        \n        mu = np.mean(X,axis=0)\n        sigma = np.std(X,axis=0)\n        for i in range(n):\n            X[:,i] = (X[:,i]-mu[i])/sigma[i]\n        return X,mu,sigma\n ```\n- \xe8\xae\xa1\xe7\xae\x97`\xe5\x8d\x8f\xe6\x96\xb9\xe5\xb7\xae\xe7\x9f\xa9\xe9\x98\xb5\xce\xa3`\xef\xbc\x88Covariance Matrix\xef\xbc\x89\xef\xbc\x9a![$$\\Sigma  = {1 \\over m}\\sum\\limits_{i = 1}^n {{x^{(i)}}{{({x^{(i)}})}^T}} $$](http://latex.codecogs.com/gif.latex?%24%24%5CSigma%20%3D%20%7B1%20%5Cover%20m%7D%5Csum%5Climits_%7Bi%20%3D%201%7D%5En%20%7B%7Bx%5E%7B%28i%29%7D%7D%7B%7B%28%7Bx%5E%7B%28i%29%7D%7D%29%7D%5ET%7D%7D%20%24%24)\n - \xe6\xb3\xa8\xe6\x84\x8f\xe8\xbf\x99\xe9\x87\x8c\xe7\x9a\x84`\xce\xa3`\xe5\x92\x8c\xe6\xb1\x82\xe5\x92\x8c\xe7\xac\xa6\xe5\x8f\xb7\xe4\xb8\x8d\xe5\x90\x8c\n - \xe5\x8d\x8f\xe6\x96\xb9\xe5\xb7\xae\xe7\x9f\xa9\xe9\x98\xb5`\xe5\xaf\xb9\xe7\xa7\xb0\xe6\xad\xa3\xe5\xae\x9a`\xef\xbc\x88\xe4\xb8\x8d\xe7\x90\x86\xe8\xa7\xa3\xe6\xad\xa3\xe5\xae\x9a\xe7\x9a\x84\xe7\x9c\x8b\xe7\x9c\x8b\xe7\xba\xbf\xe4\xbb\xa3\xef\xbc\x89\n - \xe5\xa4\xa7\xe5\xb0\x8f\xe4\xb8\xba`nxn`,`n`\xe4\xb8\xba`feature`\xe7\x9a\x84\xe7\xbb\xb4\xe5\xba\xa6\n - \xe5\xae\x9e\xe7\x8e\xb0\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a\n ```\n Sigma = np.dot(np.transpose(X_norm),X_norm)/m  # \xe6\xb1\x82Sigma\n ```\n- \xe8\xae\xa1\xe7\xae\x97`\xce\xa3`\xe7\x9a\x84\xe7\x89\xb9\xe5\xbe\x81\xe5\x80\xbc\xe5\x92\x8c\xe7\x89\xb9\xe5\xbe\x81\xe5\x90\x91\xe9\x87\x8f\n - \xe5\x8f\xaf\xe4\xbb\xa5\xe6\x98\xaf\xe7\x94\xa8`svd`\xe5\xa5\x87\xe5\xbc\x82\xe5\x80\xbc\xe5\x88\x86\xe8\xa7\xa3\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x9a`U,S,V = svd(\xce\xa3)`\n - \xe8\xbf\x94\xe5\x9b\x9e\xe7\x9a\x84\xe6\x98\xaf\xe4\xb8\x8e`\xce\xa3`\xe5\x90\x8c\xe6\xa0\xb7\xe5\xa4\xa7\xe5\xb0\x8f\xe7\x9a\x84\xe5\xaf\xb9\xe8\xa7\x92\xe9\x98\xb5`S`\xef\xbc\x88\xe7\x94\xb1`\xce\xa3`\xe7\x9a\x84\xe7\x89\xb9\xe5\xbe\x81\xe5\x80\xbc\xe7\xbb\x84\xe6\x88\x90\xef\xbc\x89[**\xe6\xb3\xa8\xe6\x84\x8f**\xef\xbc\x9a`matlab`\xe4\xb8\xad\xe5\x87\xbd\xe6\x95\xb0\xe8\xbf\x94\xe5\x9b\x9e\xe7\x9a\x84\xe6\x98\xaf\xe5\xaf\xb9\xe8\xa7\x92\xe9\x98\xb5\xef\xbc\x8c\xe5\x9c\xa8`python`\xe4\xb8\xad\xe8\xbf\x94\xe5\x9b\x9e\xe7\x9a\x84\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe5\x90\x91\xe9\x87\x8f\xef\xbc\x8c\xe8\x8a\x82\xe7\x9c\x81\xe7\xa9\xba\xe9\x97\xb4]\n - \xe8\xbf\x98\xe6\x9c\x89\xe4\xb8\xa4\xe4\xb8\xaa**\xe9\x85\x89\xe7\x9f\xa9\xe9\x98\xb5**U\xe5\x92\x8cV\xef\xbc\x8c\xe4\xb8\x94![$$\\Sigma  = US{V^T}$$](http://latex.codecogs.com/gif.latex?%24%24%5CSigma%20%3D%20US%7BV%5ET%7D%24%24)\n - ![enter description here][42]\n - **\xe6\xb3\xa8\xe6\x84\x8f**\xef\xbc\x9a`svd`\xe5\x87\xbd\xe6\x95\xb0\xe6\xb1\x82\xe5\x87\xba\xe7\x9a\x84`S`\xe6\x98\xaf\xe6\x8c\x89\xe7\x89\xb9\xe5\xbe\x81\xe5\x80\xbc\xe9\x99\x8d\xe5\xba\x8f\xe6\x8e\x92\xe5\x88\x97\xe7\x9a\x84\xef\xbc\x8c\xe8\x8b\xa5\xe4\xb8\x8d\xe6\x98\xaf\xe4\xbd\xbf\xe7\x94\xa8`svd`,\xe9\x9c\x80\xe8\xa6\x81\xe6\x8c\x89**\xe7\x89\xb9\xe5\xbe\x81\xe5\x80\xbc**\xe5\xa4\xa7\xe5\xb0\x8f\xe9\x87\x8d\xe6\x96\xb0\xe6\x8e\x92\xe5\x88\x97`U`\n- \xe9\x99\x8d\xe7\xbb\xb4\n - \xe9\x80\x89\xe5\x8f\x96`U`\xe4\xb8\xad\xe7\x9a\x84\xe5\x89\x8d`K`\xe5\x88\x97\xef\xbc\x88\xe5\x81\x87\xe8\xae\xbe\xe8\xa6\x81\xe9\x99\x8d\xe4\xb8\xba`K`\xe7\xbb\xb4\xef\xbc\x89\n - ![enter description here][43]\n - `Z`\xe5\xb0\xb1\xe6\x98\xaf\xe5\xaf\xb9\xe5\xba\x94\xe9\x99\x8d\xe7\xbb\xb4\xe4\xb9\x8b\xe5\x90\x8e\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\n - \xe5\xae\x9e\xe7\x8e\xb0\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a\n ```\n     # \xe6\x98\xa0\xe5\xb0\x84\xe6\x95\xb0\xe6\x8d\xae\n    def projectData(X_norm,U,K):\n        Z = np.zeros((X_norm.shape[0],K))\n        \n        U_reduce = U[:,0:K]          # \xe5\x8f\x96\xe5\x89\x8dK\xe4\xb8\xaa\n        Z = np.dot(X_norm,U_reduce) \n        return Z\n ```\n- \xe8\xbf\x87\xe7\xa8\x8b\xe6\x80\xbb\xe7\xbb\x93\xef\xbc\x9a\n - `Sigma = X\'*X/m`\n - `U,S,V = svd(Sigma)`\n - `Ureduce = U[:,0:k]`\n - `Z = Ureduce\'*x`\n\n### 5\xe3\x80\x81\xe6\x95\xb0\xe6\x8d\xae\xe6\x81\xa2\xe5\xa4\x8d\n - \xe5\x9b\xa0\xe4\xb8\xba\xef\xbc\x9a![$${Z^{(i)}} = U_{reduce}^T*{X^{(i)}}$$](http://latex.codecogs.com/gif.latex?%5Cfn_cm%20%24%24%7BZ%5E%7B%28i%29%7D%7D%20%3D%20U_%7Breduce%7D%5ET*%7BX%5E%7B%28i%29%7D%7D%24%24)\n - \xe6\x89\x80\xe4\xbb\xa5\xef\xbc\x9a![$${X_{approx}} = {(U_{reduce}^T)^{ - 1}}Z$$](http://latex.codecogs.com/gif.latex?%5Cfn_cm%20%24%24%7BX_%7Bapprox%7D%7D%20%3D%20%7B%28U_%7Breduce%7D%5ET%29%5E%7B%20-%201%7D%7DZ%24%24)     \xef\xbc\x88\xe6\xb3\xa8\xe6\x84\x8f\xe8\xbf\x99\xe9\x87\x8c\xe6\x98\xafX\xe7\x9a\x84\xe8\xbf\x91\xe4\xbc\xbc\xe5\x80\xbc\xef\xbc\x89\n - \xe5\x8f\x88\xe5\x9b\xa0\xe4\xb8\xba`Ureduce`\xe4\xb8\xba\xe6\xad\xa3\xe5\xae\x9a\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x8c\xe3\x80\x90\xe6\xad\xa3\xe5\xae\x9a\xe7\x9f\xa9\xe9\x98\xb5\xe6\xbb\xa1\xe8\xb6\xb3\xef\xbc\x9a![$$A{A^T} = {A^T}A = E$$](http://latex.codecogs.com/gif.latex?%5Cfn_cm%20%24%24A%7BA%5ET%7D%20%3D%20%7BA%5ET%7DA%20%3D%20E%24%24)\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xef\xbc\x9a![$${A^{ - 1}} = {A^T}$$](http://latex.codecogs.com/gif.latex?%5Cfn_cm%20%24%24%7BA%5E%7B%20-%201%7D%7D%20%3D%20%7BA%5ET%7D%24%24)\xe3\x80\x91\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xe8\xbf\x99\xe9\x87\x8c\xef\xbc\x9a\n - ![$${X_{approx}} = {(U_{reduce}^{ - 1})^{ - 1}}Z = {U_{reduce}}Z$$](http://latex.codecogs.com/gif.latex?%5Cfn_cm%20%24%24%7BX_%7Bapprox%7D%7D%20%3D%20%7B%28U_%7Breduce%7D%5E%7B%20-%201%7D%29%5E%7B%20-%201%7D%7DZ%20%3D%20%7BU_%7Breduce%7D%7DZ%24%24)\n - \xe5\xae\x9e\xe7\x8e\xb0\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a\n```\n    # \xe6\x81\xa2\xe5\xa4\x8d\xe6\x95\xb0\xe6\x8d\xae \n    def recoverData(Z,U,K):\n        X_rec = np.zeros((Z.shape[0],U.shape[0]))\n        U_recude = U[:,0:K]\n        X_rec = np.dot(Z,np.transpose(U_recude))  # \xe8\xbf\x98\xe5\x8e\x9f\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x88\xe8\xbf\x91\xe4\xbc\xbc\xef\xbc\x89\n        return X_rec\n```\n\n### 6\xe3\x80\x81\xe4\xb8\xbb\xe6\x88\x90\xe5\x88\x86\xe4\xb8\xaa\xe6\x95\xb0\xe7\x9a\x84\xe9\x80\x89\xe6\x8b\xa9\xef\xbc\x88\xe5\x8d\xb3\xe8\xa6\x81\xe9\x99\x8d\xe7\x9a\x84\xe7\xbb\xb4\xe5\xba\xa6\xef\xbc\x89\n- \xe5\xa6\x82\xe4\xbd\x95\xe9\x80\x89\xe6\x8b\xa9\n - **\xe6\x8a\x95\xe5\xbd\xb1\xe8\xaf\xaf\xe5\xb7\xae**\xef\xbc\x88project error\xef\xbc\x89\xef\xbc\x9a![$${1 \\over m}\\sum\\limits_{i = 1}^m {||{x^{(i)}} - x_{approx}^{(i)}|{|^2}} $$](http://latex.codecogs.com/gif.latex?%5Cfn_cm%20%24%24%7B1%20%5Cover%20m%7D%5Csum%5Climits_%7Bi%20%3D%201%7D%5Em%20%7B%7C%7C%7Bx%5E%7B%28i%29%7D%7D%20-%20x_%7Bapprox%7D%5E%7B%28i%29%7D%7C%7B%7C%5E2%7D%7D%20%24%24)\n - **\xe6\x80\xbb\xe5\x8f\x98\xe5\xb7\xae**\xef\xbc\x88total variation\xef\xbc\x89:![$${1 \\over m}\\sum\\limits_{i = 1}^m {||{x^{(i)}}|{|^2}} $$](http://latex.codecogs.com/gif.latex?%5Cfn_cm%20%24%24%7B1%20%5Cover%20m%7D%5Csum%5Climits_%7Bi%20%3D%201%7D%5Em%20%7B%7C%7C%7Bx%5E%7B%28i%29%7D%7D%7C%7B%7C%5E2%7D%7D%20%24%24)\n - \xe8\x8b\xa5**\xe8\xaf\xaf\xe5\xb7\xae\xe7\x8e\x87**\xef\xbc\x88error ratio\xef\xbc\x89\xef\xbc\x9a![$${{{1 \\over m}\\sum\\limits_{i = 1}^m {||{x^{(i)}} - x_{approx}^{(i)}|{|^2}} } \\over {{1 \\over m}\\sum\\limits_{i = 1}^m {||{x^{(i)}}|{|^2}} }} \\le 0.01$$](http://latex.codecogs.com/gif.latex?%5Cfn_cm%20%24%24%7B%7B%7B1%20%5Cover%20m%7D%5Csum%5Climits_%7Bi%20%3D%201%7D%5Em%20%7B%7C%7C%7Bx%5E%7B%28i%29%7D%7D%20-%20x_%7Bapprox%7D%5E%7B%28i%29%7D%7C%7B%7C%5E2%7D%7D%20%7D%20%5Cover%20%7B%7B1%20%5Cover%20m%7D%5Csum%5Climits_%7Bi%20%3D%201%7D%5Em%20%7B%7C%7C%7Bx%5E%7B%28i%29%7D%7D%7C%7B%7C%5E2%7D%7D%20%7D%7D%20%5Cle%200.01%24%24)\xef\xbc\x8c\xe5\x88\x99\xe7\xa7\xb0`99%`\xe4\xbf\x9d\xe7\x95\x99\xe5\xb7\xae\xe5\xbc\x82\xe6\x80\xa7\n - \xe8\xaf\xaf\xe5\xb7\xae\xe7\x8e\x87\xe4\xb8\x80\xe8\x88\xac\xe5\x8f\x96`1%\xef\xbc\x8c5%\xef\xbc\x8c10%`\xe7\xad\x89\n- \xe5\xa6\x82\xe4\xbd\x95\xe5\xae\x9e\xe7\x8e\xb0\n - \xe8\x8b\xa5\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe4\xb8\xaa\xe8\xaf\x95\xe7\x9a\x84\xe8\xaf\x9d\xe4\xbb\xa3\xe4\xbb\xb7\xe5\xa4\xaa\xe5\xa4\xa7\n - \xe4\xb9\x8b\xe5\x89\x8d`U,S,V = svd(Sigma)`,\xe6\x88\x91\xe4\xbb\xac\xe5\xbe\x97\xe5\x88\xb0\xe4\xba\x86`S`\xef\xbc\x8c\xe8\xbf\x99\xe9\x87\x8c\xe8\xaf\xaf\xe5\xb7\xae\xe7\x8e\x87error ratio:    \n ![$$error{\\kern 1pt} \\;ratio = 1 - {{\\sum\\limits_{i = 1}^k {{S_{ii}}} } \\over {\\sum\\limits_{i = 1}^n {{S_{ii}}} }} \\le threshold$$](http://latex.codecogs.com/gif.latex?%5Cfn_cm%20%24%24error%7B%5Ckern%201pt%7D%20%5C%3Bratio%20%3D%201%20-%20%7B%7B%5Csum%5Climits_%7Bi%20%3D%201%7D%5Ek%20%7B%7BS_%7Bii%7D%7D%7D%20%7D%20%5Cover%20%7B%5Csum%5Climits_%7Bi%20%3D%201%7D%5En%20%7B%7BS_%7Bii%7D%7D%7D%20%7D%7D%20%5Cle%20threshold%24%24)\n - \xe5\x8f\xaf\xe4\xbb\xa5\xe4\xb8\x80\xe7\x82\xb9\xe7\x82\xb9\xe5\xa2\x9e\xe5\x8a\xa0`K`\xe5\xb0\x9d\xe8\xaf\x95\xe3\x80\x82\n\n### 7\xe3\x80\x81\xe4\xbd\xbf\xe7\x94\xa8\xe5\xbb\xba\xe8\xae\xae\n- \xe4\xb8\x8d\xe8\xa6\x81\xe4\xbd\xbf\xe7\x94\xa8PCA\xe5\x8e\xbb\xe8\xa7\xa3\xe5\x86\xb3\xe8\xbf\x87\xe6\x8b\x9f\xe5\x90\x88\xe9\x97\xae\xe9\xa2\x98`Overfitting`\xef\xbc\x8c\xe8\xbf\x98\xe6\x98\xaf\xe4\xbd\xbf\xe7\x94\xa8\xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96\xe7\x9a\x84\xe6\x96\xb9\xe6\xb3\x95\xef\xbc\x88\xe5\xa6\x82\xe6\x9e\x9c\xe4\xbf\x9d\xe7\x95\x99\xe4\xba\x86\xe5\xbe\x88\xe9\xab\x98\xe7\x9a\x84\xe5\xb7\xae\xe5\xbc\x82\xe6\x80\xa7\xe8\xbf\x98\xe6\x98\xaf\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x9a\x84\xef\xbc\x89\n- \xe5\x8f\xaa\xe6\x9c\x89\xe5\x9c\xa8\xe5\x8e\x9f\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\x8a\xe6\x9c\x89\xe5\xa5\xbd\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xef\xbc\x8c\xe4\xbd\x86\xe6\x98\xaf\xe8\xbf\x90\xe8\xa1\x8c\xe5\xbe\x88\xe6\x85\xa2\xef\xbc\x8c\xe6\x89\x8d\xe8\x80\x83\xe8\x99\x91\xe4\xbd\xbf\xe7\x94\xa8PCA\n\n### 8\xe3\x80\x81\xe8\xbf\x90\xe8\xa1\x8c\xe7\xbb\x93\xe6\x9e\x9c\n- 2\xe7\xbb\xb4\xe6\x95\xb0\xe6\x8d\xae\xe9\x99\x8d\xe4\xb8\xba1\xe7\xbb\xb4\n - \xe8\xa6\x81\xe6\x8a\x95\xe5\xbd\xb1\xe7\x9a\x84\xe6\x96\xb9\xe5\x90\x91     \n![enter description here][44]\n - 2D\xe9\x99\x8d\xe4\xb8\xba1D\xe5\x8f\x8a\xe5\xaf\xb9\xe5\xba\x94\xe5\x85\xb3\xe7\xb3\xbb        \n![enter description here][45]\n- \xe4\xba\xba\xe8\x84\xb8\xe6\x95\xb0\xe6\x8d\xae\xe9\x99\x8d\xe7\xbb\xb4\n - \xe5\x8e\x9f\xe5\xa7\x8b\xe6\x95\xb0\xe6\x8d\xae         \n ![enter description here][46]\n - \xe5\x8f\xaf\xe8\xa7\x86\xe5\x8c\x96\xe9\x83\xa8\xe5\x88\x86`U`\xe7\x9f\xa9\xe9\x98\xb5\xe4\xbf\xa1\xe6\x81\xaf    \n ![enter description here][47]\n - \xe6\x81\xa2\xe5\xa4\x8d\xe6\x95\xb0\xe6\x8d\xae    \n ![enter description here][48]\n\n### 9\xe3\x80\x81[\xe4\xbd\xbf\xe7\x94\xa8scikit-learn\xe5\xba\x93\xe4\xb8\xad\xe7\x9a\x84PCA\xe5\xae\x9e\xe7\x8e\xb0\xe9\x99\x8d\xe7\xbb\xb4](/PCA/PCA.py_scikit-learn.py)\n- \xe5\xaf\xbc\xe5\x85\xa5\xe9\x9c\x80\xe8\xa6\x81\xe7\x9a\x84\xe5\x8c\x85\xef\xbc\x9a\n```\n#-*- coding: utf-8 -*-\n# Author:bob\n# Date:2016.12.22\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom scipy import io as spio\nfrom sklearn.decomposition import pca\nfrom sklearn.preprocessing import StandardScaler\n```\n- \xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe6\x95\xb0\xe6\x8d\xae\n```\n    \'\'\'\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe6\x95\xb0\xe6\x8d\xae\xe5\xb9\xb6\xe4\xbd\x9c\xe5\x9b\xbe\'\'\'\n    scaler = StandardScaler()\n    scaler.fit(X)\n    x_train = scaler.transform(X)\n```\n- \xe4\xbd\xbf\xe7\x94\xa8PCA\xe6\xa8\xa1\xe5\x9e\x8b\xe6\x8b\x9f\xe5\x90\x88\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe5\xb9\xb6\xe9\x99\x8d\xe7\xbb\xb4\n - `n_components`\xe5\xaf\xb9\xe5\xba\x94\xe8\xa6\x81\xe5\xb0\x86\xe7\x9a\x84\xe7\xbb\xb4\xe5\xba\xa6\n```\n    \'\'\'\xe6\x8b\x9f\xe5\x90\x88\xe6\x95\xb0\xe6\x8d\xae\'\'\'\n    K=1 # \xe8\xa6\x81\xe9\x99\x8d\xe7\x9a\x84\xe7\xbb\xb4\xe5\xba\xa6\n    model = pca.PCA(n_components=K).fit(x_train)   # \xe6\x8b\x9f\xe5\x90\x88\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8cn_components\xe5\xae\x9a\xe4\xb9\x89\xe8\xa6\x81\xe9\x99\x8d\xe7\x9a\x84\xe7\xbb\xb4\xe5\xba\xa6\n    Z = model.transform(x_train)    # transform\xe5\xb0\xb1\xe4\xbc\x9a\xe6\x89\xa7\xe8\xa1\x8c\xe9\x99\x8d\xe7\xbb\xb4\xe6\x93\x8d\xe4\xbd\x9c\n```\n\n- \xe6\x95\xb0\xe6\x8d\xae\xe6\x81\xa2\xe5\xa4\x8d\n - `model.components_`\xe4\xbc\x9a\xe5\xbe\x97\xe5\x88\xb0\xe9\x99\x8d\xe7\xbb\xb4\xe4\xbd\xbf\xe7\x94\xa8\xe7\x9a\x84`U`\xe7\x9f\xa9\xe9\x98\xb5 \n```\n    \'\'\'\xe6\x95\xb0\xe6\x8d\xae\xe6\x81\xa2\xe5\xa4\x8d\xe5\xb9\xb6\xe4\xbd\x9c\xe5\x9b\xbe\'\'\'\n    Ureduce = model.components_     # \xe5\xbe\x97\xe5\x88\xb0\xe9\x99\x8d\xe7\xbb\xb4\xe7\x94\xa8\xe7\x9a\x84Ureduce\n    x_rec = np.dot(Z,Ureduce)       # \xe6\x95\xb0\xe6\x8d\xae\xe6\x81\xa2\xe5\xa4\x8d\n```\n\n\n\n---------------------------------------------------------------\n\n\n## \xe4\xb8\x83\xe3\x80\x81\xe5\xbc\x82\xe5\xb8\xb8\xe6\xa3\x80\xe6\xb5\x8b Anomaly Detection\n- [\xe5\x85\xa8\xe9\x83\xa8\xe4\xbb\xa3\xe7\xa0\x81](/AnomalyDetection/AnomalyDetection.py)\n\n### 1\xe3\x80\x81\xe9\xab\x98\xe6\x96\xaf\xe5\x88\x86\xe5\xb8\x83\xef\xbc\x88\xe6\xad\xa3\xe6\x80\x81\xe5\x88\x86\xe5\xb8\x83\xef\xbc\x89`Gaussian distribution` \n- \xe5\x88\x86\xe5\xb8\x83\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x9a![$$p(x) = {1 \\over {\\sqrt {2\\pi } \\sigma }}{e^{ - {{{{(x - u)}^2}} \\over {2{\\sigma ^2}}}}}$$](http://latex.codecogs.com/png.latex?%5Cfn_cm%20%24%24p%28x%29%20%3D%20%7B1%20%5Cover%20%7B%5Csqrt%20%7B2%5Cpi%20%7D%20%5Csigma%20%7D%7D%7Be%5E%7B%20-%20%7B%7B%7B%7B%28x%20-%20u%29%7D%5E2%7D%7D%20%5Cover%20%7B2%7B%5Csigma%20%5E2%7D%7D%7D%7D%7D%24%24)\n - \xe5\x85\xb6\xe4\xb8\xad\xef\xbc\x8c`u`\xe4\xb8\xba\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84**\xe5\x9d\x87\xe5\x80\xbc**\xef\xbc\x8c`\xcf\x83`\xe4\xb8\xba\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84**\xe6\xa0\x87\xe5\x87\x86\xe5\xb7\xae**\n - `\xcf\x83`\xe8\xb6\x8a**\xe5\xb0\x8f**\xef\xbc\x8c\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe5\x9b\xbe\xe5\x83\x8f\xe8\xb6\x8a**\xe5\xb0\x96**\n- \xe5\x8f\x82\xe6\x95\xb0\xe4\xbc\xb0\xe8\xae\xa1\xef\xbc\x88`parameter estimation`\xef\xbc\x89\n - ![$$u = {1 \\over m}\\sum\\limits_{i = 1}^m {{x^{(i)}}} $$](http://latex.codecogs.com/png.latex?%5Cfn_cm%20%24%24u%20%3D%20%7B1%20%5Cover%20m%7D%5Csum%5Climits_%7Bi%20%3D%201%7D%5Em%20%7B%7Bx%5E%7B%28i%29%7D%7D%7D%20%24%24)\n - ![$${\\sigma ^2} = {1 \\over m}\\sum\\limits_{i = 1}^m {{{({x^{(i)}} - u)}^2}} $$](http://latex.codecogs.com/png.latex?%5Cfn_cm%20%24%24%7B%5Csigma%20%5E2%7D%20%3D%20%7B1%20%5Cover%20m%7D%5Csum%5Climits_%7Bi%20%3D%201%7D%5Em%20%7B%7B%7B%28%7Bx%5E%7B%28i%29%7D%7D%20-%20u%29%7D%5E2%7D%7D%20%24%24)\n\n### 2\xe3\x80\x81\xe5\xbc\x82\xe5\xb8\xb8\xe6\xa3\x80\xe6\xb5\x8b\xe7\xae\x97\xe6\xb3\x95\n- \xe4\xbe\x8b\xe5\xad\x90\n - \xe8\xae\xad\xe7\xbb\x83\xe9\x9b\x86\xef\xbc\x9a![$$\\{ {x^{(1)}},{x^{(2)}}, \\cdots {x^{(m)}}\\} $$](http://latex.codecogs.com/png.latex?%5Cfn_cm%20%24%24%5C%7B%20%7Bx%5E%7B%281%29%7D%7D%2C%7Bx%5E%7B%282%29%7D%7D%2C%20%5Ccdots%20%7Bx%5E%7B%28m%29%7D%7D%5C%7D%20%24%24),\xe5\x85\xb6\xe4\xb8\xad![$$x \\in {R^n}$$](http://latex.codecogs.com/png.latex?%5Cfn_cm%20%24%24x%20%5Cin%20%7BR%5En%7D%24%24)\n - \xe5\x81\x87\xe8\xae\xbe![$${x_1},{x_2} \\cdots {x_n}$$](http://latex.codecogs.com/png.latex?%5Cfn_cm%20%24%24%7Bx_1%7D%2C%7Bx_2%7D%20%5Ccdots%20%7Bx_n%7D%24%24)\xe7\x9b\xb8\xe4\xba\x92\xe7\x8b\xac\xe7\xab\x8b\xef\xbc\x8c\xe5\xbb\xba\xe7\xab\x8bmodel\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x9a![$$p(x) = p({x_1};{u_1},\\sigma _1^2)p({x_2};{u_2},\\sigma _2^2) \\cdots p({x_n};{u_n},\\sigma _n^2) = \\prod\\limits_{j = 1}^n {p({x_j};{u_j},\\sigma _j^2)} $$](http://latex.codecogs.com/png.latex?%5Cfn_cm%20%24%24p%28x%29%20%3D%20p%28%7Bx_1%7D%3B%7Bu_1%7D%2C%5Csigma%20_1%5E2%29p%28%7Bx_2%7D%3B%7Bu_2%7D%2C%5Csigma%20_2%5E2%29%20%5Ccdots%20p%28%7Bx_n%7D%3B%7Bu_n%7D%2C%5Csigma%20_n%5E2%29%20%3D%20%5Cprod%5Climits_%7Bj%20%3D%201%7D%5En%20%7Bp%28%7Bx_j%7D%3B%7Bu_j%7D%2C%5Csigma%20_j%5E2%29%7D%20%24%24)\n- \xe8\xbf\x87\xe7\xa8\x8b\n - \xe9\x80\x89\xe6\x8b\xa9\xe5\x85\xb7\xe6\x9c\x89\xe4\xbb\xa3\xe8\xa1\xa8\xe5\xbc\x82\xe5\xb8\xb8\xe7\x9a\x84`feature`:xi\n - \xe5\x8f\x82\xe6\x95\xb0\xe4\xbc\xb0\xe8\xae\xa1\xef\xbc\x9a![$${u_1},{u_2}, \\cdots ,{u_n};\\sigma _1^2,\\sigma _2^2 \\cdots ,\\sigma _n^2$$](http://latex.codecogs.com/png.latex?%5Cfn_cm%20%24%24%7Bu_1%7D%2C%7Bu_2%7D%2C%20%5Ccdots%20%2C%7Bu_n%7D%3B%5Csigma%20_1%5E2%2C%5Csigma%20_2%5E2%20%5Ccdots%20%2C%5Csigma%20_n%5E2%24%24)\n - \xe8\xae\xa1\xe7\xae\x97`p(x)`,\xe8\x8b\xa5\xe6\x98\xaf`P(x)<\xce\xb5`\xe5\x88\x99\xe8\xae\xa4\xe4\xb8\xba\xe5\xbc\x82\xe5\xb8\xb8\xef\xbc\x8c\xe5\x85\xb6\xe4\xb8\xad`\xce\xb5`\xe4\xb8\xba\xe6\x88\x91\xe4\xbb\xac\xe8\xa6\x81\xe6\xb1\x82\xe7\x9a\x84\xe6\xa6\x82\xe7\x8e\x87\xe7\x9a\x84\xe4\xb8\xb4\xe7\x95\x8c\xe5\x80\xbc`threshold`\n- \xe8\xbf\x99\xe9\x87\x8c\xe5\x8f\xaa\xe6\x98\xaf**\xe5\x8d\x95\xe5\x85\x83\xe9\xab\x98\xe6\x96\xaf\xe5\x88\x86\xe5\xb8\x83**\xef\xbc\x8c\xe5\x81\x87\xe8\xae\xbe\xe4\xba\x86`feature`\xe4\xb9\x8b\xe9\x97\xb4\xe6\x98\xaf\xe7\x8b\xac\xe7\xab\x8b\xe7\x9a\x84\xef\xbc\x8c\xe4\xb8\x8b\xe9\x9d\xa2\xe4\xbc\x9a\xe8\xae\xb2\xe5\x88\xb0**\xe5\xa4\x9a\xe5\x85\x83\xe9\xab\x98\xe6\x96\xaf\xe5\x88\x86\xe5\xb8\x83**\xef\xbc\x8c\xe4\xbc\x9a\xe8\x87\xaa\xe5\x8a\xa8\xe6\x8d\x95\xe6\x8d\x89\xe5\x88\xb0`feature`\xe4\xb9\x8b\xe9\x97\xb4\xe7\x9a\x84\xe5\x85\xb3\xe7\xb3\xbb\n- **\xe5\x8f\x82\xe6\x95\xb0\xe4\xbc\xb0\xe8\xae\xa1**\xe5\xae\x9e\xe7\x8e\xb0\xe4\xbb\xa3\xe7\xa0\x81\n```\n# \xe5\x8f\x82\xe6\x95\xb0\xe4\xbc\xb0\xe8\xae\xa1\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x88\xe5\xb0\xb1\xe6\x98\xaf\xe6\xb1\x82\xe5\x9d\x87\xe5\x80\xbc\xe5\x92\x8c\xe6\x96\xb9\xe5\xb7\xae\xef\xbc\x89\ndef estimateGaussian(X):\n    m,n = X.shape\n    mu = np.zeros((n,1))\n    sigma2 = np.zeros((n,1))\n    \n    mu = np.mean(X, axis=0) # axis=0\xe8\xa1\xa8\xe7\xa4\xba\xe5\x88\x97\xef\xbc\x8c\xe6\xaf\x8f\xe5\x88\x97\xe7\x9a\x84\xe5\x9d\x87\xe5\x80\xbc\n    sigma2 = np.var(X,axis=0) # \xe6\xb1\x82\xe6\xaf\x8f\xe5\x88\x97\xe7\x9a\x84\xe6\x96\xb9\xe5\xb7\xae\n    return mu,sigma2\n```\n\n### 3\xe3\x80\x81\xe8\xaf\x84\xe4\xbb\xb7`p(x)`\xe7\x9a\x84\xe5\xa5\xbd\xe5\x9d\x8f\xef\xbc\x8c\xe4\xbb\xa5\xe5\x8f\x8a`\xce\xb5`\xe7\x9a\x84\xe9\x80\x89\xe5\x8f\x96\n- \xe5\xaf\xb9**\xe5\x81\x8f\xe6\x96\x9c\xe6\x95\xb0\xe6\x8d\xae**\xe7\x9a\x84\xe9\x94\x99\xe8\xaf\xaf\xe5\xba\xa6\xe9\x87\x8f\n - \xe5\x9b\xa0\xe4\xb8\xba\xe6\x95\xb0\xe6\x8d\xae\xe5\x8f\xaf\xe8\x83\xbd\xe6\x98\xaf\xe9\x9d\x9e\xe5\xb8\xb8**\xe5\x81\x8f\xe6\x96\x9c**\xe7\x9a\x84\xef\xbc\x88\xe5\xb0\xb1\xe6\x98\xaf`y=1`\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\xe9\x9d\x9e\xe5\xb8\xb8\xe5\xb0\x91\xef\xbc\x8c(`y=1`\xe8\xa1\xa8\xe7\xa4\xba\xe5\xbc\x82\xe5\xb8\xb8)\xef\xbc\x89\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xe5\x8f\xaf\xe4\xbb\xa5\xe4\xbd\xbf\xe7\x94\xa8`Precision/Recall`\xef\xbc\x8c\xe8\xae\xa1\xe7\xae\x97`F1Score`(\xe5\x9c\xa8**CV\xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\xe9\x9b\x86**\xe4\xb8\x8a)\n - \xe4\xbe\x8b\xe5\xa6\x82\xef\xbc\x9a\xe9\xa2\x84\xe6\xb5\x8b\xe7\x99\x8c\xe7\x97\x87\xef\xbc\x8c\xe5\x81\x87\xe8\xae\xbe\xe6\xa8\xa1\xe5\x9e\x8b\xe5\x8f\xaf\xe4\xbb\xa5\xe5\xbe\x97\xe5\x88\xb0`99%`\xe8\x83\xbd\xe5\xa4\x9f\xe9\xa2\x84\xe6\xb5\x8b\xe6\xad\xa3\xe7\xa1\xae\xef\xbc\x8c`1%`\xe7\x9a\x84\xe9\x94\x99\xe8\xaf\xaf\xe7\x8e\x87\xef\xbc\x8c\xe4\xbd\x86\xe6\x98\xaf\xe5\xae\x9e\xe9\x99\x85\xe7\x99\x8c\xe7\x97\x87\xe7\x9a\x84\xe6\xa6\x82\xe7\x8e\x87\xe5\xbe\x88\xe5\xb0\x8f\xef\xbc\x8c\xe5\x8f\xaa\xe6\x9c\x89`0.5%`\xef\xbc\x8c\xe9\x82\xa3\xe4\xb9\x88\xe6\x88\x91\xe4\xbb\xac\xe5\xa7\x8b\xe7\xbb\x88\xe9\xa2\x84\xe6\xb5\x8b\xe6\xb2\xa1\xe6\x9c\x89\xe7\x99\x8c\xe7\x97\x87y=0\xe5\x8f\x8d\xe8\x80\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe5\xbe\x97\xe5\x88\xb0\xe6\x9b\xb4\xe5\xb0\x8f\xe7\x9a\x84\xe9\x94\x99\xe8\xaf\xaf\xe7\x8e\x87\xe3\x80\x82\xe4\xbd\xbf\xe7\x94\xa8`error rate`\xe6\x9d\xa5\xe8\xaf\x84\xe4\xbc\xb0\xe5\xb0\xb1\xe4\xb8\x8d\xe7\xa7\x91\xe5\xad\xa6\xe4\xba\x86\xe3\x80\x82\n - \xe5\xa6\x82\xe4\xb8\x8b\xe5\x9b\xbe\xe8\xae\xb0\xe5\xbd\x95\xef\xbc\x9a    \n ![enter description here][49]\n - ![$$\\Pr ecision = {{TP} \\over {TP + FP}}$$](http://latex.codecogs.com/png.latex?%5Cfn_cm%20%24%24%5CPr%20ecision%20%3D%20%7B%7BTP%7D%20%5Cover%20%7BTP%20&plus;%20FP%7D%7D%24%24) \xef\xbc\x8c\xe5\x8d\xb3\xef\xbc\x9a**\xe6\xad\xa3\xe7\xa1\xae\xe9\xa2\x84\xe6\xb5\x8b\xe6\xad\xa3\xe6\xa0\xb7\xe6\x9c\xac/\xe6\x89\x80\xe6\x9c\x89\xe9\xa2\x84\xe6\xb5\x8b\xe6\xad\xa3\xe6\xa0\xb7\xe6\x9c\xac**\n - ![$${\\mathop{\\rm Re}\\nolimits} {\\rm{call}} = {{TP} \\over {TP + FN}}$$](http://latex.codecogs.com/png.latex?%5Cfn_cm%20%24%24%7B%5Cmathop%7B%5Crm%20Re%7D%5Cnolimits%7D%20%7B%5Crm%7Bcall%7D%7D%20%3D%20%7B%7BTP%7D%20%5Cover%20%7BTP%20&plus;%20FN%7D%7D%24%24) \xef\xbc\x8c\xe5\x8d\xb3\xef\xbc\x9a**\xe6\xad\xa3\xe7\xa1\xae\xe9\xa2\x84\xe6\xb5\x8b\xe6\xad\xa3\xe6\xa0\xb7\xe6\x9c\xac/\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe4\xb8\xba\xe6\xad\xa3\xe6\xa0\xb7\xe6\x9c\xac**\n - \xe6\x80\xbb\xe6\x98\xaf\xe8\xae\xa9`y=1`(\xe8\xbe\x83\xe5\xb0\x91\xe7\x9a\x84\xe7\xb1\xbb)\xef\xbc\x8c\xe8\xae\xa1\xe7\xae\x97`Precision`\xe5\x92\x8c`Recall`\n - ![$${F_1}Score = 2{{PR} \\over {P + R}}$$](http://latex.codecogs.com/png.latex?%5Cfn_cm%20%24%24%7BF_1%7DScore%20%3D%202%7B%7BPR%7D%20%5Cover%20%7BP%20&plus;%20R%7D%7D%24%24)\n - \xe8\xbf\x98\xe6\x98\xaf\xe4\xbb\xa5\xe7\x99\x8c\xe7\x97\x87\xe9\xa2\x84\xe6\xb5\x8b\xe4\xb8\xba\xe4\xbe\x8b\xef\xbc\x8c\xe5\x81\x87\xe8\xae\xbe\xe9\xa2\x84\xe6\xb5\x8b\xe9\x83\xbd\xe6\x98\xafno-cancer\xef\xbc\x8cTN=199\xef\xbc\x8cFN=1\xef\xbc\x8cTP=0\xef\xbc\x8cFP=0\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xef\xbc\x9aPrecision=0/0\xef\xbc\x8cRecall=0/1=0\xef\xbc\x8c\xe5\xb0\xbd\xe7\xae\xa1accuracy=199/200=99.5%\xef\xbc\x8c\xe4\xbd\x86\xe6\x98\xaf\xe4\xb8\x8d\xe5\x8f\xaf\xe4\xbf\xa1\xe3\x80\x82\n\n- `\xce\xb5`\xe7\x9a\x84\xe9\x80\x89\xe5\x8f\x96\n - \xe5\xb0\x9d\xe8\xaf\x95\xe5\xa4\x9a\xe4\xb8\xaa`\xce\xb5`\xe5\x80\xbc\xef\xbc\x8c\xe4\xbd\xbf`F1Score`\xe7\x9a\x84\xe5\x80\xbc\xe9\xab\x98\n- \xe5\xae\x9e\xe7\x8e\xb0\xe4\xbb\xa3\xe7\xa0\x81\n```\n# \xe9\x80\x89\xe6\x8b\xa9\xe6\x9c\x80\xe4\xbc\x98\xe7\x9a\x84epsilon\xef\xbc\x8c\xe5\x8d\xb3\xef\xbc\x9a\xe4\xbd\xbfF1Score\xe6\x9c\x80\xe5\xa4\xa7    \ndef selectThreshold(yval,pval):\n    \'\'\'\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe6\x89\x80\xe9\x9c\x80\xe5\x8f\x98\xe9\x87\x8f\'\'\'\n    bestEpsilon = 0.\n    bestF1 = 0.\n    F1 = 0.\n    step = (np.max(pval)-np.min(pval))/1000\n    \'\'\'\xe8\xae\xa1\xe7\xae\x97\'\'\'\n    for epsilon in np.arange(np.min(pval),np.max(pval),step):\n        cvPrecision = pval<epsilon\n        tp = np.sum((cvPrecision == 1) & (yval == 1).ravel()).astype(float)  # sum\xe6\xb1\x82\xe5\x92\x8c\xe6\x98\xafint\xe5\x9e\x8b\xe7\x9a\x84\xef\xbc\x8c\xe9\x9c\x80\xe8\xa6\x81\xe8\xbd\xac\xe4\xb8\xbafloat\n        fp = np.sum((cvPrecision == 1) & (yval == 0).ravel()).astype(float)\n        fn = np.sum((cvPrecision == 0) & (yval == 1).ravel()).astype(float)\n        precision = tp/(tp+fp)  # \xe7\xb2\xbe\xe5\x87\x86\xe5\xba\xa6\n        recision = tp/(tp+fn)   # \xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\n        F1 = (2*precision*recision)/(precision+recision)  # F1Score\xe8\xae\xa1\xe7\xae\x97\xe5\x85\xac\xe5\xbc\x8f\n        if F1 > bestF1:  # \xe4\xbf\xae\xe6\x94\xb9\xe6\x9c\x80\xe4\xbc\x98\xe7\x9a\x84F1 Score\n            bestF1 = F1\n            bestEpsilon = epsilon\n    return bestEpsilon,bestF1\n```\n\n### 4\xe3\x80\x81\xe9\x80\x89\xe6\x8b\xa9\xe4\xbd\xbf\xe7\x94\xa8\xe4\xbb\x80\xe4\xb9\x88\xe6\xa0\xb7\xe7\x9a\x84feature\xef\xbc\x88\xe5\x8d\x95\xe5\x85\x83\xe9\xab\x98\xe6\x96\xaf\xe5\x88\x86\xe5\xb8\x83\xef\xbc\x89\n- \xe5\xa6\x82\xe6\x9e\x9c\xe4\xb8\x80\xe4\xba\x9b\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\x8d\xe6\x98\xaf\xe6\xbb\xa1\xe8\xb6\xb3\xe9\xab\x98\xe6\x96\xaf\xe5\x88\x86\xe5\xb8\x83\xe7\x9a\x84\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe5\x8f\x98\xe5\x8c\x96\xe4\xb8\x80\xe4\xb8\x8b\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe4\xbe\x8b\xe5\xa6\x82`log(x+C),x^(1/2)`\xe7\xad\x89\n- \xe5\xa6\x82\xe6\x9e\x9c`p(x)`\xe7\x9a\x84\xe5\x80\xbc\xe6\x97\xa0\xe8\xae\xba\xe5\xbc\x82\xe5\xb8\xb8\xe4\xb8\x8e\xe5\x90\xa6\xe9\x83\xbd\xe5\xbe\x88\xe5\xa4\xa7\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe5\xb0\x9d\xe8\xaf\x95\xe7\xbb\x84\xe5\x90\x88\xe5\xa4\x9a\xe4\xb8\xaa`feature`,(\xe5\x9b\xa0\xe4\xb8\xbafeature\xe4\xb9\x8b\xe9\x97\xb4\xe5\x8f\xaf\xe8\x83\xbd\xe6\x98\xaf\xe6\x9c\x89\xe5\x85\xb3\xe7\xb3\xbb\xe7\x9a\x84)\n\n### 5\xe3\x80\x81\xe5\xa4\x9a\xe5\x85\x83\xe9\xab\x98\xe6\x96\xaf\xe5\x88\x86\xe5\xb8\x83\n- \xe5\x8d\x95\xe5\x85\x83\xe9\xab\x98\xe6\x96\xaf\xe5\x88\x86\xe5\xb8\x83\xe5\xad\x98\xe5\x9c\xa8\xe7\x9a\x84\xe9\x97\xae\xe9\xa2\x98\n - \xe5\xa6\x82\xe4\xb8\x8b\xe5\x9b\xbe\xef\xbc\x8c\xe7\xba\xa2\xe8\x89\xb2\xe7\x9a\x84\xe7\x82\xb9\xe4\xb8\xba\xe5\xbc\x82\xe5\xb8\xb8\xe7\x82\xb9\xef\xbc\x8c\xe5\x85\xb6\xe4\xbb\x96\xe7\x9a\x84\xe9\x83\xbd\xe6\x98\xaf\xe6\xad\xa3\xe5\xb8\xb8\xe7\x82\xb9\xef\xbc\x88\xe6\xaf\x94\xe5\xa6\x82CPU\xe5\x92\x8cmemory\xe7\x9a\x84\xe5\x8f\x98\xe5\x8c\x96\xef\xbc\x89   \n ![enter description here][50]\n - x1\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe9\xab\x98\xe6\x96\xaf\xe5\x88\x86\xe5\xb8\x83\xe5\xa6\x82\xe4\xb8\x8b\xef\xbc\x9a   \n ![enter description here][51]\n - x2\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe9\xab\x98\xe6\x96\xaf\xe5\x88\x86\xe5\xb8\x83\xe5\xa6\x82\xe4\xb8\x8b\xef\xbc\x9a   \n ![enter description here][52]\n - \xe5\x8f\xaf\xe4\xbb\xa5\xe7\x9c\x8b\xe5\x87\xba\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84p(x1)\xe5\x92\x8cp(x2)\xe7\x9a\x84\xe5\x80\xbc\xe5\x8f\x98\xe5\x8c\x96\xe5\xb9\xb6\xe4\xb8\x8d\xe5\xa4\xa7\xef\xbc\x8c\xe5\xb0\xb1\xe4\xb8\x8d\xe4\xbc\x9a\xe8\xae\xa4\xe4\xb8\xba\xe5\xbc\x82\xe5\xb8\xb8\n - \xe5\x9b\xa0\xe4\xb8\xba\xe6\x88\x91\xe4\xbb\xac\xe8\xae\xa4\xe4\xb8\xbafeature\xe4\xb9\x8b\xe9\x97\xb4\xe6\x98\xaf\xe7\x9b\xb8\xe4\xba\x92\xe7\x8b\xac\xe7\xab\x8b\xe7\x9a\x84\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xe5\xa6\x82\xe4\xb8\x8a\xe5\x9b\xbe\xe6\x98\xaf\xe4\xbb\xa5**\xe6\xad\xa3\xe5\x9c\x86**\xe7\x9a\x84\xe6\x96\xb9\xe5\xbc\x8f\xe6\x89\xa9\xe5\xb1\x95\n- \xe5\xa4\x9a\xe5\x85\x83\xe9\xab\x98\xe6\x96\xaf\xe5\x88\x86\xe5\xb8\x83\n - ![$$x \\in {R^n}$$](http://latex.codecogs.com/png.latex?%5Cfn_cm%20%24%24x%20%5Cin%20%7BR%5En%7D%24%24)\xef\xbc\x8c\xe5\xb9\xb6\xe4\xb8\x8d\xe6\x98\xaf\xe5\xbb\xba\xe7\xab\x8b`p(x1),p(x2)...p(xn)`\xef\xbc\x8c\xe8\x80\x8c\xe6\x98\xaf\xe7\xbb\x9f\xe4\xb8\x80\xe5\xbb\xba\xe7\xab\x8b`p(x)`\n - \xe5\x85\xb6\xe4\xb8\xad\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x9a![$$\\mu  \\in {R^n},\\Sigma  \\in {R^{n \\times {\\rm{n}}}}$$](http://latex.codecogs.com/png.latex?%5Cfn_cm%20%24%24%5Cmu%20%5Cin%20%7BR%5En%7D%2C%5CSigma%20%5Cin%20%7BR%5E%7Bn%20%5Ctimes%20%7B%5Crm%7Bn%7D%7D%7D%7D%24%24),`\xce\xa3`\xe4\xb8\xba**\xe5\x8d\x8f\xe6\x96\xb9\xe5\xb7\xae\xe7\x9f\xa9\xe9\x98\xb5**\n - ![$$p(x) = {1 \\over {{{(2\\pi )}^{{n \\over 2}}}|\\Sigma {|^{{1 \\over 2}}}}}{e^{ - {1 \\over 2}{{(x - u)}^T}{\\Sigma ^{ - 1}}(x - u)}}$$](http://latex.codecogs.com/png.latex?%5Cfn_cm%20%24%24p%28x%29%20%3D%20%7B1%20%5Cover%20%7B%7B%7B%282%5Cpi%20%29%7D%5E%7B%7Bn%20%5Cover%202%7D%7D%7D%7C%5CSigma%20%7B%7C%5E%7B%7B1%20%5Cover%202%7D%7D%7D%7D%7D%7Be%5E%7B%20-%20%7B1%20%5Cover%202%7D%7B%7B%28x%20-%20u%29%7D%5ET%7D%7B%5CSigma%20%5E%7B%20-%201%7D%7D%28x%20-%20u%29%7D%7D%24%24)\n - \xe5\x90\x8c\xe6\xa0\xb7\xef\xbc\x8c`|\xce\xa3|`\xe8\xb6\x8a\xe5\xb0\x8f\xef\xbc\x8c`p(x)`\xe8\xb6\x8a\xe5\xb0\x96\n - \xe4\xbe\x8b\xe5\xa6\x82\xef\xbc\x9a    \n ![enter description here][53]\xef\xbc\x8c  \n \xe8\xa1\xa8\xe7\xa4\xbax1,x2**\xe6\xad\xa3\xe7\x9b\xb8\xe5\x85\xb3**\xef\xbc\x8c\xe5\x8d\xb3x1\xe8\xb6\x8a\xe5\xa4\xa7\xef\xbc\x8cx2\xe4\xb9\x9f\xe5\xb0\xb1\xe8\xb6\x8a\xe5\xa4\xa7\xef\xbc\x8c\xe5\xa6\x82\xe4\xb8\x8b\xe5\x9b\xbe\xef\xbc\x8c\xe4\xb9\x9f\xe5\xb0\xb1\xe5\x8f\xaf\xe4\xbb\xa5\xe5\xb0\x86\xe7\xba\xa2\xe8\x89\xb2\xe7\x9a\x84\xe5\xbc\x82\xe5\xb8\xb8\xe7\x82\xb9\xe6\xa3\x80\xe6\x9f\xa5\xe5\x87\xba\xe4\xba\x86\n ![enter description here][54]      \n \xe8\x8b\xa5\xef\xbc\x9a   \n  ![enter description here][55]\xef\xbc\x8c   \n \xe8\xa1\xa8\xe7\xa4\xbax1,x2**\xe8\xb4\x9f\xe7\x9b\xb8\xe5\x85\xb3**\n- \xe5\xae\x9e\xe7\x8e\xb0\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a\n```\n# \xe5\xa4\x9a\xe5\x85\x83\xe9\xab\x98\xe6\x96\xaf\xe5\x88\x86\xe5\xb8\x83\xe5\x87\xbd\xe6\x95\xb0    \ndef multivariateGaussian(X,mu,Sigma2):\n    k = len(mu)\n    if (Sigma2.shape[0]>1):\n        Sigma2 = np.diag(Sigma2)\n    \'\'\'\xe5\xa4\x9a\xe5\x85\x83\xe9\xab\x98\xe6\x96\xaf\xe5\x88\x86\xe5\xb8\x83\xe5\x87\xbd\xe6\x95\xb0\'\'\'    \n    X = X-mu\n    argu = (2*np.pi)**(-k/2)*np.linalg.det(Sigma2)**(-0.5)\n    p = argu*np.exp(-0.5*np.sum(np.dot(X,np.linalg.inv(Sigma2))*X,axis=1))  # axis\xe8\xa1\xa8\xe7\xa4\xba\xe6\xaf\x8f\xe8\xa1\x8c\n    return p\n```\n### 6\xe3\x80\x81\xe5\x8d\x95\xe5\x85\x83\xe5\x92\x8c\xe5\xa4\x9a\xe5\x85\x83\xe9\xab\x98\xe6\x96\xaf\xe5\x88\x86\xe5\xb8\x83\xe7\x89\xb9\xe7\x82\xb9\n- \xe5\x8d\x95\xe5\x85\x83\xe9\xab\x98\xe6\x96\xaf\xe5\x88\x86\xe5\xb8\x83\n - \xe4\xba\xba\xe4\xb8\xba\xe5\x8f\xaf\xe4\xbb\xa5\xe6\x8d\x95\xe6\x8d\x89\xe5\x88\xb0`feature`\xe4\xb9\x8b\xe9\x97\xb4\xe7\x9a\x84\xe5\x85\xb3\xe7\xb3\xbb\xe6\x97\xb6\xe5\x8f\xaf\xe4\xbb\xa5\xe4\xbd\xbf\xe7\x94\xa8\n - \xe8\xae\xa1\xe7\xae\x97\xe9\x87\x8f\xe5\xb0\x8f\n- \xe5\xa4\x9a\xe5\x85\x83\xe9\xab\x98\xe6\x96\xaf\xe5\x88\x86\xe5\xb8\x83\n - \xe8\x87\xaa\xe5\x8a\xa8\xe6\x8d\x95\xe6\x8d\x89\xe5\x88\xb0\xe7\x9b\xb8\xe5\x85\xb3\xe7\x9a\x84feature\n - \xe8\xae\xa1\xe7\xae\x97\xe9\x87\x8f\xe5\xa4\xa7\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xba\xef\xbc\x9a![$$\\Sigma  \\in {R^{n \\times {\\rm{n}}}}$$](http://latex.codecogs.com/png.latex?%5Cfn_cm%20%24%24%5CSigma%20%5Cin%20%7BR%5E%7Bn%20%5Ctimes%20%7B%5Crm%7Bn%7D%7D%7D%7D%24%24)\n - `m>n`\xe6\x88\x96`\xce\xa3`\xe5\x8f\xaf\xe9\x80\x86\xe6\x97\xb6\xe5\x8f\xaf\xe4\xbb\xa5\xe4\xbd\xbf\xe7\x94\xa8\xe3\x80\x82\xef\xbc\x88\xe8\x8b\xa5\xe4\xb8\x8d\xe5\x8f\xaf\xe9\x80\x86\xef\xbc\x8c\xe5\x8f\xaf\xe8\x83\xbd\xe6\x9c\x89\xe5\x86\x97\xe4\xbd\x99\xe7\x9a\x84x\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xba\xe7\xba\xbf\xe6\x80\xa7\xe7\x9b\xb8\xe5\x85\xb3\xef\xbc\x8c\xe4\xb8\x8d\xe5\x8f\xaf\xe9\x80\x86\xef\xbc\x8c\xe6\x88\x96\xe8\x80\x85\xe5\xb0\xb1\xe6\x98\xafm<n\xef\xbc\x89\n\n### 7\xe3\x80\x81\xe7\xa8\x8b\xe5\xba\x8f\xe8\xbf\x90\xe8\xa1\x8c\xe7\xbb\x93\xe6\x9e\x9c\n- \xe6\x98\xbe\xe7\xa4\xba\xe6\x95\xb0\xe6\x8d\xae     \n![enter description here][56]\n- \xe7\xad\x89\xe9\xab\x98\xe7\xba\xbf      \n![enter description here][57]\n- \xe5\xbc\x82\xe5\xb8\xb8\xe7\x82\xb9\xe6\xa0\x87\xe6\xb3\xa8   \n![enter description here][58]\n\n\n\n----------------------------------\n\n\n  [1]: ./images/LinearRegression_01.png ""LinearRegression_01.png""\n  [2]: ./images/LogisticRegression_01.png ""LogisticRegression_01.png""\n  [3]: ./images/LogisticRegression_02.png ""LogisticRegression_02.png""\n  [4]: ./images/LogisticRegression_03.jpg ""LogisticRegression_03.jpg""\n  [5]: ./images/LogisticRegression_04.png ""LogisticRegression_04.png""\n  [6]: ./images/LogisticRegression_05.png ""LogisticRegression_05.png""\n  [7]: ./images/LogisticRegression_06.png ""LogisticRegression_06.png""\n  [8]: ./images/LogisticRegression_07.png ""LogisticRegression_07.png""\n  [9]: ./images/LogisticRegression_08.png ""LogisticRegression_08.png""\n  [10]: ./images/LogisticRegression_09.png ""LogisticRegression_09.png""\n  [11]: ./images/LogisticRegression_11.png ""LogisticRegression_11.png""\n  [12]: ./images/LogisticRegression_10.png ""LogisticRegression_10.png""\n  [13]: ./images/LogisticRegression_12.png ""LogisticRegression_12.png""\n  [14]: ./images/LogisticRegression_13.png ""LogisticRegression_13.png""\n  [15]: ./images/NeuralNetwork_01.png ""NeuralNetwork_01.png""\n  [16]: ./images/NeuralNetwork_02.png ""NeuralNetwork_02.png""\n  [17]: ./images/NeuralNetwork_03.jpg ""NeuralNetwork_03.jpg""\n  [18]: ./images/NeuralNetwork_04.png ""NeuralNetwork_04.png""\n  [19]: ./images/NeuralNetwork_05.png ""NeuralNetwork_05.png""\n  [20]: ./images/NeuralNetwork_06.png ""NeuralNetwork_06.png""\n  [21]: ./images/NeuralNetwork_07.png ""NeuralNetwork_07.png""\n  [22]: ./images/NeuralNetwork_08.png ""NeuralNetwork_08.png""\n  [23]: ./images/NeuralNetwork_09.png ""NeuralNetwork_09.png""\n  [24]: ./images/SVM_01.png ""SVM_01.png""\n  [25]: ./images/SVM_02.png ""SVM_02.png""\n  [26]: ./images/SVM_03.png ""SVM_03.png""\n  [27]: ./images/SVM_04.png ""SVM_04.png""\n  [28]: ./images/SVM_05.png ""SVM_05.png""\n  [29]: ./images/SVM_06.png ""SVM_06.png""\n  [30]: ./images/SVM_07.png ""SVM_07.png""\n  [31]: ./images/SVM_08.png ""SVM_08.png""\n  [32]: ./images/SVM_09.png ""SVM_09.png""\n  [33]: ./images/SVM_10.png ""SVM_10.png""\n  [34]: ./images/K-Means_01.png ""K-Means_01.png""\n  [35]: ./images/K-Means_02.png ""K-Means_02.png""\n  [36]: ./images/K-Means_03.png ""K-Means_03.png""\n  [37]: ./images/K-Means_07.png ""K-Means_07.png""\n  [38]: ./images/K-Means_04.png ""K-Means_04.png""\n  [39]: ./images/K-Means_05.png ""K-Means_05.png""\n  [40]: ./images/K-Means_06.png ""K-Means_06.png""\n  [41]: ./images/PCA_01.png ""PCA_01.png""\n  [42]: ./images/PCA_02.png ""PCA_02.png""\n  [43]: ./images/PCA_03.png ""PCA_03.png""\n  [44]: ./images/PCA_04.png ""PCA_04.png""\n  [45]: ./images/PCA_05.png ""PCA_05.png""\n  [46]: ./images/PCA_06.png ""PCA_06.png""\n  [47]: ./images/PCA_07.png ""PCA_07.png""\n  [48]: ./images/PCA_08.png ""PCA_08.png""\n  [49]: ./images/AnomalyDetection_01.png ""AnomalyDetection_01.png""\n  [50]: ./images/AnomalyDetection_04.png ""AnomalyDetection_04.png""\n  [51]: ./images/AnomalyDetection_02.png ""AnomalyDetection_02.png""\n  [52]: ./images/AnomalyDetection_03.png ""AnomalyDetection_03.png""\n  [53]: ./images/AnomalyDetection_05.png ""AnomalyDetection_05.png""\n  [54]: ./images/AnomalyDetection_07.png ""AnomalyDetection_07.png""\n  [55]: ./images/AnomalyDetection_06.png ""AnomalyDetection_06.png""\n  [56]: ./images/AnomalyDetection_08.png ""AnomalyDetection_08.png""\n  [57]: ./images/AnomalyDetection_09.png ""AnomalyDetection_09.png""\n  [58]: ./images/AnomalyDetection_10.png ""AnomalyDetection_10.png""\n'"
7,Jack-Cherish/Machine-Learning,Jack-Cherish,:zap:机器学习实战（Python3）：kNN、决策树、贝叶斯、逻辑回归、SVM、线性回归、树回归,2017-03-25 07:32:37,2020-06-18 20:50:12,HTML,2804,2964,"b'# Machine-Learning\n* [In English](https://github.com/Jack-Cherish/Machine-Learning/blob/master/README-eng.md ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"")<br>\n\n\xe5\x8e\x9f\xe5\x88\x9b\xe6\x96\x87\xe7\xab\xa0\xe6\xaf\x8f\xe5\x91\xa8\xe6\x9c\x80\xe5\xb0\x91\xe4\xb8\xa4\xe7\xaf\x87\xef\xbc\x8c**\xe5\x90\x8e\xe7\xbb\xad\xe6\x9c\x80\xe6\x96\xb0\xe6\x96\x87\xe7\xab\xa0**\xe4\xbc\x9a\xe5\x9c\xa8[\xe3\x80\x90\xe5\x85\xac\xe4\xbc\x97\xe5\x8f\xb7\xe3\x80\x91](#\xe5\x85\xac\xe4\xbc\x97\xe5\x8f\xb7)\xe9\xa6\x96\xe5\x8f\x91\xef\xbc\x8c\xe5\xa4\xa7\xe5\xae\xb6\xe5\x8f\xaf\xe4\xbb\xa5\xe5\x8a\xa0\xe6\x88\x91[\xe3\x80\x90\xe5\xbe\xae\xe4\xbf\xa1\xe3\x80\x91](#\xe5\xbe\xae\xe4\xbf\xa1)\xe8\xbf\x9b**\xe4\xba\xa4\xe6\xb5\x81\xe7\xbe\xa4**\xef\xbc\x8c\xe6\x8a\x80\xe6\x9c\xaf\xe4\xba\xa4\xe6\xb5\x81\xe6\x88\x96\xe6\x8f\x90\xe6\x84\x8f\xe8\xa7\x81\xe9\x83\xbd\xe5\x8f\xaf\xe4\xbb\xa5\xef\xbc\x8c\xe6\xac\xa2\xe8\xbf\x8e**Star**\xef\xbc\x81\n\n<p align=""center"">\n  <a href=""#\xe5\xbe\xae\xe4\xbf\xa1"" target=""_blank""><img src=""https://img.shields.io/badge/weChat-\xe5\xbe\xae\xe4\xbf\xa1\xe7\xbe\xa4-blue.svg"" alt=""\xe5\xbe\xae\xe4\xbf\xa1\xe7\xbe\xa4""></a>\n  <a href=""#\xe5\x85\xac\xe4\xbc\x97\xe5\x8f\xb7"" target=""_blank""><img src=""https://img.shields.io/badge/%E5%85%AC%E4%BC%97%E5%8F%B7-Jack%20Cui-lightgrey.svg"" alt=""\xe5\x85\xac\xe4\xbc\x97\xe5\x8f\xb7""></a>\n  <a href=""https://blog.csdn.net/c406495762"" target=""_blank""><img src=""https://img.shields.io/badge/csdn-CSDN-red.svg"" alt=""\xe6\x8a\x95\xe7\xa8\xbf""></a>\n  <a href=""https://www.zhihu.com/people/Jack--Cui"" target=""_blank""><img src=""https://img.shields.io/badge/zhihu-\xe7\x9f\xa5\xe4\xb9\x8e-informational"" alt=""\xe6\x8a\x95\xe7\xa8\xbf""></a>\n  <a href=""https://juejin.im/user/5ea2ca74e51d4546b50d5f9f"" target=""_blank""><img src=""https://img.shields.io/badge/juejin-\xe6\x8e\x98\xe9\x87\x91-blue.svg"" alt=""\xe6\x8a\x95\xe7\xa8\xbf""></a>\n</p>\n\t\n### \xe6\x96\x87\xe7\xab\xa0\xe9\xa6\x96\xe5\x8f\x91\xe5\xa3\xb0\xe6\x98\x8e\n\n* \xe6\x96\x87\xe7\xab\xa0\xe5\x9c\xa8\xe8\x87\xaa\xe5\xb7\xb1\xe7\x9a\x84\xe4\xb8\xaa\xe4\xba\xba\xe7\xbd\x91\xe7\xab\x99\xe9\xa6\x96\xe5\x8f\x91\xef\xbc\x8c\xe5\x85\xb6\xe4\xbb\x96\xe5\xb9\xb3\xe5\x8f\xb0\xe6\x96\x87\xe7\xab\xa0\xe5\x9d\x87\xe5\xb1\x9e\xe8\xbd\xac\xe5\x8f\x91\xef\xbc\x8c\xe5\xa6\x82\xe6\x83\xb3\xe8\x8e\xb7\xe5\xbe\x97\xe6\x9c\x80\xe6\x96\xb0\xe6\x9b\xb4\xe6\x96\xb0\xe8\xbf\x9b\xe5\xb1\x95\xef\xbc\x8c\xe6\xac\xa2\xe8\xbf\x8e\xe5\x85\xb3\xe6\xb3\xa8\xe6\x88\x91\xe7\x9a\x84\xe4\xb8\xaa\xe4\xba\xba\xe7\xbd\x91\xe7\xab\x99\xef\xbc\x9ahttp://cuijiahua.com/\n\n## \xe7\xac\xac\xe4\xba\x8c\xe7\xab\xa0\xef\xbc\x9akNN\xef\xbc\x88k-\xe9\x82\xbb\xe5\x9f\x9f\xe7\xae\x97\xe6\xb3\x95\xef\xbc\x89\n\n|   \xe6\x96\x87\xe7\xab\xa0   |  \xe4\xb8\xaa\xe4\xba\xba\xe7\xbd\x91\xe7\xab\x99  |    CSDN    |    \xe7\x9f\xa5\xe4\xb9\x8e    |\n| :------  | :--------: | :--------: | :--------: |\n| Python3\xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xae\x9e\xe6\x88\x98\xe3\x80\x8b\xe5\xad\xa6\xe4\xb9\xa0\xe7\xac\x94\xe8\xae\xb0(\xe4\xb8\x80)\xef\xbc\x9ak-\xe8\xbf\x91\xe9\x82\xbb\xe7\xae\x97\xe6\xb3\x95(\xe5\x8f\xb2\xe8\xaf\x97\xe7\xba\xa7\xe5\xb9\xb2\xe8\xb4\xa7\xe9\x95\xbf\xe6\x96\x87) | [\xe4\xb8\xaa\xe4\xba\xba\xe7\xbd\x91\xe7\xab\x99](http://cuijiahua.com/blog/2017/11/ml_1_knn.html ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") | [CSDN](http://blog.csdn.net/c406495762/article/details/75172850 ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") | [\xe7\x9f\xa5\xe4\xb9\x8e](https://zhuanlan.zhihu.com/p/28656126 ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") |\n\n\n### \xe4\xbb\xa3\xe7\xa0\x81\n\n* [1.\xe7\xae\x80\xe5\x8d\x95k-NN](https://github.com/Jack-Cherish/Machine-Learning/tree/master/kNN/1.%E7%AE%80%E5%8D%95k-NN ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"")\n\n* [2.\xe6\xb5\xb7\xe4\xbc\xa6\xe7\xba\xa6\xe4\xbc\x9a](https://github.com/Jack-Cherish/Machine-Learning/tree/master/kNN/2.%E6%B5%B7%E4%BC%A6%E7%BA%A6%E4%BC%9A ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"")\n\n* [3.\xe6\x95\xb0\xe5\xad\x97\xe8\xaf\x86\xe5\x88\xab](https://github.com/Jack-Cherish/Machine-Learning/tree/master/kNN/3.%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"")\n\n## \xe7\xac\xac\xe4\xb8\x89\xe7\xab\xa0\xef\xbc\x9aDecision Tree\xef\xbc\x88\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xef\xbc\x89\n\n|   \xe6\x96\x87\xe7\xab\xa0   |  \xe4\xb8\xaa\xe4\xba\xba\xe7\xbd\x91\xe7\xab\x99  |    CSDN    |    \xe7\x9f\xa5\xe4\xb9\x8e    |\n| :------  | :--------: | :--------: | :--------: |\n| Python3\xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xae\x9e\xe6\x88\x98\xe3\x80\x8b\xe5\xad\xa6\xe4\xb9\xa0\xe7\xac\x94\xe8\xae\xb0(\xe4\xba\x8c)\xef\xbc\x9a\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe5\x9f\xba\xe7\xa1\x80\xe7\xaf\x87\xe4\xb9\x8b\xe8\xae\xa9\xe6\x88\x91\xe4\xbb\xac\xe4\xbb\x8e\xe7\x9b\xb8\xe4\xba\xb2\xe8\xaf\xb4\xe8\xb5\xb7 | [\xe4\xb8\xaa\xe4\xba\xba\xe7\xbd\x91\xe7\xab\x99](http://cuijiahua.com/blog/2017/11/ml_2_decision_tree_1.html ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") | [CSDN](http://blog.csdn.net/c406495762/article/details/75663451 ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") | [\xe7\x9f\xa5\xe4\xb9\x8e](https://zhuanlan.zhihu.com/p/28688281 ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") |\n| Python3\xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xae\x9e\xe6\x88\x98\xe3\x80\x8b\xe5\xad\xa6\xe4\xb9\xa0\xe7\xac\x94\xe8\xae\xb0(\xe4\xb8\x89)\xef\xbc\x9a\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe5\xae\x9e\xe6\x88\x98\xe7\xaf\x87\xe4\xb9\x8b\xe4\xb8\xba\xe8\x87\xaa\xe5\xb7\xb1\xe9\x85\x8d\xe4\xb8\xaa\xe9\x9a\x90\xe5\xbd\xa2\xe7\x9c\xbc\xe9\x95\x9c | [\xe4\xb8\xaa\xe4\xba\xba\xe7\xbd\x91\xe7\xab\x99](http://cuijiahua.com/blog/2017/11/ml_3_decision_tree_2.html ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") | [CSDN](http://blog.csdn.net/c406495762/article/details/76262487 ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") | [\xe7\x9f\xa5\xe4\xb9\x8e](https://zhuanlan.zhihu.com/p/28714382 ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") |\n\n### \xe4\xbb\xa3\xe7\xa0\x81\n  \n* [1.\xe8\xb4\xb7\xe6\xac\xbe\xe9\xa2\x84\xe6\xb5\x8b](https://github.com/Jack-Cherish/Machine-Learning/blob/master/Decision%20Tree/Decision%20Tree.py ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"")\n\n* [2.\xe9\x9a\x90\xe5\xbd\xa2\xe7\x9c\xbc\xe9\x95\x9c](https://github.com/Jack-Cherish/Machine-Learning/blob/master/Decision%20Tree/Sklearn-Decision%20Tree.py ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"")\n\n## \xe7\xac\xac\xe5\x9b\x9b\xe7\xab\xa0\xef\xbc\x9aNavie Bayes\xef\xbc\x88\xe6\x9c\xb4\xe7\xb4\xa0\xe8\xb4\x9d\xe5\x8f\xb6\xe6\x96\xaf\xef\xbc\x89\n\n|   \xe6\x96\x87\xe7\xab\xa0   |  \xe4\xb8\xaa\xe4\xba\xba\xe7\xbd\x91\xe7\xab\x99  |    CSDN    |    \xe7\x9f\xa5\xe4\xb9\x8e    |\n| :------  | :--------: | :--------: | :--------: |\n| Python3\xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xae\x9e\xe6\x88\x98\xe3\x80\x8b\xe5\xad\xa6\xe4\xb9\xa0\xe7\xac\x94\xe8\xae\xb0\xef\xbc\x88\xe5\x9b\x9b\xef\xbc\x89\xef\xbc\x9a\xe6\x9c\xb4\xe7\xb4\xa0\xe8\xb4\x9d\xe5\x8f\xb6\xe6\x96\xaf\xe5\x9f\xba\xe7\xa1\x80\xe7\xaf\x87\xe4\xb9\x8b\xe8\xa8\x80\xe8\xae\xba\xe8\xbf\x87\xe6\xbb\xa4\xe5\x99\xa8 | [\xe4\xb8\xaa\xe4\xba\xba\xe7\xbd\x91\xe7\xab\x99](http://cuijiahua.com/blog/2017/11/ml_4_bayes_1.html ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") | [CSDN](http://blog.csdn.net/c406495762/article/details/77341116 ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") | [\xe7\x9f\xa5\xe4\xb9\x8e](https://zhuanlan.zhihu.com/p/28719332 ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") |\n| Python3\xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xae\x9e\xe6\x88\x98\xe3\x80\x8b\xe5\xad\xa6\xe4\xb9\xa0\xe7\xac\x94\xe8\xae\xb0\xef\xbc\x88\xe4\xba\x94\xef\xbc\x89\xef\xbc\x9a\xe6\x9c\xb4\xe7\xb4\xa0\xe8\xb4\x9d\xe5\x8f\xb6\xe6\x96\xaf\xe5\xae\x9e\xe6\x88\x98\xe7\xaf\x87\xe4\xb9\x8b\xe6\x96\xb0\xe6\xb5\xaa\xe6\x96\xb0\xe9\x97\xbb\xe5\x88\x86\xe7\xb1\xbb | [\xe4\xb8\xaa\xe4\xba\xba\xe7\xbd\x91\xe7\xab\x99](http://cuijiahua.com/blog/2017/11/ml_5_bayes_2.html ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") | [CSDN](http://blog.csdn.net/c406495762/article/details/77500679 ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") | [\xe7\x9f\xa5\xe4\xb9\x8e](https://zhuanlan.zhihu.com/p/28720393 ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") |\n\n### \xe4\xbb\xa3\xe7\xa0\x81\n  \n* [1.\xe8\xa8\x80\xe8\xae\xba\xe8\xbf\x87\xe6\xbb\xa4\xe5\x99\xa8](https://github.com/Jack-Cherish/Machine-Learning/blob/master/Naive%20Bayes/bayes.py ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"")\n\n* [2.\xe5\x9e\x83\xe5\x9c\xbe\xe9\x82\xae\xe4\xbb\xb6\xe8\xbf\x87\xe6\xbb\xa4\xe5\x99\xa8](https://github.com/Jack-Cherish/Machine-Learning/blob/master/Naive%20Bayes/bayes-modify.py ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"")\n\n* [3.\xe6\x96\xb0\xe6\xb5\xaa\xe6\x96\xb0\xe9\x97\xbb\xe5\x88\x86\xe7\xb1\xbb\xe5\x99\xa8](https://github.com/Jack-Cherish/Machine-Learning/blob/master/Naive%20Bayes/nbc.py ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"")\n  \n## \xe7\xac\xac\xe4\xba\x94\xe7\xab\xa0\xef\xbc\x9aLogistic\xef\xbc\x88Logistic\xe5\x9b\x9e\xe5\xbd\x92\xef\xbc\x89\n\n|   \xe6\x96\x87\xe7\xab\xa0   |  \xe4\xb8\xaa\xe4\xba\xba\xe7\xbd\x91\xe7\xab\x99  |    CSDN    |    \xe7\x9f\xa5\xe4\xb9\x8e    |\n| :------  | :--------: | :--------: | :--------: |\n| Python3\xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xae\x9e\xe6\x88\x98\xe3\x80\x8b\xe5\xad\xa6\xe4\xb9\xa0\xe7\xac\x94\xe8\xae\xb0\xef\xbc\x88\xe5\x85\xad\xef\xbc\x89\xef\xbc\x9aLogistic\xe5\x9b\x9e\xe5\xbd\x92\xe5\x9f\xba\xe7\xa1\x80\xe7\xaf\x87\xe4\xb9\x8b\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8a\xe5\x8d\x87\xe7\xae\x97\xe6\xb3\x95 | [\xe4\xb8\xaa\xe4\xba\xba\xe7\xbd\x91\xe7\xab\x99](http://cuijiahua.com/blog/2017/11/ml_6_logistic_1.html ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") | [CSDN](http://blog.csdn.net/c406495762/article/details/77723333 ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") | [\xe7\x9f\xa5\xe4\xb9\x8e](https://zhuanlan.zhihu.com/p/28922957 ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") |\n| Python3\xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xae\x9e\xe6\x88\x98\xe3\x80\x8b\xe5\xad\xa6\xe4\xb9\xa0\xe7\xac\x94\xe8\xae\xb0\xef\xbc\x88\xe4\xb8\x83\xef\xbc\x89\xef\xbc\x9aLogistic\xe5\x9b\x9e\xe5\xbd\x92\xe5\xae\x9e\xe6\x88\x98\xe7\xaf\x87\xe4\xb9\x8b\xe9\xa2\x84\xe6\xb5\x8b\xe7\x97\x85\xe9\xa9\xac\xe6\xad\xbb\xe4\xba\xa1\xe7\x8e\x87 | [\xe4\xb8\xaa\xe4\xba\xba\xe7\xbd\x91\xe7\xab\x99](http://cuijiahua.com/blog/2017/11/ml_7_logistic_2.html ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") | [CSDN](http://blog.csdn.net/c406495762/article/details/77851973 ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") | [\xe7\x9f\xa5\xe4\xb9\x8e](https://zhuanlan.zhihu.com/p/29073560 ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") |\n\n### \xe4\xbb\xa3\xe7\xa0\x81\n\n* [1.Logistic\xe5\x9f\xba\xe7\xa1\x80\xe8\xae\xad\xe7\xbb\x83](https://github.com/Jack-Cherish/Machine-Learning/blob/master/Logistic/LogRegres.py ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"")\n\n* [2.\xe6\x94\xb9\xe8\xbf\x9b\xe7\x9a\x84\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8a\xe5\x8d\x87\xe7\xae\x97\xe6\xb3\x95](https://github.com/Jack-Cherish/Machine-Learning/blob/master/Logistic/LogRegres-gj.py ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"")\n\n* [3.\xe7\x97\x85\xe9\xa9\xac\xe6\xad\xbb\xe4\xba\xa1\xe7\x8e\x87\xe9\xa2\x84\xe6\xb5\x8b](https://github.com/Jack-Cherish/Machine-Learning/blob/master/Logistic/colicLogRegres.py ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"")\n\n## \xe7\xac\xac\xe5\x85\xad\xe7\xab\xa0\xef\xbc\x9aSVM\xef\xbc\x88\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba\xef\xbc\x89\n\n|   \xe6\x96\x87\xe7\xab\xa0   |  \xe4\xb8\xaa\xe4\xba\xba\xe7\xbd\x91\xe7\xab\x99  |    CSDN    |    \xe7\x9f\xa5\xe4\xb9\x8e    |\n| :------  | :--------: | :--------: | :--------: |\n| Python3\xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xae\x9e\xe6\x88\x98\xe3\x80\x8b\xe5\xad\xa6\xe4\xb9\xa0\xe7\xac\x94\xe8\xae\xb0\xef\xbc\x88\xe5\x85\xab\xef\xbc\x89\xef\xbc\x9a\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba\xe5\x8e\x9f\xe7\x90\x86\xe7\xaf\x87\xe4\xb9\x8b\xe6\x89\x8b\xe6\x92\x95\xe7\xba\xbf\xe6\x80\xa7SVM | [\xe4\xb8\xaa\xe4\xba\xba\xe7\xbd\x91\xe7\xab\x99](http://cuijiahua.com/blog/2017/11/ml_8_svm_1.html ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") | [CSDN](http://blog.csdn.net/c406495762/article/details/78072313 ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") | [\xe7\x9f\xa5\xe4\xb9\x8e](https://zhuanlan.zhihu.com/p/29604517 ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") |\n| Python3\xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xae\x9e\xe6\x88\x98\xe3\x80\x8b\xe5\xad\xa6\xe4\xb9\xa0\xe7\xac\x94\xe8\xae\xb0\xef\xbc\x88\xe4\xb9\x9d\xef\xbc\x89\xef\xbc\x9a\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba\xe5\xae\x9e\xe6\x88\x98\xe7\xaf\x87\xe4\xb9\x8b\xe5\x86\x8d\xe6\x92\x95\xe9\x9d\x9e\xe7\xba\xbf\xe6\x80\xa7SVM | [\xe4\xb8\xaa\xe4\xba\xba\xe7\xbd\x91\xe7\xab\x99](http://cuijiahua.com/blog/2017/11/ml_9_svm_2.html ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") | [CSDN](http://blog.csdn.net/c406495762/article/details/78158354 ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") | [\xe7\x9f\xa5\xe4\xb9\x8e](https://zhuanlan.zhihu.com/p/29872905 ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") |\n\n### \xe4\xbb\xa3\xe7\xa0\x81\n\n* [1.\xe7\xae\x80\xe5\x8c\x96\xe7\x89\x88SMO\xe7\xae\x97\xe6\xb3\x95](https://github.com/Jack-Cherish/Machine-Learning/blob/master/SVM/svm-simple.py ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"")\n\n* [2.\xe5\xae\x8c\xe6\x95\xb4\xe7\x89\x88SMO\xe7\xae\x97\xe6\xb3\x95](https://github.com/Jack-Cherish/Machine-Learning/blob/master/SVM/svm-smo.py ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"")\n\n* [3.\xe9\x9d\x9e\xe7\xba\xbf\xe6\x80\xa7SVM](https://github.com/Jack-Cherish/Machine-Learning/blob/master/SVM/svmMLiA.py ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"")\n\n* [4.Sklearn SVC\xe6\x89\x8b\xe5\x86\x99\xe6\x95\xb0\xe5\xad\x97\xe8\xaf\x86\xe5\x88\xab](https://github.com/Jack-Cherish/Machine-Learning/blob/master/SVM/svm-svc.py ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"")\n\n## \xe7\xac\xac\xe4\xb8\x83\xe7\xab\xa0\xef\xbc\x9aAdaBoost\n\n|   \xe6\x96\x87\xe7\xab\xa0   |  \xe4\xb8\xaa\xe4\xba\xba\xe7\xbd\x91\xe7\xab\x99  |    CSDN    |    \xe7\x9f\xa5\xe4\xb9\x8e    |\n| :------  | :--------: | :--------: | :--------: |\n| Python3\xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xae\x9e\xe6\x88\x98\xe3\x80\x8b\xe5\xad\xa6\xe4\xb9\xa0\xe7\xac\x94\xe8\xae\xb0\xef\xbc\x88\xe5\x8d\x81\xef\xbc\x89\xef\xbc\x9a\xe6\x8f\x90\xe5\x8d\x87\xe5\x88\x86\xe7\xb1\xbb\xe5\x99\xa8\xe6\x80\xa7\xe8\x83\xbd\xe5\x88\xa9\xe5\x99\xa8-AdaBoost | [\xe4\xb8\xaa\xe4\xba\xba\xe7\xbd\x91\xe7\xab\x99](http://cuijiahua.com/blog/2017/11/ml_10_adaboost.html ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") | [CSDN](http://blog.csdn.net/c406495762/article/details/78212124 ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") | [\xe7\x9f\xa5\xe4\xb9\x8e](https://zhuanlan.zhihu.com/p/30035094 ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") |\n\n### \xe4\xbb\xa3\xe7\xa0\x81\n\n* [1.\xe5\x9f\xba\xe4\xba\x8e\xe5\x8d\x95\xe5\xb1\x82\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe7\x9a\x84AdaBoost\xe8\xae\xad\xe7\xbb\x83\xe8\xbf\x87\xe7\xa8\x8b](https://github.com/Jack-Cherish/Machine-Learning/blob/master/AdaBoost/adaboost.py ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"")\n\n* [2.\xe5\x9c\xa8\xe9\x9a\xbe\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe4\xb8\x8a\xe5\xba\x94\xe7\x94\xa8AdaBoost](https://github.com/Jack-Cherish/Machine-Learning/blob/master/AdaBoost/horse_adaboost.py ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"")\n\n* [3.sklearn\xe5\xae\x9e\xe7\x8e\xb0AdaBoost](https://github.com/Jack-Cherish/Machine-Learning/blob/master/AdaBoost/sklearn_adaboost.py ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"")\n\n* [4.ROC\xe6\x9b\xb2\xe7\xba\xbf\xe7\xbb\x98\xe5\x88\xb6](https://github.com/Jack-Cherish/Machine-Learning/blob/master/AdaBoost/ROC.py ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"")\n\n## \xe7\xac\xac\xe5\x85\xab\xe7\xab\xa0\xef\xbc\x9aRegression\n\n|   \xe6\x96\x87\xe7\xab\xa0   |  \xe4\xb8\xaa\xe4\xba\xba\xe7\xbd\x91\xe7\xab\x99  |    CSDN    |    \xe7\x9f\xa5\xe4\xb9\x8e    |\n| :------  | :--------: | :--------: | :--------: |\n| Python3\xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xae\x9e\xe6\x88\x98\xe3\x80\x8b\xe5\xad\xa6\xe4\xb9\xa0\xe7\xac\x94\xe8\xae\xb0\xef\xbc\x88\xe5\x8d\x81\xe4\xb8\x80\xef\xbc\x89\xef\xbc\x9a\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe5\x9f\xba\xe7\xa1\x80\xe7\xaf\x87\xe4\xb9\x8b\xe9\xa2\x84\xe6\xb5\x8b\xe9\xb2\x8d\xe9\xb1\xbc\xe5\xb9\xb4\xe9\xbe\x84 | [\xe4\xb8\xaa\xe4\xba\xba\xe7\xbd\x91\xe7\xab\x99](http://cuijiahua.com/blog/2017/11/ml_11_regression_1.html ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") |[CSDN](http://blog.csdn.net/c406495762/article/details/78760239 ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") | [\xe7\x9f\xa5\xe4\xb9\x8e](https://zhuanlan.zhihu.com/p/31860100  ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"")|\n| Python3\xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xae\x9e\xe6\x88\x98\xe3\x80\x8b\xe5\xad\xa6\xe4\xb9\xa0\xe7\xac\x94\xe8\xae\xb0\xef\xbc\x88\xe5\x8d\x81\xe4\xba\x8c\xef\xbc\x89\xef\xbc\x9a\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe6\x8f\x90\xe9\xab\x98\xe7\xaf\x87\xe4\xb9\x8b\xe4\xb9\x90\xe9\xab\x98\xe7\x8e\xa9\xe5\x85\xb7\xe5\xa5\x97\xe4\xbb\xb6\xe4\xba\x8c\xe6\x89\x8b\xe4\xbb\xb7\xe9\xa2\x84\xe6\xb5\x8b | [\xe4\xb8\xaa\xe4\xba\xba\xe7\xbd\x91\xe7\xab\x99](http://cuijiahua.com/blog/2017/12/ml_12_regression_2.html ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") | no | no |\n\n### \xe4\xbb\xa3\xe7\xa0\x81\n\n* [1.\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92(\xe6\x99\xae\xe9\x80\x9a\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92+\xe5\xb1\x80\xe9\x83\xa8\xe5\x8a\xa0\xe6\x9d\x83\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92)](https://github.com/Jack-Cherish/Machine-Learning/blob/master/Regression/regression_old.py ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"")\n\n* [2.\xe9\xa2\x84\xe6\xb5\x8b\xe9\xb2\x8d\xe9\xb1\xbc\xe5\xb9\xb4\xe9\xbe\x84](https://github.com/Jack-Cherish/Machine-Learning/blob/master/Regression/abalone.py ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"")\n\n* [3.\xe9\x80\x90\xe6\xad\xa5\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92](https://github.com/Jack-Cherish/Machine-Learning/blob/master/Regression/regression.py ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"")\n\n* [4.\xe4\xb9\x90\xe9\xab\x98\xe7\x8e\xa9\xe5\x85\xb7\xe4\xba\x8c\xe6\x89\x8b\xe4\xbb\xb7\xe6\xa0\xbc\xe9\xa2\x84\xe6\xb5\x8b](https://github.com/Jack-Cherish/Machine-Learning/blob/master/Regression/lego.py ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"")\n\n## \xe7\xac\xac\xe4\xb9\x9d\xe7\xab\xa0\xef\xbc\x9aRegression Tree\n\n|   \xe6\x96\x87\xe7\xab\xa0   |  \xe4\xb8\xaa\xe4\xba\xba\xe7\xbd\x91\xe7\xab\x99  |    CSDN    |    \xe7\x9f\xa5\xe4\xb9\x8e    |\n| :------  | :--------: | :--------: | :--------: |\n| Python3\xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xae\x9e\xe6\x88\x98\xe3\x80\x8b\xe5\xad\xa6\xe4\xb9\xa0\xe7\xac\x94\xe8\xae\xb0\xef\xbc\x88\xe5\x8d\x81\xe4\xb8\x89\xef\xbc\x89\xef\xbc\x9a\xe6\xa0\x91\xe5\x9b\x9e\xe5\xbd\x92\xe5\x9f\xba\xe7\xa1\x80\xe7\xaf\x87\xe4\xb9\x8bCART\xe7\xae\x97\xe6\xb3\x95\xe4\xb8\x8e\xe6\xa0\x91\xe5\x89\xaa\xe6\x9e\x9d | [\xe4\xb8\xaa\xe4\xba\xba\xe7\xbd\x91\xe7\xab\x99](http://cuijiahua.com/blog/2017/12/ml_13_regtree_1.html ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"") | no | no |\n\n\n### \xe4\xbb\xa3\xe7\xa0\x81\n\n* [1.\xe6\xa0\x91\xe5\x9b\x9e\xe5\xbd\x92](https://github.com/Jack-Cherish/Machine-Learning/blob/master/Regression%20Trees/regTrees.py ""\xe6\x82\xac\xe5\x81\x9c\xe6\x98\xbe\xe7\xa4\xba"")\n\n\xe6\x9b\xb4\xe5\xa4\x9a\xe7\xb2\xbe\xe5\xbd\xa9\xef\xbc\x8c\xe6\x95\xac\xe8\xaf\xb7\xe6\x9c\x9f\xe5\xbe\x85\xef\xbc\x81\n\n<a name=""\xe5\xbe\xae\xe4\xbf\xa1""></a>  <a name=""\xe5\x85\xac\xe4\xbc\x97\xe5\x8f\xb7""></a>\n\n![\xe5\x85\xac\xe4\xbc\x97\xe5\x8f\xb7](https://cuijiahua.com/wp-content/uploads/2020/05/gzh-w.jpg)\n'"
8,ujjwalkarn/Machine-Learning-Tutorials,ujjwalkarn,"machine learning and deep learning tutorials, articles and other resources ",2015-09-12 14:51:38,2020-06-18 14:20:07,,3165,10374,"b'\n# Machine Learning & Deep Learning Tutorials [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)\n\n- This repository contains a topic-wise curated list of Machine Learning and Deep Learning tutorials, articles and other resources. Other awesome lists can be found in this [list](https://github.com/sindresorhus/awesome).\n\n- If you want to contribute to this list, please read [Contributing Guidelines](https://github.com/ujjwalkarn/Machine-Learning-Tutorials/blob/master/contributing.md).\n\n- [Curated list of R tutorials for Data Science, NLP and Machine Learning](https://github.com/ujjwalkarn/DataScienceR).\n\n- [Curated list of Python tutorials for Data Science, NLP and Machine Learning](https://github.com/ujjwalkarn/DataSciencePython).\n\n\n## Contents\n- [Introduction](#general)\n- [Interview Resources](#interview)\n- [Artificial Intelligence](#ai)\n- [Genetic Algorithms](#ga)\n- [Statistics](#stat)\n- [Useful Blogs](#blogs)\n- [Resources on Quora](#quora)\n- [Resources on Kaggle](#kaggle)\n- [Cheat Sheets](#cs)\n- [Classification](#classification)\n- [Linear Regression](#linear)\n- [Logistic Regression](#logistic)\n- [Model Validation using Resampling](#validation)\n    - [Cross Validation](#cross)\n    - [Bootstraping](#boot)\n- [Deep Learning](#deep)\n    - [Frameworks](#frame)\n    - [Feed Forward Networks](#feed)\n    - [Recurrent Neural Nets, LSTM, GRU](#rnn)\n    - [Restricted Boltzmann Machine, DBNs](#rbm)\n    - [Autoencoders](#auto)\n    - [Convolutional Neural Nets](#cnn)\n    - [Graph Representation Learning](#nrl)\n- [Natural Language Processing](#nlp)\n    - [Topic Modeling, LDA](#topic)\n    - [Word2Vec](#word2vec)\n- [Computer Vision](#vision)\n- [Support Vector Machine](#svm)\n- [Reinforcement Learning](#rl)\n- [Decision Trees](#dt)\n- [Random Forest / Bagging](#rf)\n- [Boosting](#gbm)\n- [Ensembles](#ensem)\n- [Stacking Models](#stack)\n- [VC Dimension](#vc)\n- [Bayesian Machine Learning](#bayes)\n- [Semi Supervised Learning](#semi)\n- [Optimizations](#opt)\n- [Other Useful Tutorials](#other)\n\n<a name=""general"" />\n\n## Introduction\n\n- [Machine Learning Course by Andrew Ng (Stanford University)](https://www.coursera.org/learn/machine-learning)\n\n- [Curated List of Machine Learning Resources](https://hackr.io/tutorials/learn-machine-learning-ml)\n\n- [In-depth introduction to machine learning in 15 hours of expert videos](http://www.dataschool.io/15-hours-of-expert-machine-learning-videos/)\n\n- [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/)\n\n- [List of Machine Learning University Courses](https://github.com/prakhar1989/awesome-courses#machine-learning)\n\n- [Machine Learning for Software Engineers](https://github.com/ZuzooVn/machine-learning-for-software-engineers)\n\n- [Dive into Machine Learning](https://github.com/hangtwenty/dive-into-machine-learning)\n\n- [A curated list of awesome Machine Learning frameworks, libraries and software](https://github.com/josephmisiti/awesome-machine-learning)\n\n- [A curated list of awesome data visualization libraries and resources.](https://github.com/fasouto/awesome-dataviz)\n\n- [An awesome Data Science repository to learn and apply for real world problems](https://github.com/okulbilisim/awesome-datascience)\n\n- [The Open Source Data Science Masters](http://datasciencemasters.org/)\n\n- [Machine Learning FAQs on Cross Validated](http://stats.stackexchange.com/questions/tagged/machine-learning)\n\n- [Machine Learning algorithms that you should always have a strong understanding of](https://www.quora.com/What-are-some-Machine-Learning-algorithms-that-you-should-always-have-a-strong-understanding-of-and-why)\n\n- [Difference between Linearly Independent, Orthogonal, and Uncorrelated Variables](http://terpconnect.umd.edu/~bmomen/BIOM621/LineardepCorrOrthogonal.pdf)\n\n- [List of Machine Learning Concepts](https://en.wikipedia.org/wiki/List_of_machine_learning_concepts)\n\n- [Slides on Several Machine Learning Topics](http://www.slideshare.net/pierluca.lanzi/presentations)\n\n- [MIT Machine Learning Lecture Slides](http://www.ai.mit.edu/courses/6.867-f04/lectures.html)\n\n- [Comparison Supervised Learning Algorithms](http://www.dataschool.io/comparing-supervised-learning-algorithms/)\n\n- [Learning Data Science Fundamentals](http://www.dataschool.io/learning-data-science-fundamentals/)\n\n- [Machine Learning mistakes to avoid](https://medium.com/@nomadic_mind/new-to-machine-learning-avoid-these-three-mistakes-73258b3848a4#.lih061l3l)\n\n- [Statistical Machine Learning Course](http://www.stat.cmu.edu/~larry/=sml/)\n\n- [TheAnalyticsEdge edX Notes and Codes](https://github.com/pedrosan/TheAnalyticsEdge)\n\n- [Have Fun With Machine Learning](https://github.com/humphd/have-fun-with-machine-learning)\n\n- [Twitter\'s Most Shared #machineLearning Content From The Past 7 Days](http://theherdlocker.com/tweet/popularity/machinelearning)\n\n<a name=""interview"" />\n\n## Interview Resources\n\n- [41 Essential Machine Learning Interview Questions (with answers)](https://www.springboard.com/blog/machine-learning-interview-questions/)\n\n- [How can a computer science graduate student prepare himself for data scientist interviews?](https://www.quora.com/How-can-a-computer-science-graduate-student-prepare-himself-for-data-scientist-machine-learning-intern-interviews)\n\n- [How do I learn Machine Learning?](https://www.quora.com/How-do-I-learn-machine-learning-1)\n\n- [FAQs about Data Science Interviews](https://www.quora.com/topic/Data-Science-Interviews/faq)\n\n- [What are the key skills of a data scientist?](https://www.quora.com/What-are-the-key-skills-of-a-data-scientist)\n\n- [The Big List of DS/ML Interview Resources](https://towardsdatascience.com/the-big-list-of-ds-ml-interview-resources-2db4f651bd63)\n\n<a name=""ai"" />\n\n## Artificial Intelligence\n\n- [Awesome Artificial Intelligence (GitHub Repo)](https://github.com/owainlewis/awesome-artificial-intelligence)\n\n- [UC Berkeley CS188 Intro to AI](http://ai.berkeley.edu/home.html), [Lecture Videos](http://ai.berkeley.edu/lecture_videos.html), [2](https://www.youtube.com/watch?v=W1S-HSakPTM)\n\n- [Programming Community Curated Resources for learning Artificial Intelligence](https://hackr.io/tutorials/learn-artificial-intelligence-ai) \n\n- [MIT 6.034 Artificial Intelligence Lecture Videos](https://www.youtube.com/playlist?list=PLUl4u3cNGP63gFHB6xb-kVBiQHYe_4hSi), [Complete Course](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/)\n\n- [edX course | Klein & Abbeel](https://courses.edx.org/courses/BerkeleyX/CS188x_1/1T2013/info)\n\n- [Udacity Course | Norvig & Thrun](https://www.udacity.com/course/intro-to-artificial-intelligence--cs271)\n\n- [TED talks on AI](http://www.ted.com/playlists/310/talks_on_artificial_intelligen)\n\n<a name=""ga"" />\n\n## Genetic Algorithms\n\n- [Genetic Algorithms Wikipedia Page](https://en.wikipedia.org/wiki/Genetic_algorithm)\n\n- [Simple Implementation of Genetic Algorithms in Python (Part 1)](http://outlace.com/miniga.html), [Part 2](http://outlace.com/miniga_addendum.html)\n\n- [Genetic Algorithms vs Artificial Neural Networks](http://stackoverflow.com/questions/1402370/when-to-use-genetic-algorithms-vs-when-to-use-neural-networks)\n\n- [Genetic Algorithms Explained in Plain English](http://www.ai-junkie.com/ga/intro/gat1.html)\n\n- [Genetic Programming](https://en.wikipedia.org/wiki/Genetic_programming)\n\n    - [Genetic Programming in Python (GitHub)](https://github.com/trevorstephens/gplearn)\n    \n    - [Genetic Alogorithms vs Genetic Programming (Quora)](https://www.quora.com/Whats-the-difference-between-Genetic-Algorithms-and-Genetic-Programming), [StackOverflow](http://stackoverflow.com/questions/3819977/what-are-the-differences-between-genetic-algorithms-and-genetic-programming)\n\n<a name=""stat"" />\n\n## Statistics\n\n- [Stat Trek Website](http://stattrek.com/) - A dedicated website to teach yourselves Statistics\n\n- [Learn Statistics Using Python](https://github.com/rouseguy/intro2stats) - Learn Statistics using an application-centric programming approach\n\n- [Statistics for Hackers | Slides | @jakevdp](https://speakerdeck.com/jakevdp/statistics-for-hackers) - Slides by Jake VanderPlas\n\n- [Online Statistics Book](http://onlinestatbook.com/2/index.html) - An Interactive Multimedia Course for Studying Statistics\n\n- [What is a Sampling Distribution?](http://stattrek.com/sampling/sampling-distribution.aspx)\n\n- Tutorials\n\n    - [AP Statistics Tutorial](http://stattrek.com/tutorials/ap-statistics-tutorial.aspx)\n    \n    - [Statistics and Probability Tutorial](http://stattrek.com/tutorials/statistics-tutorial.aspx)\n    \n    - [Matrix Algebra Tutorial](http://stattrek.com/tutorials/matrix-algebra-tutorial.aspx)\n    \n- [What is an Unbiased Estimator?](https://www.physicsforums.com/threads/what-is-an-unbiased-estimator.547728/)\n\n- [Goodness of Fit Explained](https://en.wikipedia.org/wiki/Goodness_of_fit)\n\n- [What are QQ Plots?](http://onlinestatbook.com/2/advanced_graphs/q-q_plots.html)\n\n- [OpenIntro Statistics](https://www.openintro.org/stat/textbook.php?stat_book=os) - Free PDF textbook\n\n<a name=""blogs"" />\n\n## Useful Blogs\n\n- [Edwin Chen\'s Blog](http://blog.echen.me/) - A blog about Math, stats, ML, crowdsourcing, data science\n\n- [The Data School Blog](http://www.dataschool.io/) - Data science for beginners!\n\n- [ML Wave](http://mlwave.com/) - A blog for Learning Machine Learning\n\n- [Andrej Karpathy](http://karpathy.github.io/) - A blog about Deep Learning and Data Science in general\n\n- [Colah\'s Blog](http://colah.github.io/) - Awesome Neural Networks Blog\n\n- [Alex Minnaar\'s Blog](http://alexminnaar.com/) - A blog about Machine Learning and Software Engineering\n\n- [Statistically Significant](http://andland.github.io/) - Andrew Landgraf\'s Data Science Blog\n\n- [Simply Statistics](http://simplystatistics.org/) - A blog by three biostatistics professors\n\n- [Yanir Seroussi\'s Blog](https://yanirseroussi.com/) - A blog about Data Science and beyond\n\n- [fastML](http://fastml.com/) - Machine learning made easy\n\n- [Trevor Stephens Blog](http://trevorstephens.com/) - Trevor Stephens Personal Page\n\n- [no free hunch | kaggle](http://blog.kaggle.com/) - The Kaggle Blog about all things Data Science\n\n- [A Quantitative Journey | outlace](http://outlace.com/) -  learning quantitative applications\n\n- [r4stats](http://r4stats.com/) - analyze the world of data science, and to help people learn to use R\n\n- [Variance Explained](http://varianceexplained.org/) - David Robinson\'s Blog\n\n- [AI Junkie](http://www.ai-junkie.com/) - a blog about Artificial Intellingence\n\n- [Deep Learning Blog by Tim Dettmers](http://timdettmers.com/) - Making deep learning accessible\n\n- [J Alammar\'s Blog](http://jalammar.github.io/)- Blog posts about Machine Learning and Neural Nets\n\n- [Adam Geitgey](https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471#.f7vwrtfne) - Easiest Introduction to machine learning\n\n- [Ethen\'s Notebook Collection](https://github.com/ethen8181/machine-learning) - Continuously updated machine learning documentations (mainly in Python3). Contents include educational implementation of machine learning algorithms from scratch and open-source library usage\n\n<a name=""quora"" />\n\n## Resources on Quora\n\n- [Most Viewed Machine Learning writers](https://www.quora.com/topic/Machine-Learning/writers)\n\n- [Data Science Topic on Quora](https://www.quora.com/Data-Science)\n\n- [William Chen\'s Answers](https://www.quora.com/William-Chen-6/answers)\n\n- [Michael Hochster\'s Answers](https://www.quora.com/Michael-Hochster/answers)\n\n- [Ricardo Vladimiro\'s Answers](https://www.quora.com/Ricardo-Vladimiro-1/answers)\n\n- [Storytelling with Statistics](https://datastories.quora.com/)\n\n- [Data Science FAQs on Quora](https://www.quora.com/topic/Data-Science/faq)\n\n- [Machine Learning FAQs on Quora](https://www.quora.com/topic/Machine-Learning/faq)\n\n<a name=""kaggle"" />\n\n## Kaggle Competitions WriteUp\n\n- [How to almost win Kaggle Competitions](https://yanirseroussi.com/2014/08/24/how-to-almost-win-kaggle-competitions/)\n\n- [Convolution Neural Networks for EEG detection](http://blog.kaggle.com/2015/10/05/grasp-and-lift-eeg-detection-winners-interview-3rd-place-team-hedj/)\n\n- [Facebook Recruiting III Explained](http://alexminnaar.com/tag/kaggle-competitions.html)\n\n- [Predicting CTR with Online ML](http://mlwave.com/predicting-click-through-rates-with-online-machine-learning/)\n\n- [How to Rank 10% in Your First Kaggle Competition](https://dnc1994.com/2016/05/rank-10-percent-in-first-kaggle-competition-en/)\n\n<a name=""cs"" />\n\n## Cheat Sheets\n\n- [Probability Cheat Sheet](http://static1.squarespace.com/static/54bf3241e4b0f0d81bf7ff36/t/55e9494fe4b011aed10e48e5/1441352015658/probability_cheatsheet.pdf),\n[Source](http://www.wzchen.com/probability-cheatsheet/)\n\n- [Machine Learning Cheat Sheet](https://github.com/soulmachine/machine-learning-cheat-sheet)\n\n- [ML Compiled](https://ml-compiled.readthedocs.io/en/latest/)\n\n<a name=""classification"" />\n\n## Classification\n\n- [Does Balancing Classes Improve Classifier Performance?](http://www.win-vector.com/blog/2015/02/does-balancing-classes-improve-classifier-performance/)\n\n- [What is Deviance?](http://stats.stackexchange.com/questions/6581/what-is-deviance-specifically-in-cart-rpart)\n\n- [When to choose which machine learning classifier?](http://stackoverflow.com/questions/2595176/when-to-choose-which-machine-learning-classifier)\n\n- [What are the advantages of different classification algorithms?](https://www.quora.com/What-are-the-advantages-of-different-classification-algorithms)\n\n- [ROC and AUC Explained](http://www.dataschool.io/roc-curves-and-auc-explained/) ([related video](https://youtu.be/OAl6eAyP-yo))\n\n- [An introduction to ROC analysis](https://ccrma.stanford.edu/workshops/mir2009/references/ROCintro.pdf)\n\n- [Simple guide to confusion matrix terminology](http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/)\n\n\n<a name=""linear"" />\n\n## Linear Regression\n\n- [General](#general-)\n\n    - [Assumptions of Linear Regression](http://pareonline.net/getvn.asp?n=2&v=8), [Stack Exchange](http://stats.stackexchange.com/questions/16381/what-is-a-complete-list-of-the-usual-assumptions-for-linear-regression)\n    \n    - [Linear Regression Comprehensive Resource](http://people.duke.edu/~rnau/regintro.htm)\n    \n    - [Applying and Interpreting Linear Regression](http://www.dataschool.io/applying-and-interpreting-linear-regression/)\n    \n    - [What does having constant variance in a linear regression model mean?](http://stats.stackexchange.com/questions/52089/what-does-having-constant-variance-in-a-linear-regression-model-mean/52107?stw=2#52107)\n    \n    - [Difference between linear regression on y with x and x with y](http://stats.stackexchange.com/questions/22718/what-is-the-difference-between-linear-regression-on-y-with-x-and-x-with-y?lq=1)\n    \n    - [Is linear regression valid when the dependant variable is not normally distributed?](https://www.researchgate.net/post/Is_linear_regression_valid_when_the_outcome_dependant_variable_not_normally_distributed)\n- Multicollinearity and VIF\n\n    - [Dummy Variable Trap | Multicollinearity](https://en.wikipedia.org/wiki/Multicollinearity)\n    \n    - [Dealing with multicollinearity using VIFs](https://jonlefcheck.net/2012/12/28/dealing-with-multicollinearity-using-variance-inflation-factors/)\n\n- [Residual Analysis](#residuals-)\n\n    - [Interpreting plot.lm() in R](http://stats.stackexchange.com/questions/58141/interpreting-plot-lm)\n    \n    - [How to interpret a QQ plot?](http://stats.stackexchange.com/questions/101274/how-to-interpret-a-qq-plot?lq=1)\n    \n    - [Interpreting Residuals vs Fitted Plot](http://stats.stackexchange.com/questions/76226/interpreting-the-residuals-vs-fitted-values-plot-for-verifying-the-assumptions)\n\n- [Outliers](#outliers-)\n\n    - [How should outliers be dealt with?](http://stats.stackexchange.com/questions/175/how-should-outliers-be-dealt-with-in-linear-regression-analysis)\n\n- [Elastic Net](https://en.wikipedia.org/wiki/Elastic_net_regularization)\n    - [Regularization and Variable Selection via the\nElastic Net](https://web.stanford.edu/~hastie/Papers/elasticnet.pdf)\n\n<a name=""logistic"" />\n\n## Logistic Regression\n\n- [Logistic Regression Wiki](https://en.wikipedia.org/wiki/Logistic_regression)\n\n- [Geometric Intuition of Logistic Regression](http://florianhartl.com/logistic-regression-geometric-intuition.html)\n\n- [Obtaining predicted categories (choosing threshold)](http://stats.stackexchange.com/questions/25389/obtaining-predicted-values-y-1-or-0-from-a-logistic-regression-model-fit)\n\n- [Residuals in logistic regression](http://stats.stackexchange.com/questions/1432/what-do-the-residuals-in-a-logistic-regression-mean)\n\n- [Difference between logit and probit models](http://stats.stackexchange.com/questions/20523/difference-between-logit-and-probit-models#30909), [Logistic Regression Wiki](https://en.wikipedia.org/wiki/Logistic_regression), [Probit Model Wiki](https://en.wikipedia.org/wiki/Probit_model)\n\n- [Pseudo R2 for Logistic Regression](http://stats.stackexchange.com/questions/3559/which-pseudo-r2-measure-is-the-one-to-report-for-logistic-regression-cox-s), [How to calculate](http://stats.stackexchange.com/questions/8511/how-to-calculate-pseudo-r2-from-rs-logistic-regression), [Other Details](http://www.ats.ucla.edu/stat/mult_pkg/faq/general/Psuedo_RSquareds.htm)\n\n- [Guide to an in-depth understanding of logistic regression](http://www.dataschool.io/guide-to-logistic-regression/)\n\n<a name=""validation"" />\n\n## Model Validation using Resampling\n\n- [Resampling Explained](https://en.wikipedia.org/wiki/Resampling_(statistics))\n\n- [Partioning data set in R](http://stackoverflow.com/questions/13536537/partitioning-data-set-in-r-based-on-multiple-classes-of-observations)\n\n- [Implementing hold-out Validaion in R](http://stackoverflow.com/questions/22972854/how-to-implement-a-hold-out-validation-in-r), [2](http://www.gettinggeneticsdone.com/2011/02/split-data-frame-into-testing-and.html)\n\n<a name=""cross"" />\n\n- [Cross Validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics))\n    - [How to use cross-validation in predictive modeling](http://stuartlacy.co.uk/2016/02/04/how-to-correctly-use-cross-validation-in-predictive-modelling/)\n    - [Training with Full dataset after CV?](http://stats.stackexchange.com/questions/11602/training-with-the-full-dataset-after-cross-validation)\n    \n    - [Which CV method is best?](http://stats.stackexchange.com/questions/103459/how-do-i-know-which-method-of-cross-validation-is-best)\n    \n    - [Variance Estimates in k-fold CV](http://stats.stackexchange.com/questions/31190/variance-estimates-in-k-fold-cross-validation)\n    \n    - [Is CV a subsitute for Validation Set?](http://stats.stackexchange.com/questions/18856/is-cross-validation-a-proper-substitute-for-validation-set)\n    \n    - [Choice of k in k-fold CV](http://stats.stackexchange.com/questions/27730/choice-of-k-in-k-fold-cross-validation)\n    \n    - [CV for ensemble learning](http://stats.stackexchange.com/questions/102631/k-fold-cross-validation-of-ensemble-learning)\n    \n    - [k-fold CV in R](http://stackoverflow.com/questions/22909197/creating-folds-for-k-fold-cv-in-r-using-caret)\n    \n    - [Good Resources](http://www.chioka.in/tag/cross-validation/)\n    \n    - Overfitting and Cross Validation\n    \n        - [Preventing Overfitting the Cross Validation Data | Andrew Ng](http://ai.stanford.edu/~ang/papers/cv-final.pdf)\n        \n        - [Over-fitting in Model Selection and Subsequent Selection Bias in Performance Evaluation](http://www.jmlr.org/papers/volume11/cawley10a/cawley10a.pdf)\n\n        - [CV for detecting and preventing Overfitting](http://www.autonlab.org/tutorials/overfit10.pdf)\n        \n        - [How does CV overcome the Overfitting Problem](http://stats.stackexchange.com/questions/9053/how-does-cross-validation-overcome-the-overfitting-problem)\n\n\n<a name=""boot"" />\n\n- [Bootstrapping](https://en.wikipedia.org/wiki/Bootstrapping_(statistics))\n\n    - [Why Bootstrapping Works?](http://stats.stackexchange.com/questions/26088/explaining-to-laypeople-why-bootstrapping-works)\n    \n    - [Good Animation](https://www.stat.auckland.ac.nz/~wild/BootAnim/)\n    \n    - [Example of Bootstapping](http://statistics.about.com/od/Applications/a/Example-Of-Bootstrapping.htm)\n    \n    - [Understanding Bootstapping for Validation and Model Selection](http://stats.stackexchange.com/questions/14516/understanding-bootstrapping-for-validation-and-model-selection?rq=1)\n    \n    - [Cross Validation vs Bootstrap to estimate prediction error](http://stats.stackexchange.com/questions/18348/differences-between-cross-validation-and-bootstrapping-to-estimate-the-predictio), [Cross-validation vs .632 bootstrapping to evaluate classification performance](http://stats.stackexchange.com/questions/71184/cross-validation-or-bootstrapping-to-evaluate-classification-performance)\n\n\n<a name=""deep"" />\n\n## Deep Learning\n\n- [fast.ai - Practical Deep Learning For Coders](http://course.fast.ai/)\n\n- [fast.ai - Cutting Edge Deep Learning For Coders](http://course.fast.ai/part2.html)\n\n- [A curated list of awesome Deep Learning tutorials, projects and communities](https://github.com/ChristosChristofidis/awesome-deep-learning)\n\n- **[Deep Learning Papers Reading Roadmap](https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap/blob/master/README.md)**\n\n- [Lots of Deep Learning Resources](http://deeplearning4j.org/documentation.html)\n\n- [Interesting Deep Learning and NLP Projects (Stanford)](http://cs224d.stanford.edu/reports.html), [Website](http://cs224d.stanford.edu/)\n\n- [Core Concepts of Deep Learning](https://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-core-concepts/)\n\n- [Understanding Natural Language with Deep Neural Networks Using Torch](https://devblogs.nvidia.com/parallelforall/understanding-natural-language-deep-neural-networks-using-torch/)\n\n- [Stanford Deep Learning Tutorial](http://ufldl.stanford.edu/tutorial/)\n\n- [Deep Learning FAQs on Quora](https://www.quora.com/topic/Deep-Learning/faq)\n\n- [Google+ Deep Learning Page](https://plus.google.com/communities/112866381580457264725)\n\n- [Recent Reddit AMAs related to Deep Learning](http://deeplearning.net/2014/11/22/recent-reddit-amas-about-deep-learning/), [Another AMA](https://www.reddit.com/r/IAmA/comments/3mdk9v/we_are_google_researchers_working_on_deep/)\n\n- [Where to Learn Deep Learning?](http://www.kdnuggets.com/2014/05/learn-deep-learning-courses-tutorials-overviews.html)\n\n- [Deep Learning nvidia concepts](http://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-core-concepts/)\n\n- [Introduction to Deep Learning Using Python (GitHub)](https://github.com/rouseguy/intro2deeplearning), [Good Introduction Slides](https://speakerdeck.com/bargava/introduction-to-deep-learning)\n\n- [Video Lectures Oxford 2015](https://www.youtube.com/playlist?list=PLE6Wd9FR--EfW8dtjAuPoTuPcqmOV53Fu), [Video Lectures Summer School Montreal](http://videolectures.net/deeplearning2015_montreal/)\n\n- [Deep Learning Software List](http://deeplearning.net/software_links/)\n\n- [Hacker\'s guide to Neural Nets](http://karpathy.github.io/neuralnets/)\n\n- [Top arxiv Deep Learning Papers explained](http://www.kdnuggets.com/2015/10/top-arxiv-deep-learning-papers-explained.html)\n\n- [Geoff Hinton Youtube Vidoes on Deep Learning](https://www.youtube.com/watch?v=IcOMKXAw5VA)\n\n- [Awesome Deep Learning Reading List](http://deeplearning.net/reading-list/)\n\n- [Deep Learning Comprehensive Website](http://deeplearning.net/), [Software](http://deeplearning.net/software_links/)\n\n- [deeplearning Tutorials](http://deeplearning4j.org/)\n\n- [AWESOME! Deep Learning Tutorial](https://www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks)\n\n- [Deep Learning Basics](http://alexminnaar.com/deep-learning-basics-neural-networks-backpropagation-and-stochastic-gradient-descent.html)\n\n- [Intuition Behind Backpropagation](https://medium.com/spidernitt/breaking-down-neural-networks-an-intuitive-approach-to-backpropagation-3b2ff958794c)\n\n- [Stanford Tutorials](http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/)\n\n- [Train, Validation & Test in Artificial Neural Networks](http://stackoverflow.com/questions/2976452/whats-is-the-difference-between-train-validation-and-test-set-in-neural-networ)\n\n- [Artificial Neural Networks Tutorials](http://stackoverflow.com/questions/478947/what-are-some-good-resources-for-learning-about-artificial-neural-networks)\n\n- [Neural Networks FAQs on Stack Overflow](http://stackoverflow.com/questions/tagged/neural-network?sort=votes&pageSize=50)\n\n- [Deep Learning Tutorials on deeplearning.net](http://deeplearning.net/tutorial/index.html)\n\n- [Neural Networks and Deep Learning Online Book](http://neuralnetworksanddeeplearning.com/)\n\n- Neural Machine Translation\n\n    - **[Machine Translation Reading List](https://github.com/THUNLP-MT/MT-Reading-List#machine-translation-reading-list)**\n\n    - [Introduction to Neural Machine Translation with GPUs (part 1)](https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-with-gpus/), [Part 2](https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-2/), [Part 3](https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-3/)\n    \n    - [Deep Speech: Accurate Speech Recognition with GPU-Accelerated Deep Learning](https://devblogs.nvidia.com/parallelforall/deep-speech-accurate-speech-recognition-gpu-accelerated-deep-learning/)\n\n<a name=""frame"" />\n\n- Deep Learning Frameworks\n\n    - [Torch vs. Theano](http://fastml.com/torch-vs-theano/)\n    \n    - [dl4j vs. torch7 vs. theano](http://deeplearning4j.org/compare-dl4j-torch7-pylearn.html)\n    \n    - [Deep Learning Libraries by Language](http://www.teglor.com/b/deep-learning-libraries-language-cm569/)\n    \n\n    - [Theano](https://en.wikipedia.org/wiki/Theano_(software))\n    \n        - [Website](http://deeplearning.net/software/theano/)\n        \n        - [Theano Introduction](http://www.wildml.com/2015/09/speeding-up-your-neural-network-with-theano-and-the-gpu/)\n        \n        - [Theano Tutorial](http://outlace.com/Beginner-Tutorial-Theano/)\n        \n        - [Good Theano Tutorial](http://deeplearning.net/software/theano/tutorial/)\n        \n        - [Logistic Regression using Theano for classifying digits](http://deeplearning.net/tutorial/logreg.html#logreg)\n        \n        - [MLP using Theano](http://deeplearning.net/tutorial/mlp.html#mlp)\n        \n        - [CNN using Theano](http://deeplearning.net/tutorial/lenet.html#lenet)\n        \n        - [RNNs using Theano](http://deeplearning.net/tutorial/rnnslu.html#rnnslu)\n        \n        - [LSTM for Sentiment Analysis in Theano](http://deeplearning.net/tutorial/lstm.html#lstm)\n        \n        - [RBM using Theano](http://deeplearning.net/tutorial/rbm.html#rbm)\n        \n        - [DBNs using Theano](http://deeplearning.net/tutorial/DBN.html#dbn)\n        \n        - [All Codes](https://github.com/lisa-lab/DeepLearningTutorials)\n        \n        - [Deep Learning Implementation Tutorials - Keras and Lasagne](https://github.com/vict0rsch/deep_learning/)\n\n    - [Torch](http://torch.ch/)\n    \n        - [Torch ML Tutorial](http://code.madbits.com/wiki/doku.php), [Code](https://github.com/torch/tutorials)\n        \n        - [Intro to Torch](http://ml.informatik.uni-freiburg.de/_media/teaching/ws1415/presentation_dl_lect3.pdf)\n        \n        - [Learning Torch GitHub Repo](https://github.com/chetannaik/learning_torch)\n        \n        - [Awesome-Torch (Repository on GitHub)](https://github.com/carpedm20/awesome-torch)\n        \n        - [Machine Learning using Torch Oxford Univ](https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/), [Code](https://github.com/oxford-cs-ml-2015)\n        \n        - [Torch Internals Overview](https://apaszke.github.io/torch-internals.html)\n        \n        - [Torch Cheatsheet](https://github.com/torch/torch7/wiki/Cheatsheet)\n        \n        - [Understanding Natural Language with Deep Neural Networks Using Torch](http://devblogs.nvidia.com/parallelforall/understanding-natural-language-deep-neural-networks-using-torch/)\n\n    - Caffe\n        - [Deep Learning for Computer Vision with Caffe and cuDNN](https://devblogs.nvidia.com/parallelforall/deep-learning-computer-vision-caffe-cudnn/)\n\n    - TensorFlow\n        - [Website](http://tensorflow.org/)\n        \n        - [TensorFlow Examples for Beginners](https://github.com/aymericdamien/TensorFlow-Examples)\n        \n        - [Stanford Tensorflow for Deep Learning Research Course](https://web.stanford.edu/class/cs20si/syllabus.html)\n        \n            - [GitHub Repo](https://github.com/chiphuyen/tf-stanford-tutorials)\n            \n        - [Simplified Scikit-learn Style Interface to TensorFlow](https://github.com/tensorflow/skflow)\n        \n        - [Learning TensorFlow GitHub Repo](https://github.com/chetannaik/learning_tensorflow)\n        \n        - [Benchmark TensorFlow GitHub](https://github.com/soumith/convnet-benchmarks/issues/66)\n        \n        - [Awesome TensorFlow List](https://github.com/jtoy/awesome-tensorflow)\n        \n        - [TensorFlow Book](https://github.com/BinRoot/TensorFlow-Book)\n        \n        - [Android TensorFlow Machine Learning Example](https://blog.mindorks.com/android-tensorflow-machine-learning-example-ff0e9b2654cc)\n        \n            - [GitHub Repo](https://github.com/MindorksOpenSource/AndroidTensorFlowMachineLearningExample)\n        - [Creating Custom Model For Android Using TensorFlow](https://blog.mindorks.com/creating-custom-model-for-android-using-tensorflow-3f963d270bfb)\n            - [GitHub Repo](https://github.com/MindorksOpenSource/AndroidTensorFlowMNISTExample)            \n\n<a name=""feed"" />\n\n- Feed Forward Networks\n\n    - [A Quick Introduction to Neural Networks](https://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/)\n    \n    - [Implementing a Neural Network from scratch](http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/), [Code](https://github.com/dennybritz/nn-from-scratch)\n    \n    - [Speeding up your Neural Network with Theano and the gpu](http://www.wildml.com/2015/09/speeding-up-your-neural-network-with-theano-and-the-gpu/), [Code](https://github.com/dennybritz/nn-theano)\n    \n    - [Basic ANN Theory](https://takinginitiative.wordpress.com/2008/04/03/basic-neural-network-tutorial-theory/)\n    \n    - [Role of Bias in Neural Networks](http://stackoverflow.com/questions/2480650/role-of-bias-in-neural-networks)\n    \n    - [Choosing number of hidden layers and nodes](http://stackoverflow.com/questions/3345079/estimating-the-number-of-neurons-and-number-of-layers-of-an-artificial-neural-ne),[2](http://stackoverflow.com/questions/10565868/multi-layer-perceptron-mlp-architecture-criteria-for-choosing-number-of-hidde?lq=1),[3](http://stackoverflow.com/questions/9436209/how-to-choose-number-of-hidden-layers-and-nodes-in-neural-network/2#)\n    \n    - [Backpropagation in Matrix Form](http://sudeepraja.github.io/Neural/)\n    \n    - [ANN implemented in C++ | AI Junkie](http://www.ai-junkie.com/ann/evolved/nnt6.html)\n    \n    - [Simple Implementation](http://stackoverflow.com/questions/15395835/simple-multi-layer-neural-network-implementation)\n    \n    - [NN for Beginners](http://www.codeproject.com/Articles/16419/AI-Neural-Network-for-beginners-Part-of)\n    \n    - [Regression and Classification with NNs (Slides)](http://www.autonlab.org/tutorials/neural13.pdf)\n    \n    - [Another Intro](http://www.doc.ic.ac.uk/~nd/surprise_96/journal/vol4/cs11/report.html)\n\n<a name=""rnn"" />\n\n- Recurrent and LSTM Networks\n    - [awesome-rnn: list of resources (GitHub Repo)](https://github.com/kjw0612/awesome-rnn)\n    \n    - [Recurrent Neural Net Tutorial Part 1](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/), [Part 2](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-2-implementing-a-language-model-rnn-with-python-numpy-and-theano/), [Part 3](http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/), [Code](https://github.com/dennybritz/rnn-tutorial-rnnlm/)\n    \n    - [NLP RNN Representations](http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/)\n    \n    - [The Unreasonable effectiveness of RNNs](http://karpathy.github.io/2015/05/21/rnn-effectiveness/), [Torch Code](https://github.com/karpathy/char-rnn), [Python Code](https://gist.github.com/karpathy/d4dee566867f8291f086)\n    \n    - [Intro to RNN](http://deeplearning4j.org/recurrentnetwork.html), [LSTM](http://deeplearning4j.org/lstm.html)\n    \n    - [An application of RNN](http://hackaday.com/2015/10/15/73-computer-scientists-created-a-neural-net-and-you-wont-believe-what-happened-next/)\n    \n    - [Optimizing RNN Performance](http://svail.github.io/)\n    \n    - [Simple RNN](http://outlace.com/Simple-Recurrent-Neural-Network/)\n    \n    - [Auto-Generating Clickbait with RNN](https://larseidnes.com/2015/10/13/auto-generating-clickbait-with-recurrent-neural-networks/)\n    \n    - [Sequence Learning using RNN (Slides)](http://www.slideshare.net/indicods/general-sequence-learning-with-recurrent-neural-networks-for-next-ml)\n    \n    - [Machine Translation using RNN (Paper)](http://emnlp2014.org/papers/pdf/EMNLP2014179.pdf)\n    \n    - [Music generation using RNNs (Keras)](https://github.com/MattVitelli/GRUV)\n    \n    - [Using RNN to create on-the-fly dialogue (Keras)](http://neuralniche.com/post/tutorial/)\n    \n    - Long Short Term Memory (LSTM)\n    \n        - [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n        \n        - [LSTM explained](https://apaszke.github.io/lstm-explained.html)\n        \n        - [Beginner\xe2\x80\x99s Guide to LSTM](http://deeplearning4j.org/lstm.html)\n        \n        - [Implementing LSTM from scratch](http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/), [Python/Theano code](https://github.com/dennybritz/rnn-tutorial-gru-lstm)\n        \n        - [Torch Code for character-level language models using LSTM](https://github.com/karpathy/char-rnn)\n        \n        - [LSTM for Kaggle EEG Detection competition (Torch Code)](https://github.com/apaszke/kaggle-grasp-and-lift)\n        \n        - [LSTM for Sentiment Analysis in Theano](http://deeplearning.net/tutorial/lstm.html#lstm)\n        \n        - [Deep Learning for Visual Q&A | LSTM | CNN](http://avisingh599.github.io/deeplearning/visual-qa/), [Code](https://github.com/avisingh599/visual-qa)\n        \n        - [Computer Responds to email using LSTM | Google](http://googleresearch.blogspot.in/2015/11/computer-respond-to-this-email.html)\n        \n        - [LSTM dramatically improves Google Voice Search](http://googleresearch.blogspot.ch/2015/09/google-voice-search-faster-and-more.html), [Another Article](http://deeplearning.net/2015/09/30/long-short-term-memory-dramatically-improves-google-voice-etc-now-available-to-a-billion-users/)\n        \n        - [Understanding Natural Language with LSTM Using Torch](http://devblogs.nvidia.com/parallelforall/understanding-natural-language-deep-neural-networks-using-torch/)\n        \n        - [Torch code for Visual Question Answering using a CNN+LSTM model](https://github.com/abhshkdz/neural-vqa)\n        \n        - [LSTM for Human Activity Recognition](https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition/)\n        \n    - Gated Recurrent Units (GRU)\n    \n        - [LSTM vs GRU](http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/)\n    \n    - [Time series forecasting with Sequence-to-Sequence (seq2seq) rnn models](https://github.com/guillaume-chevalier/seq2seq-signal-prediction)\n\n\n<a name=""rnn2"" />\n\n- [Recursive Neural Network (not Recurrent)](https://en.wikipedia.org/wiki/Recursive_neural_network)\n\n    - [Recursive Neural Tensor Network (RNTN)](http://deeplearning4j.org/recursiveneuraltensornetwork.html)\n    \n    - [word2vec, DBN, RNTN for Sentiment Analysis ](http://deeplearning4j.org/zh-sentiment_analysis_word2vec.html)\n\n<a name=""rbm"" />\n\n- Restricted Boltzmann Machine\n\n    - [Beginner\'s Guide about RBMs](http://deeplearning4j.org/restrictedboltzmannmachine.html)\n    \n    - [Another Good Tutorial](http://deeplearning.net/tutorial/rbm.html)\n    \n    - [Introduction to RBMs](http://blog.echen.me/2011/07/18/introduction-to-restricted-boltzmann-machines/)\n    \n    - [Hinton\'s Guide to Training RBMs](https://www.cs.toronto.edu/~hinton/absps/guideTR.pdf)\n    \n    - [RBMs in R](https://github.com/zachmayer/rbm)\n    \n    - [Deep Belief Networks Tutorial](http://deeplearning4j.org/deepbeliefnetwork.html)\n    \n    - [word2vec, DBN, RNTN for Sentiment Analysis ](http://deeplearning4j.org/zh-sentiment_analysis_word2vec.html)\n\n<a name=""auto"" />\n\n- Autoencoders: Unsupervised (applies BackProp after setting target = input)\n\n    - [Andrew Ng Sparse Autoencoders pdf](https://web.stanford.edu/class/cs294a/sparseAutoencoder.pdf)\n    \n    - [Deep Autoencoders Tutorial](http://deeplearning4j.org/deepautoencoder.html)\n    \n    - [Denoising Autoencoders](http://deeplearning.net/tutorial/dA.html), [Theano Code](http://deeplearning.net/tutorial/code/dA.py)\n    \n    - [Stacked Denoising Autoencoders](http://deeplearning.net/tutorial/SdA.html#sda)\n\n\n<a name=""cnn"" />\n\n- Convolutional Neural Networks\n\n    - [An Intuitive Explanation of Convolutional Neural Networks](https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/)\n    \n    - [Awesome Deep Vision: List of Resources (GitHub)](https://github.com/kjw0612/awesome-deep-vision)\n    \n    - [Intro to CNNs](http://deeplearning4j.org/convolutionalnets.html)\n    \n    - [Understanding CNN for NLP](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/)\n    \n    - [Stanford Notes](http://vision.stanford.edu/teaching/cs231n/), [Codes](http://cs231n.github.io/), [GitHub](https://github.com/cs231n/cs231n.github.io)\n    \n    - [JavaScript Library (Browser Based) for CNNs](http://cs.stanford.edu/people/karpathy/convnetjs/)\n    \n    - [Using CNNs to detect facial keypoints](http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/)\n    \n    - [Deep learning to classify business photos at Yelp](http://engineeringblog.yelp.com/2015/10/how-we-use-deep-learning-to-classify-business-photos-at-yelp.html)\n    \n    - [Interview with Yann LeCun | Kaggle](http://blog.kaggle.com/2014/12/22/convolutional-nets-and-cifar-10-an-interview-with-yan-lecun/)\n    \n    - [Visualising and Understanding CNNs](https://www.cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf)\n\n<a name=""nrl"" />\n\n- Network Representation Learning\n\n    - [Awesome Graph Embedding](https://github.com/benedekrozemberczki/awesome-graph-embedding)\n    \n    - [Awesome Network Embedding](https://github.com/chihming/awesome-network-embedding)\n    \n    - [Network Representation Learning Papers](https://github.com/thunlp)\n    \n    - [Knowledge Representation Learning Papers](https://github.com/thunlp/KRLPapers)\n    \n    - [Graph Based Deep Learning Literature](https://github.com/naganandy/graph-based-deep-learning-literature)\n\n<a name=""nlp"" />\n\n## Natural Language Processing\n\n- [A curated list of speech and natural language processing resources](https://github.com/edobashira/speech-language-processing)\n\n- [Understanding Natural Language with Deep Neural Networks Using Torch](http://devblogs.nvidia.com/parallelforall/understanding-natural-language-deep-neural-networks-using-torch/)\n\n- [tf-idf explained](http://michaelerasm.us/post/tf-idf-in-10-minutes/)\n\n- [Interesting Deep Learning NLP Projects Stanford](http://cs224d.stanford.edu/reports.html), [Website](http://cs224d.stanford.edu/)\n\n- [The Stanford NLP Group](https://nlp.stanford.edu/)\n\n- [NLP from Scratch | Google Paper](https://static.googleusercontent.com/media/research.google.com/en/us/pubs/archive/35671.pdf)\n\n- [Graph Based Semi Supervised Learning for NLP](http://graph-ssl.wdfiles.com/local--files/blog%3A_start/graph_ssl_acl12_tutorial_slides_final.pdf)\n\n- [Bag of Words](https://en.wikipedia.org/wiki/Bag-of-words_model)\n\n    - [Classification text with Bag of Words](http://fastml.com/classifying-text-with-bag-of-words-a-tutorial/)\n    \n<a name=""topic"" />\n\n- Topic Modeling\n    - [Topic Modeling Wikipedia](https://en.wikipedia.org/wiki/Topic_model) \n    - [**Probabilistic Topic Models Princeton PDF**](http://www.cs.columbia.edu/~blei/papers/Blei2012.pdf)\n\n    - [LDA Wikipedia](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation), [LSA Wikipedia](https://en.wikipedia.org/wiki/Latent_semantic_analysis), [Probabilistic LSA Wikipedia](https://en.wikipedia.org/wiki/Probabilistic_latent_semantic_analysis)\n    \n    - [What is a good explanation of Latent Dirichlet Allocation (LDA)?](https://www.quora.com/What-is-a-good-explanation-of-Latent-Dirichlet-Allocation)\n    \n    - [**Introduction to LDA**](http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/), [Another good explanation](http://confusedlanguagetech.blogspot.in/2012/07/jordan-boyd-graber-and-philip-resnik.html)\n    \n    - [The LDA Buffet - Intuitive Explanation](http://www.matthewjockers.net/2011/09/29/the-lda-buffet-is-now-open-or-latent-dirichlet-allocation-for-english-majors/)\n    \n    - [Your Guide to Latent Dirichlet Allocation (LDA)](https://medium.com/@lettier/how-does-lda-work-ill-explain-using-emoji-108abf40fa7d)\n    \n    - [Difference between LSI and LDA](https://www.quora.com/Whats-the-difference-between-Latent-Semantic-Indexing-LSI-and-Latent-Dirichlet-Allocation-LDA)\n    \n    - [Original LDA Paper](https://www.cs.princeton.edu/~blei/papers/BleiNgJordan2003.pdf)\n    \n    - [alpha and beta in LDA](http://datascience.stackexchange.com/questions/199/what-does-the-alpha-and-beta-hyperparameters-contribute-to-in-latent-dirichlet-a)\n    \n    - [Intuitive explanation of the Dirichlet distribution](https://www.quora.com/What-is-an-intuitive-explanation-of-the-Dirichlet-distribution)\n    - [topicmodels: An R Package for Fitting Topic Models](https://cran.r-project.org/web/packages/topicmodels/vignettes/topicmodels.pdf)\n\n    - [Topic modeling made just simple enough](https://tedunderwood.com/2012/04/07/topic-modeling-made-just-simple-enough/)\n    \n    - [Online LDA](http://alexminnaar.com/online-latent-dirichlet-allocation-the-best-option-for-topic-modeling-with-large-data-sets.html), [Online LDA with Spark](http://alexminnaar.com/distributed-online-latent-dirichlet-allocation-with-apache-spark.html)\n    \n    - [LDA in Scala](http://alexminnaar.com/latent-dirichlet-allocation-in-scala-part-i-the-theory.html), [Part 2](http://alexminnaar.com/latent-dirichlet-allocation-in-scala-part-ii-the-code.html)\n    \n    - [Segmentation of Twitter Timelines via Topic Modeling](https://alexisperrier.com/nlp/2015/09/16/segmentation_twitter_timelines_lda_vs_lsa.html)\n    \n    - [Topic Modeling of Twitter Followers](http://alexperrier.github.io/jekyll/update/2015/09/04/topic-modeling-of-twitter-followers.html)\n\n    - [Multilingual Latent Dirichlet Allocation (LDA)](https://github.com/ArtificiAI/Multilingual-Latent-Dirichlet-Allocation-LDA). ([Tutorial here](https://github.com/ArtificiAI/Multilingual-Latent-Dirichlet-Allocation-LDA/blob/master/Multilingual-LDA-Pipeline-Tutorial.ipynb))\n\n    - [Deep Belief Nets for Topic Modeling](https://github.com/larsmaaloee/deep-belief-nets-for-topic-modeling)\n    - [Gaussian LDA for Topic Models with Word Embeddings](http://www.cs.cmu.edu/~rajarshd/papers/acl2015.pdf)\n    - Python\n        - [Series of lecture notes for probabilistic topic models written in ipython notebook](https://github.com/arongdari/topic-model-lecture-note)\n        - [Implementation of various topic models in Python](https://github.com/arongdari/python-topic-model)\n           \n<a name=""word2vec"" />\n\n- word2vec\n\n    - [Google word2vec](https://code.google.com/archive/p/word2vec)\n    \n    - [Bag of Words Model Wiki](https://en.wikipedia.org/wiki/Bag-of-words_model)\n    \n    - [word2vec Tutorial](https://rare-technologies.com/word2vec-tutorial/)\n    \n    - [A closer look at Skip Gram Modeling](http://homepages.inf.ed.ac.uk/ballison/pdf/lrec_skipgrams.pdf)\n    \n    - [Skip Gram Model Tutorial](http://alexminnaar.com/word2vec-tutorial-part-i-the-skip-gram-model.html), [CBoW Model](http://alexminnaar.com/word2vec-tutorial-part-ii-the-continuous-bag-of-words-model.html)\n    \n    - [Word Vectors Kaggle Tutorial Python](https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-2-word-vectors), [Part 2](https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-3-more-fun-with-word-vectors)\n    \n    - [Making sense of word2vec](http://rare-technologies.com/making-sense-of-word2vec/)\n    \n    - [word2vec explained on deeplearning4j](http://deeplearning4j.org/word2vec.html)\n    \n    - [Quora word2vec](https://www.quora.com/How-does-word2vec-work)\n    \n    - [Other Quora Resources](https://www.quora.com/What-are-the-continuous-bag-of-words-and-skip-gram-architectures-in-laymans-terms), [2](https://www.quora.com/What-is-the-difference-between-the-Bag-of-Words-model-and-the-Continuous-Bag-of-Words-model), [3](https://www.quora.com/Is-skip-gram-negative-sampling-better-than-CBOW-NS-for-word2vec-If-so-why)\n    \n    - [word2vec, DBN, RNTN for Sentiment Analysis ](http://deeplearning4j.org/zh-sentiment_analysis_word2vec.html)\n\n- Text Clustering\n\n    - [How string clustering works](http://stackoverflow.com/questions/8196371/how-clustering-works-especially-string-clustering)\n    \n    - [Levenshtein distance for measuring the difference between two sequences](https://en.wikipedia.org/wiki/Levenshtein_distance)\n    \n    - [Text clustering with Levenshtein distances](http://stackoverflow.com/questions/21511801/text-clustering-with-levenshtein-distances)\n\n- Text Classification\n\n    - [Classification Text with Bag of Words](http://fastml.com/classifying-text-with-bag-of-words-a-tutorial/)\n\n- Named Entity Recognitation \n    \n     - [Stanford Named Entity Recognizer (NER)](https://nlp.stanford.edu/software/CRF-NER.shtml)\n\n     - [Named Entity Recognition: Applications and Use Cases- Towards Data Science](https://towardsdatascience.com/named-entity-recognition-applications-and-use-cases-acdbf57d595e)\n\t\n- [Language learning with NLP and reinforcement learning](http://blog.dennybritz.com/2015/09/11/reimagining-language-learning-with-nlp-and-reinforcement-learning/)\n\n- [Kaggle Tutorial Bag of Words and Word vectors](https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words), [Part 2](https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-2-word-vectors), [Part 3](https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-3-more-fun-with-word-vectors)\n\n- [What would Shakespeare say (NLP Tutorial)](https://gigadom.wordpress.com/2015/10/02/natural-language-processing-what-would-shakespeare-say/)\n\n- [A closer look at Skip Gram Modeling](http://homepages.inf.ed.ac.uk/ballison/pdf/lrec_skipgrams.pdf)\n\n<a name=""vision"" />\n\n## Computer Vision\n- [Awesome computer vision (github)](https://github.com/jbhuang0604/awesome-computer-vision)\n\n- [Awesome deep vision (github)](https://github.com/kjw0612/awesome-deep-vision)\n\n\n<a name=""svm"" />\n\n## Support Vector Machine\n\n- [Highest Voted Questions about SVMs on Cross Validated](http://stats.stackexchange.com/questions/tagged/svm)\n\n- [Help me Understand SVMs!](http://stats.stackexchange.com/questions/3947/help-me-understand-support-vector-machines)\n\n- [SVM in Layman\'s terms](https://www.quora.com/What-does-support-vector-machine-SVM-mean-in-laymans-terms)\n\n- [How does SVM Work | Comparisons](http://stats.stackexchange.com/questions/23391/how-does-a-support-vector-machine-svm-work)\n\n- [A tutorial on SVMs](http://alex.smola.org/papers/2003/SmoSch03b.pdf)\n\n- [Practical Guide to SVC](http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf), [Slides](http://www.csie.ntu.edu.tw/~cjlin/talks/freiburg.pdf)\n\n- [Introductory Overview of SVMs](http://www.statsoft.com/Textbook/Support-Vector-Machines)\n\n- Comparisons\n\n    - [SVMs > ANNs](http://stackoverflow.com/questions/6699222/support-vector-machines-better-than-artificial-neural-networks-in-which-learn?rq=1), [ANNs > SVMs](http://stackoverflow.com/questions/11632516/what-are-advantages-of-artificial-neural-networks-over-support-vector-machines), [Another Comparison](http://www.svms.org/anns.html)\n    \n    - [Trees > SVMs](http://stats.stackexchange.com/questions/57438/why-is-svm-not-so-good-as-decision-tree-on-the-same-data)\n    \n    - [Kernel Logistic Regression vs SVM](http://stats.stackexchange.com/questions/43996/kernel-logistic-regression-vs-svm)\n    \n    - [Logistic Regression vs SVM](http://stats.stackexchange.com/questions/58684/regularized-logistic-regression-and-support-vector-machine), [2](http://stats.stackexchange.com/questions/95340/svm-v-s-logistic-regression), [3](https://www.quora.com/Support-Vector-Machines/What-is-the-difference-between-Linear-SVMs-and-Logistic-Regression)\n    \n- [Optimization Algorithms in Support Vector Machines](http://pages.cs.wisc.edu/~swright/talks/sjw-complearning.pdf)\n\n- [Variable Importance from SVM](http://stats.stackexchange.com/questions/2179/variable-importance-from-svm)\n\n- Software\n\n    - [LIBSVM](https://www.csie.ntu.edu.tw/~cjlin/libsvm/)\n    \n    - [Intro to SVM in R](http://cbio.ensmp.fr/~jvert/svn/tutorials/practical/svmbasic/svmbasic_notes.pdf)\n    \n- Kernels\n    - [What are Kernels in ML and SVM?](https://www.quora.com/What-are-Kernels-in-Machine-Learning-and-SVM)\n    \n    - [Intuition Behind Gaussian Kernel in SVMs?](https://www.quora.com/Support-Vector-Machines/What-is-the-intuition-behind-Gaussian-kernel-in-SVM)\n    \n- Probabilities post SVM\n\n    - [Platt\'s Probabilistic Outputs for SVM](http://www.csie.ntu.edu.tw/~htlin/paper/doc/plattprob.pdf)\n    \n    - [Platt Calibration Wiki](https://en.wikipedia.org/wiki/Platt_scaling)\n    \n    - [Why use Platts Scaling](http://stats.stackexchange.com/questions/5196/why-use-platts-scaling)\n    \n    - [Classifier Classification with Platt\'s Scaling](http://fastml.com/classifier-calibration-with-platts-scaling-and-isotonic-regression/)\n\n\n<a name=""rl"" />\n\n## Reinforcement Learning\n\n- [Awesome Reinforcement Learning (GitHub)](https://github.com/aikorea/awesome-rl)\n\n- [RL Tutorial Part 1](http://outlace.com/Reinforcement-Learning-Part-1/), [Part 2](http://outlace.com/Reinforcement-Learning-Part-2/)\n\n<a name=""dt"" />\n\n## Decision Trees\n\n- [Wikipedia Page - Lots of Good Info](https://en.wikipedia.org/wiki/Decision_tree_learning)\n\n- [FAQs about Decision Trees](http://stats.stackexchange.com/questions/tagged/cart)\n\n- [Brief Tour of Trees and Forests](https://statistical-research.com/index.php/2013/04/29/a-brief-tour-of-the-trees-and-forests/)\n\n- [Tree Based Models in R](http://www.statmethods.net/advstats/cart.html)\n\n- [How Decision Trees work?](http://www.aihorizon.com/essays/generalai/decision_trees.htm)\n\n- [Weak side of Decision Trees](http://stats.stackexchange.com/questions/1292/what-is-the-weak-side-of-decision-trees)\n\n- [Thorough Explanation and different algorithms](http://www.ise.bgu.ac.il/faculty/liorr/hbchap9.pdf)\n\n- [What is entropy and information gain in the context of building decision trees?](http://stackoverflow.com/questions/1859554/what-is-entropy-and-information-gain)\n\n- [Slides Related to Decision Trees](http://www.slideshare.net/pierluca.lanzi/machine-learning-and-data-mining-11-decision-trees)\n\n- [How do decision tree learning algorithms deal with missing values?](http://stats.stackexchange.com/questions/96025/how-do-decision-tree-learning-algorithms-deal-with-missing-values-under-the-hoo)\n\n- [Using Surrogates to Improve Datasets with Missing Values](https://www.salford-systems.com/videos/tutorials/tips-and-tricks/using-surrogates-to-improve-datasets-with-missing-values)\n\n- [Good Article](https://www.mindtools.com/dectree.html)\n\n- [Are decision trees almost always binary trees?](http://stats.stackexchange.com/questions/12187/are-decision-trees-almost-always-binary-trees)\n\n- [Pruning Decision Trees](https://en.wikipedia.org/wiki/Pruning_(decision_trees)), [Grafting of Decision Trees](https://en.wikipedia.org/wiki/Grafting_(decision_trees))\n\n- [What is Deviance in context of Decision Trees?](http://stats.stackexchange.com/questions/6581/what-is-deviance-specifically-in-cart-rpart)\n\n- [Discover structure behind data with decision trees](http://vooban.com/en/tips-articles-geek-stuff/discover-structure-behind-data-with-decision-trees/) - Grow and plot a decision tree to automatically figure out hidden rules in your data\n\n- Comparison of Different Algorithms\n\n    - [CART vs CTREE](http://stats.stackexchange.com/questions/12140/conditional-inference-trees-vs-traditional-decision-trees)\n    \n    - [Comparison of complexity or performance](https://stackoverflow.com/questions/9979461/different-decision-tree-algorithms-with-comparison-of-complexity-or-performance)\n    \n    - [CHAID vs CART](http://stats.stackexchange.com/questions/61230/chaid-vs-crt-or-cart) , [CART vs CHAID](http://www.bzst.com/2006/10/classification-trees-cart-vs-chaid.html)\n    \n    - [Good Article on comparison](http://www.ftpress.com/articles/article.aspx?p=2248639&seqNum=11)\n    \n- CART\n\n    - [Recursive Partitioning Wikipedia](https://en.wikipedia.org/wiki/Recursive_partitioning)\n    \n    - [CART Explained](http://documents.software.dell.com/Statistics/Textbook/Classification-and-Regression-Trees)\n    \n    - [How to measure/rank \xe2\x80\x9cvariable importance\xe2\x80\x9d when using CART?](http://stats.stackexchange.com/questions/6478/how-to-measure-rank-variable-importance-when-using-cart-specifically-using)\n    \n    - [Pruning a Tree in R](http://stackoverflow.com/questions/15318409/how-to-prune-a-tree-in-r)\n    \n    - [Does rpart use multivariate splits by default?](http://stats.stackexchange.com/questions/4356/does-rpart-use-multivariate-splits-by-default)\n    \n    - [FAQs about Recursive Partitioning](http://stats.stackexchange.com/questions/tagged/rpart)\n    \n- CTREE\n\n    - [party package in R](https://cran.r-project.org/web/packages/party/party.pdf)\n    \n    - [Show volumne in each node using ctree in R](http://stackoverflow.com/questions/13772715/show-volume-in-each-node-using-ctree-plot-in-r)\n    \n    - [How to extract tree structure from ctree function?](http://stackoverflow.com/questions/8675664/how-to-extract-tree-structure-from-ctree-function)\n    \n- CHAID\n\n    - [Wikipedia Artice on CHAID](https://en.wikipedia.org/wiki/CHAID)\n    \n    - [Basic Introduction to CHAID](https://smartdrill.com/Introduction-to-CHAID.html)\n    \n    - [Good Tutorial on CHAID](http://www.statsoft.com/Textbook/CHAID-Analysis)\n    \n- MARS\n\n    - [Wikipedia Article on MARS](https://en.wikipedia.org/wiki/Multivariate_adaptive_regression_splines)\n    \n- Probabilistic Decision Trees\n\n    - [Bayesian Learning in Probabilistic Decision Trees](http://www.stats.org.uk/bayesian/Jordan.pdf)\n    \n    - [Probabilistic Trees Research Paper](http://people.stern.nyu.edu/adamodar/pdfiles/papers/probabilistic.pdf)\n\n<a name=""rf"" />\n\n## Random Forest / Bagging\n\n- [Awesome Random Forest (GitHub)**](https://github.com/kjw0612/awesome-random-forest)\n\n- [How to tune RF parameters in practice?](https://www.kaggle.com/forums/f/15/kaggle-forum/t/4092/how-to-tune-rf-parameters-in-practice)\n\n- [Measures of variable importance in random forests](http://stats.stackexchange.com/questions/12605/measures-of-variable-importance-in-random-forests)\n\n- [Compare R-squared from two different Random Forest models](http://stats.stackexchange.com/questions/13869/compare-r-squared-from-two-different-random-forest-models)\n\n- [OOB Estimate Explained | RF vs LDA](https://stat.ethz.ch/education/semesters/ss2012/ams/slides/v10.2.pdf)\n\n- [Evaluating Random Forests for Survival Analysis Using Prediction Error Curve](https://www.jstatsoft.org/index.php/jss/article/view/v050i11)\n\n- [Why doesn\'t Random Forest handle missing values in predictors?](http://stats.stackexchange.com/questions/98953/why-doesnt-random-forest-handle-missing-values-in-predictors)\n\n- [How to build random forests in R with missing (NA) values?](http://stackoverflow.com/questions/8370455/how-to-build-random-forests-in-r-with-missing-na-values)\n\n- [FAQs about Random Forest](http://stats.stackexchange.com/questions/tagged/random-forest), [More FAQs](http://stackoverflow.com/questions/tagged/random-forest)\n\n- [Obtaining knowledge from a random forest](http://stats.stackexchange.com/questions/21152/obtaining-knowledge-from-a-random-forest)\n\n- [Some Questions for R implementation](http://stackoverflow.com/questions/20537186/getting-predictions-after-rfimpute), [2](http://stats.stackexchange.com/questions/81609/whether-preprocessing-is-needed-before-prediction-using-finalmodel-of-randomfore), [3](http://stackoverflow.com/questions/17059432/random-forest-package-in-r-shows-error-during-prediction-if-there-are-new-fact)\n\n<a name=""gbm"" />\n\n## Boosting\n\n- [Boosting for Better Predictions](http://www.datasciencecentral.com/profiles/blogs/boosting-algorithms-for-better-predictions)\n\n- [Boosting Wikipedia Page](https://en.wikipedia.org/wiki/Boosting_(machine_learning))\n\n- [Introduction to Boosted Trees | Tianqi Chen](https://homes.cs.washington.edu/~tqchen/pdf/BoostedTree.pdf)\n\n- Gradient Boosting Machine\n\n    - [Gradiet Boosting Wiki](https://en.wikipedia.org/wiki/Gradient_boosting)\n    \n    - [Guidelines for GBM parameters in R](http://stats.stackexchange.com/questions/25748/what-are-some-useful-guidelines-for-gbm-parameters), [Strategy to set parameters](http://stats.stackexchange.com/questions/35984/strategy-to-set-the-gbm-parameters)\n    \n    - [Meaning of Interaction Depth](http://stats.stackexchange.com/questions/16501/what-does-interaction-depth-mean-in-gbm), [2](http://stats.stackexchange.com/questions/16501/what-does-interaction-depth-mean-in-gbm)\n    \n    - [Role of n.minobsinnode parameter of GBM in R](http://stats.stackexchange.com/questions/30645/role-of-n-minobsinnode-parameter-of-gbm-in-r)\n    \n    - [GBM in R](http://www.slideshare.net/mark_landry/gbm-package-in-r)\n    \n    - [FAQs about GBM](http://stats.stackexchange.com/tags/gbm/hot)\n    \n    - [GBM vs xgboost](https://www.kaggle.com/c/higgs-boson/forums/t/9497/r-s-gbm-vs-python-s-xgboost)\n\n- xgboost\n\n    - [xgboost tuning kaggle](https://www.kaggle.com/khozzy/rossmann-store-sales/xgboost-parameter-tuning-template/log)\n    \n    - [xgboost vs gbm](https://www.kaggle.com/c/otto-group-product-classification-challenge/forums/t/13012/question-to-experienced-kagglers-and-anyone-who-wants-to-take-a-shot/68296#post68296)\n    \n    - [xgboost survey](https://www.kaggle.com/c/higgs-boson/forums/t/10335/xgboost-post-competition-survey)\n    \n    - [Practical XGBoost in Python online course (free)](http://education.parrotprediction.teachable.com/courses/practical-xgboost-in-python)\n    \n- AdaBoost\n\n    - [AdaBoost Wiki](https://en.wikipedia.org/wiki/AdaBoost), [Python Code](https://gist.github.com/tristanwietsma/5486024)\n    \n    - [AdaBoost Sparse Input Support](http://hamzehal.blogspot.com/2014/06/adaboost-sparse-input-support.html)\n    \n    - [adaBag R package](https://cran.r-project.org/web/packages/adabag/adabag.pdf)\n    \n    - [Tutorial](http://math.mit.edu/~rothvoss/18.304.3PM/Presentations/1-Eric-Boosting304FinalRpdf.pdf)\n\n- CatBoost\n\n    - [CatBoost Documentation](https://catboost.ai/docs/)\n\n    - [Benchmarks](https://catboost.ai/#benchmark)\n\n    - [Tutorial](https://github.com/catboost/tutorials)\n\n    - [GitHub Project](https://github.com/catboost)\n\n    - [CatBoost vs. Light GBM vs. XGBoost](https://towardsdatascience.com/catboost-vs-light-gbm-vs-xgboost-5f93620723db)\n\n<a name=""ensem"" />\n\n## Ensembles\n\n- [Wikipedia Article on Ensemble Learning](https://en.wikipedia.org/wiki/Ensemble_learning)\n\n- [Kaggle Ensembling Guide](http://mlwave.com/kaggle-ensembling-guide/)\n\n- [The Power of Simple Ensembles](http://www.overkillanalytics.net/more-is-always-better-the-power-of-simple-ensembles/)\n\n- [Ensemble Learning Intro](http://machine-learning.martinsewell.com/ensembles/)\n\n- [Ensemble Learning Paper](http://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/springerEBR09.pdf)\n\n- [Ensembling models with R](http://amunategui.github.io/blending-models/), [Ensembling Regression Models in R](http://stats.stackexchange.com/questions/26790/ensembling-regression-models), [Intro to Ensembles in R](http://www.vikparuchuri.com/blog/intro-to-ensemble-learning-in-r/)\n\n- [Ensembling Models with caret](http://stats.stackexchange.com/questions/27361/stacking-ensembling-models-with-caret)\n\n- [Bagging vs Boosting vs Stacking](http://stats.stackexchange.com/questions/18891/bagging-boosting-and-stacking-in-machine-learning)\n\n- [Good Resources | Kaggle Africa Soil Property Prediction](https://www.kaggle.com/c/afsis-soil-properties/forums/t/10391/best-ensemble-references)\n\n- [Boosting vs Bagging](http://www.chioka.in/which-is-better-boosting-or-bagging/)\n\n- [Resources for learning how to implement ensemble methods](http://stats.stackexchange.com/questions/32703/resources-for-learning-how-to-implement-ensemble-methods)\n\n- [How are classifications merged in an ensemble classifier?](http://stats.stackexchange.com/questions/21502/how-are-classifications-merged-in-an-ensemble-classifier)\n\n<a name=""stack"" />\n\n## Stacking Models\n\n- [Stacking, Blending and Stacked Generalization](http://www.chioka.in/stacking-blending-and-stacked-generalization/)\n\n- [Stacked Generalization (Stacking)](http://machine-learning.martinsewell.com/ensembles/stacking/)\n\n- [Stacked Generalization: when does it work?](http://www.ijcai.org/Proceedings/97-2/011.pdf)\n\n- [Stacked Generalization Paper](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.56.1533&rep=rep1&type=pdf)\n\n<a name=""vc"" />\n\n## Vapnik\xe2\x80\x93Chervonenkis Dimension\n\n- [Wikipedia article on VC Dimension](https://en.wikipedia.org/wiki/VC_dimension)\n\n- [Intuitive Explanantion of VC Dimension](https://www.quora.com/Explain-VC-dimension-and-shattering-in-lucid-Way)\n\n- [Video explaining VC Dimension](https://www.youtube.com/watch?v=puDzy2XmR5c)\n\n- [Introduction to VC Dimension](http://www.svms.org/vc-dimension/)\n\n- [FAQs about VC Dimension](http://stats.stackexchange.com/questions/tagged/vc-dimension)\n\n- [Do ensemble techniques increase VC-dimension?](http://stats.stackexchange.com/questions/78076/do-ensemble-techniques-increase-vc-dimension)\n\n\n<a name=""bayes"" />\n\n## Bayesian Machine Learning\n\n- [Bayesian Methods for Hackers (using pyMC)](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers)\n\n- [Should all Machine Learning be Bayesian?](http://videolectures.net/bark08_ghahramani_samlbb/)\n\n- [Tutorial on Bayesian Optimisation for Machine Learning](http://www.iro.umontreal.ca/~bengioy/cifar/NCAP2014-summerschool/slides/Ryan_adams_140814_bayesopt_ncap.pdf)\n\n- [Bayesian Reasoning and Deep Learning](http://blog.shakirm.com/2015/10/bayesian-reasoning-and-deep-learning/), [Slides](http://blog.shakirm.com/wp-content/uploads/2015/10/Bayes_Deep.pdf)\n\n- [Bayesian Statistics Made Simple](http://greenteapress.com/wp/think-bayes/)\n\n- [Kalman & Bayesian Filters in Python](https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python)\n\n- [Markov Chain Wikipedia Page](https://en.wikipedia.org/wiki/Markov_chain)\n\n\n<a name=""semi"" />\n\n## Semi Supervised Learning\n\n- [Wikipedia article on Semi Supervised Learning](https://en.wikipedia.org/wiki/Semi-supervised_learning)\n\n- [Tutorial on Semi Supervised Learning](http://pages.cs.wisc.edu/~jerryzhu/pub/sslicml07.pdf)\n\n- [Graph Based Semi Supervised Learning for NLP](http://graph-ssl.wdfiles.com/local--files/blog%3A_start/graph_ssl_acl12_tutorial_slides_final.pdf)\n\n- [Taxonomy](http://is.tuebingen.mpg.de/fileadmin/user_upload/files/publications/taxo_[0].pdf)\n\n- [Video Tutorial Weka](https://www.youtube.com/watch?v=sWxcIjZFGNM)\n\n- [Unsupervised, Supervised and Semi Supervised learning](http://stats.stackexchange.com/questions/517/unsupervised-supervised-and-semi-supervised-learning)\n\n- [Research Papers 1](http://mlg.eng.cam.ac.uk/zoubin/papers/zglactive.pdf), [2](http://mlg.eng.cam.ac.uk/zoubin/papers/zgl.pdf), [3](http://icml.cc/2012/papers/616.pdf)\n\n\n<a name=""opt"" />\n\n## Optimization\n\n- [Mean Variance Portfolio Optimization with R and Quadratic Programming](http://www.wdiam.com/2012/06/10/mean-variance-portfolio-optimization-with-r-and-quadratic-programming/?utm_content=buffer04c12&utm_medium=social&utm_source=linkedin.com&utm_campaign=buffer)\n\n- [Algorithms for Sparse Optimization and Machine Learning](http://www.ima.umn.edu/2011-2012/W3.26-30.12/activities/Wright-Steve/sjw-ima12)\n\n- [Optimization Algorithms in Machine Learning](http://pages.cs.wisc.edu/~swright/nips2010/sjw-nips10.pdf), [Video Lecture](http://videolectures.net/nips2010_wright_oaml/)\n\n- [Optimization Algorithms for Data Analysis](http://www.birs.ca/workshops/2011/11w2035/files/Wright.pdf)\n\n- [Video Lectures on Optimization](http://videolectures.net/stephen_j_wright/)\n\n- [Optimization Algorithms in Support Vector Machines](http://pages.cs.wisc.edu/~swright/talks/sjw-complearning.pdf)\n\n- [The Interplay of Optimization and Machine Learning Research](http://jmlr.org/papers/volume7/MLOPT-intro06a/MLOPT-intro06a.pdf)\n\n- [Hyperopt tutorial for Optimizing Neural Networks\xe2\x80\x99 Hyperparameters](http://vooban.com/en/tips-articles-geek-stuff/hyperopt-tutorial-for-optimizing-neural-networks-hyperparameters/)\n\n\n<a name=""other"" />\n\n## Other Tutorials\n\n- For a collection of Data Science Tutorials using R, please refer to [this list](https://github.com/ujjwalkarn/DataScienceR).\n\n- For a collection of Data Science Tutorials using Python, please refer to [this list](https://github.com/ujjwalkarn/DataSciencePython).\n'"
9,trekhleb/homemade-machine-learning,trekhleb,🤖 Python examples of popular machine learning algorithms with interactive Jupyter demos and math being explained,2018-11-01 04:34:19,2020-06-18 13:03:23,Jupyter Notebook,2791,14151,"b'# Homemade Machine Learning\n\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/trekhleb/homemade-machine-learning/master?filepath=notebooks)\n[![Build Status](https://travis-ci.org/trekhleb/homemade-machine-learning.svg?branch=master)](https://travis-ci.org/trekhleb/homemade-machine-learning)\n\n> _You might be interested in \xf0\x9f\xa4\x96 [Interactive Machine Learning Experiments](https://github.com/trekhleb/machine-learning-experiments)_\n\n_For Octave/MatLab version of this repository please check [machine-learning-octave](https://github.com/trekhleb/machine-learning-octave) project._\n\n> This repository contains examples of popular machine learning algorithms implemented in **Python** with mathematics behind them being explained. Each algorithm has interactive **Jupyter Notebook** demo that allows you to play with training data, algorithms configurations and immediately see the results, charts and predictions **right in your browser**. In most cases the explanations are based on [this great machine learning course](https://www.coursera.org/learn/machine-learning) by Andrew Ng.\n\nThe purpose of this repository is _not_ to implement machine learning algorithms by using 3<sup>rd</sup> party library one-liners _but_ rather to practice implementing these algorithms from scratch and get better understanding of the mathematics behind each algorithm. That\'s why all algorithms implementations are called ""homemade"" and not intended to be used for production.\n\n## Supervised Learning\n\nIn supervised learning we have a set of training data as an input and a set of labels or ""correct answers"" for each training set as an output. Then we\'re training our model (machine learning algorithm parameters) to map the input to the output correctly (to do correct prediction). The ultimate purpose is to find such model parameters that will successfully continue correct _input\xe2\x86\x92output_ mapping (predictions) even for new input examples.\n\n### Regression\n\nIn regression problems we do real value predictions. Basically we try to draw a line/plane/n-dimensional plane along the training examples.\n\n_Usage examples: stock price forecast, sales analysis, dependency of any number, etc._\n\n#### \xf0\x9f\xa4\x96 Linear Regression\n\n- \xf0\x9f\x93\x97 [Math | Linear Regression](homemade/linear_regression) - theory and links for further readings\n- \xe2\x9a\x99\xef\xb8\x8f [Code | Linear Regression](homemade/linear_regression/linear_regression.py) - implementation example\n- \xe2\x96\xb6\xef\xb8\x8f [Demo | Univariate Linear Regression](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/linear_regression/univariate_linear_regression_demo.ipynb) - predict `country happiness` score by `economy GDP`\n- \xe2\x96\xb6\xef\xb8\x8f [Demo | Multivariate Linear Regression](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/linear_regression/multivariate_linear_regression_demo.ipynb) - predict `country happiness` score by `economy GDP` and `freedom index`\n- \xe2\x96\xb6\xef\xb8\x8f [Demo | Non-linear Regression](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/linear_regression/non_linear_regression_demo.ipynb) - use linear regression with _polynomial_ and _sinusoid_ features to predict non-linear dependencies\n\n### Classification\n\nIn classification problems we split input examples by certain characteristic.\n\n_Usage examples: spam-filters, language detection, finding similar documents, handwritten letters recognition, etc._\n\n#### \xf0\x9f\xa4\x96 Logistic Regression\n\n- \xf0\x9f\x93\x97 [Math | Logistic Regression](homemade/logistic_regression) - theory and links for further readings\n- \xe2\x9a\x99\xef\xb8\x8f [Code | Logistic Regression](homemade/logistic_regression/logistic_regression.py) - implementation example\n- \xe2\x96\xb6\xef\xb8\x8f [Demo | Logistic Regression (Linear Boundary)](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/logistic_regression/logistic_regression_with_linear_boundary_demo.ipynb) - predict Iris flower `class` based on `petal_length` and `petal_width`\n- \xe2\x96\xb6\xef\xb8\x8f [Demo | Logistic Regression (Non-Linear Boundary)](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/logistic_regression/logistic_regression_with_non_linear_boundary_demo.ipynb) - predict microchip `validity` based on `param_1` and `param_2`\n- \xe2\x96\xb6\xef\xb8\x8f [Demo | Multivariate Logistic Regression | MNIST](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/logistic_regression/multivariate_logistic_regression_demo.ipynb) - recognize handwritten digits from `28x28` pixel images\n- \xe2\x96\xb6\xef\xb8\x8f [Demo | Multivariate Logistic Regression | Fashion MNIST](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/logistic_regression/multivariate_logistic_regression_fashion_demo.ipynb) - recognize clothes types from `28x28` pixel images\n\n## Unsupervised Learning\n\nUnsupervised learning is a branch of machine learning that learns from test data that has not been labeled, classified or categorized. Instead of responding to feedback, unsupervised learning identifies commonalities in the data and reacts based on the presence or absence of such commonalities in each new piece of data.\n\n### Clustering\n\nIn clustering problems we split the training examples by unknown characteristics. The algorithm itself decides what characteristic to use for splitting.\n\n_Usage examples: market segmentation, social networks analysis, organize computing clusters, astronomical data analysis, image compression, etc._\n\n#### \xf0\x9f\xa4\x96 K-means Algorithm\n\n- \xf0\x9f\x93\x97 [Math | K-means Algorithm](homemade/k_means) - theory and links for further readings\n- \xe2\x9a\x99\xef\xb8\x8f [Code | K-means Algorithm](homemade/k_means/k_means.py) - implementation example\n- \xe2\x96\xb6\xef\xb8\x8f [Demo | K-means Algorithm](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/k_means/k_means_demo.ipynb) - split Iris flowers into clusters based on `petal_length` and `petal_width`\n\n### Anomaly Detection\n\nAnomaly detection (also outlier detection) is the identification of rare items, events or observations which raise suspicions by differing significantly from the majority of the data.\n\n_Usage examples: intrusion detection, fraud detection, system health monitoring, removing anomalous data from the dataset etc._\n\n#### \xf0\x9f\xa4\x96 Anomaly Detection using Gaussian Distribution\n\n- \xf0\x9f\x93\x97 [Math | Anomaly Detection using Gaussian Distribution](homemade/anomaly_detection) - theory and links for further readings\n- \xe2\x9a\x99\xef\xb8\x8f [Code | Anomaly Detection using Gaussian Distribution](homemade/anomaly_detection/gaussian_anomaly_detection.py) - implementation example\n- \xe2\x96\xb6\xef\xb8\x8f [Demo | Anomaly Detection](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/anomaly_detection/anomaly_detection_gaussian_demo.ipynb) - find anomalies in server operational parameters like `latency` and `threshold`\n\n## Neural Network (NN)\n\nThe neural network itself isn\'t an algorithm, but rather a framework for many different machine learning algorithms to work together and process complex data inputs.\n\n_Usage examples: as a substitute of all other algorithms in general, image recognition, voice recognition, image processing (applying specific style), language translation, etc._\n\n#### \xf0\x9f\xa4\x96 Multilayer Perceptron (MLP)\n\n- \xf0\x9f\x93\x97 [Math | Multilayer Perceptron](homemade/neural_network) - theory and links for further readings\n- \xe2\x9a\x99\xef\xb8\x8f [Code | Multilayer Perceptron](homemade/neural_network/multilayer_perceptron.py) - implementation example\n- \xe2\x96\xb6\xef\xb8\x8f [Demo | Multilayer Perceptron | MNIST](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/neural_network/multilayer_perceptron_demo.ipynb) - recognize handwritten digits from `28x28` pixel images\n- \xe2\x96\xb6\xef\xb8\x8f [Demo | Multilayer Perceptron | Fashion MNIST](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/neural_network/multilayer_perceptron_fashion_demo.ipynb) - recognize the type of clothes from `28x28` pixel images\n\n## Machine Learning Map\n\n![Machine Learning Map](images/machine-learning-map.png)\n\nThe source of the following machine learning topics map is [this wonderful blog post](https://vas3k.ru/blog/machine_learning/)\n\n## Prerequisites\n\n#### Installing Python\n\nMake sure that you have [Python installed](https://realpython.com/installing-python/) on your machine.\n\nYou might want to use [venv](https://docs.python.org/3/library/venv.html) standard Python library\nto create virtual environments and have Python, `pip` and all dependent packages to be installed and \nserved from the local project directory to avoid messing with system wide packages and their \nversions.\n\n#### Installing Dependencies\n\nInstall all dependencies that are required for the project by running:\n\n```bash\npip install -r requirements.txt\n```\n\n#### Launching Jupyter Locally\n\nAll demos in the project may be run directly in your browser without installing Jupyter locally. But if you want to launch [Jupyter Notebook](http://jupyter.org/) locally you may do it by running the following command from the root folder of the project:\n\n```bash\njupyter notebook\n```\nAfter this Jupyter Notebook will be accessible by `http://localhost:8888`.\n\n#### Launching Jupyter Remotely\n\nEach algorithm section contains demo links to [Jupyter NBViewer](http://nbviewer.jupyter.org/). This is fast online previewer for Jupyter notebooks where you may see demo code, charts and data right in your browser without installing anything locally. In case if you want to _change_ the code and _experiment_ with demo notebook you need to launch the notebook in [Binder](https://mybinder.org/). You may do it by simply clicking the _""Execute on Binder""_ link in top right corner of the NBViewer.\n\n![](./images/binder-button-place.png)\n\n## Datasets\n\nThe list of datasets that is being used for Jupyter Notebook demos may be found in [data folder](data).\n'"
10,allmachinelearning/MachineLearning,allmachinelearning,Machine learning resources,2017-05-09 10:29:21,2020-06-16 09:42:47,,910,2764,"b""# \xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xb5\x84\xe6\xba\x90 Machine learning Resources\r\n\r\n**\xe8\x87\xb4\xe5\x8a\x9b\xe4\xba\x8e\xe5\x88\x86\xe4\xba\xab\xe6\x9c\x80\xe6\x96\xb0\xe6\x9c\x80\xe5\x85\xa8\xe9\x9d\xa2\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xb5\x84\xe6\x96\x99\xef\xbc\x8c\xe6\xac\xa2\xe8\xbf\x8e\xe4\xbd\xa0\xe6\x88\x90\xe4\xb8\xba\xe8\xb4\xa1\xe7\x8c\xae\xe8\x80\x85!**\r\n\r\n*\xe5\xbf\xab\xe9\x80\x9f\xe5\xbc\x80\xe5\xa7\x8b\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x9a* \r\n- \xe5\x91\xa8\xe5\xbf\x97\xe5\x8d\x8e\xe7\x9a\x84[\xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe3\x80\x8b](https://pan.baidu.com/s/1hscnaQC)\xe4\xbd\x9c\xe4\xb8\xba\xe9\x80\x9a\xe8\xaf\xbb\xe6\x95\x99\xe6\x9d\x90\xef\xbc\x8c\xe4\xb8\x8d\xe7\x94\xa8\xe6\xb7\xb1\xe5\x85\xa5\xef\xbc\x8c\xe4\xbb\x8e\xe5\xae\x8f\xe8\xa7\x82\xe4\xb8\x8a\xe4\xba\x86\xe8\xa7\xa3\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\r\n\r\n- \xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe3\x80\x8b\xe8\xa5\xbf\xe7\x93\x9c\xe4\xb9\xa6\xe5\x85\xac\xe5\xbc\x8f\xe6\x8e\xa8\xe5\xaf\xbc\xe8\xa7\xa3\xe6\x9e\x90\xef\xbc\x9ahttps://datawhalechina.github.io/pumpkin-book/\r\n\r\n- \xe6\x9c\x80\xe6\x96\xb0\xe7\x9a\x84[\xe3\x80\x8a\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe4\xb8\x8e\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe3\x80\x8b](https://mp.weixin.qq.com/s?__biz=MzIwOTc2MTUyMg==&mid=2247488439&idx=1&sn=df51b67ac2a42fe1a8417a7e4d308b8b&chksm=976fb62aa0183f3c8cfbfcf2c1613aa3a168f782bc5b439aa2a5db9574a33f678a081a1d24a5&mpshare=1&scene=1&srcid=0409hgaWjfxz2LzGtniTpAKh&key=12a4c5f4665589b6914fa6a60a7fe4bd6a4fc4855ac8967b945678646a60c26482467697a46b85e85c7a6a7d564aac41d6c0312307a7f95ba299d3b3cf8433f9a159f999d9484534452672dbdd9fd270&ascene=1&uin=NjMzMjQzMTYw&devicetype=Windows+10&version=62060739&lang=zh_CN&pass_ticket=CIhr0hAvTnkZIvwFNRQ2%2BWhir8OVCkCt9tarvfIPS5SWtyyQKMLGOBt%2BItSffrll)\r\n\r\n- \xe6\x9d\x8e\xe8\x88\xaa\xe7\x9a\x84[\xe3\x80\x8a\xe7\xbb\x9f\xe8\xae\xa1\xe5\xad\xa6\xe4\xb9\xa0\xe6\x96\xb9\xe6\xb3\x95\xe3\x80\x8b](https://pan.baidu.com/s/1dF2b4jf)\xe4\xbd\x9c\xe4\xb8\xba\xe7\xbb\x8f\xe5\x85\xb8\xe7\x9a\x84\xe6\xb7\xb1\xe5\x85\xa5\xe6\xa1\x88\xe4\xbe\x8b\xef\xbc\x8c\xe4\xbb\x94\xe7\xbb\x86\xe7\xa0\x94\xe7\xa9\xb6\xe5\x87\xa0\xe4\xb8\xaa\xe7\xae\x97\xe6\xb3\x95\xe7\x9a\x84\xe6\x9d\xa5\xe9\xbe\x99\xe5\x8e\xbb\xe8\x84\x89 | [\xe4\xb9\xa6\xe4\xb8\xad\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81\xe5\xae\x9e\xe7\x8e\xb0](https://github.com/WenDesi/lihang_book_algorithm)\r\n\r\n- \xe4\xbd\xbf\xe7\x94\xa8Python\xe8\xaf\xad\xe8\xa8\x80\xef\xbc\x8c\xe6\xa0\xb9\xe6\x8d\xae[\xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xae\x9e\xe6\x88\x98\xe3\x80\x8b](https://pan.baidu.com/s/1gfzV7PL)\xe5\xbf\xab\xe9\x80\x9f\xe4\xb8\x8a\xe6\x89\x8b\xe5\x86\x99\xe7\xa8\x8b\xe5\xba\x8f\r\n\r\n- \xe5\x90\xb4\xe6\x81\xa9\xe8\xbe\xbe\xe7\x9a\x84\xe6\x9c\x80\xe6\x96\xb0\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe8\xaf\xbe\xe7\xa8\x8b\xe8\xb5\x84\xe6\xba\x90\xef\xbc\x9ahttps://www.jiqizhixin.com/articles/2018-06-21-6\r\n\r\n- \xe5\x8f\x82\xe7\x85\xa7Youtube\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xba\xa2\xe4\xba\xbaSiraj Raval\xe7\x9a\x84\xe8\xa7\x86\xe9\xa2\x91+\xe4\xbb\xa3\xe7\xa0\x81\xe5\x8f\xaf\xe4\xbb\xa5\xe5\xb8\xae\xe5\x8a\xa9\xe4\xbd\xa0\xe6\x9b\xb4\xe5\xa5\xbd\xe5\x9c\xb0\xe8\xbf\x9b\xe5\x85\xa5\xe7\x8a\xb6\xe6\x80\x81\xef\xbc\x81\r\n    - [\xe5\x8e\x9fYoutube\xe5\x9c\xb0\xe5\x9d\x80\xe9\x9c\x80\xe8\xa6\x81\xe6\xa2\xaf\xe5\xad\x90](https://www.youtube.com/watch?v=xRJCOz3AfYY&list=PL2-dafEMk2A7mu0bSksCGMJEmeddU_H4D) | [\xe7\x99\xbe\xe5\xba\xa6\xe7\xbd\x91\xe7\x9b\x98](https://pan.baidu.com/s/1jICGJFg)\r\n    \r\n- \xe6\x9d\xa5\xe8\x87\xaa\xe5\x9b\xbd\xe7\xab\x8b\xe5\x8f\xb0\xe6\xb9\xbe\xe5\xa4\xa7\xe5\xad\xa6\xe6\x9d\x8e\xe5\xae\x8f\xe6\xaf\x85\xe8\x80\x81\xe5\xb8\x88\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x92\x8c\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe4\xb8\xad\xe6\x96\x87\xe8\xaf\xbe\xe7\xa8\x8b\xef\xbc\x8c\xe5\xbc\xba\xe7\x83\x88\xe6\x8e\xa8\xe8\x8d\x90\xef\xbc\x9a[\xe8\xaf\xbe\xe7\xa8\x8b](http://speech.ee.ntu.edu.tw/~tlkagk/courses.html)\r\n\r\n- \xe6\x9c\x80\xe5\x90\x8e\xef\xbc\x8c\xe4\xbd\xa0\xe5\x8f\xaf\xe8\x83\xbd\xe6\x83\xb3\xe7\x9c\x9f\xe6\xad\xa3\xe5\xae\x9e\xe6\x88\x98\xe4\xb8\x80\xe4\xb8\x8b\xe3\x80\x82\xe9\x82\xa3\xe4\xb9\x88\xef\xbc\x8c\xe8\xaf\xb7\xe5\x88\xb0\xe6\xb3\xa8\xe6\x98\x8e\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xab\x9e\xe8\xb5\x9b\xe5\xb9\xb3\xe5\x8f\xb0Kaggle\xe4\xb8\x8a\xe5\x81\x9a\xe4\xb8\x80\xe4\xb8\x8b\xe8\xbf\x99\xe4\xba\x9b\xe5\x9f\xba\xe7\xa1\x80\xe5\x85\xa5\xe9\x97\xa8\xe7\x9a\x84[\xe9\xa2\x98\xe7\x9b\xae](https://www.kaggle.com/competitions?sortBy=deadline&group=all&page=1&pageSize=20&segment=gettingStarted)\xe5\x90\xa7\xef\xbc\x81(Kaggle\xe4\xb8\x8a\xe5\xaf\xb9\xe4\xba\x8e\xe6\xaf\x8f\xe4\xb8\xaa\xe9\x97\xae\xe9\xa2\x98\xe4\xbd\xa0\xe9\x83\xbd\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x9c\x8b\xe5\x88\xb0\xe5\x88\xab\xe4\xba\xba\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x8c\xe6\x96\xb9\xe4\xbe\xbf\xe4\xbd\xa0\xe6\x9b\xb4\xe5\x8a\xa0\xe5\xbf\xab\xe9\x80\x9f\xe5\x9c\xb0\xe5\xad\xa6\xe4\xb9\xa0) \xc2\xa0[Kaggle\xe4\xbb\x8b\xe7\xbb\x8d\xe5\x8f\x8a\xe5\x85\xa5\xe9\x97\xa8\xe8\xa7\xa3\xe8\xaf\xbb](https://zhuanlan.zhihu.com/p/25686876) [\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x94\xa8\xe6\x9d\xa5\xe7\xbb\x83\xe6\x89\x8b\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86](https://www.kaggle.com/annavictoria/ml-friendly-public-datasets/notebook)\r\n\r\n\xe5\x85\xb6\xe4\xbb\x96\xe6\x9c\x89\xe7\x94\xa8\xe7\x9a\x84\xe8\xb5\x84\xe6\x96\x99\xef\xbc\x9a\r\n\r\n- \xe6\x83\xb3\xe7\x9c\x8b\xe5\x88\xab\xe4\xba\xba\xe6\x80\x8e\xe4\xb9\x88\xe5\x86\x99\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9f[\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xbb\x8f\xe5\x85\xb8\xe6\x95\x99\xe6\x9d\x90\xe3\x80\x8aPRML\xe3\x80\x8b\xe6\x89\x80\xe6\x9c\x89\xe4\xbb\xa3\xe7\xa0\x81\xe5\xae\x9e\xe7\x8e\xb0](https://github.com/ctgk/PRML)\r\n\r\n- [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xae\x97\xe6\xb3\x95Python\xe5\xae\x9e\xe7\x8e\xb0](https://github.com/lawlite19/MachineLearning_Python)\r\n\r\n- [\xe5\x90\xb4\xe6\x81\xa9\xe8\xbe\xbe\xe6\x96\xb0\xe4\xb9\xa6\xef\xbc\x9aMachine Learning Yearning\xe4\xb8\xad\xe6\x96\x87\xe7\x89\x88](https://pan.baidu.com/s/10kosKx6rDguS4tPejY-fRw)\r\n\r\n- \xe5\x8f\xa6\xe5\xa4\x96\xef\xbc\x8c\xe5\xaf\xb9\xe4\xba\x8e\xe4\xb8\x80\xe4\xba\x9b\xe5\x9f\xba\xe7\xa1\x80\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\xa6\xe7\x9f\xa5\xe8\xaf\x86\xef\xbc\x8c\xe4\xbd\xa0\xe7\x9c\x8b[\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0(\xe8\x8a\xb1\xe4\xb9\xa6)\xe4\xb8\xad\xe6\x96\x87\xe7\x89\x88](https://github.com/exacity/deeplearningbook-chinese)\xe5\xb0\xb1\xe5\xa4\x9f\xe4\xba\x86\xe3\x80\x82\xe8\xbf\x99\xe6\x9c\xac\xe4\xb9\xa6\xe5\x90\x8c\xe6\x97\xb6\xe4\xb9\x9f\xe6\x98\xaf**\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0**\xe7\xbb\x8f\xe5\x85\xb8\xe4\xb9\x8b\xe4\xb9\xa6\xe3\x80\x82\r\n\r\n- \xe6\x9d\xa5\xe8\x87\xaa\xe5\x8d\x97\xe4\xba\xac\xe5\xa4\xa7\xe5\xad\xa6\xe5\x91\xa8\xe5\xbf\x97\xe5\x8d\x8e\xe5\xb0\x8f\xe7\xbb\x84\xe7\x9a\x84\xe5\x8d\x9a\xe5\xa3\xab\xe7\x94\x9f\xe5\x86\x99\xe7\x9a\x84\xe4\xb8\x80\xe6\x9c\xac\xe5\xb0\x8f\xe8\x80\x8c\xe7\xb2\xbe\xe7\x9a\x84[\xe8\xa7\xa3\xe6\x9e\x90\xe5\x8d\xb7\xe7\xa7\xaf\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe2\x80\x94\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe5\xae\x9e\xe8\xb7\xb5\xe6\x89\x8b\xe5\x86\x8c](http://lamda.nju.edu.cn/weixs/book/CNN_book.html)\r\n\r\n- - -\r\n\r\n[\xe4\xb8\x80\xe4\xb8\xaa\xe7\xae\x80\xe6\xb4\x81\xe6\x98\x8e\xe4\xba\x86\xe7\x9a\x84\xe6\x97\xb6\xe9\x97\xb4\xe5\xba\x8f\xe5\x88\x97\xe5\xa4\x84\xe7\x90\x86(\xe5\x88\x86\xe7\xaa\x97\xe3\x80\x81\xe7\x89\xb9\xe5\xbe\x81\xe6\x8f\x90\xe5\x8f\x96\xe3\x80\x81\xe5\x88\x86\xe7\xb1\xbb)\xe5\xba\x93\xef\xbc\x9aSeglearn](https://dmbee.github.io/seglearn/index.html)\r\n\r\n[\xe8\xae\xa1\xe7\xae\x97\xe6\x9c\xba\xe8\xa7\x86\xe8\xa7\x89\xe8\xbf\x99\xe4\xb8\x80\xe5\xb9\xb4\xef\xbc\x9a\xe8\xbf\x99\xe6\x98\xaf\xe6\x9c\x80\xe5\x85\xa8\xe7\x9a\x84\xe4\xb8\x80\xe4\xbb\xbdCV\xe6\x8a\x80\xe6\x9c\xaf\xe6\x8a\xa5\xe5\x91\x8a](https://zhuanlan.zhihu.com/p/31430602)\r\n\r\n[\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0(\xe8\x8a\xb1\xe4\xb9\xa6)\xe4\xb8\xad\xe6\x96\x87\xe7\x89\x88](https://github.com/exacity/deeplearningbook-chinese)\r\n\r\n**[\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe6\x9c\x80\xe5\x80\xbc\xe5\xbe\x97\xe7\x9c\x8b\xe7\x9a\x84\xe8\xae\xba\xe6\x96\x87](http://www.dlworld.cn/YeJieDongTai/4385.html)**\r\n\r\n**[\xe6\x9c\x80\xe5\x85\xa8\xe9\x9d\xa2\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe8\x87\xaa\xe5\xad\xa6\xe8\xb5\x84\xe6\xba\x90\xe9\x9b\x86\xe9\x94\xa6](http://dataunion.org/29975.html)**\r\n\r\n**[Machine learning surveys](https://github.com/metrofun/machine-learning-surveys/)**\r\n\r\n**[\xe5\xbf\xab\xe9\x80\x9f\xe5\x85\xa5\xe9\x97\xa8TensorFlow](https://github.com/aymericdamien/TensorFlow-Examples)**\r\n\r\n[\xe8\x87\xaa\xe7\x84\xb6\xe8\xaf\xad\xe8\xa8\x80\xe5\xa4\x84\xe7\x90\x86\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86](http://abunchofdata.com/datasets-for-natural-language-processing/)\r\n\xc2\xa0\r\n[Learning Machine Learning? Six articles you don\xe2\x80\x99t want to miss](http://www.ibmbigdatahub.com/blog/learning-machine-learning-six-articles-you-don-t-want-miss)\r\n\r\n[Getting started with machine learning documented by github](https://github.com/collections/machine-learning)\r\n\r\n- - -\r\n\r\n\r\n## \xe7\xa0\x94\xe7\xa9\xb6\xe9\xa2\x86\xe5\x9f\x9f\xe8\xb5\x84\xe6\xba\x90\xe7\xbb\x86\xe5\x88\x86\r\n\r\n- ### [\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0 Deep learning](https://github.com/ChristosChristofidis/awesome-deep-learning)\r\n\r\n- ### [\xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0 Reinforcement learning](https://github.com/aikorea/awesome-rl)\r\n\r\n- ### [\xe8\xbf\x81\xe7\xa7\xbb\xe5\xad\xa6\xe4\xb9\xa0 Transfer learning](https://jindongwang.github.io/transferlearning/)\r\n\r\n- ### [\xe5\x88\x86\xe5\xb8\x83\xe5\xbc\x8f\xe5\xad\xa6\xe4\xb9\xa0\xe7\xb3\xbb\xe7\xbb\x9f Distributed learning system](https://github.com/theanalyst/awesome-distributed-systems)\r\n\r\n- ### [\xe8\xae\xa1\xe7\xae\x97\xe6\x9c\xba\xe8\xa7\x86\xe8\xa7\x89/\xe6\x9c\xba\xe5\x99\xa8\xe8\xa7\x86\xe8\xa7\x89 Computer vision / machine vision](https://github.com/jbhuang0604/awesome-computer-vision)\r\n\r\n- ### [\xe8\x87\xaa\xe7\x84\xb6\xe8\xaf\xad\xe8\xa8\x80\xe5\xa4\x84\xe7\x90\x86 Natural language procesing](https://github.com/Nativeatom/NaturalLanguageProcessing)\r\n\r\n- ### [\xe7\x94\x9f\xe7\x89\xa9\xe4\xbf\xa1\xe6\x81\xaf\xe5\xad\xa6 Bioinfomatics](https://github.com/danielecook/Awesome-Bioinformatics)\r\n\r\n- ### [\xe8\xa1\x8c\xe4\xb8\xba\xe8\xaf\x86\xe5\x88\xab Activity recognition](https://github.com/jindongwang/activityrecognition)\r\n\r\n- ### [\xe5\xa4\x9a\xe6\x99\xba\xe8\x83\xbd\xe4\xbd\x93 Multi-Agent](http://ddl.escience.cn/f/ILKI)\r\n\r\n- - -\r\n\r\n##  \xe5\xbc\x80\xe5\xa7\x8b\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x9a\xe9\xa2\x84\xe5\xa4\x87\xe7\x9f\xa5\xe8\xaf\x86 Prerequisite\r\n\r\n- [\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9f\xa5\xe8\xaf\x86\xe4\xb8\x8e\xe8\xb7\xaf\xe7\xba\xbf\xe5\x9b\xbe](https://metacademy.org/)\r\n\r\n- [MIT\xe7\xba\xbf\xe6\x80\xa7\xe4\xbb\xa3\xe6\x95\xb0\xe8\xaf\xbe\xe5\xa0\x82\xe7\xac\x94\xe8\xae\xb0(\xe4\xb8\xad\xe6\x96\x87)](https://github.com/zlotus/notes-linear-algebra)\r\n\r\n- [\xe6\xa6\x82\xe7\x8e\x87\xe4\xb8\x8e\xe7\xbb\x9f\xe8\xae\xa1 The Probability and Statistics Cookbook](http://statistics.zone/)\r\n\r\n- Python\r\n\r\n    - [Learn X in Y minutes](https://learnxinyminutes.com/docs/python/)\r\n\r\n    - [Python\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe4\xba\x92\xe5\x8a\xa8\xe6\x95\x99\xe7\xa8\x8b](https://www.springboard.com/learning-paths/machine-learning-python/)\r\n\r\n- Markdown\r\n\r\n    - [Mastering Markdown](https://guides.github.com/features/mastering-markdown/) - Markdown is a easy-to-use writing tool on the GitHu.\r\n\r\n- R\r\n\r\n    - [R Tutorial](http://www.cyclismo.org/tutorial/R/)\r\n\r\n- Python\xe5\x92\x8cMatlab\xe7\x9a\x84\xe4\xb8\x80\xe4\xba\x9bcheat sheet\xef\xbc\x9ahttp://ddl.escience.cn/f/IDkq \xe5\x8c\x85\xe5\x90\xab\xef\xbc\x9a\r\n\r\n    - Numpy\xe3\x80\x81Scipy\xe3\x80\x81Pandas\xe7\xa7\x91\xe5\xad\xa6\xe8\xae\xa1\xe7\xae\x97\xe5\xba\x93\r\n\r\n    - Matlab\xe7\xa7\x91\xe5\xad\xa6\xe8\xae\xa1\xe7\xae\x97\r\n\r\n    - Matplotlib\xe7\x94\xbb\xe5\x9b\xbe\r\n\r\n- \xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe6\xa1\x86\xe6\x9e\xb6\r\n\r\n    - Python\r\n        - [TensorFlow](https://www.tensorflow.org/)\r\n        - [Scikit-learn](http://scikit-learn.org/)\r\n        - [PyTorch](http://pytorch.org/)\r\n        - [Keras](https://keras.io/)\r\n        - [MXNet](http://mxnet.io/)|[\xe7\x9b\xb8\xe5\x85\xb3\xe8\xb5\x84\xe6\xba\x90\xe5\xa4\xa7\xe5\x88\x97\xe8\xa1\xa8](https://github.com/chinakook/Awesome-MXNet)\r\n        - [Caffe](http://caffe.berkeleyvision.org/)\r\n        - [Caffe2](https://caffe2.ai/)\r\n\r\n    - Java\r\n        - [Deeplearning4j](https://deeplearning4j.org/)\r\n\r\n    - Matlab\r\n        - [Neural Network Toolbox](https://cn.mathworks.com/help/nnet/index.html)\r\n        - [Deep Learning Toolbox](https://cn.mathworks.com/matlabcentral/fileexchange/38310-deep-learning-toolbox)\r\n\r\n- - -\r\n\r\n\r\n## \xe6\x96\x87\xe6\xa1\xa3 notes\r\n\r\n- [\xe7\xbb\xbc\xe8\xbf\xb0\xe6\x96\x87\xe7\xab\xa0\xe6\xb1\x87\xe6\x80\xbb](https://github.com/allmachinelearning/MachineLearning/blob/master/notes/survey_readme.md)\r\n\r\n- [\xe8\xbf\x91200\xe7\xaf\x87\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xb5\x84\xe6\x96\x99\xe6\xb1\x87\xe6\x80\xbb\xef\xbc\x81](https://zhuanlan.zhihu.com/p/26136757)\r\n\r\n- [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x85\xa5\xe9\x97\xa8\xe8\xb5\x84\xe6\x96\x99](https://github.com/allmachinelearning/MachineLearning/blob/master/notes/MLMaterials.md)\r\n\r\n- [MIT.Introduction to Machine Learning](http://ddl.escience.cn/f/Iwtu)\r\n\r\n- [\xe4\xb8\x9c\xe4\xba\xac\xe5\xa4\xa7\xe5\xad\xa6\xe5\x90\x8c\xe5\xad\xa6\xe5\x81\x9a\xe7\x9a\x84\xe4\xba\xba\xe6\x9c\xba\xe4\xba\xa4\xe4\xba\x92\xe6\x8a\xa5\xe5\x91\x8a](https://github.com/allmachinelearning/MachineLearning/blob/master/notes/FieldResearchinChina927-104.pdf)\r\n\r\n- [\xe4\xba\xba\xe6\x9c\xba\xe4\xba\xa4\xe4\xba\x92\xe7\xae\x80\xe4\xbb\x8b](https://github.com/jindongwang/HCI)\r\n\r\n- [\xe4\xba\xba\xe6\x9c\xba\xe4\xba\xa4\xe4\xba\x92\xe4\xb8\x8e\xe5\x88\x9b\xe4\xb8\x9a\xe8\xae\xba\xe5\x9d\x9b](https://github.com/allmachinelearning/MachineLearning/blob/master/notes/%E4%BA%BA%E6%9C%BA%E4%BA%A4%E4%BA%92%E4%B8%8E%E5%88%9B%E4%B8%9A%E8%AE%BA%E5%9D%9B.md)\r\n\r\n- [\xe8\x81\x8c\xe5\x9c\xba\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x85\xa5\xe9\x97\xa8](https://github.com/allmachinelearning/MachineLearning/blob/master/notes/%E8%81%8C%E5%9C%BA-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.md)\r\n\r\n- [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9a\x84\xe5\x8f\x91\xe5\xb1\x95\xe5\x8e\x86\xe7\xa8\x8b\xe5\x8f\x8a\xe5\x90\xaf\xe7\xa4\xba](http://mt.sohu.com/20170326/n484898474.shtml), (@Prof. Zhihua Zhang/@\xe5\xbc\xa0\xe5\xbf\x97\xe5\x8d\x8e\xe6\x95\x99\xe6\x8e\x88)\r\n\r\n- [\xe5\xb8\xb8\xe7\x94\xa8\xe7\x9a\x84\xe8\xb7\x9d\xe7\xa6\xbb\xe5\x92\x8c\xe7\x9b\xb8\xe4\xbc\xbc\xe5\xba\xa6\xe5\xba\xa6\xe9\x87\x8f](https://github.com/allmachinelearning/MachineLearning/blob/master/notes/distance%20and%20similarity.md)\r\n\r\n- - -\r\n\r\n\r\n## \xe8\xaf\xbe\xe7\xa8\x8b\xe4\xb8\x8e\xe8\xae\xb2\xe5\xba\xa7 Course and talk\r\n\r\n### \xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0 Machine Learning\r\n\xc2\xa0\r\n[\xe5\x8f\xb0\xe6\xb9\xbe\xe5\xa4\xa7\xe5\xad\xa6\xe5\xba\x94\xe7\x94\xa8\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe8\xaf\xbe\xe7\xa8\x8b](https://www.csie.ntu.edu.tw/~yvchen/f106-adl/index.html)\r\n\r\n-\xc2\xa0[\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xef\xbc\x8c\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x8c\xe7\xae\x97\xe6\xb3\x95\xef\xbc\x8c\xe4\xba\xba\xe5\xb7\xa5\xe6\x99\xba\xe8\x83\xbd\xe7\xad\x89 30 \xe9\x97\xa8\xe5\x85\x8d\xe8\xb4\xb9\xe8\xaf\xbe\xe7\xa8\x8b\xe8\xaf\xa6\xe7\xbb\x86\xe6\xb8\x85\xe5\x8d\x95](http://www.datasciencecentral.com/profiles/blogs/neural-networks-for-machine-learning)\r\n\xc2\xa0 \r\n- [\xe6\x96\xaf\xe5\x9d\xa6\xe7\xa6\x8f\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x85\xa5\xe9\x97\xa8\xe8\xaf\xbe\xe7\xa8\x8b](https://www.coursera.org/learn/machine-learning)\xef\xbc\x8c\xe8\xae\xb2\xe5\xb8\x88\xe4\xb8\xbaAndrew Ng\xef\xbc\x8c\xe9\x80\x82\xe5\x90\x88\xe6\x95\xb0\xe5\xad\xa6\xe5\x9f\xba\xe7\xa1\x80\xe4\xb8\x80\xe8\x88\xac\xe7\x9a\x84\xe4\xba\xba\xef\xbc\x8c\xe9\x80\x82\xe5\x90\x88\xe5\x85\xa5\xe9\x97\xa8\xef\xbc\x8c\xe4\xbd\x86\xe6\x98\xaf\xe5\xad\xa6\xe5\xae\x8c\xe4\xbc\x9a\xe5\x8f\x91\xe7\x8e\xb0\xe5\x8f\xaa\xe6\x98\xaf\xe6\x87\x82\xe4\xb8\xaa\xe5\xa4\xa7\xe6\xa6\x82\xef\xbc\x8c\xe4\xb9\x9f\xe5\xb0\xb1\xe7\x9b\xb8\xe5\xbd\x93\xe4\xba\x8e\xe4\xbb\x80\xe4\xb9\x88\xe9\x83\xbd\xe4\xb8\x8d\xe6\x87\x82\xe3\x80\x82\xe7\x9c\x81\xe7\x95\xa5\xe4\xba\x86\xe5\xbe\x88\xe5\xa4\x9a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9a\x84\xe7\xbb\x86\xe8\x8a\x82\r\n\r\n- [Neural Networks for Machine Learning](https://www.coursera.org/learn/neural-networks), Coursera\xe4\xb8\x8a\xe7\x9a\x84\xe8\x91\x97\xe5\x90\x8d\xe8\xaf\xbe\xe7\xa8\x8b\xef\xbc\x8c\xe7\x94\xb1Geoffrey Hinton\xe6\x95\x99\xe6\x8e\x88\xe4\xb8\xbb\xe8\xae\xb2\xe3\x80\x82\r\n\r\n- [Stanford CS 229](http://cs229.stanford.edu/materials.html), Andrew Ng\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xaf\xbe\xe6\x97\xa0\xe9\x98\x89\xe5\x89\xb2\xe7\x89\x88\xef\xbc\x8cNotes\xe6\xaf\x94\xe8\xbe\x83\xe8\xaf\xa6\xe7\xbb\x86\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe5\xaf\xb9\xe7\x85\xa7\xe5\xad\xa6\xe4\xb9\xa0[CS229\xe8\xaf\xbe\xe7\xa8\x8b\xe8\xae\xb2\xe4\xb9\x89\xe7\x9a\x84\xe4\xb8\xad\xe6\x96\x87\xe7\xbf\xbb\xe8\xaf\x91](https://github.com/Kivy-CN/Stanford-CS-229-CN)\xe3\x80\x82\r\n\r\n- [CMU 10-702 Statistical Machine Learning](http://www.stat.cmu.edu/~larry/=sml/), \xe8\xae\xb2\xe5\xb8\x88\xe6\x98\xafLarry Wasserman\xef\xbc\x8c\xe5\xba\x94\xe8\xaf\xa5\xe6\x98\xaf\xe7\xbb\x9f\xe8\xae\xa1\xe7\xb3\xbb\xe5\xbc\x80\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x8c\xe9\x9d\x9e\xe5\xb8\xb8\xe6\x95\xb0\xe5\xad\xa6\xe5\x8c\x96\xef\xbc\x8c\xe7\xac\xac\xe4\xb8\x80\xe8\x8a\x82\xe8\xaf\xbe\xe5\xb0\xb1\xe6\x8f\x90\xe5\x88\xb0\xe4\xba\x86RKHS(Reproducing Kernel Hilbert Space),\xe5\xbb\xba\xe8\xae\xae\xe6\x95\xb0\xe5\xad\xa6\xe5\x87\xba\xe8\xba\xab\xe7\x9a\x84\xe5\x90\x8c\xe5\xad\xa6\xe7\x9c\x8b\xe6\x88\x96\xe8\x80\x85\xe6\x98\xaf\xe5\xad\xa6\xe8\xbf\x87\xe5\xae\x9e\xe5\x8f\x98\xe5\x87\xbd\xe6\x95\xb0\xe6\xb3\x9b\xe5\x87\xbd\xe5\x88\x86\xe6\x9e\x90\xe7\x9a\x84\xe4\xba\xba\xe7\x9c\x8b\xe4\xb8\x80\xe7\x9c\x8b\r\n\r\n- [CMU 10-715 Advanced Introduction to Machine Learning](https://www.cs.cmu.edu/~epxing/Class/10715/)\xef\xbc\x8c\xe5\x90\x8c\xe6\xa0\xb7\xe6\x98\xafCMU phd\xe7\xba\xa7\xe5\x88\xab\xe7\x9a\x84\xe8\xaf\xbe\xef\xbc\x8c\xe8\x8a\x82\xe5\xa5\x8f\xe5\xbf\xab\xe9\x9a\xbe\xe5\xba\xa6\xe9\xab\x98\r\n\r\n- [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x9f\xba\xe7\x9f\xb3](https://www.coursera.org/course/ntumlone)\xef\xbc\x88\xe9\x80\x82\xe5\x90\x88\xe5\x85\xa5\xe9\x97\xa8\xef\xbc\x89\xe3\x80\x82\xe5\x9b\xbd\xe7\xab\x8b\xe5\x8f\xb0\xe6\xb9\xbe\xe5\xa4\xa7\xe5\xad\xa6[\xe6\x9e\x97\xe8\xbd\xa9\xe7\x94\xb0](https://www.coursera.org/instructor/htlin)\r\n\r\n- [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x8a\x80\xe6\xb3\x95](https://www.coursera.org/course/ntumltwo)\xef\xbc\x88\xe9\x80\x82\xe5\x90\x88\xe6\x8f\x90\xe9\xab\x98\xef\xbc\x89\xe3\x80\x82\xe5\x9b\xbd\xe7\xab\x8b\xe5\x8f\xb0\xe6\xb9\xbe\xe5\xa4\xa7\xe5\xad\xa6[\xe6\x9e\x97\xe8\xbd\xa9\xe7\x94\xb0](https://www.coursera.org/instructor/htlin)\r\n\r\n- [Machine Learning for Data Analysis](https://www.coursera.org/learn/machine-learning-data-analysis), Coursera\xe4\xb8\x8aWesleyan\xe5\xa4\xa7\xe5\xad\xa6\xe7\x9a\x84Data Analysis and Interpretation\xe4\xb8\x93\xe9\xa1\xb9\xe8\xaf\xbe\xe7\xa8\x8b\xe7\xac\xac\xe5\x9b\x9b\xe8\xaf\xbe\xe3\x80\x82\r\n\r\n- Max Planck Institute for Intelligent Systems T\xc3\xbcbingen[\xe5\xbe\xb7\xe5\x9b\xbd\xe9\xa9\xac\xe6\x99\xae\xe6\x89\x80\xe6\x99\xba\xe8\x83\xbd\xe7\xb3\xbb\xe7\xbb\x9f\xe7\xa0\x94\xe7\xa9\xb6\xe6\x89\x802013\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x9a\x91\xe6\x9c\x9f\xe5\xad\xa6\xe6\xa0\xa1\xe8\xa7\x86\xe9\xa2\x91](https://www.youtube.com/playlist?list=PLqJm7Rc5-EXFv6RXaPZzzlzo93Hl0v91E),\xe4\xbb\x94\xe7\xbb\x86\xe7\xbf\xbb\xe8\xbf\x99\xe4\xb8\xaa\xe9\xa2\x91\xe9\x81\x93\xe8\xbf\x98\xe5\x8f\xaf\xe4\xbb\xa5\xe6\x89\xbe\xe5\x88\xb02015\xe7\x9a\x84\xe6\x9a\x91\xe6\x9c\x9f\xe5\xad\xa6\xe6\xa0\xa1\xe8\xa7\x86\xe9\xa2\x91\r\n\r\n- \xe7\x9f\xa5\xe4\xb9\x8eLive\xef\xbc\x9a[\xe6\x88\x91\xe4\xbb\xac\xe4\xb8\x80\xe8\xb5\xb7\xe5\xbc\x80\xe5\xa7\x8b\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x90\xa7](https://www.zhihu.com/lives/792423196996546560)\xef\xbc\x8c[\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x85\xa5\xe9\x97\xa8\xe4\xb9\x8b\xe7\x89\xb9\xe5\xbe\x81\xe5\xb7\xa5\xe7\xa8\x8b](https://www.zhihu.com/lives/819543866939174912)\r\n\r\n### \xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0 Machine Learning\r\n\r\n- \xe6\x96\xaf\xe5\x9d\xa6\xe7\xa6\x8f\xe5\xa4\xa7\xe5\xad\xa6Feifei Li\xe6\x95\x99\xe6\x8e\x88\xe7\x9a\x84[CS231n\xe7\xb3\xbb\xe5\x88\x97\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe8\xaf\xbe\xe7\xa8\x8b](http://cs231n.stanford.edu/)\xe3\x80\x82Feifei Li\xe7\x9b\xae\xe5\x89\x8d\xe6\x98\xafGoogle\xe7\x9a\x84\xe7\xa7\x91\xe5\xad\xa6\xe5\xae\xb6\xef\xbc\x8c\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe4\xb8\x8e\xe5\x9b\xbe\xe5\x83\x8f\xe8\xaf\x86\xe5\x88\xab\xe6\x96\xb9\xe9\x9d\xa2\xe7\x9a\x84\xe5\xa4\xa7\xe7\x89\x9b\xe3\x80\x82\xe8\xbf\x99\xe9\x97\xa8\xe8\xaf\xbe\xe7\x9a\x84\xe7\xac\x94\xe8\xae\xb0\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x9c\x8b[\xe8\xbf\x99\xe9\x87\x8c](https://zhuanlan.zhihu.com/p/21930884)\xe3\x80\x82\r\n\r\n- [CS224n: Natural Language Processing](http://cs224n.stanford.edu). Course instructors: Chris Manning, Richard Socher.\r\n\r\n### \xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0 Machine Learning\r\n\r\n- [CS 294 Deep Reinforcement Learning, Fall 2017](http://rll.berkeley.edu/deeprlcourse/). Course instructors: Sergey Levine, John Schulman, Chelsea Finn.\r\n\r\n- [UCL Course on RL](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html)\r\n\r\n- [CS234: Reinforcement Learning](http://web.stanford.edu/class/cs234/index.html). \xe6\x9a\x82\xe6\x97\xa0\xe8\xa7\x86\xe9\xa2\x91\r\n\r\n- - -\r\n\r\n\r\n## \xe7\x9b\xb8\xe5\x85\xb3\xe4\xb9\xa6\xe7\xb1\x8d reference book\r\n\r\n- [Hands on Machine Learning with Scikit-learn and Tensorflow](https://my.pcloud.com/publink/show?code=XZ9ev77Zk2l6xcMtfIhHm7mRKAYhISb6sl3k)\r\n\r\n- \xe5\x85\xa5\xe9\x97\xa8\xe8\xaf\xbb\xe7\x89\xa9 [The Elements of Statistical Learning(\xe8\x8b\xb1\xe6\x96\x87\xe7\xac\xac\xe4\xba\x8c\xe7\x89\x88),The Elements of Statistical Learning.pdf](http://ddl.escience.cn/ff/emZH)\r\n\r\n- [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0](https://book.douban.com/subject/26708119/), (@Prof. Zhihua Zhou/\xe5\x91\xa8\xe5\xbf\x97\xe5\x8d\x8e\xe6\x95\x99\xe6\x8e\x88)\r\n\r\n- [\xe7\xbb\x9f\xe8\xae\xa1\xe5\xad\xa6\xe4\xb9\xa0\xe6\x96\xb9\xe6\xb3\x95](https://book.douban.com/subject/10590856/), (@Dr. Hang Li/\xe6\x9d\x8e\xe8\x88\xaa\xe5\x8d\x9a\xe5\xa3\xab)\r\n\r\n- [\xe4\xb8\x80\xe4\xba\x9bKindle\xe8\xaf\xbb\xe7\x89\xa9](http://ddl.escience.cn/f/IwWE):\r\n\r\n\t- \xe5\x88\xa9\xe7\x94\xa8Python\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe6\x9e\x90\r\n\r\n\t- \xe8\xb7\x9f\xe8\x80\x81\xe9\xbd\x90\xe5\xad\xa6Python\xef\xbc\x9a\xe4\xbb\x8e\xe5\x85\xa5\xe9\x97\xa8\xe5\x88\xb0\xe7\xb2\xbe\xe9\x80\x9a\r\n\r\n\t- Python\xe4\xb8\x8e\xe6\x95\xb0\xe6\x8d\xae\xe6\x8c\x96\xe6\x8e\x98 (\xe5\xa4\xa7\xe6\x95\xb0\xe6\x8d\xae\xe6\x8a\x80\xe6\x9c\xaf\xe4\xb8\x9b\xe4\xb9\xa6) - \xe5\xbc\xa0\xe8\x89\xaf\xe5\x9d\x87\r\n\r\n\t- Python\xe5\xad\xa6\xe4\xb9\xa0\xe6\x89\x8b\xe5\x86\x8c\r\n\r\n\t- Python\xe6\x80\xa7\xe8\x83\xbd\xe5\x88\x86\xe6\x9e\x90\xe4\xb8\x8e\xe4\xbc\x98\xe5\x8c\x96\r\n\r\n\t- Python\xe6\x95\xb0\xe6\x8d\xae\xe6\x8c\x96\xe6\x8e\x98\xe5\x85\xa5\xe9\x97\xa8\xe4\xb8\x8e\xe5\xae\x9e\xe8\xb7\xb5\r\n\r\n\t- Python\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe6\x9e\x90\xe4\xb8\x8e\xe6\x8c\x96\xe6\x8e\x98\xe5\xae\x9e\xe6\x88\x98(\xe5\xa4\xa7\xe6\x95\xb0\xe6\x8d\xae\xe6\x8a\x80\xe6\x9c\xaf\xe4\xb8\x9b\xe4\xb9\xa6) - \xe5\xbc\xa0\xe8\x89\xaf\xe5\x9d\x87\r\n\r\n\t- Python\xe7\xa7\x91\xe5\xad\xa6\xe8\xae\xa1\xe7\xae\x97(\xe7\xac\xac2\xe7\x89\x88)\r\n\r\n\t- Python\xe8\xae\xa1\xe7\xae\x97\xe6\x9c\xba\xe8\xa7\x86\xe8\xa7\x89\xe7\xbc\x96\xe7\xa8\x8b [\xe7\xbe\x8e] Jan Erik Solem\r\n\r\n\t- python\xe6\xa0\xb8\xe5\xbf\x83\xe7\xbc\x96\xe7\xa8\x8b(\xe7\xac\xac\xe4\xb8\x89\xe7\x89\x88)\r\n\r\n\t- Python\xe6\xa0\xb8\xe5\xbf\x83\xe7\xbc\x96\xe7\xa8\x8b\xef\xbc\x88\xe7\xac\xac\xe4\xba\x8c\xe7\x89\x88\xef\xbc\x89\r\n\r\n\t- Python\xe9\xab\x98\xe6\x89\x8b\xe4\xb9\x8b\xe8\xb7\xaf - [\xe6\xb3\x95] \xe6\x9c\xb1\xe5\x88\xa9\xe5\xae\x89\xc2\xb7\xe4\xb8\xb9\xe4\xb9\x94\xef\xbc\x88Julien Danjou\xef\xbc\x89\r\n\r\n\t- Python\xe7\xbc\x96\xe7\xa8\x8b\xe5\xbf\xab\xe9\x80\x9f\xe4\xb8\x8a\xe6\x89\x8b \xe8\xae\xa9\xe7\xb9\x81\xe7\x90\x90\xe5\xb7\xa5\xe4\xbd\x9c\xe8\x87\xaa\xe5\x8a\xa8\xe5\x8c\x96\r\n\r\n\t- Python\xe7\xbc\x96\xe7\xa8\x8b\xef\xbc\x9a\xe4\xbb\x8e\xe5\x85\xa5\xe9\x97\xa8\xe5\x88\xb0\xe5\xae\x9e\xe8\xb7\xb5\r\n\r\n\t- Python3 CookBook\xe4\xb8\xad\xe6\x96\x87\xe7\x89\x88\r\n\r\n\t- \xe7\xbb\x88\xe6\x9e\x81\xe7\xae\x97\xe6\xb3\x95\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x92\x8c\xe4\xba\xba\xe5\xb7\xa5\xe6\x99\xba\xe8\x83\xbd\xe5\xa6\x82\xe4\xbd\x95\xe9\x87\x8d\xe5\xa1\x91\xe4\xb8\x96\xe7\x95\x8c - [\xe7\xbe\x8e ]\xe4\xbd\xa9\xe5\xbe\xb7\xe7\xbd\x97\xc2\xb7\xe5\xa4\x9a\xe6\x98\x8e\xe6\x88\x88\xe6\x96\xaf\r\n\r\n\t- \xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xb3\xbb\xe7\xbb\x9f\xe8\xae\xbe\xe8\xae\xa1 (\xe5\x9b\xbe\xe7\x81\xb5\xe7\xa8\x8b\xe5\xba\x8f\xe8\xae\xbe\xe8\xae\xa1\xe4\xb8\x9b\xe4\xb9\xa6) - [\xe7\xbe\x8e]Willi Richert &amp; Luis Pedro Coelho\r\n\r\n\t- \xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xae\x9e\xe8\xb7\xb5\xe6\x8c\x87\xe5\x8d\x97\xef\xbc\x9a\xe6\xa1\x88\xe4\xbe\x8b\xe5\xba\x94\xe7\x94\xa8\xe8\xa7\xa3\xe6\x9e\x90\xef\xbc\x88\xe7\xac\xac2\xe7\x89\x88\xef\xbc\x89 (\xe5\xa4\xa7\xe6\x95\xb0\xe6\x8d\xae\xe6\x8a\x80\xe6\x9c\xaf\xe4\xb8\x9b\xe4\xb9\xa6) - \xe9\xba\xa6\xe5\xa5\xbd\r\n\r\n\t- \xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xae\x9e\xe8\xb7\xb5 \xe6\xb5\x8b\xe8\xaf\x95\xe9\xa9\xb1\xe5\x8a\xa8\xe7\x9a\x84\xe5\xbc\x80\xe5\x8f\x91\xe6\x96\xb9\xe6\xb3\x95 (\xe5\x9b\xbe\xe7\x81\xb5\xe7\xa8\x8b\xe5\xba\x8f\xe8\xae\xbe\xe8\xae\xa1\xe4\xb8\x9b\xe4\xb9\xa6) - [\xe7\xbe\x8e] \xe6\x9f\xaf\xe5\x85\x8b\xef\xbc\x88Matthew Kirk\xef\xbc\x89\r\n\r\n\t- \xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x9a\xe5\xae\x9e\xe7\x94\xa8\xe6\xa1\x88\xe4\xbe\x8b\xe8\xa7\xa3\xe6\x9e\x90\r\n  \r\n\r\n- [\xe6\x95\xb0\xe5\xad\xa6](https://mega.nz/#F!WVAlGL6B!mqIjYoTjiQnO4jBGVLRIWA\r\n):\r\n\r\n    - Algebra - Michael Artin\r\n\r\n    - Algebra - Serge Lang\r\n\r\n    - Basic Topology - M.A. Armstrong\r\n\r\n    - Convex Optimization by Stephen Boyd & Lieven Vandenberghe\r\n\r\n    - Functional Analysis by Walter Rudin\r\n\r\n    - Functional Analysis, Sobolev Spaces and Partial Differential Equations by Haim Brezis\r\n\r\n    - Graph Theory - J.A. Bondy, U.S.R. Murty\r\n\r\n    - Graph Theory - Reinhard Diestel\r\n\r\n    - Inside Interesting Integrals - Pual J. Nahin\r\n\r\n    - Linear Algebra and Its Applications - Gilbert Strang\r\n\r\n    - Linear and Nonlinear Functional Analysis with Applications - Philippe G. Ciarlet\r\n\r\n    - Mathematical Analysis I - Vladimir A. Zorich\r\n\r\n    - Mathematical Analysis II - Vladimir A. Zorich\r\n\r\n    - Mathematics for Computer Science - Eric Lehman, F Thomson Leighton, Alber R Meyer\r\n\r\n    - Matrix Cookbook, The - Kaare Brandt Petersen, Michael Syskind Pedersen\r\n\r\n    - Measures, Integrals and Martingales - Rene\xcc\x81 L. Schilling\r\n\r\n    - Principles of Mathematical Analysis - Walter Rudin\r\n\r\n    - Probabilistic Graphical Models: Principles and Techniques - Daphne Koller, Nir Friedman\r\n\r\n    - Probability: Theory and Examples - Rick Durrett\r\n\r\n    - Real and Complex Analysis - Walter Rudin\r\n\r\n    - Thomas' Calculus - George B. Thomas\r\n\r\n    - \xe6\x99\xae\xe6\x9e\x97\xe6\x96\xaf\xe9\xa1\xbf\xe5\xbe\xae\xe7\xa7\xaf\xe5\x88\x86\xe8\xaf\xbb\xe6\x9c\xac - Adrian Banner\r\n\r\n\r\n- [Packt\xe6\xaf\x8f\xe6\x97\xa5\xe9\x99\x90\xe5\x85\x8d\xe7\x94\xb5\xe5\xad\x90\xe4\xb9\xa6\xe7\xb2\xbe\xe9\x80\x89](http://ddl.escience.cn/f/IS4a):\r\n\r\n\t- Learning Data Mining with Python\r\n\r\n\t- Matplotlib for python developers\r\n\r\n\t- Machine Learing with Spark\r\n\r\n\t- Mastering R for Quantitative Finance\r\n\r\n\t- Mastering matplotlib\r\n\r\n\t- Neural Network Programming with Java\r\n\r\n\t- Python Machine Learning\r\n\r\n\t- R Data Visualization Cookbook\r\n\r\n\t- R Deep Learning Essentials\r\n\r\n\t- R Graphs Cookbook second edition\r\n\r\n\t- D3.js By Example \r\n\r\n\t- Data Analysis With R\r\n\r\n\t- Java Deep Learning Essentials\r\n\r\n\t- Learning Bayesian Models with R\r\n\r\n\t- Learning Pandas\r\n\r\n\t- Python Parallel Programming Cookbook\r\n\r\n\t- Machine Learning with R\r\n\r\n---\r\n\r\n\r\n## \xe5\x85\xb6\xe4\xbb\x96 Miscellaneous\r\n\r\n- [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x97\xa5\xe6\x8a\xa5](http://forum.ai100.com.cn/)\xef\xbc\x9a\xe6\xaf\x8f\xe5\xa4\xa9\xe6\x9b\xb4\xe6\x96\xb0\xe5\xad\xa6\xe6\x9c\xaf\xe5\x92\x8c\xe5\xb7\xa5\xe4\xb8\x9a\xe7\x95\x8c\xe6\x9c\x80\xe6\x96\xb0\xe7\x9a\x84\xe7\xa0\x94\xe7\xa9\xb6\xe6\x88\x90\xe6\x9e\x9c\r\n\r\n- [\xe6\x9c\xba\xe5\x99\xa8\xe4\xb9\x8b\xe5\xbf\x83](https://www.jiqizhixin.com/)\r\n\r\n- [\xe9\x9b\x86\xe6\x99\xba\xe7\xa4\xbe\xe5\x8c\xba](https://jizhi.im/index)\r\n\r\n- - -\r\n\r\n\r\n## \xe5\xa6\x82\xe4\xbd\x95\xe5\x8a\xa0\xe5\x85\xa5 How to contribute\r\n\r\n\xe5\xa6\x82\xe6\x9e\x9c\xe4\xbd\xa0\xe5\xaf\xb9\xe6\x9c\xac\xe9\xa1\xb9\xe7\x9b\xae\xe6\x84\x9f\xe5\x85\xb4\xe8\xb6\xa3\xef\xbc\x8c\xe9\x9d\x9e\xe5\xb8\xb8\xe6\xac\xa2\xe8\xbf\x8e\xe4\xbd\xa0\xe5\x8a\xa0\xe5\x85\xa5\xef\xbc\x81\r\n\r\n- \xe6\xad\xa3\xe5\xb8\xb8\xe5\x8f\x82\xe4\xb8\x8e\xef\xbc\x9a\xe8\xaf\xb7\xe7\x9b\xb4\xe6\x8e\xa5fork\xe3\x80\x81pull\xe9\x83\xbd\xe5\x8f\xaf\xe4\xbb\xa5\r\n- \xe5\xa6\x82\xe6\x9e\x9c\xe8\xa6\x81\xe4\xb8\x8a\xe4\xbc\xa0\xe6\x96\x87\xe4\xbb\xb6\xef\xbc\x9a\xe8\xaf\xb7**\xe4\xb8\x8d\xe8\xa6\x81**\xe7\x9b\xb4\xe6\x8e\xa5\xe4\xb8\x8a\xe4\xbc\xa0\xe5\x88\xb0\xe9\xa1\xb9\xe7\x9b\xae\xe4\xb8\xad\xef\xbc\x8c\xe5\x90\xa6\xe5\x88\x99\xe4\xbc\x9a\xe9\x80\xa0\xe6\x88\x90git\xe7\x89\x88\xe6\x9c\xac\xe5\xba\x93\xe8\xbf\x87\xe5\xa4\xa7\xe3\x80\x82\xe6\xad\xa3\xe7\xa1\xae\xe7\x9a\x84\xe6\x96\xb9\xe6\xb3\x95\xe6\x98\xaf\xe4\xb8\x8a\xe4\xbc\xa0\xe5\xae\x83\xe7\x9a\x84**\xe8\xb6\x85\xe9\x93\xbe\xe6\x8e\xa5**\xe3\x80\x82\xe5\xa6\x82\xe6\x9e\x9c\xe4\xbd\xa0\xe8\xa6\x81\xe4\xb8\x8a\xe4\xbc\xa0\xe7\x9a\x84\xe6\x96\x87\xe4\xbb\xb6\xe6\x9c\xac\xe8\xba\xab\xe5\xb0\xb1\xe5\x9c\xa8\xe7\xbd\x91\xe7\xbb\x9c\xe4\xb8\xad\xef\xbc\x88\xe5\xa6\x82paper\xe9\x83\xbd\xe4\xbc\x9a\xe6\x9c\x89\xe9\x93\xbe\xe6\x8e\xa5\xef\xbc\x89\xef\xbc\x8c\xe7\x9b\xb4\xe6\x8e\xa5\xe4\xb8\x8a\xe4\xbc\xa0\xe5\x8d\xb3\xe5\x8f\xaf\xef\xbc\x9b\xe5\xa6\x82\xe6\x9e\x9c\xe6\x98\xaf\xe8\x87\xaa\xe5\xb7\xb1\xe6\x83\xb3\xe5\x88\x86\xe4\xba\xab\xe7\x9a\x84\xe4\xb8\x80\xe4\xba\x9b\xe6\x96\x87\xe4\xbb\xb6\xe3\x80\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\xad\x89\xef\xbc\x8c\xe9\x89\xb4\xe4\xba\x8e\xe5\x9b\xbd\xe5\x86\x85\xe7\xbd\x91\xe7\x9b\x98\xe7\x9a\x84\xe6\x83\x85\xe5\x86\xb5\xef\xbc\x8c\xe8\xaf\xb7\xe6\x8c\x89\xe7\x85\xa7\xe5\xa6\x82\xe4\xb8\x8b\xe6\x96\xb9\xe5\xbc\x8f\xe4\xb8\x8a\xe4\xbc\xa0\xef\xbc\x9a\r\n\t- (\xe5\xa2\x99\xe5\x86\x85)\xe7\x9b\xae\xe5\x89\x8d\xe6\xb2\xa1\xe6\x9c\x89\xe6\x89\xbe\xe5\x88\xb0\xe6\xaf\x94\xe8\xbe\x83\xe5\xa5\xbd\xe7\x9a\x84\xe6\x96\xb9\xe5\xbc\x8f\xef\xbc\x8c\xe5\x8f\xaa\xe8\x83\xbd\xe9\x80\x9a\xe8\xbf\x87\xe9\x93\xbe\xe6\x8e\xa5\xef\xbc\x8c\xe6\x88\x96\xe8\x80\x85\xe8\x87\xaa\xe5\xb7\xb1\xe7\xbd\x91\xe7\x9b\x98\xe7\x9a\x84\xe9\x93\xbe\xe6\x8e\xa5\xe6\x9d\xa5\xe5\x81\x9a\xe3\x80\x82\r\n\t- (\xe5\xa2\x99\xe5\xa4\x96)\xe9\xa6\x96\xe5\x85\x88\xe5\x9c\xa8[UPLOAD](https://my.pcloud.com/#page=puplink&code=4e9Z0Vwpmfzvx0y2OqTTTMzkrRUz8q9V)\xe7\x9b\xb4\xe6\x8e\xa5\xe4\xb8\x8a\xe4\xbc\xa0\xef\xbc\x88**\xe4\xb8\x8d**\xe9\x9c\x80\xe8\xa6\x81\xe6\xb3\xa8\xe5\x86\x8c\xe8\xb4\xa6\xe5\x8f\xb7\xef\xbc\x89\xef\xbc\x9b\xe4\xb8\x8a\xe4\xbc\xa0\xe6\x88\x90\xe5\x8a\x9f\xe5\x90\x8e\xef\xbc\x8c\xe5\x9c\xa8[DOWNLOAD](https://my.pcloud.com/publink/show?code=kZWtboZbDDVguCHGV49QkmlLliNPJRMHrFX)\xe9\x87\x8c\xe6\x89\xbe\xe5\x88\xb0\xe4\xbd\xa0\xe5\x88\x9a\xe4\xb8\x8a\xe4\xbc\xa0\xe7\x9a\x84\xe6\x96\x87\xe4\xbb\xb6\xef\xbc\x8c\xe5\x85\xb1\xe4\xba\xab\xe9\x93\xbe\xe6\x8e\xa5\xe5\x8d\xb3\xe5\x8f\xaf\xe3\x80\x82\r\n\r\n\r\n\r\n## \xe5\xa6\x82\xe4\xbd\x95\xe5\xbc\x80\xe5\xa7\x8b\xe9\xa1\xb9\xe7\x9b\xae\xe5\x8d\x8f\xe5\x90\x8c\xe5\x90\x88\xe4\xbd\x9c\r\n\r\n[\xe5\xbf\xab\xe9\x80\x9f\xe4\xba\x86\xe8\xa7\xa3github\xe5\x8d\x8f\xe5\x90\x8c\xe5\xb7\xa5\xe4\xbd\x9c](http://hucaihua.cn/2016/12/02/github_cooperation/)\r\n\r\n[\xe5\x8f\x8a\xe6\x97\xb6\xe6\x9b\xb4\xe6\x96\xb0fork\xe9\xa1\xb9\xe7\x9b\xae](https://jinlong.github.io/2015/10/12/syncing-a-fork/)\r\n\r\n\r\n#### [\xe8\xb4\xa1\xe7\x8c\xae\xe8\x80\x85 Contributors](https://github.com/allmachinelearning/MachineLearning/blob/master/contributors.md)\r\n\r\n\r\n\r\n\r\n\r\n"""
11,Vay-keen/Machine-learning-learning-notes,Vay-keen,周志华《机器学习》又称西瓜书是一本较为全面的书籍，书中详细介绍了机器学习领域不同类型的算法(例如：监督学习、无监督学习、半监督学习、强化学习、集成降维、特征选择等)，记录了本人在学习过程中的理解思路与扩展知识点，希望对新人阅读西瓜书有所帮助！,2018-03-24 06:48:10,2020-06-18 16:22:04,,1176,4049,b'\xe6\x9c\xac\xe6\x96\x87\xe4\xb8\xba\xe5\x91\xa8\xe5\xbf\x97\xe5\x8d\x8e\xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe3\x80\x8b\xe7\x9a\x84\xe5\xad\xa6\xe4\xb9\xa0\xe7\xac\x94\xe8\xae\xb0\xef\xbc\x8c\xe8\xae\xb0\xe5\xbd\x95\xe4\xba\x86\xe6\x9c\xac\xe4\xba\xba\xe5\x9c\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xbf\x99\xe6\x9c\xac\xe4\xb9\xa6\xe7\x9a\x84\xe8\xbf\x87\xe7\xa8\x8b\xe4\xb8\xad\xe7\x9a\x84\xe7\x90\x86\xe8\xa7\xa3\xe6\x80\x9d\xe8\xb7\xaf\xe4\xbb\xa5\xe5\x8f\x8a\xe4\xb8\x80\xe4\xba\x9b\xe6\x9c\x89\xe5\x8a\xa9\xe4\xba\x8e\xe6\xb6\x88\xe5\x8c\x96\xe4\xb9\xa6\xe5\x86\x85\xe5\xae\xb9\xe7\x9a\x84\xe6\x8b\x93\xe5\xb1\x95\xe7\x9f\xa5\xe8\xaf\x86\xef\xbc\x8c\xe7\xac\x94\xe8\xae\xb0\xe4\xb8\xad\xe5\x8f\x82\xe8\x80\x83\xe4\xba\x86\xe8\xae\xb8\xe5\xa4\x9a\xe7\xbd\x91\xe4\xb8\x8a\xe7\x9a\x84\xe5\xa4\xa7\xe7\x89\x9b\xe7\xbb\x8f\xe5\x85\xb8\xe5\x8d\x9a\xe5\xae\xa2\xe4\xbb\xa5\xe5\x8f\x8a\xe6\x9d\x8e\xe8\x88\xaa\xe3\x80\x8a\xe7\xbb\x9f\xe8\xae\xa1\xe5\xad\xa6\xe4\xb9\xa0\xe3\x80\x8b\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9\xef\xbc\x8c\xe5\x90\x91\xe5\x89\x8d\xe8\xbe\x88\xe4\xbb\xac\xe5\x92\x8c\xe7\x9f\xa5\xe8\xaf\x86\xe8\x87\xb4\xe6\x95\xac\xef\xbc\x81\n\n> \xe5\x95\x83\xe8\xa5\xbf\xe7\x93\x9c\xe5\xad\xa6\xe4\xb9\xa0\xe4\xba\xa4\xe6\xb5\x81QQ\xe7\xbe\xa4: 531701485\xef\xbc\x8c \xe9\x81\x87\xe5\x88\xb0\xe7\x96\x91\xe9\x97\xae\xe5\x8f\xaf\xe4\xbb\xa5\xe9\x9a\x8f\xe6\x97\xb6\xe5\x9c\xa8\xe4\xb8\x8a\xe9\x9d\xa2\xe6\x8f\x90\xe9\x97\xae\xef\xbc\x8c\xe5\xb9\xb6\xe4\xbc\x9a\xe4\xb8\x8d\xe5\xae\x9a\xe6\x9c\x9f\xe5\x88\x86\xe4\xba\xab\xe4\xbc\x98\xe8\xb4\xa8\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8/\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe8\xb5\x84\xe6\x96\x99\xef\xbc\x8c\xe6\xac\xa2\xe8\xbf\x8e\xe5\x90\x84\xe4\xbd\x8d\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\x88\xb1\xe5\xa5\xbd\xe8\x80\x85\xe7\x9a\x84\xe5\x85\xa5\xe7\xbe\xa4\xe8\xae\xa8\xe8\xae\xba\xe5\xad\xa6\xe4\xb9\xa0!'
12,Azure/MachineLearningNotebooks,Azure,Python notebooks with ML and deep learning examples with Azure Machine Learning | Microsoft,2018-08-17 17:29:14,2020-06-18 20:16:33,Jupyter Notebook,1155,1693,"b'# Azure Machine Learning service example notebooks\n\nThis repository contains example notebooks demonstrating the [Azure Machine Learning](https://azure.microsoft.com/en-us/services/machine-learning-service/) Python SDK which allows you to build, train, deploy and manage machine learning solutions using Azure.  The AML SDK allows you the choice of using local or cloud compute resources, while managing and maintaining the complete data science workflow from the cloud.\n\n![Azure ML Workflow](https://raw.githubusercontent.com/MicrosoftDocs/azure-docs/master/articles/machine-learning/media/concept-azure-machine-learning-architecture/workflow.png)\n\n\n## Quick installation\n```sh\npip install azureml-sdk\n```\nRead more detailed instructions on [how to set up your environment](./NBSETUP.md) using Azure Notebook service, your own Jupyter notebook server, or Docker.\n\n## How to navigate and use the example notebooks?\nIf you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, you should always run the [Configuration](./configuration.ipynb) notebook first when setting up a notebook library on a new machine or in a new environment. It configures your notebook library to connect to an Azure Machine Learning workspace, and sets up your workspace and compute to be used by many of the other examples. \nThis [index](./index.md) should assist in navigating the Azure Machine Learning notebook samples and encourage efficient retrieval of topics and content. \n\nIf you want to...\n\n * ...try out and explore Azure ML, start with image classification tutorials: [Part 1 (Training)](./tutorials/image-classification-mnist-data/img-classification-part1-training.ipynb) and [Part 2 (Deployment)](./tutorials/image-classification-mnist-data/img-classification-part2-deploy.ipynb).\n * ...learn about experimentation and tracking run history, first [train within Notebook](./how-to-use-azureml/training/train-within-notebook/train-within-notebook.ipynb), then try [training on remote VM](./how-to-use-azureml/training/train-on-remote-vm/train-on-remote-vm.ipynb) and [using logging APIs](./how-to-use-azureml/training/logging-api/logging-api.ipynb).\n * ...train deep learning models at scale, first learn about [Machine Learning Compute](./how-to-use-azureml/training/train-on-amlcompute/train-on-amlcompute.ipynb), and then try [distributed hyperparameter tuning](./how-to-use-azureml/training-with-deep-learning/train-hyperparameter-tune-deploy-with-pytorch/train-hyperparameter-tune-deploy-with-pytorch.ipynb) and [distributed training](./how-to-use-azureml/training-with-deep-learning/distributed-pytorch-with-horovod/distributed-pytorch-with-horovod.ipynb).\n * ...deploy models as a realtime scoring service, first learn the basics by [training within Notebook and deploying to Azure Container Instance](./how-to-use-azureml/training/train-within-notebook/train-within-notebook.ipynb), then learn how to [production deploy models on Azure Kubernetes Cluster](./how-to-use-azureml/deployment/production-deploy-to-aks/production-deploy-to-aks.ipynb).\n * ...deploy models as a batch scoring service, first [train a model within Notebook](./how-to-use-azureml/training/train-within-notebook/train-within-notebook.ipynb), then [create Machine Learning Compute for scoring compute](./how-to-use-azureml/training/train-on-amlcompute/train-on-amlcompute.ipynb), and [use Machine Learning Pipelines to deploy your model](https://aka.ms/pl-batch-scoring).\n * ...monitor your deployed models, learn about using [App Insights](./how-to-use-azureml/deployment/enable-app-insights-in-production-service/enable-app-insights-in-production-service.ipynb).\n\n## Tutorials\n\nThe [Tutorials](./tutorials) folder contains notebooks for the tutorials described in the [Azure Machine Learning documentation](https://aka.ms/aml-docs).\n  \n## How to use Azure ML\n\nThe [How to use Azure ML](./how-to-use-azureml) folder contains specific examples demonstrating the features of the Azure Machine Learning SDK\n\n- [Training](./how-to-use-azureml/training) - Examples of how to build models using Azure ML\'s logging and execution capabilities on local and remote compute targets\n- [Training with Deep Learning](./how-to-use-azureml/training-with-deep-learning) - Examples demonstrating how to build deep learning models using estimators and parameter sweeps\n- [Manage Azure ML Service](./how-to-use-azureml/manage-azureml-service) - Examples how to perform tasks, such as authenticate against Azure ML service in different ways.\n- [Automated Machine Learning](./how-to-use-azureml/automated-machine-learning) - Examples using Automated Machine Learning to automatically generate optimal machine learning pipelines and models\n- [Machine Learning Pipelines](./how-to-use-azureml/machine-learning-pipelines) - Examples showing how to create and use reusable pipelines for training and batch scoring\n- [Deployment](./how-to-use-azureml/deployment) - Examples showing how to deploy and manage machine learning models and solutions\n- [Azure Databricks](./how-to-use-azureml/azure-databricks) - Examples showing how to use Azure ML with Azure Databricks\n- [Monitor Models](./how-to-use-azureml/monitor-models) - Examples showing how to enable model monitoring services such as DataDrift\n- [Reinforcement Learning](./how-to-use-azureml/reinforcement-learning) - Examples showing how to train reinforcement learning agents\n\n---\n## Documentation\n\n * Quickstarts, end-to-end tutorials, and how-tos on the [official documentation site for Azure Machine Learning service](https://docs.microsoft.com/en-us/azure/machine-learning/service/).\n * [Python SDK reference](https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py)\n * Azure ML Data Prep SDK [overview](https://aka.ms/data-prep-sdk), [Python SDK reference](https://aka.ms/aml-data-prep-apiref), and [tutorials and how-tos](https://aka.ms/aml-data-prep-notebooks).\n\n---\n\n\n## Community Repository \nVisit this [community repository](https://github.com/microsoft/MLOps/tree/master/examples) to find useful end-to-end sample notebooks. Also, please follow these [contribution guidelines](https://github.com/microsoft/MLOps/blob/master/contributing.md) when contributing to this repository.   \n\n## Projects using Azure Machine Learning\n\nVisit following repos to see projects contributed by Azure ML users:\n - [AMLSamples](https://github.com/microsoft/MLOps) Number of end-to-end examples, including face recognition, predictive maintenance, customer churn and sentiment analysis.\n - [Learn about Natural Language Processing best practices using Azure Machine Learning service](https://github.com/microsoft/nlp)\n - [Pre-Train BERT models using Azure Machine Learning service](https://github.com/Microsoft/AzureML-BERT)\n - [Fashion MNIST with Azure ML SDK](https://github.com/amynic/azureml-sdk-fashion)\n - [UMass Amherst Student Samples](https://github.com/katiehouse3/microsoft-azure-ml-notebooks) - A number of end-to-end machine learning notebooks, including machine translation, image classification, and customer churn, created by students in the 696DS course at UMass Amherst.\n \n## Data/Telemetry \nThis repository collects usage data and sends it to Mircosoft to help improve our products and services. Read Microsoft\'s [privacy statement to learn more](https://privacy.microsoft.com/en-US/privacystatement)\n\nTo opt out of tracking, please go to the raw markdown or .ipynb files and remove the following line of code:\n\n```sh\n    ""![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/README.png)""\n```\nThis URL will be slightly different depending on the file. \n\n ![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/README.png)\n'"
13,hangtwenty/dive-into-machine-learning,hangtwenty,Dive into Machine Learning with Python Jupyter notebook and scikit-learn!,2015-02-22 23:48:16,2020-06-18 14:07:58,,1862,9993,"b'# Dive into Machine Learning [![Creative Commons License](http://i.creativecommons.org/l/by/4.0/88x31.png)](https://creativecommons.org/licenses/by/4.0/) [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)\n\n**Hi there! This guide is for you:**\n\n* **You\'re new to [Machine Learning.](https://en.wikipedia.org/wiki/Machine_learning)**\n* **You know Python.** (At least the basics! If you want to learn more Python, [try this](https://github.com/hangtwenty/python-is-for-lovers))\n\nI learned Python by hacking first, and getting serious *later.* I wanted to do this with Machine Learning. If this is your style, join me in getting a bit ahead of yourself.\n\n<br/>\n\n## Does your employer support your growth?\n\nIf you\'re reading this guide, you like to learn by doing. Your employer should give you projects in line with your strengths and interests. If not, you owe it to yourself to move on!\n\n<a href=""https://triplebyte.com/a/POPZ5Di/diveintomachinelearning""><img align=""right"" src=""https://user-images.githubusercontent.com/2420688/67127456-3f4b1700-f1ae-11e9-8cad-371212258d5c.png"" width=""300""  alt=""Triplebyte""></a> <a href=""https://triplebyte.com/a/POPZ5Di/diveintomachinelearning"">Take the Triplebyte coding quiz and **let the jobs come to you. Remote OK!** You can support <i>Dive Into Machine Learning</i> by using my link.</a>\n\n<br/>\n\n# Let\'s get started\n\nI suggest you get your feet wet to start. You\'ll boost your confidence.\n\n## Tools you\'ll need\n\n- [Python](https://www.python.org/). Python 3 is the best option.\n- [IPython and the Jupyter Notebook](http://ipython.org/). (FKA IPython and IPython Notebook.)\n- Some scientific computing packages:\n\t- numpy\n\t- pandas\n\t- scikit-learn\n\t- matplotlib\n\nYou can install Python 3 and all of these packages in a few clicks with the [Anaconda Python distribution](https://www.anaconda.com/download/). Anaconda is popular in Data Science and Machine Learning communities.\n\nIf you\'re using Python 2.7, don\'t worry. You don\'t have to migrate to Python 3 just for this guide. Also, if you\'re using pip/virtualenv instead of Anaconda, that\'s alright too! And re: installing packages, this is a helpful doc: [conda vs. pip vs. virtualenv](https://conda.io/docs/commands.html#conda-vs-pip-vs-virtualenv-commands)\n\n## Let\'s go!\n\n**[Learn how to use IPython Notebook](http://opentechschool.github.io/python-data-intro/core/notebook.html) (5-10 minutes).** (You can [learn by screencast](https://www.youtube.com/watch?v=qb7FT68tcA8) instead.)\n\nNow, follow along with this brief exercise (10 minutes): **[An introduction to machine learning with scikit-learn](http://scikit-learn.org/stable/tutorial/basic/tutorial.html)**. Do it in `ipython` or IPython Notebook. It\'ll really boost your confidence.\n\n[![I\'ll wait.](https://user-images.githubusercontent.com/2420688/29441281-00eff0c4-837f-11e7-9666-d653a1cd2372.jpeg)](http://scikit-learn.org/stable/tutorial/basic/tutorial.html)\n\n## What just happened?\n\nYou just classified some hand-written digits using [scikit-learn]. Neat huh?\n\n[scikit-learn] is the go-to library for machine learning in Python. [It\'s used widely.](http://scikit-learn.org/stable/testimonials/testimonials.html) Machine learning is hard. You\'ll be glad your tools are easy to work with.\n\n[scikit-learn]: http://scikit-learn.org/stable/index.html\n\nI encourage you to look at the [scikit-learn] homepage  and spend about 5 minutes looking over the names of the strategies (Classification, Regression, etc.), and their applications. Don\'t click through yet! Just get a glimpse of the vocabulary.\n\n# Dive in\n\n## A Visual Introduction to Machine Learning\n\nLet\'s learn a bit more about Machine Learning, and a couple of common ideas and concerns. Read [""A Visual Introduction to Machine Learning, Part 1""](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/) by [Stephanie Yee](https://twitter.com/stephaniejyee) and [Tony Chu](https://twitter.com/tonyhschu/).\n\n[![A Visual Introduction to Machine Learning, Part 1](https://user-images.githubusercontent.com/2420688/29441234-a2028c98-837e-11e7-88f2-1ca5a94684f6.gif)](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/)\n\nIt won\'t take long. It\'s a beautiful introduction ... Try not to drool too much!\n\n## A Few Useful Things to Know about Machine Learning\n\nOK. Let\'s dive deeper.\n\nRead **[""A Few Useful Things to Know about Machine Learning""](http://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)** by [Prof. Pedro Domingos](https://homes.cs.washington.edu/~pedrod/). It\'s densely packed with valuable information, but not opaque. The author understands that there\'s a lot of ""black art"" and folk wisdom, and they invite you in.\n\nTake your time with this one. Take notes. Don\'t worry if you don\'t understand it all yet.\n\nThe whole paper is packed with value, but I want to call out two points:\n\n- **Data alone is not enough.** This is where science meets art in machine-learning. Quoting Domingos: ""... the need for knowledge in learning should not be surprising. Machine learning is not magic; it can\xe2\x80\x99t get something from nothing. What it does is get more from less. Programming, like all engineering, is a lot of work: we have to build everything from scratch. Learning is more like farming, which lets nature do most of the work. Farmers combine seeds with nutrients to grow crops. Learners combine knowledge with data to grow programs.""\n- **More data beats a cleverer algorithm.** Listen up, programmers. We like cool tools. Resist the temptation to reinvent the wheel, or to over-engineer solutions. Your starting point is to [Do the Simplest Thing that Could _Possibly_ Work](http://www.artima.com/intv/simplest3.html). Quoting Domingos: ""Suppose you\xe2\x80\x99ve constructed the best set of features you can, but the classifiers you\xe2\x80\x99re getting are still not accurate enough. What can you do now? There are two main choices: design a better learning algorithm, or gather more data. [...] As a rule of thumb, a dumb algorithm with lots and lots of data beats a clever one with modest amounts of it. (After all, machine learning is all about letting data do the heavy lifting.)""\n\nWhen you work on a real Machine Learning problem, you should focus your efforts on your **domain knowledge** and **data** before optimizing your choice of algorithms. Prefer to [Do Simple Things] until you _have_ to increase complexity. You should not rush into neural networks because you think they\'re cool. To improve your model, **get more data.** Then use your knowledge of the problem to [explore and process](https://www.thetalkingmachines.com/episodes/software-and-statistics-machine-learning) the data. You should only optimize the choice of algorithms after you have gathered enough data, and you\'ve processed it well.\n\n![What has the most impact in Machine Learning](https://user-images.githubusercontent.com/2420688/29441212-798d2bba-837e-11e7-90b1-21daaf8d7b73.png)\n\n(Chart inspired by a slide from [Alex Pinto\'s talk, ""Secure Because Math: A Deep-Dive on ML-Based Monitoring""](https://www.youtube.com/watch?v=TYVCVzEJhhQ).)\n\n[Do Simple Things]: http://wiki.c2.com/?DoSimpleThings\n\n## Jargon note\n\n* [What is the difference between Data Analytics, Data Analysis, Data Mining, Data Science, Machine Learning, and Big Data?](http://www.quora.com/What-is-the-difference-between-Data-Analytics-Data-Analysis-Data-Mining-Data-Science-Machine-Learning-and-Big-Data-1) \n* Another handy term: [_**Data Engineering**_](https://towardsdatascience.com/who-is-a-data-engineer-how-to-become-a-data-engineer-1167ddc12811?gi=67df10cc32ea), which may involve or support Machine Learning, but is not limited to Machine Learning.\n\n## Just about time for a break...\n\nBefore you take a break, grab some podcasts. \n\nFirst, download [an interview with Prof. Domingos on the _Data Skeptic_ podcast](https://dataskeptic.com/blog/episodes/2018/the-master-algorithm) (2018). Prof. Domingos wrote [the paper we read earlier](http://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf). You might also start reading his book, [_The Master Algorithm_ by Prof. Pedro Domingos](https://www.goodreads.com/book/show/24612233-the-master-algorithm), a clear and accessible overview of machine learning. \n\nNext, subscribe to more machine learning and data science podcasts! These are great, low-effort resources that you can casually learn more from. To [learn effectively](https://www.coursera.org/learn/learning-how-to-learn), listen over time, with plenty of headspace. [Do not speed up your podcasts!](https://www.theringer.com/2017/8/2/16095364/inefficiency-week-podcasts-speed-comprehension-f0ea43949e42)\n\nSubscribe to _**[Talking Machines](http://www.thetalkingmachines.com/)**_.\n\nI suggest this listening order:\n\n* **Download the [""Starting Simple""](http://www.thetalkingmachines.com/episodes/starting-simple-and-machine-learning-meds) episode, and listen to that soon.** It supports what we read from Domingos. [Ryan Adams](http://people.seas.harvard.edu/~rpa/) talks about starting simple, as we discussed above. Adams also stresses the importance of feature engineering. Feature engineering is an exercise of the ""knowledge"" Domingos writes about. In a later episode, [they share many concrete tips for feature engineering](https://www.thetalkingmachines.com/episodes/software-and-statistics-machine-learning).\n* Then, over time, you can listen to the entire podcast series (start from the beginning).\n\nWant to subscribe to more podcasts? Here\'s [a good listicle](https://towardsdatascience.com/5-data-science-ai-and-machine-learning-podcasts-to-listen-to-now-e5078b18d184) of suggestions, [and another](https://mty.ai/blog/the-best-ai-podcasts/).\n\nOK! Take a break, come back refreshed.\n\n----\n\n## Play to learn\n\nNext, pick **one or two** of these IPython Notebooks and play along.\n\n- [Face Recognition on a subset of the Labeled Faces in the Wild](http://nbviewer.jupyter.org/github/ogrisel/notebooks/blob/master/Labeled%20Faces%20in%20the%20Wild%20recognition.ipynb)\n- [Machine Learning from Disaster](http://agconti.github.io/kaggle-titanic/): Using Titanic data, ""Demonstrates basic data munging, analysis, and visualization techniques. Shows examples of supervised machine learning techniques.""\n- [Election Forecasting](https://github.com/jseabold/538model): A replication of the model [Nate Silver](https://fivethirtyeight.com/contributors/nate-silver/) used to make predictions about the 2012 US Presidential Election for the _New York Times_.\n- [An example Machine Learning notebook](https://github.com/rhiever/Data-Analysis-and-Machine-Learning-Projects/blob/master/example-data-science-notebook/Example%20Machine%20Learning%20Notebook.ipynb): ""let\'s pretend we\'re working for a startup that just got funded to create a smartphone app that automatically identifies species of flowers from pictures taken on the smartphone.  We\'ve been tasked by our head of data science to create a demo machine learning model that takes four measurements from the flowers (sepal length, sepal width, petal length, and petal width) and identifies the species based on those measurements alone.""\n- ClickSecurity\'s ""data hacking"" series (thanks [hummus](https://github.com/hummus)!)\n\t- [Detect Algorithmically Generated Domains](http://nbviewer.jupyter.org/github/ClickSecurity/data_hacking/blob/master/dga_detection/DGA_Domain_Detection.ipynb)\n\t- [Detect SQL Injection](http://nbviewer.jupyter.org/github/ClickSecurity/data_hacking/blob/master/sql_injection/sql_injection.ipynb)\n\t- [Java Class File Analysis](http://nbviewer.jupyter.org/github/ClickSecurity/data_hacking/blob/master/java_classification/java_classification.ipynb): is this Java code malicious or benign?\n- If you want more of a data science bent, pick a notebook from [this excellent list of Data Science ipython notebooks](https://github.com/donnemartin/data-science-ipython-notebooks). ""Continually updated Data Science Python Notebooks: Spark, Hadoop MapReduce, HDFS, AWS, Kaggle, scikit-learn, matplotlib, pandas, NumPy, SciPy, and various command lines.""\n- Or more generic tutorials/overviews ...\n\t- [Tutorial introduction to machine learning with sklearn](http://amueller.github.io/sklearn_tutorial/)\n\t- [An Introduction to Supervised Learning via Scikit Learn](http://bugra.github.io/work/notes/2014-11-22/an-introduction-to-supervised-learning-scikit-learn/)\n\t- [An Introduction to Unsupervised Learning via Scikit Learn](http://bugra.github.io/work/notes/2014-11-16/an-introduction-to-unsupervised-learning-scikit-learn/)\n\nThere are more places to find great IPython Notebooks:\n\n* [A Gallery of Interesting IPython notebooks (wiki page on GitHub): Statistics, Machine Learning and Data Science](https://github.com/ipython/ipython/wiki/A-gallery-of-interesting-IPython-Notebooks#statistics-machine-learning-and-data-science)\n* [Fabian Pedregosa\'s larger, automatic gallery](https://web.archive.org/web/20180227081121/http://nb.bianp.net/sort/views/)\n\n_Know another great notebook? Please submit a PR!_\n\n----\n\n# Immerse yourself\n\nNow you should be hooked, and hungry to learn more. Pick one of the courses below and start on your way.\n\n## [Recommended course: Prof. Andrew Ng\'s _Machine Learning_ on Coursera](https://www.coursera.org/learn/machine-learning)\n\n**[Prof. Andrew Ng\'s](http://www.andrewng.org/about/) [_Machine Learning_](https://www.coursera.org/learn/machine-learning) is a popular and esteemed free online course. I\'ve seen it [recommended](https://www.quora.com/How-do-I-learn-machine-learning-1/answer/Cory-Hicks-1) [often.](https://www.coursetalk.com/providers/coursera/courses/machine-learning?page=1&sort=-content_rating#reviews) [And](https://www.quora.com/How-do-I-learn-machine-learning-1/answer/Xavier-Amatriain) [emphatically.](https://www.forbes.com/sites/anthonykosner/2013/12/29/why-is-machine-learning-cs-229-the-most-popular-course-at-stanford/)**\n\nIt\'s helpful if you decide on a pet project to play around with, as you go, so you have a way to apply your knowledge. You could use one of these [Awesome Public Datasets](https://github.com/caesar0301/awesome-public-datasets). And remember, IPython Notebook is your friend.\n\nAlso, you should grab an in-depth textbook to use as a reference. The two best options are [_Understanding Machine Learning_ ](http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/copy.html) and _[Elements of Statistical Learning](https://web.stanford.edu/~hastie/Papers/ESLII.pdf)_. You\'ll see these recommended as reference textbooks. [You only need to use one of the two options as your main reference; here\'s some context/comparison to help you pick which one is right for you.](https://github.com/hangtwenty/dive-into-machine-learning/issues/29) You can download each book free as PDFs at those links - so grab them!\n\n### Tips for studying\n\n* Busy schedule? Read [Ray Li\'s review of Prof. Andrew Ng\'s course](https://rayli.net/blog/data/coursera-machine-learning-review/) for some helpful tips.\n* Review some of the [""Learning How to Learn""](https://www.coursera.org/learn/learning-how-to-learn/) videos. This is just about how to study in general. In the course, they [advocate the learn-by-doing approach](https://www.coursera.org/learn/learning-how-to-learn/lecture/8IUbH/interview-with-dr-terrence-sejnowski), as we\'re doing here. You\'ll get various other tips that are easy to apply, but go a long way to make your time investment more effective.\n\n## Other courses\n\nHere are some other free online courses I\'ve seen recommended. (Machine Learning, Data Science, and related topics.)\n\n* [Prof. Pedro Domingos\'s introductory video series](https://homes.cs.washington.edu/~pedrod/). Domingos wrote the paper [""A Few Useful Things to Know About Machine Learning""](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf), recommended earlier in this guide.\n* Kevin Markham\'s video series, [Intro to Machine Learning with scikit-learn](http://blog.kaggle.com/2015/04/08/new-video-series-introduction-to-machine-learning-with-scikit-learn/), starts with what we\'ve already covered, then continues on at a comfortable place. After the videos you could do Markham\'s [General Assembly\'s Data Science course.](https://github.com/justmarkham/DAT8) Interactive. Markham\'s course is also offered in-person in Washington, DC.\n* [UC Berkeley\'s Data 8: The Foundations of Data Science](http://data8.org/) course and the textbook [Computational and Inferential Thinking](https://www.inferentialthinking.com/) teaches critical concepts in Data Science.\n    * The textbook also provides an academic definition of Data Science: **""Data Science is about drawing useful conclusions from large and diverse data sets through exploration, prediction, and inference"".**\n    * [Foundations of Data Science](https://www.edx.org/professional-certificate/berkeleyx-foundations-of-data-science) online course based on Data 8 is now offered via edX too.\n* Data science courses as IPython Notebooks:\n\t* [Practical Data Science](http://radimrehurek.com/data_science_python/)\n\t* [Learn Data Science (an entire self-directed course!)](http://learnds.com/)\n\t* Supplementary material: [donnemartin/data-science-ipython-notebooks](https://github.com/donnemartin/data-science-ipython-notebooks). ""Continually updated Data Science Python Notebooks: Spark, Hadoop MapReduce, HDFS, AWS, Kaggle, scikit-learn, matplotlib, pandas, NumPy, SciPy, and various command lines.""\n* Prof. Mark A. Girolami\'s [Machine Learning Module (GitHub Mirror).](https://github.com/josephmisiti/machine-learning-module) Good for people with a strong mathematics background.\n* Surveys of Data Science courseware (a bit more Choose Your Own Adventure)\n\t* Check out [Jack Golding\'s survey of Data Science courseware](https://www.quora.com/Is-it-worth-it-to-pay-9-*-49-for-a-data-science-specialization-on-Coursera/answer/Jack-Golding). Includes Coursera\'s [Data Science Specialization](https://www.coursera.org/specializations/jhu-data-science) with 9 courses in it. The Specialization certificate isn\'t free, but you can take the courses 1-by-1 for free if you don\'t care about the certificate. The survey also covers [Harvard CS109](http://cs109.github.io/2014/) which I\'ve seen recommended elsewhere.\n\t* [Another epic Quora thread: How can I become a data scientist?](https://www.quora.com/How-can-I-become-a-data-scientist?redirected_qid=59455)\n\t* Data Science Weekly\'s [Big List of Data Science Resources](https://www.datascienceweekly.org/data-science-resources/the-big-list-of-data-science-resources) has a [List of Data Science MOOCs](https://www.datascienceweekly.org/data-science-resources/data-science-moocs)\n* [Advanced Statistical Computing (Vanderbilt BIOS8366)](http://stronginference.com/Bios8366/lectures.html). Interactive (lots of IPython Notebook material)\n* [Data Science (Harvard CS109)](http://cs109.github.io/2014/)\n\n\n## Getting Help: Questions, Answers, Chats\n\nStart with the support forums and chats related to the course(s) you\'re taking.\n\nCheck out [datascience.stackexchange.com](https://datascience.stackexchange.com/) and [stats.stackexchange.com \xe2\x80\x93 such as the tag, _machine-learning_.](https://stats.stackexchange.com/questions/tagged/machine-learning?sort=frequent&pageSize=15) There are some subreddits like [/r/machinelearning](https://www.reddit.com/r/machinelearning).\n\nThere are also many relevant discussions on Quora, for example: [What is the difference between Data Analytics, Data Analysis, Data Mining, Data Science, Machine Learning, and Big Data?](http://www.quora.com/What-is-the-difference-between-Data-Analytics-Data-Analysis-Data-Mining-Data-Science-Machine-Learning-and-Big-Data-1)\n\nFor help and community in meatspace, seek out meetups. Data Science Weekly\'s [Big List of Data Science Resources](http://www.datascienceweekly.org/data-science-resources/the-big-list-of-data-science-resources) may help you.\n\n## Supplement: Learning Pandas well\n\nYou\'ll want to get more familiar with Pandas.\n\n* **Essential**: [10 Minutes to Pandas](http://pandas.pydata.org/pandas-docs/stable/10min.html)\n* **Essential**: [Things in Pandas I Wish I\'d Had Known Earlier](http://nbviewer.jupyter.org/github/rasbt/python_reference/blob/master/tutorials/things_in_pandas.ipynb) (IPython Notebook)\n* Another helpful tutorial: [Real World Data Cleanup with Python and Pandas](https://trendct.org/2016/08/05/real-world-data-cleanup-with-python-and-pandas/)\n* [Video series from Data School, about Pandas](https://www.youtube.com/playlist?list=PL5-da3qGB5ICCsgW1MxlZ0Hq8LL5U3u9y). ""Reference guide to 30 common pandas tasks (plus 6 hours of supporting video).""\n* [Useful Pandas Snippets](http://www.swegler.com/becky/blog/2014/08/06/useful-pandas-snippets/)\n* Here are some docs I found especially helpful as I continued learning:\n\t* [Cookbook](http://pandas.pydata.org/pandas-docs/stable/cookbook.html)\n\t* [Data Structures](http://pandas.pydata.org/pandas-docs/stable/dsintro.html), esp. [DataFrame](http://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe) section\n\t* [Reshaping by pivoting DataFrames](https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html)\n\t* [Computational tools](http://pandas.pydata.org/pandas-docs/stable/computation.html) and [StackExchange thread: ""What is covariance in plain language?""](https://stats.stackexchange.com/questions/29713/what-is-covariance-in-plain-language)\n\t* [Group By (split, apply, and combine DataFrames)](http://pandas.pydata.org/pandas-docs/stable/groupby.html)\n\t* [Visualizing your DataFrames](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html)\n* Bookmarks for later when you need to scale\n\t* [The `odo` library](http://odo.readthedocs.io/) for converting between _many_ formats.\n\t* [`dask`](https://dask.org/): A Pandas-like interface, but for larger-than-memory data and ""under the hood"" parallelism. Very interesting, but only needed when you\'re getting advanced. \n\n## Supplement: Cheat Sheets\n\nSome good cheat sheets I\'ve come across. (Please [submit a Pull Request](https://github.com/hangtwenty/dive-into-machine-learning/pulls) to add other useful cheat sheets.)\n\n- [scikit-learn algorithm cheat sheet](http://scikit-learn.org/stable/tutorial/machine_learning_map/)\n- [Metacademy: a package manager for [machine learning] knowledge](http://hunch.net/?p=2714). A mind map of machine learning concepts, with great detail on each.\n- [Matplotlib / Pandas / Python cheat sheets](https://drive.google.com/drive/folders/0ByIrJAE4KMTtaGhRcXkxNHhmY2M).\n\n# Assorted Opinions and Other Resources\n\n## More Data Science materials\n\nI\'m not repeating the materials mentioned above, but here are some other Data Science resources:\n\n* **Extremely accessible data science book: [_Data Smart_ by John Foreman](http://www.john-foreman.com/data-smart-book.html)**\n* **[An entire self-directed course in Data Science, as a IPython Notebook](http://learnds.com/)**\n* [Data Science Workflow: Overview and Challenges](https://cacm.acm.org/blogs/blog-cacm/169199-data-science-workflow-overview-and-challenges/fulltext) (read the article *and also* the comment by Joseph McCarthy)\n* Fun little IPython Notebook: [Web Scraping Indeed.com for Key Data Science Job Skills](http://nbviewer.jupyter.org/github/jmsteinw/Notebooks/blob/master/IndeedJobs.ipynb)\n* Swami Chandrasekaran\'s [""Becoming a Data Scientist""](http://nirvacana.com/thoughts/becoming-a-data-scientist/) is a concise, printable picture of a data science curriculum\n* [Python Data Science Handbook](https://github.com/jakevdp/PythonDataScienceHandbook) is one of the best entry level book that you can find on Internet.\n\n\n## Bayesian Statistics and Machine Learning\n\nFrom [the ""Bayesian Machine Learning"" overview on Metacademy](https://metacademy.org/roadmaps/rgrosse/bayesian_machine_learning):\n\n> ... Bayesian ideas have had a big impact in machine learning in the past 20 years or so because of the flexibility they provide in building structured models of real world phenomena. Algorithmic advances and increasing computational resources have made it possible to fit rich, highly structured models which were previously considered intractable.\n\nYou can learn more by studying one of the following resources. Both resources use Python, [PyMC](https://github.com/pymc-devs/pymc), and Jupyter Notebooks.\n* The **free book,** _[Probabilistic Programming and Bayesian Methods for Hackers](http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/)._ Made with a ""computation/understanding-first, mathematics-second point of view."" It\'s available in print too!\n* [Bayesian Modelling in Python](https://github.com/markdregan/Bayesian-Modelling-in-Python)\n\n## Risks\n\n""Machine learning systems automatically learn programs from\ndata."" Pedro Domingos, in [""A Few Useful Things to Know about Machine Learning.""](http://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf) The programs you generate will require maintenance. Like any way of creating programs faster, you can rack up [technical debt](https://en.wikipedia.org/wiki/Technical_debt).\n\nHere is the abstract of [Machine Learning: The High-Interest Credit Card of Technical Debt](https://static.googleusercontent.com/media/research.google.com/en/us/pubs/archive/43146.pdf):\n\n> Machine learning offers a fantastically powerful toolkit for building complex systems quickly. This paper argues that it is dangerous to think of these quick wins as coming for free. Using the framework of technical debt, we note that it is remarkably easy to incur massive ongoing maintenance costs at the system level when applying machine learning. The goal of this paper is highlight several machine learning specific risk factors and design patterns to be avoided or refactored where possible. These include boundary erosion, entanglement, hidden feedback loops, undeclared consumers, data dependencies, changes in the external world, and a variety of system-level anti-patterns.\n\nIf you\'re following this guide, you should read that paper. You can also [listen to a podcast episode interviewing one of the authors of this paper](https://softwareengineeringdaily.com/2015/11/17/machine-learning-and-technical-debt-with-d-sculley/).\n\nA few more articles on the challenges running ML-powered systems in Production:\n\n- **[""Rules of Machine Learning: Best Practices for [Reliable] ML Engineering,""](http://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf)** by Martin Zinkevich, regarding ML engineering practices and patterns in production at Google. Optional: [accompanying video](http://cs.stanford.edu/~jsteinhardt/wildml2016nips/videos/1_2_Martin.wmv).\n- [**""What\xe2\x80\x99s your ML Test Score? A rubric for ML production systems""**](https://0586f9b3-a-62cb3a1a-s-sites.googlegroups.com/site/wildml2016nips/SculleyPaper1.pdf?attachauth=ANoY7crRjdpoElseeyOPu-wR0eV9Engf3Cm9LKs0PAB4j-nDQuw9gE426Ug2HM-0BZ7qJjtLHVtpgwbP6zfNYyE_2gWkU5ACKczAIuKCTHq9nT0JEGpEL5TCT3APmScXKkS8HTqhJz-wen6vbq9XeHh_M5Heg49ozxsIiGMzX7PvIKxpnvViDOBLNymVQOkxuvX0-xnQThxU9CjEWQH25vOwdpJi-VQl1w%3D%3D&attredirects=0) by Eric Breck, Shanqing Cai, Eric Nielsen, Michael Salib, D. Sculley, Google.\n- **[Surviving Data Science ""at the Speed of Hype""](http://www.john-foreman.com/blog/surviving-data-science-at-the-speed-of-hype)** by John Foreman, Data Scientist at MailChimp\n- [The High Cost of Maintaining Machine Learning Systems](http://www.kdnuggets.com/2015/01/high-cost-machine-learning-technical-debt.html)\n- [11 Clever Methods of Overfitting and How to Avoid Them](http://hunch.net/?p=22)\n- [The Perilous World of Machine Learning for Fun and Profit: Pipeline Jungles and Hidden Feedback Loops](http://www.john-foreman.com/blog/the-perilous-world-of-machine-learning-for-fun-and-profit-pipeline-jungles-and-hidden-feedback-loops)\n\n\n### Welcome to the Danger Zone\n\nSo you are dabbling with Machine Learning. You\'ve got Hacking Skills. Maybe you\'ve got some ""knowledge"" in Domingos\' sense (some ""Substantive Expertise"" or ""Domain Knowledge""). This diagram is modified slightly from Drew Conway\'s ""Data Science Venn Diagram."" It isn\'t a _perfect_ fit for us, but it may get the point across:\n\n[![Drew Conway\'s Data Science Venn Diagram, modified slightly](https://user-images.githubusercontent.com/2420688/29441268-f429d88c-837e-11e7-83ff-30874d832c89.png)](http://drewconway.com/zia/2013/3/26/the-data-science-venn-diagram)\n\n**Please** don\'t sell yourself as a Machine Learning expert while you\'re still in the Danger Zone. Don\'t build bad products or publish junk science. (Also please [don\'t be evil](https://arstechnica.co.uk/security/2016/02/the-nsas-skynet-program-may-be-killing-thousands-of-innocent-people/).) This guide can\'t tell you how you\'ll know you\'ve ""made it"" into Machine Learning competence ... let alone expertise. It\'s hard to evaluate proficiency without schools or other institutions. This is a common problem for self-taught people.\n\n#### Towards Expertise\n\nYou need **practice.** [On Hacker News, user olympus commented to say you could use competitions to practice and evaluate yourself](https://news.ycombinator.com/item?id=10508565). [Kaggle](https://www.kaggle.com/competitions) and [ChaLearn](http://www.chalearn.org/) are hubs for Machine Learning competitions. You can find some [examples of code for popular Kaggle competitions here](https://github.com/apeeyush/machine-learning). For smaller exercises, [try HackerRank](https://www.hackerrank.com/domains/ai/machine-learning/page/1).\n\nYou also need **understanding.** You should review what Kaggle competition winners say about their solutions, [for example, the ""No Free Hunch"" blog](http://blog.kaggle.com/). These might be over your head at first but once you\'re starting to understand and appreciate these, you know you\'re getting somewhere.\n\nCompetitions and challenges are just one way to practice. You shouldn\'t limit yourself, though - and you should also understand that [Machine Learning isn\'t **all** about Kaggle competitions](https://jvns.ca/blog/2014/06/19/machine-learning-isnt-kaggle-competitions).\n\nHere\'s a complementary way to practice: **do practice studies.**\n\n1. **Ask a question. Start your own study.** The [""most important thing in data science is the question""](https://github.com/DataScienceSpecialization/courses/blob/master/01_DataScientistToolbox/03_02_whatIsData/index.Rmd#the-data-is-the-second-most-important-thing) ([Dr. Jeff T. Leek](https://github.com/jtleek)). So start with a question. Then, find [real data](https://github.com/caesar0301/awesome-public-datasets). Analyze it. Then ...\n2. **Communicate results.** When you have a novel finding, reach out for peer review.\n3. **Fix issues.** Learn. Share what you learn.\n\nAnd repeat. Re-phrasing this, it fits with the [scientific method](https://en.wikipedia.org/wiki/Scientific_method): formulate a question (or problem statement), create a hypothesis, gather data, analyze the data, and communicate results. (You should [watch this video about the scientific method in data science](http://101.datascience.community/2012/06/27/the-data-scientific-method/), and/or [read this article](http://customerthink.com/getting-insights-using-data-science-skills-and-the-scientific-method/).)\n\nHow can you come up with interesting questions? Here\'s one way. Every Sunday, [browse datasets](https://github.com/caesar0301/awesome-public-datasets) and write down some questions. Also, sign up for [Data is Plural](https://tinyletter.com/data-is-plural), a newsletter of interesting datasets; look at these, datasets, and write down questions. Stay curious. When a question inspires you, start a study.\n\nThis advice, to do practice studies and learn from peer review, is based on [a conversation](https://github.com/hangtwenty/dive-into-machine-learning/issues/11#issuecomment-153934120) with [Dr. Randal S. Olson](http://www.randalolson.com/). Here\'s more advice from Olson, [quoted with permission:](https://github.com/hangtwenty/dive-into-machine-learning/issues/11#issuecomment-154135498)\n\n> I think the best advice is to tell people to always present their methods clearly and to avoid over-interpreting their results. Part of being an expert is knowing that there\'s rarely a clear answer, especially when you\'re working with real data.\n\nAs you repeat this process, your practice studies will become more scientific, interesting, and focused. The most important part of this process is peer review.\n\n#### Ask for Peer Review\n\nHere are some communities where you can reach out for peer review:\n\n* [Cross-Validated: stats.stackexchange.com](https://stats.stackexchange.com/)\n* [/r/DataIsBeautiful](https://reddit.com/r/DataIsBeautiful)\n* [/r/DataScience](https://reddit.com/r/DataScience)\n* [/r/MachineLearning](https://reddit.com/r/MachineLearning)\n* [Hacker News: news.ycombinator.com](https://news.ycombinator.com). You\'ll probably want to submit as ""Show HN""\n\nPost to any of those, and ask for feedback. You\'ll get feedback. You\'ll learn a ton. As experts review your work you will learn a lot about the field. You\'ll also be practicing a crucial skill: accepting critical feedback.\n\nWhen I read the feedback on my Pull Requests, first I repeat to myself, ""I will not get defensive, I will not get defensive, I will not get defensive."" You may want to do that before you read reviews of your Machine Learning work too.\n\n----\n\n## Collaborate with Domain Experts!\n\nMachine Learning can be powerful, but it is not magic.\n\nWhenever you apply Machine Learning to solve a problem, you are going to be working in some specific problem domain. To get good results, you or your team will need ""substantive expertise"" AKA ""domain knowledge."" Learn what you can, for yourself... But you should also **collaborate.** You\'ll have better results if you collaborate with domain experts. (What\'s a domain expert? See the [Wikipedia entry](https://en.wikipedia.org/wiki/Subject-matter_expert), or [c2 wiki\'s rather subjective but useful blurb](http://wiki.c2.com/?DomainExpert).)\n\n### :bow: A note about Machine Learning and User Experience (UX)\n\nI couldn\'t say it better:\n\n> **Machine learning won\xe2\x80\x99t figure out what problems to solve.** If you aren\xe2\x80\x99t aligned with a human need, you\xe2\x80\x99re just going to build a very powerful system to address a very small\xe2\x80\x94or perhaps nonexistent\xe2\x80\x94problem.\n\nQuote is from [""The UX of AI"" by  Josh Lovejoy](https://design.google/library/ux-ai/), whole article is a great read!\n\nIn other words, **[You Are Not The User](https://www.nngroup.com/articles/false-consensus/).**\n\nToday we are [_surrounded_](https://en.wikipedia.org/wiki/Machine_learning#Applications) by software that utilizes Machine Learning. Often, the results are directly user-facing, and intended to enhance UX.\n\nBefore you start working ML into _your_ software, you should get a better understanding of UX, as well as how ML and UX can relate. As an informal way to get into this subject, start with this:\n\n* [Rule #23 of _Martin Zinkevich\'s Rules of ML Engineering_](https://developers.google.com/machine-learning/guides/rules-of-ml/#human_analysis_of_the_system): **""You are not a typical end user.""**\n* There are some great [thoughtful discussions of this on Quora](https://www.quora.com/search?q=machine+learning+ux)\n\nThen, if you you know a coworker or friend who works in UX, take them out for coffee or lunch and pick their brain. I think they\'ll have words of encouragement as well as caution. You won\'t be an expert by any means, but maybe it\'ll help you konw if/when to reach out for help, review, or guidance. \n\nSpoiler: you should work with UX specialists whenever you can!\n\n### :bow: A note about Machine Learning and Security (InfoSec, AppSec)\n\nThere was a great BlackHat webcast on this topic, [Secure Because Math: Understanding Machine Learning-Based Security Products.](https://www.blackhat.com/html/webcast/02192015-secure-because-math.html) Slides are [here](https://www.blackhat.com/html/webcast/02192015-secure-because-math.html), [video recording is here.](https://attendee.gotowebinar.com/recording/80449431422110210) If you\'re using ML to recommend some media, overfitting could be harmless. If you\'re relying on ML to protect from threats, overfitting could be downright dangerous. Check the full presentation if you are interested in this space.\n\nIf you want to explore this space more deeply, there is a _lot_ of reading material in the below links:\n\n* [Security Data Science and Machine Learning Guide](http://www.covert.io/the-definitive-security-datascience-and-machinelearning-guide/)\n* [Awesome ML for Cybersecurity](https://github.com/jivoi/awesome-ml-for-cybersecurity)\n* [Awesome AI Security](https://github.com/RandomAdversary/Awesome-AI-Security)\n* [Awesome Adversarial Machine Learning](https://github.com/yenchenlin/awesome-adversarial-machine-learning)\n\n----\n\n\n## Deep Learning\n\nIn early editions of this guide, there was no specific ""Deep Learning"" section. I omitted it intentionally. I think it is not effective for us to jump too far ahead. I also know that if you become an expert in traditional Machine Learning, you\'ll be capable of moving onto advanced subjects like Deep Learning, whether or not I\'ve put that in this guide. We\'re just trying to get you started here!\n\nMaybe this is a way to check your progress: ask yourself, does Deep Learning seem like magic? If so, take that as a sign that you aren\'t ready to work with it professionally. Let the fascination motivate you to learn more. I have read some argue you can learn Deep Learning in isolation; I have read others recommend it\'s best to master traditional Machine Learning first. Why not start with traditional Machine Learning, and develop your reasoning and intuition there? You\'ll only have an easier time learning Deep Learning after that. After all of it, you\'ll able to tackle all sorts of interesting problems.\n\nIn any case, when you decide you\'re ready to dive into Deep Learning, here are some helpful resources.\n\n* **[Dive into Deep Learning](https://d2l.ai/) - An interactive book about deep learning\n* **[""Have Fun With [Deep] Learning"" by David Humphrey.](https://github.com/humphd/have-fun-with-machine-learning)** This is an excellent way to ""get ahead of yourself"" and hack-first. Then you will feel excited to move onto...\n*  **[Prof. Andrew Ng\'s](https://www.andrewng.org/about/) [courses on Deep Learning](https://www.coursera.org/specializations/deep-learning)!** There five courses, as part of the [Deep Learning Specialization on Coursera](https://www.coursera.org/specializations/deep-learning). These courses are part of his new venture, [deeplearning.ai](https://www.deeplearning.ai)\n* **[Machine Learning Crash Course from Google.](https://developers.google.com/machine-learning/crash-course/)** Google\'s fast-paced, practical introduction to machine learning which covers building deep neural networks with TensorFlow.\n* **[_Deep Learning_](http://www.deeplearningbook.org/), a free book published MIT Press.** By Ian Goodfellow, Yoshua Bengio and Aaron Courville\n* [YerevaNN\'s Deep Learning Guide](http://yerevann.com/a-guide-to-deep-learning/)\n* [Quora: ""What are the best ways to pick up Deep Learning skills as an engineer?""](https://www.quora.com/What-are-the-best-ways-to-pick-up-Deep-Learning-skills-as-an-engineer) \xe2\x80\x94 answered by Greg Brockman (Co-Founder & CTO at OpenAI, previously CTO at Stripe)\n* [Creative Applications of Deep Learning with Tensorflow](https://github.com/pkmital/CADL)\n* [Dive into Deep Learning](https://d2l.ai/) - An interactive book about deep learning\n\n\n## ""Big"" Data?\n\nIf you are working with data-intensive applications at all, I\'ll recommend this book:\n\n* **[_Designing Data-Intensive Applications_](http://dataintensive.net)** by Martin Kleppman. (You can start reading it online, free, via Safari Books.) It\'s not specific to Machine Learning, but you can bridge that gap yourself.\n\nLastly, here are some other useful links regarding Big Data and ML.\n\n* [10 things statistics taught us about big data analysis](https://simplystatistics.org/2014/05/22/10-things-statistics-taught-us-about-big-data-analysis/) (and some more food for thought: [""What Statisticians think about Data Scientists""](http://www.datasciencecentral.com/profiles/blogs/what-statisticians-think-about-data-scientists))\n* [""Talking Machines"" #12](http://www.thetalkingmachines.com/blog/2015/6/4/the-economic-impact-of-machine-learning-and-using-the-kernel-trick-to-dig-in-to-big-data): Interviews Prof. Andrew Ng (from [our main course, which has its own module on big data](https://www.coursera.org/learn/machine-learning)); this episode covers some problems relevant to _high-dimensional_ data\n- [""Talking Machines"" #15: ""Really Really Big Data and Machine Learning in Business""](http://www.thetalkingmachines.com/blog/2015/7/16/really-really-big-data-and-machine-learning-in-business)\n- Free eBook, [_Getting Data Right: Tackling the Challenges of\nBig Data Volume and Variety_](https://www.tamr.com/landing-pages/getting-data-right/) by Michael Stonebraker, Tom Davenport, James Markarian, and others, published by O\'Reilly. You can [listen to an accompanying podcast](http://radar.oreilly.com/2015/06/the-future-of-data-at-scale.html) too.\n\n----\n\n## Finding Open-Source Libraries\n\n* Bookmark **[awesome-machine-learning](https://github.com/josephmisiti/awesome-machine-learning)**, a curated list of [awesome](https://github.com/bayandin/awesome-awesomeness) Machine Learning libraries and software.\n* Bookmark [Pythonidae](https://github.com/svaksha/pythonidae/blob/master/AI.md#machine-learning), a curated list of [awesome](https://github.com/bayandin/awesome-awesomeness) libraries and software in the Python language - with a section on Machine Learning.\n* [TensorFlow](https://www.tensorflow.org/) has been a [really big deal.](https://news.ycombinator.com/item?id=10532957) People like you will do exciting things with TensorFlow. It\'s a framework. Frameworks can help you manage complexity. Just remember this rule of thumb: **""More data beats a cleverer algorithm""** (Domingos), no matter how cool your tools are. Also note, TensorFlow is not the only machine learning framework of its kind: **[Check this great, detailed comparison of TensorFlow, Torch, and Theano.](https://github.com/zer0n/deepframeworks)** See also [Newmu/Theano-Tutorials](https://github.com/Newmu/Theano-Tutorials) and  [nlintz/TensorFlow-Tutorials](https://github.com/nlintz/TensorFlow-Tutorials). See also the section on Deep Learning above.\n    * Also, consider [Lore](https://github.com/instacart/lore/). ""Lore is a python framework to make machine learning [especially deep learning] approachable for Engineers and maintainable for Data Scientists."" \n* For Machine-Learning libraries that might not be on PyPI, GitHub, etc., there\'s [MLOSS (Machine Learning Open Source Software)](http://mloss.org/software/). Seems to feature many academic libraries.\n* Bookmark [Julia.jl](https://github.com/svaksha/Julia.jl/blob/master/AI.md#machine-learning), a curated list of [awesome](https://github.com/bayandin/awesome-awesomeness) libraries and software in the Julia language - with a section on Machine Learning.\n\n----\n\n## Alternative ways to ""Dive into Machine Learning""\n\nHere are some other guides to Machine Learning. They can be alternatives or complements to this guide.\n\n* [""How would your curriculum for a machine learning beginner look like?""](https://sebastianraschka.com/faq/docs/ml-curriculum.html) by Sebastian Raschka. A selection of the core online courses and books for getting started with machine learning and gaining expert knowledge. It contextualizes Raschka\'s own book, [_Python Machine Learning_](https://github.com/rasbt/python-machine-learning-book) (which I would have linked to anyway!) See also [`pattern_classification` GitHub repository](https://github.com/rasbt/pattern_classification) maintained by the author, which contains IPython notebooks about various machine learning algorithms and various data science related resources.\n* [Materials for Learning Machine Learning](http://jacksimpson.co/materials-for-learning-machine-learning/) by Jack Simpson\n* Courses by cloud vendors (may be specific to their tools/platforms)\n    * [Machine Learning Crash Course from Google](https://developers.google.com/machine-learning/crash-course/) with TensorFlow APIs. This is Google\'s fast-paced, practical introduction to machine learning which features a series of lessons with video lectures, real-world case studies, and hands-on practice exercises.\n    *  [Amazon AWS](https://aws.amazon.com/training/learning-paths/machine-learning/) Amazon have open up their internal training to the public and also offer certification. 30 courses - 45+ hours of content.\n* [Machine Learning for Developers](http://xyclade.github.io/MachineLearning/) is another good introduction, perhaps better if you\'re more familiar with Java or Scala. It introduces machine learning for a developer audience using Smile, a machine learning library that can be used both in Java and Scala.\n* [Example Machine Learning notebook, exercise, and guide](https://github.com/rhiever/Data-Analysis-and-Machine-Learning-Projects/blob/master/example-data-science-notebook/Example%20Machine%20Learning%20Notebook.ipynb) by Dr. Randal S. Olson. Mentioned in Notebooks section as well, but it has a similar goal to this guide (introduce you, and show you where to go next). Rich ""Further Reading"" section.\n* [Machine Learning for Software Engineers](https://github.com/ZuzooVn/machine-learning-for-software-engineers) by Nam Vu. It\xe2\x80\x99s the top-down and results-first approach designed for software engineers.\n* For some news sources to follow, check out [Sam DeBrule\'s list](https://machinelearnings.co/a-humans-guide-to-machine-learning-e179f43b67a0) here.\n* [Distill](https://distill.pub/about/) is a journal devoted to clear and interactive explanations of the lastest research in machine learning. They offer an alternative to traditional academic publishing that promotes accessibility and transparency in the field.\n* [Your guide here]\n'"
14,susanli2016/Machine-Learning-with-Python,susanli2016,Python code for common Machine Learning Algorithms,2017-05-26 08:55:48,2020-06-18 19:32:38,Jupyter Notebook,3047,2401,b'# Machine-Learning-with-Python\nPython codes for common Machine Learning Algorithms\n'
15,afshinea/stanford-cs-229-machine-learning,afshinea,VIP cheatsheets for Stanford's CS 229 Machine Learning,2018-08-04 23:01:00,2020-06-18 13:01:16,,2611,10555,"b'# Machine Learning cheatsheets for Stanford\'s CS 229\n\nAvailable in [\xd8\xa7\xd9\x84\xd8\xb9\xd8\xb1\xd8\xa8\xd9\x8a\xd8\xa9](https://github.com/afshinea/stanford-cs-229-machine-learning/tree/master/ar) -  [English](https://github.com/afshinea/stanford-cs-229-machine-learning/tree/master/en) -  [Espa\xc3\xb1ol](https://github.com/afshinea/stanford-cs-229-machine-learning/tree/master/es) -  [\xd9\x81\xd8\xa7\xd8\xb1\xd8\xb3\xdb\x8c](https://github.com/afshinea/stanford-cs-229-machine-learning/tree/master/fa) -  [Fran\xc3\xa7ais](https://github.com/afshinea/stanford-cs-229-machine-learning/tree/master/fr) -  [\xed\x95\x9c\xea\xb5\xad\xec\x96\xb4](https://stanford.edu/~shervine/l/ko/teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks) -  [Portugu\xc3\xaas](https://github.com/afshinea/stanford-cs-229-machine-learning/tree/master/pt) -  [T\xc3\xbcrk\xc3\xa7e](https://github.com/afshinea/stanford-cs-229-machine-learning/tree/master/tr) - [Ti\xe1\xba\xbfng Vi\xe1\xbb\x87t](https://github.com/afshinea/stanford-cs-229-machine-learning/tree/master/vi) -  [\xe7\xae\x80\xe4\xb8\xad](https://github.com/afshinea/stanford-cs-229-machine-learning/tree/master/zh) -  [\xe7\xb9\x81\xe4\xb8\xad](https://github.com/afshinea/stanford-cs-229-machine-learning/tree/master/zh-tw)\n\n## Goal\nThis repository aims at summing up in the same place all the important notions that are covered in Stanford\'s CS 229 Machine Learning course, and include:\n- **Refreshers** in related topics that highlight the key points of the **prerequisites of the course**.\n- **Cheatsheets for each machine learning field**, as well as another dedicated to tips and tricks to have in mind when training a model.\n- All elements of the above combined in an **ultimate compilation of concepts**, to have with you at all times!\n\n## Content\n#### VIP Cheatsheets\n|<a href=""https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/cheatsheet-supervised-learning.pdf""><img src=""https://stanford.edu/~shervine/teaching/cs-229/illustrations/cover/en-001.png?"" alt=""Illustration"" width=""220px""/></a>|<a href=""https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/cheatsheet-unsupervised-learning.pdf""><img src=""https://stanford.edu/~shervine/teaching/cs-229/illustrations/cover/en-002.png"" alt=""Illustration"" width=""220px""/></a>|<a href=""https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/cheatsheet-deep-learning.pdf""><img src=""https://stanford.edu/~shervine/teaching/cs-229/illustrations/cover/en-003.png"" alt=""Illustration"" width=""220px""/></a>|<a href=""https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/cheatsheet-machine-learning-tips-and-tricks.pdf""><img src=""https://stanford.edu/~shervine/teaching/cs-229/illustrations/cover/en-004.png"" alt=""Illustration"" width=""220px""/></a>|\n|:--:|:--:|:--:|:--:|\n|Supervised Learning|Unsupervised Learning|Deep Learning|Tips and tricks|\n\n#### VIP Refreshers\n|<a href=""https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/refresher-probabilities-statistics.pdf""><img src=""https://stanford.edu/~shervine/teaching/cs-229/illustrations/cover/en-005.png"" alt=""Illustration"" width=""220px""/></a>|<a href=""https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/refresher-algebra-calculus.pdf""><img src=""https://stanford.edu/~shervine/teaching/cs-229/illustrations/cover/en-006.png#1"" alt=""Illustration"" width=""220px""/></a>|\n|:--:|:--:|\n|Probabilities and Statistics|Algebra and Calculus|\n\n\n#### Super VIP Cheatsheet\n|<a href=""https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/super-cheatsheet-machine-learning.pdf""><img src=""https://stanford.edu/~shervine/teaching/cs-229/illustrations/cover/en-007.png"" alt=""Illustration"" width=""400px""/></a>|\n|:--:|\n|All the above gathered in one place|\n\n## Website\nThis material is also available on a dedicated [website](https://stanford.edu/~shervine/teaching/cs-229), so that you can enjoy reading it from any device.\n\n## Translation\nWould you like to see these cheatsheets in your native language? You can help us translating them on [this dedicated repo](https://github.com/shervinea/cheatsheet-translation)!\n\n## Authors\n[Afshine Amidi](https://twitter.com/afshinea) (Ecole Centrale Paris, MIT) and [Shervine Amidi](https://twitter.com/shervinea) (Ecole Centrale Paris, Stanford University)\n'"
16,vivienzou1/DL-Notes-for-Interview,vivienzou1,deep learning/ machine learning,2018-06-09 21:52:58,2020-06-18 02:46:23,,8506,116,b'## \xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0/\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe9\x9d\xa2\xe8\xaf\x95\xe7\xac\x94\xe8\xae\xb0\n\n\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0/\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe9\x9d\xa2\xe8\xaf\x95\xe9\x97\xae\xe9\xa2\x98\xe6\x95\xb4\xe7\x90\x86\xef\xbc\x8c\xe5\x85\xb6\xe4\xb8\xad\xe5\xa4\xa7\xe9\x83\xa8\xe5\x88\x86\xe9\x97\xae\xe9\xa2\x98\xe6\x9d\xa5\xe8\x87\xaa\xe4\xba\x8e\xe8\xbf\x99\xe4\xb8\xaa[\xe4\xbb\x93\xe5\xba\x93](https://github.com/elviswf/DeepLearningBookQA_cn).\n\n\xe4\xb8\xaa\xe4\xba\xba\xe8\xae\xa4\xe4\xb8\xba\xe8\xaf\xa5\xe4\xbb\x93\xe5\xba\x93\xe4\xb8\xad\xe7\x9a\x84\xe9\x83\xa8\xe5\x88\x86\xe9\x97\xae\xe9\xa2\x98\xe8\xbf\x87\xe4\xba\x8e\xe6\x8a\xbd\xe8\xb1\xa1/\xe7\x90\x86\xe8\xae\xba\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xe6\xb2\xa1\xe6\x9c\x89\xe6\x94\xb6\xe5\xbd\x95\xef\xbc\x8c\xe5\xa6\x82\xe6\x9c\x89\xe9\x9c\x80\xe8\xa6\x81\xe5\x8f\xaf\xe4\xbb\xa5\xe6\xb5\x8f\xe8\xa7\x88\xe5\x8e\x9f\xe4\xbb\x93\xe5\xba\x93\xe4\xb8\xad\xe7\x9a\x84\xe9\x97\xae\xe9\xa2\x98\xe3\x80\x82\n\n> \xe8\xaf\xa5\xe4\xbb\x93\xe5\xba\x93\xe5\x8f\xaa\xe5\x88\x97\xe5\x87\xba\xe4\xba\x86\xe9\x97\xae\xe9\xa2\x98\xe7\xad\x94\xe6\xa1\x88\xe5\x9c\xa8\xe3\x80\x8a\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe3\x80\x8b\xe5\xae\x9e\xe4\xbd\x93\xe4\xb9\xa6\xe4\xb8\xad\xe7\x9a\x84\xe9\xa1\xb5\xe7\xa0\x81\xef\xbc\x8c\xe4\xb8\x8ePDF\xe7\x89\x88\xe5\xb9\xb6\xe4\xb8\x8d\xe5\xaf\xb9\xe5\xba\x94\xef\xbc\x8c\xe6\x88\x91\xe9\x87\x8d\xe6\x96\xb0\xe4\xbf\xae\xe6\x94\xb9\xe4\xb8\xba\xe4\xba\x86\xe7\xad\x94\xe6\xa1\x88\xe6\x89\x80\xe5\x9c\xa8\xe7\xab\xa0\xe8\x8a\x82\xe7\x9a\x84\xe5\x90\x8d\xe7\xa7\xb0\xe3\x80\x82\n>\n> [\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe4\xb8\xad\xe6\x96\x87\xe7\x89\x88 GitHub](https://github.com/exacity/deeplearningbook-chinese)\n\n\xe6\xad\xa4\xe5\xa4\x96\xef\xbc\x8c\xe8\xbf\x98\xe5\x8c\x85\xe6\x8b\xac\xe6\x88\x91\xe7\x9c\x8b\xe5\x88\xb0\xe7\x9a\x84\xe6\x89\x80\xe6\x9c\x89\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0/\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe9\x9d\xa2\xe7\xbb\x8f\xe4\xb8\xad\xe7\x9a\x84\xe9\x97\xae\xe9\xa2\x98\xe3\x80\x82\xe9\x99\xa4\xe4\xba\x86\xe5\x85\xb6\xe4\xb8\xad DL/ML \xe7\x9b\xb8\xe5\x85\xb3\xe7\x9a\x84\xef\xbc\x8c\xe5\x85\xb6\xe4\xbb\x96\xe4\xb8\x8e\xe7\xae\x97\xe6\xb3\x95\xe5\xb2\x97\xe7\x9b\xb8\xe5\x85\xb3\xe7\x9a\x84\xe8\xae\xa1\xe7\xae\x97\xe6\x9c\xba\xe7\x9f\xa5\xe8\xaf\x86\xe4\xb9\x9f\xe4\xbc\x9a\xe8\xae\xb0\xe5\xbd\x95\xe3\x80\x82\n\n\xe4\xbd\x86\xe6\x98\xaf\xe4\xb8\x8d\xe4\xbc\x9a\xe5\x8c\x85\xe6\x8b\xac\xe5\xa6\x82\xe5\x89\x8d\xe7\xab\xaf/\xe6\xb5\x8b\xe8\xaf\x95/JAVA/Android\xe7\xad\x89\xe5\xb2\x97\xe4\xbd\x8d\xe4\xb8\xad\xe4\xb8\x8e\xe5\x85\xb7\xe4\xbd\x93\xe8\xaf\xad\xe8\xa8\x80\xe3\x80\x81\xe6\xa1\x86\xe6\x9e\xb6\xe7\xad\x89\xe6\x9c\x89\xe5\x85\xb3\xe7\x9a\x84\xe9\x97\xae\xe9\xa2\x98\xe3\x80\x82\n\n\n- #### [\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9b\xb8\xe5\x85\xb3](/\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0)\n\n- #### [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9b\xb8\xe5\x85\xb3](/\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0)\n\n- #### []\n\n\n### Reference\n\n- exacity/[deeplearningbook-chinese](https://github.com/exacity/deeplearningbook-chinese): \xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe4\xb8\xad\xe6\x96\x87\xe7\x89\x88 \n\n- elviswf/[DeepLearningBookQA_cn](https://github.com/elviswf/DeepLearningBookQA_cn): \xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe9\x9d\xa2\xe8\xaf\x95\xe9\x97\xae\xe9\xa2\x98 \xe5\x9b\x9e\xe7\xad\x94\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84DeepLearning\xe4\xb8\xad\xe6\x96\x87\xe7\x89\x88\xe9\xa1\xb5\xe7\xa0\x81 \n\n- \xe5\x9c\xa8\xe7\xba\xbf LaTeX \xe5\x85\xac\xe5\xbc\x8f\xe7\xbc\x96\xe8\xbe\x91\xe5\x99\xa8 http://www.codecogs.com/latex/eqneditor.php'
17,scikit-learn/scikit-learn,scikit-learn,scikit-learn: machine learning in Python,2010-08-17 09:43:38,2020-06-18 19:45:42,Python,19932,41166,"b'.. -*- mode: rst -*-\n\n|Azure|_ |Travis|_ |Codecov|_ |CircleCI|_ |PythonVersion|_ |PyPi|_ |DOI|_\n\n.. |Azure| image:: https://dev.azure.com/scikit-learn/scikit-learn/_apis/build/status/scikit-learn.scikit-learn?branchName=master\n.. _Azure: https://dev.azure.com/scikit-learn/scikit-learn/_build/latest?definitionId=1&branchName=master\n\n.. |Travis| image:: https://api.travis-ci.org/scikit-learn/scikit-learn.svg?branch=master\n.. _Travis: https://travis-ci.org/scikit-learn/scikit-learn\n\n.. |Codecov| image:: https://codecov.io/github/scikit-learn/scikit-learn/badge.svg?branch=master&service=github\n.. _Codecov: https://codecov.io/github/scikit-learn/scikit-learn?branch=master\n\n.. |CircleCI| image:: https://circleci.com/gh/scikit-learn/scikit-learn/tree/master.svg?style=shield&circle-token=:circle-token\n.. _CircleCI: https://circleci.com/gh/scikit-learn/scikit-learn\n\n.. |PythonVersion| image:: https://img.shields.io/badge/python-3.6%20%7C%203.7%20%7C%203.8-blue\n.. _PythonVersion: https://img.shields.io/badge/python-3.6%20%7C%203.7%20%7C%203.8-blue\n\n.. |PyPi| image:: https://badge.fury.io/py/scikit-learn.svg\n.. _PyPi: https://badge.fury.io/py/scikit-learn\n\n.. |DOI| image:: https://zenodo.org/badge/21369/scikit-learn/scikit-learn.svg\n.. _DOI: https://zenodo.org/badge/latestdoi/21369/scikit-learn/scikit-learn\n\n.. image:: doc/logos/scikit-learn-logo.png\n  :target: https://scikit-learn.org/\n\n**scikit-learn** is a Python module for machine learning built on top of\nSciPy and is distributed under the 3-Clause BSD license.\n\nThe project was started in 2007 by David Cournapeau as a Google Summer\nof Code project, and since then many volunteers have contributed. See\nthe `About us <https://scikit-learn.org/dev/about.html#authors>`__ page\nfor a list of core contributors.\n\nIt is currently maintained by a team of volunteers.\n\nWebsite: https://scikit-learn.org\n\nInstallation\n------------\n\nDependencies\n~~~~~~~~~~~~\n\nscikit-learn requires:\n\n- Python (>= 3.6)\n- NumPy (>= 1.13.3)\n- SciPy (>= 0.19.1)\n- joblib (>= 0.11)\n- threadpoolctl (>= 2.0.0)\n\n=======\n\n**Scikit-learn 0.20 was the last version to support Python 2.7 and Python 3.4.**\nscikit-learn 0.23 and later require Python 3.6 or newer.\n\nScikit-learn plotting capabilities (i.e., functions start with ``plot_``\nand classes end with ""Display"") require Matplotlib (>= 2.1.1). For running the\nexamples Matplotlib >= 2.1.1 is required. A few examples require\nscikit-image >= 0.13, a few examples require pandas >= 0.18.0, some examples\nrequire seaborn >= 0.9.0.\n\nUser installation\n~~~~~~~~~~~~~~~~~\n\nIf you already have a working installation of numpy and scipy,\nthe easiest way to install scikit-learn is using ``pip``   ::\n\n    pip install -U scikit-learn\n\nor ``conda``::\n\n    conda install scikit-learn\n\nThe documentation includes more detailed `installation instructions <https://scikit-learn.org/stable/install.html>`_.\n\n\nChangelog\n---------\n\nSee the `changelog <https://scikit-learn.org/dev/whats_new.html>`__\nfor a history of notable changes to scikit-learn.\n\nDevelopment\n-----------\n\nWe welcome new contributors of all experience levels. The scikit-learn\ncommunity goals are to be helpful, welcoming, and effective. The\n`Development Guide <https://scikit-learn.org/stable/developers/index.html>`_\nhas detailed information about contributing code, documentation, tests, and\nmore. We\'ve included some basic information in this README.\n\nImportant links\n~~~~~~~~~~~~~~~\n\n- Official source code repo: https://github.com/scikit-learn/scikit-learn\n- Download releases: https://pypi.org/project/scikit-learn/\n- Issue tracker: https://github.com/scikit-learn/scikit-learn/issues\n\nSource code\n~~~~~~~~~~~\n\nYou can check the latest sources with the command::\n\n    git clone https://github.com/scikit-learn/scikit-learn.git\n\nContributing\n~~~~~~~~~~~~\n\nTo learn more about making a contribution to scikit-learn, please see our\n`Contributing guide\n<https://scikit-learn.org/dev/developers/contributing.html>`_.\n\nTesting\n~~~~~~~\n\nAfter installation, you can launch the test suite from outside the\nsource directory (you will need to have ``pytest`` >= 3.3.0 installed)::\n\n    pytest sklearn\n\nSee the web page https://scikit-learn.org/dev/developers/advanced_installation.html#testing\nfor more information.\n\n    Random number generation can be controlled during testing by setting\n    the ``SKLEARN_SEED`` environment variable.\n\nSubmitting a Pull Request\n~~~~~~~~~~~~~~~~~~~~~~~~~\n\nBefore opening a Pull Request, have a look at the\nfull Contributing page to make sure your code complies\nwith our guidelines: https://scikit-learn.org/stable/developers/index.html\n\nProject History\n---------------\n\nThe project was started in 2007 by David Cournapeau as a Google Summer\nof Code project, and since then many volunteers have contributed. See\nthe `About us <https://scikit-learn.org/dev/about.html#authors>`__ page\nfor a list of core contributors.\n\nThe project is currently maintained by a team of volunteers.\n\n**Note**: `scikit-learn` was previously referred to as `scikits.learn`.\n\nHelp and Support\n----------------\n\nDocumentation\n~~~~~~~~~~~~~\n\n- HTML documentation (stable release): https://scikit-learn.org\n- HTML documentation (development version): https://scikit-learn.org/dev/\n- FAQ: https://scikit-learn.org/stable/faq.html\n\nCommunication\n~~~~~~~~~~~~~\n\n- Mailing list: https://mail.python.org/mailman/listinfo/scikit-learn\n- IRC channel: ``#scikit-learn`` at ``webchat.freenode.net``\n- Stack Overflow: https://stackoverflow.com/questions/tagged/scikit-learn\n- Website: https://scikit-learn.org\n\nCitation\n~~~~~~~~\n\nIf you use scikit-learn in a scientific publication, we would appreciate citations: https://scikit-learn.org/stable/about.html#citing-scikit-learn\n'"
18,jindongwang/MachineLearning,jindongwang,一些关于机器学习的学习资料与研究介绍,2015-08-16 13:01:08,2020-06-17 09:54:47,,546,1455,"b""# \xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xb5\x84\xe6\xba\x90 Machine learning Resources\n\n*\xe6\x9c\xac\xe9\xa1\xb9\xe7\x9b\xae\xe5\xb7\xb2\xe6\x9b\xb4\xe6\x96\xb0\xef\xbc\x8c\xe8\xaf\xb7\xe7\xa7\xbb\xe6\xad\xa5\xe5\x88\xb0[\xe8\xbf\x99\xe9\x87\x8c](https://github.com/allmachinelearning/MachineLearning)\xe5\x8f\x82\xe4\xb8\x8e\xe6\x88\x91\xe4\xbb\xac\xe6\x9c\x80\xe6\x96\xb0\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xbc\x80\xe6\xba\x90\xe9\xa1\xb9\xe7\x9b\xae\xe3\x80\x82*\n\n*\xe5\xbf\xab\xe9\x80\x9f\xe5\xbc\x80\xe5\xa7\x8b\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x9a* \n- \xe5\x91\xa8\xe5\xbf\x97\xe5\x8d\x8e\xe7\x9a\x84[\xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe3\x80\x8b](https://pan.baidu.com/s/1hscnaQC)\xe4\xbd\x9c\xe4\xb8\xba\xe9\x80\x9a\xe8\xaf\xbb\xe6\x95\x99\xe6\x9d\x90\xef\xbc\x8c\xe4\xb8\x8d\xe7\x94\xa8\xe6\xb7\xb1\xe5\x85\xa5\xef\xbc\x8c\xe4\xbb\x8e\xe5\xae\x8f\xe8\xa7\x82\xe4\xb8\x8a\xe4\xba\x86\xe8\xa7\xa3\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\n\n- \xe6\x9d\x8e\xe8\x88\xaa\xe7\x9a\x84[\xe3\x80\x8a\xe7\xbb\x9f\xe8\xae\xa1\xe5\xad\xa6\xe4\xb9\xa0\xe6\x96\xb9\xe6\xb3\x95\xe3\x80\x8b](https://pan.baidu.com/s/1dF2b4jf)\xe4\xbd\x9c\xe4\xb8\xba\xe7\xbb\x8f\xe5\x85\xb8\xe7\x9a\x84\xe6\xb7\xb1\xe5\x85\xa5\xe6\xa1\x88\xe4\xbe\x8b\xef\xbc\x8c\xe4\xbb\x94\xe7\xbb\x86\xe7\xa0\x94\xe7\xa9\xb6\xe5\x87\xa0\xe4\xb8\xaa\xe7\xae\x97\xe6\xb3\x95\xe7\x9a\x84\xe6\x9d\xa5\xe9\xbe\x99\xe5\x8e\xbb\xe8\x84\x89 | [\xe4\xb9\xa6\xe4\xb8\xad\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81\xe5\xae\x9e\xe7\x8e\xb0](https://github.com/WenDesi/lihang_book_algorithm)\n\n- \xe4\xbd\xbf\xe7\x94\xa8Python\xe8\xaf\xad\xe8\xa8\x80\xef\xbc\x8c\xe6\xa0\xb9\xe6\x8d\xae[\xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xae\x9e\xe6\x88\x98\xe3\x80\x8b](https://pan.baidu.com/s/1gfzV7PL)\xe5\xbf\xab\xe9\x80\x9f\xe4\xb8\x8a\xe6\x89\x8b\xe5\x86\x99\xe7\xa8\x8b\xe5\xba\x8f\n\n- \xe5\x90\xb4\xe6\x81\xa9\xe8\xbe\xbe\xe7\x9a\x84\xe6\x9c\x80\xe6\x96\xb0\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe8\xaf\xbe\xe7\xa8\x8b\xe8\xb5\x84\xe6\xba\x90\xef\xbc\x9ahttps://www.jiqizhixin.com/articles/2018-06-21-6\n\n- \xe5\x8f\x82\xe7\x85\xa7Youtube\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xba\xa2\xe4\xba\xbaSiraj Raval\xe7\x9a\x84\xe8\xa7\x86\xe9\xa2\x91+\xe4\xbb\xa3\xe7\xa0\x81\xe5\x8f\xaf\xe4\xbb\xa5\xe5\xb8\xae\xe5\x8a\xa9\xe4\xbd\xa0\xe6\x9b\xb4\xe5\xa5\xbd\xe5\x9c\xb0\xe8\xbf\x9b\xe5\x85\xa5\xe7\x8a\xb6\xe6\x80\x81\xef\xbc\x81\n    - [\xe5\x8e\x9fYoutube\xe5\x9c\xb0\xe5\x9d\x80\xe9\x9c\x80\xe8\xa6\x81\xe6\xa2\xaf\xe5\xad\x90](https://www.youtube.com/watch?v=xRJCOz3AfYY&list=PL2-dafEMk2A7mu0bSksCGMJEmeddU_H4D) | [\xe7\x99\xbe\xe5\xba\xa6\xe7\xbd\x91\xe7\x9b\x98](https://pan.baidu.com/s/1jICGJFg)\n    \n- \xe6\x9d\xa5\xe8\x87\xaa\xe5\x9b\xbd\xe7\xab\x8b\xe5\x8f\xb0\xe6\xb9\xbe\xe5\xa4\xa7\xe5\xad\xa6\xe6\x9d\x8e\xe5\xae\x8f\xe6\xaf\x85\xe8\x80\x81\xe5\xb8\x88\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x92\x8c\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe4\xb8\xad\xe6\x96\x87\xe8\xaf\xbe\xe7\xa8\x8b\xef\xbc\x8c\xe5\xbc\xba\xe7\x83\x88\xe6\x8e\xa8\xe8\x8d\x90\xef\xbc\x9a[\xe8\xaf\xbe\xe7\xa8\x8b](http://speech.ee.ntu.edu.tw/~tlkagk/courses.html)\n\n- \xe6\x9c\x80\xe5\x90\x8e\xef\xbc\x8c\xe4\xbd\xa0\xe5\x8f\xaf\xe8\x83\xbd\xe6\x83\xb3\xe7\x9c\x9f\xe6\xad\xa3\xe5\xae\x9e\xe6\x88\x98\xe4\xb8\x80\xe4\xb8\x8b\xe3\x80\x82\xe9\x82\xa3\xe4\xb9\x88\xef\xbc\x8c\xe8\xaf\xb7\xe5\x88\xb0\xe6\xb3\xa8\xe6\x98\x8e\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xab\x9e\xe8\xb5\x9b\xe5\xb9\xb3\xe5\x8f\xb0Kaggle\xe4\xb8\x8a\xe5\x81\x9a\xe4\xb8\x80\xe4\xb8\x8b\xe8\xbf\x99\xe4\xba\x9b\xe5\x9f\xba\xe7\xa1\x80\xe5\x85\xa5\xe9\x97\xa8\xe7\x9a\x84[\xe9\xa2\x98\xe7\x9b\xae](https://www.kaggle.com/competitions?sortBy=deadline&group=all&page=1&pageSize=20&segment=gettingStarted)\xe5\x90\xa7\xef\xbc\x81(Kaggle\xe4\xb8\x8a\xe5\xaf\xb9\xe4\xba\x8e\xe6\xaf\x8f\xe4\xb8\xaa\xe9\x97\xae\xe9\xa2\x98\xe4\xbd\xa0\xe9\x83\xbd\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x9c\x8b\xe5\x88\xb0\xe5\x88\xab\xe4\xba\xba\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x8c\xe6\x96\xb9\xe4\xbe\xbf\xe4\xbd\xa0\xe6\x9b\xb4\xe5\x8a\xa0\xe5\xbf\xab\xe9\x80\x9f\xe5\x9c\xb0\xe5\xad\xa6\xe4\xb9\xa0) \xc2\xa0[Kaggle\xe4\xbb\x8b\xe7\xbb\x8d\xe5\x8f\x8a\xe5\x85\xa5\xe9\x97\xa8\xe8\xa7\xa3\xe8\xaf\xbb](https://zhuanlan.zhihu.com/p/25686876) [\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x94\xa8\xe6\x9d\xa5\xe7\xbb\x83\xe6\x89\x8b\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86](https://www.kaggle.com/annavictoria/ml-friendly-public-datasets/notebook)\n\n\xe5\x85\xb6\xe4\xbb\x96\xe6\x9c\x89\xe7\x94\xa8\xe7\x9a\x84\xe8\xb5\x84\xe6\x96\x99\xef\xbc\x9a\n\n- \xe6\x83\xb3\xe7\x9c\x8b\xe5\x88\xab\xe4\xba\xba\xe6\x80\x8e\xe4\xb9\x88\xe5\x86\x99\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9f[\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xbb\x8f\xe5\x85\xb8\xe6\x95\x99\xe6\x9d\x90\xe3\x80\x8aPRML\xe3\x80\x8b\xe6\x89\x80\xe6\x9c\x89\xe4\xbb\xa3\xe7\xa0\x81\xe5\xae\x9e\xe7\x8e\xb0](https://github.com/ctgk/PRML)\n\n- [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xae\x97\xe6\xb3\x95Python\xe5\xae\x9e\xe7\x8e\xb0](https://github.com/lawlite19/MachineLearning_Python)\n\n- [\xe5\x90\xb4\xe6\x81\xa9\xe8\xbe\xbe\xe6\x96\xb0\xe4\xb9\xa6\xef\xbc\x9aMachine Learning Yearning\xe4\xb8\xad\xe6\x96\x87\xe7\x89\x88](https://pan.baidu.com/s/10kosKx6rDguS4tPejY-fRw)\n\n- \xe5\x8f\xa6\xe5\xa4\x96\xef\xbc\x8c\xe5\xaf\xb9\xe4\xba\x8e\xe4\xb8\x80\xe4\xba\x9b\xe5\x9f\xba\xe7\xa1\x80\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\xa6\xe7\x9f\xa5\xe8\xaf\x86\xef\xbc\x8c\xe4\xbd\xa0\xe7\x9c\x8b[\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0(\xe8\x8a\xb1\xe4\xb9\xa6)\xe4\xb8\xad\xe6\x96\x87\xe7\x89\x88](https://github.com/exacity/deeplearningbook-chinese)\xe5\xb0\xb1\xe5\xa4\x9f\xe4\xba\x86\xe3\x80\x82\xe8\xbf\x99\xe6\x9c\xac\xe4\xb9\xa6\xe5\x90\x8c\xe6\x97\xb6\xe4\xb9\x9f\xe6\x98\xaf**\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0**\xe7\xbb\x8f\xe5\x85\xb8\xe4\xb9\x8b\xe4\xb9\xa6\xe3\x80\x82\n\n- \xe6\x9d\xa5\xe8\x87\xaa\xe5\x8d\x97\xe4\xba\xac\xe5\xa4\xa7\xe5\xad\xa6\xe5\x91\xa8\xe5\xbf\x97\xe5\x8d\x8e\xe5\xb0\x8f\xe7\xbb\x84\xe7\x9a\x84\xe5\x8d\x9a\xe5\xa3\xab\xe7\x94\x9f\xe5\x86\x99\xe7\x9a\x84\xe4\xb8\x80\xe6\x9c\xac\xe5\xb0\x8f\xe8\x80\x8c\xe7\xb2\xbe\xe7\x9a\x84[\xe8\xa7\xa3\xe6\x9e\x90\xe5\x8d\xb7\xe7\xa7\xaf\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe2\x80\x94\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe5\xae\x9e\xe8\xb7\xb5\xe6\x89\x8b\xe5\x86\x8c](http://lamda.nju.edu.cn/weixs/book/CNN_book.html)\n\n- - -\n\n[\xe4\xb8\x80\xe4\xb8\xaa\xe7\xae\x80\xe6\xb4\x81\xe6\x98\x8e\xe4\xba\x86\xe7\x9a\x84\xe6\x97\xb6\xe9\x97\xb4\xe5\xba\x8f\xe5\x88\x97\xe5\xa4\x84\xe7\x90\x86(\xe5\x88\x86\xe7\xaa\x97\xe3\x80\x81\xe7\x89\xb9\xe5\xbe\x81\xe6\x8f\x90\xe5\x8f\x96\xe3\x80\x81\xe5\x88\x86\xe7\xb1\xbb)\xe5\xba\x93\xef\xbc\x9aSeglearn](https://dmbee.github.io/seglearn/index.html)\n\n[\xe8\xae\xa1\xe7\xae\x97\xe6\x9c\xba\xe8\xa7\x86\xe8\xa7\x89\xe8\xbf\x99\xe4\xb8\x80\xe5\xb9\xb4\xef\xbc\x9a\xe8\xbf\x99\xe6\x98\xaf\xe6\x9c\x80\xe5\x85\xa8\xe7\x9a\x84\xe4\xb8\x80\xe4\xbb\xbdCV\xe6\x8a\x80\xe6\x9c\xaf\xe6\x8a\xa5\xe5\x91\x8a](https://zhuanlan.zhihu.com/p/31430602)\n\n[\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0(\xe8\x8a\xb1\xe4\xb9\xa6)\xe4\xb8\xad\xe6\x96\x87\xe7\x89\x88](https://github.com/exacity/deeplearningbook-chinese)\n\n**[\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe6\x9c\x80\xe5\x80\xbc\xe5\xbe\x97\xe7\x9c\x8b\xe7\x9a\x84\xe8\xae\xba\xe6\x96\x87](http://www.dlworld.cn/YeJieDongTai/4385.html)**\n\n**[\xe6\x9c\x80\xe5\x85\xa8\xe9\x9d\xa2\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe8\x87\xaa\xe5\xad\xa6\xe8\xb5\x84\xe6\xba\x90\xe9\x9b\x86\xe9\x94\xa6](http://dataunion.org/29975.html)**\n\n**[Machine learning surveys](https://github.com/metrofun/machine-learning-surveys/)**\n\n**[\xe5\xbf\xab\xe9\x80\x9f\xe5\x85\xa5\xe9\x97\xa8TensorFlow](https://github.com/aymericdamien/TensorFlow-Examples)**\n\n[\xe8\x87\xaa\xe7\x84\xb6\xe8\xaf\xad\xe8\xa8\x80\xe5\xa4\x84\xe7\x90\x86\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86](http://abunchofdata.com/datasets-for-natural-language-processing/)\n\xc2\xa0\n[Learning Machine Learning? Six articles you don\xe2\x80\x99t want to miss](http://www.ibmbigdatahub.com/blog/learning-machine-learning-six-articles-you-don-t-want-miss)\n\n[Getting started with machine learning documented by github](https://github.com/collections/machine-learning)\n\n- - -\n\n\n## \xe7\xa0\x94\xe7\xa9\xb6\xe9\xa2\x86\xe5\x9f\x9f\xe8\xb5\x84\xe6\xba\x90\xe7\xbb\x86\xe5\x88\x86\n\n- ### [\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0 Deep learning](https://github.com/ChristosChristofidis/awesome-deep-learning)\n\n- ### [\xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0 Reinforcement learning](https://github.com/aikorea/awesome-rl)\n\n- ### [\xe8\xbf\x81\xe7\xa7\xbb\xe5\xad\xa6\xe4\xb9\xa0 Transfer learning](https://jindongwang.github.io/transferlearning/)\n\n- ### [\xe5\x88\x86\xe5\xb8\x83\xe5\xbc\x8f\xe5\xad\xa6\xe4\xb9\xa0\xe7\xb3\xbb\xe7\xbb\x9f Distributed learning system](https://github.com/theanalyst/awesome-distributed-systems)\n\n- ### [\xe8\xae\xa1\xe7\xae\x97\xe6\x9c\xba\xe8\xa7\x86\xe8\xa7\x89/\xe6\x9c\xba\xe5\x99\xa8\xe8\xa7\x86\xe8\xa7\x89 Computer vision / machine vision](https://github.com/jbhuang0604/awesome-computer-vision)\n\n- ### [\xe8\x87\xaa\xe7\x84\xb6\xe8\xaf\xad\xe8\xa8\x80\xe5\xa4\x84\xe7\x90\x86 Natural language procesing](https://github.com/Nativeatom/NaturalLanguageProcessing)\n\n- ### [\xe7\x94\x9f\xe7\x89\xa9\xe4\xbf\xa1\xe6\x81\xaf\xe5\xad\xa6 Bioinfomatics](https://github.com/danielecook/Awesome-Bioinformatics)\n\n- ### [\xe8\xa1\x8c\xe4\xb8\xba\xe8\xaf\x86\xe5\x88\xab Activity recognition](https://github.com/jindongwang/activityrecognition)\n\n- ### [\xe5\xa4\x9a\xe6\x99\xba\xe8\x83\xbd\xe4\xbd\x93 Multi-Agent](http://ddl.escience.cn/f/ILKI)\n\n- - -\n\n##  \xe5\xbc\x80\xe5\xa7\x8b\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x9a\xe9\xa2\x84\xe5\xa4\x87\xe7\x9f\xa5\xe8\xaf\x86 Prerequisite\n\n- [\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9f\xa5\xe8\xaf\x86\xe4\xb8\x8e\xe8\xb7\xaf\xe7\xba\xbf\xe5\x9b\xbe](https://metacademy.org/)\n\n- [MIT\xe7\xba\xbf\xe6\x80\xa7\xe4\xbb\xa3\xe6\x95\xb0\xe8\xaf\xbe\xe5\xa0\x82\xe7\xac\x94\xe8\xae\xb0(\xe4\xb8\xad\xe6\x96\x87)](https://github.com/zlotus/notes-linear-algebra)\n\n- [\xe6\xa6\x82\xe7\x8e\x87\xe4\xb8\x8e\xe7\xbb\x9f\xe8\xae\xa1 The Probability and Statistics Cookbook](http://statistics.zone/)\n\n- Python\n\n    - [Learn X in Y minutes](https://learnxinyminutes.com/docs/python/)\n\n    - [Python\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe4\xba\x92\xe5\x8a\xa8\xe6\x95\x99\xe7\xa8\x8b](https://www.springboard.com/learning-paths/machine-learning-python/)\n\n- Markdown\n\n    - [Mastering Markdown](https://guides.github.com/features/mastering-markdown/) - Markdown is a easy-to-use writing tool on the GitHu.\n\n- R\n\n    - [R Tutorial](http://www.cyclismo.org/tutorial/R/)\n\n- Python\xe5\x92\x8cMatlab\xe7\x9a\x84\xe4\xb8\x80\xe4\xba\x9bcheat sheet\xef\xbc\x9ahttp://ddl.escience.cn/f/IDkq \xe5\x8c\x85\xe5\x90\xab\xef\xbc\x9a\n\n    - Numpy\xe3\x80\x81Scipy\xe3\x80\x81Pandas\xe7\xa7\x91\xe5\xad\xa6\xe8\xae\xa1\xe7\xae\x97\xe5\xba\x93\n\n    - Matlab\xe7\xa7\x91\xe5\xad\xa6\xe8\xae\xa1\xe7\xae\x97\n\n    - Matplotlib\xe7\x94\xbb\xe5\x9b\xbe\n\n- \xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe6\xa1\x86\xe6\x9e\xb6\n\n    - Python\n        - [TensorFlow](https://www.tensorflow.org/)\n        - [Scikit-learn](http://scikit-learn.org/)\n        - [PyTorch](http://pytorch.org/)\n        - [Keras](https://keras.io/)\n        - [MXNet](http://mxnet.io/)|[\xe7\x9b\xb8\xe5\x85\xb3\xe8\xb5\x84\xe6\xba\x90\xe5\xa4\xa7\xe5\x88\x97\xe8\xa1\xa8](https://github.com/chinakook/Awesome-MXNet)\n        - [Caffe](http://caffe.berkeleyvision.org/)\n        - [Caffe2](https://caffe2.ai/)\n\n    - Java\n        - [Deeplearning4j](https://deeplearning4j.org/)\n\n    - Matlab\n        - [Neural Network Toolbox](https://cn.mathworks.com/help/nnet/index.html)\n        - [Deep Learning Toolbox](https://cn.mathworks.com/matlabcentral/fileexchange/38310-deep-learning-toolbox)\n\n- - -\n\n\n## \xe6\x96\x87\xe6\xa1\xa3 notes\n\n- [\xe7\xbb\xbc\xe8\xbf\xb0\xe6\x96\x87\xe7\xab\xa0\xe6\xb1\x87\xe6\x80\xbb](https://github.com/allmachinelearning/MachineLearning/blob/master/notes/survey_readme.md)\n\n- [\xe8\xbf\x91200\xe7\xaf\x87\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xb5\x84\xe6\x96\x99\xe6\xb1\x87\xe6\x80\xbb\xef\xbc\x81](https://zhuanlan.zhihu.com/p/26136757)\n\n- [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x85\xa5\xe9\x97\xa8\xe8\xb5\x84\xe6\x96\x99](https://github.com/allmachinelearning/MachineLearning/blob/master/notes/MLMaterials.md)\n\n- [MIT.Introduction to Machine Learning](http://ddl.escience.cn/f/Iwtu)\n\n- [\xe4\xb8\x9c\xe4\xba\xac\xe5\xa4\xa7\xe5\xad\xa6\xe5\x90\x8c\xe5\xad\xa6\xe5\x81\x9a\xe7\x9a\x84\xe4\xba\xba\xe6\x9c\xba\xe4\xba\xa4\xe4\xba\x92\xe6\x8a\xa5\xe5\x91\x8a](https://github.com/allmachinelearning/MachineLearning/blob/master/notes/FieldResearchinChina927-104.pdf)\n\n- [\xe4\xba\xba\xe6\x9c\xba\xe4\xba\xa4\xe4\xba\x92\xe7\xae\x80\xe4\xbb\x8b](https://github.com/jindongwang/HCI)\n\n- [\xe4\xba\xba\xe6\x9c\xba\xe4\xba\xa4\xe4\xba\x92\xe4\xb8\x8e\xe5\x88\x9b\xe4\xb8\x9a\xe8\xae\xba\xe5\x9d\x9b](https://github.com/allmachinelearning/MachineLearning/blob/master/notes/%E4%BA%BA%E6%9C%BA%E4%BA%A4%E4%BA%92%E4%B8%8E%E5%88%9B%E4%B8%9A%E8%AE%BA%E5%9D%9B.md)\n\n- [\xe8\x81\x8c\xe5\x9c\xba\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x85\xa5\xe9\x97\xa8](https://github.com/allmachinelearning/MachineLearning/blob/master/notes/%E8%81%8C%E5%9C%BA-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.md)\n\n- [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9a\x84\xe5\x8f\x91\xe5\xb1\x95\xe5\x8e\x86\xe7\xa8\x8b\xe5\x8f\x8a\xe5\x90\xaf\xe7\xa4\xba](http://mt.sohu.com/20170326/n484898474.shtml), (@Prof. Zhihua Zhang/@\xe5\xbc\xa0\xe5\xbf\x97\xe5\x8d\x8e\xe6\x95\x99\xe6\x8e\x88)\n\n- [\xe5\xb8\xb8\xe7\x94\xa8\xe7\x9a\x84\xe8\xb7\x9d\xe7\xa6\xbb\xe5\x92\x8c\xe7\x9b\xb8\xe4\xbc\xbc\xe5\xba\xa6\xe5\xba\xa6\xe9\x87\x8f](https://github.com/allmachinelearning/MachineLearning/blob/master/notes/distance%20and%20similarity.md)\n\n- - -\n\n\n## \xe8\xaf\xbe\xe7\xa8\x8b\xe4\xb8\x8e\xe8\xae\xb2\xe5\xba\xa7 Course and talk\n\n### \xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0 Machine Learning\n\xc2\xa0\n[\xe5\x8f\xb0\xe6\xb9\xbe\xe5\xa4\xa7\xe5\xad\xa6\xe5\xba\x94\xe7\x94\xa8\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe8\xaf\xbe\xe7\xa8\x8b](https://www.csie.ntu.edu.tw/~yvchen/f106-adl/index.html)\n\n-\xc2\xa0[\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xef\xbc\x8c\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x8c\xe7\xae\x97\xe6\xb3\x95\xef\xbc\x8c\xe4\xba\xba\xe5\xb7\xa5\xe6\x99\xba\xe8\x83\xbd\xe7\xad\x89 30 \xe9\x97\xa8\xe5\x85\x8d\xe8\xb4\xb9\xe8\xaf\xbe\xe7\xa8\x8b\xe8\xaf\xa6\xe7\xbb\x86\xe6\xb8\x85\xe5\x8d\x95](http://www.datasciencecentral.com/profiles/blogs/neural-networks-for-machine-learning)\n\xc2\xa0 \n- [\xe6\x96\xaf\xe5\x9d\xa6\xe7\xa6\x8f\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x85\xa5\xe9\x97\xa8\xe8\xaf\xbe\xe7\xa8\x8b](https://www.coursera.org/learn/machine-learning)\xef\xbc\x8c\xe8\xae\xb2\xe5\xb8\x88\xe4\xb8\xbaAndrew Ng\xef\xbc\x8c\xe9\x80\x82\xe5\x90\x88\xe6\x95\xb0\xe5\xad\xa6\xe5\x9f\xba\xe7\xa1\x80\xe4\xb8\x80\xe8\x88\xac\xe7\x9a\x84\xe4\xba\xba\xef\xbc\x8c\xe9\x80\x82\xe5\x90\x88\xe5\x85\xa5\xe9\x97\xa8\xef\xbc\x8c\xe4\xbd\x86\xe6\x98\xaf\xe5\xad\xa6\xe5\xae\x8c\xe4\xbc\x9a\xe5\x8f\x91\xe7\x8e\xb0\xe5\x8f\xaa\xe6\x98\xaf\xe6\x87\x82\xe4\xb8\xaa\xe5\xa4\xa7\xe6\xa6\x82\xef\xbc\x8c\xe4\xb9\x9f\xe5\xb0\xb1\xe7\x9b\xb8\xe5\xbd\x93\xe4\xba\x8e\xe4\xbb\x80\xe4\xb9\x88\xe9\x83\xbd\xe4\xb8\x8d\xe6\x87\x82\xe3\x80\x82\xe7\x9c\x81\xe7\x95\xa5\xe4\xba\x86\xe5\xbe\x88\xe5\xa4\x9a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9a\x84\xe7\xbb\x86\xe8\x8a\x82\n\n- [Neural Networks for Machine Learning](https://www.coursera.org/learn/neural-networks), Coursera\xe4\xb8\x8a\xe7\x9a\x84\xe8\x91\x97\xe5\x90\x8d\xe8\xaf\xbe\xe7\xa8\x8b\xef\xbc\x8c\xe7\x94\xb1Geoffrey Hinton\xe6\x95\x99\xe6\x8e\x88\xe4\xb8\xbb\xe8\xae\xb2\xe3\x80\x82\n\n- [Stanford CS 229](http://cs229.stanford.edu/materials.html), Andrew Ng\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xaf\xbe\xe6\x97\xa0\xe9\x98\x89\xe5\x89\xb2\xe7\x89\x88\xef\xbc\x8cNotes\xe6\xaf\x94\xe8\xbe\x83\xe8\xaf\xa6\xe7\xbb\x86\n\n- [CMU 10-702 Statistical Machine Learning](http://www.stat.cmu.edu/~larry/=sml/), \xe8\xae\xb2\xe5\xb8\x88\xe6\x98\xafLarry Wasserman\xef\xbc\x8c\xe5\xba\x94\xe8\xaf\xa5\xe6\x98\xaf\xe7\xbb\x9f\xe8\xae\xa1\xe7\xb3\xbb\xe5\xbc\x80\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x8c\xe9\x9d\x9e\xe5\xb8\xb8\xe6\x95\xb0\xe5\xad\xa6\xe5\x8c\x96\xef\xbc\x8c\xe7\xac\xac\xe4\xb8\x80\xe8\x8a\x82\xe8\xaf\xbe\xe5\xb0\xb1\xe6\x8f\x90\xe5\x88\xb0\xe4\xba\x86RKHS(Reproducing Kernel Hilbert Space),\xe5\xbb\xba\xe8\xae\xae\xe6\x95\xb0\xe5\xad\xa6\xe5\x87\xba\xe8\xba\xab\xe7\x9a\x84\xe5\x90\x8c\xe5\xad\xa6\xe7\x9c\x8b\xe6\x88\x96\xe8\x80\x85\xe6\x98\xaf\xe5\xad\xa6\xe8\xbf\x87\xe5\xae\x9e\xe5\x8f\x98\xe5\x87\xbd\xe6\x95\xb0\xe6\xb3\x9b\xe5\x87\xbd\xe5\x88\x86\xe6\x9e\x90\xe7\x9a\x84\xe4\xba\xba\xe7\x9c\x8b\xe4\xb8\x80\xe7\x9c\x8b\n\n- [CMU 10-715 Advanced Introduction to Machine Learning](https://www.cs.cmu.edu/~epxing/Class/10715/)\xef\xbc\x8c\xe5\x90\x8c\xe6\xa0\xb7\xe6\x98\xafCMU phd\xe7\xba\xa7\xe5\x88\xab\xe7\x9a\x84\xe8\xaf\xbe\xef\xbc\x8c\xe8\x8a\x82\xe5\xa5\x8f\xe5\xbf\xab\xe9\x9a\xbe\xe5\xba\xa6\xe9\xab\x98\n\n- [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x9f\xba\xe7\x9f\xb3](https://www.coursera.org/course/ntumlone)\xef\xbc\x88\xe9\x80\x82\xe5\x90\x88\xe5\x85\xa5\xe9\x97\xa8\xef\xbc\x89\xe3\x80\x82\xe5\x9b\xbd\xe7\xab\x8b\xe5\x8f\xb0\xe6\xb9\xbe\xe5\xa4\xa7\xe5\xad\xa6[\xe6\x9e\x97\xe8\xbd\xa9\xe7\x94\xb0](https://www.coursera.org/instructor/htlin)\n\n- [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x8a\x80\xe6\xb3\x95](https://www.coursera.org/course/ntumltwo)\xef\xbc\x88\xe9\x80\x82\xe5\x90\x88\xe6\x8f\x90\xe9\xab\x98\xef\xbc\x89\xe3\x80\x82\xe5\x9b\xbd\xe7\xab\x8b\xe5\x8f\xb0\xe6\xb9\xbe\xe5\xa4\xa7\xe5\xad\xa6[\xe6\x9e\x97\xe8\xbd\xa9\xe7\x94\xb0](https://www.coursera.org/instructor/htlin)\n\n- [Machine Learning for Data Analysis](https://www.coursera.org/learn/machine-learning-data-analysis), Coursera\xe4\xb8\x8aWesleyan\xe5\xa4\xa7\xe5\xad\xa6\xe7\x9a\x84Data Analysis and Interpretation\xe4\xb8\x93\xe9\xa1\xb9\xe8\xaf\xbe\xe7\xa8\x8b\xe7\xac\xac\xe5\x9b\x9b\xe8\xaf\xbe\xe3\x80\x82\n\n- Max Planck Institute for Intelligent Systems T\xc3\xbcbingen[\xe5\xbe\xb7\xe5\x9b\xbd\xe9\xa9\xac\xe6\x99\xae\xe6\x89\x80\xe6\x99\xba\xe8\x83\xbd\xe7\xb3\xbb\xe7\xbb\x9f\xe7\xa0\x94\xe7\xa9\xb6\xe6\x89\x802013\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x9a\x91\xe6\x9c\x9f\xe5\xad\xa6\xe6\xa0\xa1\xe8\xa7\x86\xe9\xa2\x91](https://www.youtube.com/playlist?list=PLqJm7Rc5-EXFv6RXaPZzzlzo93Hl0v91E),\xe4\xbb\x94\xe7\xbb\x86\xe7\xbf\xbb\xe8\xbf\x99\xe4\xb8\xaa\xe9\xa2\x91\xe9\x81\x93\xe8\xbf\x98\xe5\x8f\xaf\xe4\xbb\xa5\xe6\x89\xbe\xe5\x88\xb02015\xe7\x9a\x84\xe6\x9a\x91\xe6\x9c\x9f\xe5\xad\xa6\xe6\xa0\xa1\xe8\xa7\x86\xe9\xa2\x91\n\n- \xe7\x9f\xa5\xe4\xb9\x8eLive\xef\xbc\x9a[\xe6\x88\x91\xe4\xbb\xac\xe4\xb8\x80\xe8\xb5\xb7\xe5\xbc\x80\xe5\xa7\x8b\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x90\xa7](https://www.zhihu.com/lives/792423196996546560)\xef\xbc\x8c[\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x85\xa5\xe9\x97\xa8\xe4\xb9\x8b\xe7\x89\xb9\xe5\xbe\x81\xe5\xb7\xa5\xe7\xa8\x8b](https://www.zhihu.com/lives/819543866939174912)\n\n### \xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0 Machine Learning\n\n- \xe6\x96\xaf\xe5\x9d\xa6\xe7\xa6\x8f\xe5\xa4\xa7\xe5\xad\xa6Feifei Li\xe6\x95\x99\xe6\x8e\x88\xe7\x9a\x84[CS231n\xe7\xb3\xbb\xe5\x88\x97\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe8\xaf\xbe\xe7\xa8\x8b](http://cs231n.stanford.edu/)\xe3\x80\x82Feifei Li\xe7\x9b\xae\xe5\x89\x8d\xe6\x98\xafGoogle\xe7\x9a\x84\xe7\xa7\x91\xe5\xad\xa6\xe5\xae\xb6\xef\xbc\x8c\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe4\xb8\x8e\xe5\x9b\xbe\xe5\x83\x8f\xe8\xaf\x86\xe5\x88\xab\xe6\x96\xb9\xe9\x9d\xa2\xe7\x9a\x84\xe5\xa4\xa7\xe7\x89\x9b\xe3\x80\x82\xe8\xbf\x99\xe9\x97\xa8\xe8\xaf\xbe\xe7\x9a\x84\xe7\xac\x94\xe8\xae\xb0\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x9c\x8b[\xe8\xbf\x99\xe9\x87\x8c](https://zhuanlan.zhihu.com/p/21930884)\xe3\x80\x82\n\n- [CS224n: Natural Language Processing](http://cs224n.stanford.edu). Course instructors: Chris Manning, Richard Socher.\n\n### \xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0 Machine Learning\n\n- [CS 294 Deep Reinforcement Learning, Fall 2017](http://rll.berkeley.edu/deeprlcourse/). Course instructors: Sergey Levine, John Schulman, Chelsea Finn.\n\n- [UCL Course on RL](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html)\n\n- [CS234: Reinforcement Learning](http://web.stanford.edu/class/cs234/index.html). \xe6\x9a\x82\xe6\x97\xa0\xe8\xa7\x86\xe9\xa2\x91\n\n- - -\n\n\n## \xe7\x9b\xb8\xe5\x85\xb3\xe4\xb9\xa6\xe7\xb1\x8d reference book\n\n- [Hands on Machine Learning with Scikit-learn and Tensorflow](https://my.pcloud.com/publink/show?code=XZ9ev77Zk2l6xcMtfIhHm7mRKAYhISb6sl3k)\n\n- \xe5\x85\xa5\xe9\x97\xa8\xe8\xaf\xbb\xe7\x89\xa9 [The Elements of Statistical Learning(\xe8\x8b\xb1\xe6\x96\x87\xe7\xac\xac\xe4\xba\x8c\xe7\x89\x88),The Elements of Statistical Learning.pdf](http://ddl.escience.cn/ff/emZH)\n\n- [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0](https://book.douban.com/subject/26708119/), (@Prof. Zhihua Zhou/\xe5\x91\xa8\xe5\xbf\x97\xe5\x8d\x8e\xe6\x95\x99\xe6\x8e\x88)\n\n- [\xe7\xbb\x9f\xe8\xae\xa1\xe5\xad\xa6\xe4\xb9\xa0\xe6\x96\xb9\xe6\xb3\x95](https://book.douban.com/subject/10590856/), (@Dr. Hang Li/\xe6\x9d\x8e\xe8\x88\xaa\xe5\x8d\x9a\xe5\xa3\xab)\n\n- [\xe4\xb8\x80\xe4\xba\x9bKindle\xe8\xaf\xbb\xe7\x89\xa9](http://ddl.escience.cn/f/IwWE):\n\n\t- \xe5\x88\xa9\xe7\x94\xa8Python\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe6\x9e\x90\n\n\t- \xe8\xb7\x9f\xe8\x80\x81\xe9\xbd\x90\xe5\xad\xa6Python\xef\xbc\x9a\xe4\xbb\x8e\xe5\x85\xa5\xe9\x97\xa8\xe5\x88\xb0\xe7\xb2\xbe\xe9\x80\x9a\n\n\t- Python\xe4\xb8\x8e\xe6\x95\xb0\xe6\x8d\xae\xe6\x8c\x96\xe6\x8e\x98 (\xe5\xa4\xa7\xe6\x95\xb0\xe6\x8d\xae\xe6\x8a\x80\xe6\x9c\xaf\xe4\xb8\x9b\xe4\xb9\xa6) - \xe5\xbc\xa0\xe8\x89\xaf\xe5\x9d\x87\n\n\t- Python\xe5\xad\xa6\xe4\xb9\xa0\xe6\x89\x8b\xe5\x86\x8c\n\n\t- Python\xe6\x80\xa7\xe8\x83\xbd\xe5\x88\x86\xe6\x9e\x90\xe4\xb8\x8e\xe4\xbc\x98\xe5\x8c\x96\n\n\t- Python\xe6\x95\xb0\xe6\x8d\xae\xe6\x8c\x96\xe6\x8e\x98\xe5\x85\xa5\xe9\x97\xa8\xe4\xb8\x8e\xe5\xae\x9e\xe8\xb7\xb5\n\n\t- Python\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe6\x9e\x90\xe4\xb8\x8e\xe6\x8c\x96\xe6\x8e\x98\xe5\xae\x9e\xe6\x88\x98(\xe5\xa4\xa7\xe6\x95\xb0\xe6\x8d\xae\xe6\x8a\x80\xe6\x9c\xaf\xe4\xb8\x9b\xe4\xb9\xa6) - \xe5\xbc\xa0\xe8\x89\xaf\xe5\x9d\x87\n\n\t- Python\xe7\xa7\x91\xe5\xad\xa6\xe8\xae\xa1\xe7\xae\x97(\xe7\xac\xac2\xe7\x89\x88)\n\n\t- Python\xe8\xae\xa1\xe7\xae\x97\xe6\x9c\xba\xe8\xa7\x86\xe8\xa7\x89\xe7\xbc\x96\xe7\xa8\x8b [\xe7\xbe\x8e] Jan Erik Solem\n\n\t- python\xe6\xa0\xb8\xe5\xbf\x83\xe7\xbc\x96\xe7\xa8\x8b(\xe7\xac\xac\xe4\xb8\x89\xe7\x89\x88)\n\n\t- Python\xe6\xa0\xb8\xe5\xbf\x83\xe7\xbc\x96\xe7\xa8\x8b\xef\xbc\x88\xe7\xac\xac\xe4\xba\x8c\xe7\x89\x88\xef\xbc\x89\n\n\t- Python\xe9\xab\x98\xe6\x89\x8b\xe4\xb9\x8b\xe8\xb7\xaf - [\xe6\xb3\x95] \xe6\x9c\xb1\xe5\x88\xa9\xe5\xae\x89\xc2\xb7\xe4\xb8\xb9\xe4\xb9\x94\xef\xbc\x88Julien Danjou\xef\xbc\x89\n\n\t- Python\xe7\xbc\x96\xe7\xa8\x8b\xe5\xbf\xab\xe9\x80\x9f\xe4\xb8\x8a\xe6\x89\x8b \xe8\xae\xa9\xe7\xb9\x81\xe7\x90\x90\xe5\xb7\xa5\xe4\xbd\x9c\xe8\x87\xaa\xe5\x8a\xa8\xe5\x8c\x96\n\n\t- Python\xe7\xbc\x96\xe7\xa8\x8b\xef\xbc\x9a\xe4\xbb\x8e\xe5\x85\xa5\xe9\x97\xa8\xe5\x88\xb0\xe5\xae\x9e\xe8\xb7\xb5\n\n\t- Python3 CookBook\xe4\xb8\xad\xe6\x96\x87\xe7\x89\x88\n\n\t- \xe7\xbb\x88\xe6\x9e\x81\xe7\xae\x97\xe6\xb3\x95\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x92\x8c\xe4\xba\xba\xe5\xb7\xa5\xe6\x99\xba\xe8\x83\xbd\xe5\xa6\x82\xe4\xbd\x95\xe9\x87\x8d\xe5\xa1\x91\xe4\xb8\x96\xe7\x95\x8c - [\xe7\xbe\x8e ]\xe4\xbd\xa9\xe5\xbe\xb7\xe7\xbd\x97\xc2\xb7\xe5\xa4\x9a\xe6\x98\x8e\xe6\x88\x88\xe6\x96\xaf\n\n\t- \xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xb3\xbb\xe7\xbb\x9f\xe8\xae\xbe\xe8\xae\xa1 (\xe5\x9b\xbe\xe7\x81\xb5\xe7\xa8\x8b\xe5\xba\x8f\xe8\xae\xbe\xe8\xae\xa1\xe4\xb8\x9b\xe4\xb9\xa6) - [\xe7\xbe\x8e]Willi Richert &amp; Luis Pedro Coelho\n\n\t- \xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xae\x9e\xe8\xb7\xb5\xe6\x8c\x87\xe5\x8d\x97\xef\xbc\x9a\xe6\xa1\x88\xe4\xbe\x8b\xe5\xba\x94\xe7\x94\xa8\xe8\xa7\xa3\xe6\x9e\x90\xef\xbc\x88\xe7\xac\xac2\xe7\x89\x88\xef\xbc\x89 (\xe5\xa4\xa7\xe6\x95\xb0\xe6\x8d\xae\xe6\x8a\x80\xe6\x9c\xaf\xe4\xb8\x9b\xe4\xb9\xa6) - \xe9\xba\xa6\xe5\xa5\xbd\n\n\t- \xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xae\x9e\xe8\xb7\xb5 \xe6\xb5\x8b\xe8\xaf\x95\xe9\xa9\xb1\xe5\x8a\xa8\xe7\x9a\x84\xe5\xbc\x80\xe5\x8f\x91\xe6\x96\xb9\xe6\xb3\x95 (\xe5\x9b\xbe\xe7\x81\xb5\xe7\xa8\x8b\xe5\xba\x8f\xe8\xae\xbe\xe8\xae\xa1\xe4\xb8\x9b\xe4\xb9\xa6) - [\xe7\xbe\x8e] \xe6\x9f\xaf\xe5\x85\x8b\xef\xbc\x88Matthew Kirk\xef\xbc\x89\n\n\t- \xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x9a\xe5\xae\x9e\xe7\x94\xa8\xe6\xa1\x88\xe4\xbe\x8b\xe8\xa7\xa3\xe6\x9e\x90\n  \n\n- [\xe6\x95\xb0\xe5\xad\xa6](https://mega.nz/#F!WVAlGL6B!mqIjYoTjiQnO4jBGVLRIWA\n):\n\n    - Algebra - Michael Artin\n\n    - Algebra - Serge Lang\n\n    - Basic Topology - M.A. Armstrong\n\n    - Convex Optimization by Stephen Boyd & Lieven Vandenberghe\n\n    - Functional Analysis by Walter Rudin\n\n    - Functional Analysis, Sobolev Spaces and Partial Differential Equations by Haim Brezis\n\n    - Graph Theory - J.A. Bondy, U.S.R. Murty\n\n    - Graph Theory - Reinhard Diestel\n\n    - Inside Interesting Integrals - Pual J. Nahin\n\n    - Linear Algebra and Its Applications - Gilbert Strang\n\n    - Linear and Nonlinear Functional Analysis with Applications - Philippe G. Ciarlet\n\n    - Mathematical Analysis I - Vladimir A. Zorich\n\n    - Mathematical Analysis II - Vladimir A. Zorich\n\n    - Mathematics for Computer Science - Eric Lehman, F Thomson Leighton, Alber R Meyer\n\n    - Matrix Cookbook, The - Kaare Brandt Petersen, Michael Syskind Pedersen\n\n    - Measures, Integrals and Martingales - Rene\xcc\x81 L. Schilling\n\n    - Principles of Mathematical Analysis - Walter Rudin\n\n    - Probabilistic Graphical Models: Principles and Techniques - Daphne Koller, Nir Friedman\n\n    - Probability: Theory and Examples - Rick Durrett\n\n    - Real and Complex Analysis - Walter Rudin\n\n    - Thomas' Calculus - George B. Thomas\n\n    - \xe6\x99\xae\xe6\x9e\x97\xe6\x96\xaf\xe9\xa1\xbf\xe5\xbe\xae\xe7\xa7\xaf\xe5\x88\x86\xe8\xaf\xbb\xe6\x9c\xac - Adrian Banner\n\n\n- [Packt\xe6\xaf\x8f\xe6\x97\xa5\xe9\x99\x90\xe5\x85\x8d\xe7\x94\xb5\xe5\xad\x90\xe4\xb9\xa6\xe7\xb2\xbe\xe9\x80\x89](http://ddl.escience.cn/f/IS4a):\n\n\t- Learning Data Mining with Python\n\n\t- Matplotlib for python developers\n\n\t- Machine Learing with Spark\n\n\t- Mastering R for Quantitative Finance\n\n\t- Mastering matplotlib\n\n\t- Neural Network Programming with Java\n\n\t- Python Machine Learning\n\n\t- R Data Visualization Cookbook\n\n\t- R Deep Learning Essentials\n\n\t- R Graphs Cookbook second edition\n\n\t- D3.js By Example \n\n\t- Data Analysis With R\n\n\t- Java Deep Learning Essentials\n\n\t- Learning Bayesian Models with R\n\n\t- Learning Pandas\n\n\t- Python Parallel Programming Cookbook\n\n\t- Machine Learning with R\n\n---\n\n\n## \xe5\x85\xb6\xe4\xbb\x96 Miscellaneous\n\n- [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x97\xa5\xe6\x8a\xa5](http://forum.ai100.com.cn/)\xef\xbc\x9a\xe6\xaf\x8f\xe5\xa4\xa9\xe6\x9b\xb4\xe6\x96\xb0\xe5\xad\xa6\xe6\x9c\xaf\xe5\x92\x8c\xe5\xb7\xa5\xe4\xb8\x9a\xe7\x95\x8c\xe6\x9c\x80\xe6\x96\xb0\xe7\x9a\x84\xe7\xa0\x94\xe7\xa9\xb6\xe6\x88\x90\xe6\x9e\x9c\n\n- [\xe6\x9c\xba\xe5\x99\xa8\xe4\xb9\x8b\xe5\xbf\x83](https://www.jiqizhixin.com/)\n\n- [\xe9\x9b\x86\xe6\x99\xba\xe7\xa4\xbe\xe5\x8c\xba](https://jizhi.im/index)\n\n- - -\n\n\n## \xe5\xa6\x82\xe4\xbd\x95\xe5\x8a\xa0\xe5\x85\xa5 How to contribute\n\n\xe5\xa6\x82\xe6\x9e\x9c\xe4\xbd\xa0\xe5\xaf\xb9\xe6\x9c\xac\xe9\xa1\xb9\xe7\x9b\xae\xe6\x84\x9f\xe5\x85\xb4\xe8\xb6\xa3\xef\xbc\x8c\xe9\x9d\x9e\xe5\xb8\xb8\xe6\xac\xa2\xe8\xbf\x8e\xe4\xbd\xa0\xe5\x8a\xa0\xe5\x85\xa5\xef\xbc\x81\n\n- \xe6\xad\xa3\xe5\xb8\xb8\xe5\x8f\x82\xe4\xb8\x8e\xef\xbc\x9a\xe8\xaf\xb7\xe7\x9b\xb4\xe6\x8e\xa5fork\xe3\x80\x81pull\xe9\x83\xbd\xe5\x8f\xaf\xe4\xbb\xa5\n- \xe5\xa6\x82\xe6\x9e\x9c\xe8\xa6\x81\xe4\xb8\x8a\xe4\xbc\xa0\xe6\x96\x87\xe4\xbb\xb6\xef\xbc\x9a\xe8\xaf\xb7**\xe4\xb8\x8d\xe8\xa6\x81**\xe7\x9b\xb4\xe6\x8e\xa5\xe4\xb8\x8a\xe4\xbc\xa0\xe5\x88\xb0\xe9\xa1\xb9\xe7\x9b\xae\xe4\xb8\xad\xef\xbc\x8c\xe5\x90\xa6\xe5\x88\x99\xe4\xbc\x9a\xe9\x80\xa0\xe6\x88\x90git\xe7\x89\x88\xe6\x9c\xac\xe5\xba\x93\xe8\xbf\x87\xe5\xa4\xa7\xe3\x80\x82\xe6\xad\xa3\xe7\xa1\xae\xe7\x9a\x84\xe6\x96\xb9\xe6\xb3\x95\xe6\x98\xaf\xe4\xb8\x8a\xe4\xbc\xa0\xe5\xae\x83\xe7\x9a\x84**\xe8\xb6\x85\xe9\x93\xbe\xe6\x8e\xa5**\xe3\x80\x82\xe5\xa6\x82\xe6\x9e\x9c\xe4\xbd\xa0\xe8\xa6\x81\xe4\xb8\x8a\xe4\xbc\xa0\xe7\x9a\x84\xe6\x96\x87\xe4\xbb\xb6\xe6\x9c\xac\xe8\xba\xab\xe5\xb0\xb1\xe5\x9c\xa8\xe7\xbd\x91\xe7\xbb\x9c\xe4\xb8\xad\xef\xbc\x88\xe5\xa6\x82paper\xe9\x83\xbd\xe4\xbc\x9a\xe6\x9c\x89\xe9\x93\xbe\xe6\x8e\xa5\xef\xbc\x89\xef\xbc\x8c\xe7\x9b\xb4\xe6\x8e\xa5\xe4\xb8\x8a\xe4\xbc\xa0\xe5\x8d\xb3\xe5\x8f\xaf\xef\xbc\x9b\xe5\xa6\x82\xe6\x9e\x9c\xe6\x98\xaf\xe8\x87\xaa\xe5\xb7\xb1\xe6\x83\xb3\xe5\x88\x86\xe4\xba\xab\xe7\x9a\x84\xe4\xb8\x80\xe4\xba\x9b\xe6\x96\x87\xe4\xbb\xb6\xe3\x80\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\xad\x89\xef\xbc\x8c\xe9\x89\xb4\xe4\xba\x8e\xe5\x9b\xbd\xe5\x86\x85\xe7\xbd\x91\xe7\x9b\x98\xe7\x9a\x84\xe6\x83\x85\xe5\x86\xb5\xef\xbc\x8c\xe8\xaf\xb7\xe6\x8c\x89\xe7\x85\xa7\xe5\xa6\x82\xe4\xb8\x8b\xe6\x96\xb9\xe5\xbc\x8f\xe4\xb8\x8a\xe4\xbc\xa0\xef\xbc\x9a\n\t- (\xe5\xa2\x99\xe5\x86\x85)\xe7\x9b\xae\xe5\x89\x8d\xe6\xb2\xa1\xe6\x9c\x89\xe6\x89\xbe\xe5\x88\xb0\xe6\xaf\x94\xe8\xbe\x83\xe5\xa5\xbd\xe7\x9a\x84\xe6\x96\xb9\xe5\xbc\x8f\xef\xbc\x8c\xe5\x8f\xaa\xe8\x83\xbd\xe9\x80\x9a\xe8\xbf\x87\xe9\x93\xbe\xe6\x8e\xa5\xef\xbc\x8c\xe6\x88\x96\xe8\x80\x85\xe8\x87\xaa\xe5\xb7\xb1\xe7\xbd\x91\xe7\x9b\x98\xe7\x9a\x84\xe9\x93\xbe\xe6\x8e\xa5\xe6\x9d\xa5\xe5\x81\x9a\xe3\x80\x82\n\t- (\xe5\xa2\x99\xe5\xa4\x96)\xe9\xa6\x96\xe5\x85\x88\xe5\x9c\xa8[UPLOAD](https://my.pcloud.com/#page=puplink&code=4e9Z0Vwpmfzvx0y2OqTTTMzkrRUz8q9V)\xe7\x9b\xb4\xe6\x8e\xa5\xe4\xb8\x8a\xe4\xbc\xa0\xef\xbc\x88**\xe4\xb8\x8d**\xe9\x9c\x80\xe8\xa6\x81\xe6\xb3\xa8\xe5\x86\x8c\xe8\xb4\xa6\xe5\x8f\xb7\xef\xbc\x89\xef\xbc\x9b\xe4\xb8\x8a\xe4\xbc\xa0\xe6\x88\x90\xe5\x8a\x9f\xe5\x90\x8e\xef\xbc\x8c\xe5\x9c\xa8[DOWNLOAD](https://my.pcloud.com/publink/show?code=kZWtboZbDDVguCHGV49QkmlLliNPJRMHrFX)\xe9\x87\x8c\xe6\x89\xbe\xe5\x88\xb0\xe4\xbd\xa0\xe5\x88\x9a\xe4\xb8\x8a\xe4\xbc\xa0\xe7\x9a\x84\xe6\x96\x87\xe4\xbb\xb6\xef\xbc\x8c\xe5\x85\xb1\xe4\xba\xab\xe9\x93\xbe\xe6\x8e\xa5\xe5\x8d\xb3\xe5\x8f\xaf\xe3\x80\x82\n\n\n\n## \xe5\xa6\x82\xe4\xbd\x95\xe5\xbc\x80\xe5\xa7\x8b\xe9\xa1\xb9\xe7\x9b\xae\xe5\x8d\x8f\xe5\x90\x8c\xe5\x90\x88\xe4\xbd\x9c\n\n[\xe5\xbf\xab\xe9\x80\x9f\xe4\xba\x86\xe8\xa7\xa3github\xe5\x8d\x8f\xe5\x90\x8c\xe5\xb7\xa5\xe4\xbd\x9c](http://hucaihua.cn/2016/12/02/github_cooperation/)\n\n[\xe5\x8f\x8a\xe6\x97\xb6\xe6\x9b\xb4\xe6\x96\xb0fork\xe9\xa1\xb9\xe7\x9b\xae](https://jinlong.github.io/2015/10/12/syncing-a-fork/)\n\n\n#### [\xe8\xb4\xa1\xe7\x8c\xae\xe8\x80\x85 Contributors](https://github.com/allmachinelearning/MachineLearning/blob/master/contributors.md)\n\n\n\n\n\n\n\n\n\n\n"""
19,Yorko/mlcourse.ai,Yorko,Open Machine Learning Course,2017-02-27 08:32:20,2020-06-18 09:06:02,Python,4606,6961,"b'<div align=""center"">\n\n![ODS stickers](https://github.com/Yorko/mlcourse.ai/blob/master/img/ods_stickers.jpg)\n\n**[mlcourse.ai](https://mlcourse.ai) \xe2\x80\x93 Open Machine Learning Course**\n\n[![License: CC BY-NC-SA 4.0](https://img.shields.io/badge/license-CC%20BY--NC--SA%204.0-green)](https://creativecommons.org/licenses/by-nc-sa/4.0/)\n[![Slack](https://img.shields.io/badge/slack-ods.ai-orange)](https://opendatascience.slack.com/archives/C91N8TL83/p1567408586359500)\n[![Donate](https://img.shields.io/badge/support-patreon-red)](https://www.patreon.com/ods_mlcourse)\n[![Donate](https://img.shields.io/badge/support-ko--fi-red)](https://ko-fi.com/mlcourse_ai)\n\n\n</div>\n  \n[mlcourse.ai](https://mlcourse.ai) is an open Machine Learning course by [OpenDataScience](https://ods.ai). The course is designed to perfectly balance theory and practice. You can take part in several Kaggle Inclass competitions held during the course. From spring 2017 to fall 2019, 6 sessions of mlcourse.ai took place - 26k participants applied, 10k converted to passing the first assignment, about 1500 participants finished the course. Currently, the course is in self-paced mode. Check out a thorough [Roadmap](https://mlcourse.ai/roadmap) guiding you through the self-paced mlcourse.ai.\n\nMirrors (:uk:-only): [mlcourse.ai](https://mlcourse.ai) (main site), [Kaggle Dataset](https://www.kaggle.com/kashnitsky/mlcourse) (same notebooks as Kaggle Notebooks)\n\n### Self-paced passing\nThe [Roadmap](https://mlcourse.ai/roadmap) will guide you through 11 weeks of mlcourse.ai. For each week, from Pandas to Gradient Boosting, instructions are given on what artciles to read, lectures to watch, what assignments to accomplish. \n\n### Articles\nThis is the list of published articles on medium.com [:uk:](https://medium.com/open-machine-learning-course), habr.com [:ru:](https://habr.com/company/ods/blog/344044/). Also notebooks in Chinese are mentioned :cn: and links to Kaggle Notebooks (in English) are given. Icons are clickable.\n\n1. Exploratory Data Analysis with Pandas [:uk:](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-1-exploratory-data-analysis-with-pandas-de57880f1a68)  [:ru:](https://habrahabr.ru/company/ods/blog/322626/) [:cn:](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/master/jupyter_chinese/topic01-%E4%BD%BF%E7%94%A8-Pandas-%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2.ipynb), [Kaggle Notebook](https://www.kaggle.com/kashnitsky/topic-1-exploratory-data-analysis-with-pandas)\n2. Visual Data Analysis with Python [:uk:](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-2-visual-data-analysis-in-python-846b989675cd)  [:ru:](https://habrahabr.ru/company/ods/blog/323210/) [:cn:](http://nbviewer.ipython.org/urls/raw.github.com/Yorko/mlcourse.ai/master/jupyter_chinese/topic02-Python-%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E5%88%86%E6%9E%90.ipynb), Kaggle Notebooks: [part1](https://www.kaggle.com/kashnitsky/topic-2-visual-data-analysis-in-python), [part2](https://www.kaggle.com/kashnitsky/topic-2-part-2-seaborn-and-plotly)\n3. Classification, Decision Trees and k Nearest Neighbors [:uk:](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-3-classification-decision-trees-and-k-nearest-neighbors-8613c6b6d2cd) [:ru:](https://habrahabr.ru/company/ods/blog/322534/) [:cn:](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/master/jupyter_chinese/topic03-%E5%86%B3%E7%AD%96%E6%A0%91%E5%92%8C-K-%E8%BF%91%E9%82%BB%E5%88%86%E7%B1%BB.ipynb), [Kaggle Notebook](https://www.kaggle.com/kashnitsky/topic-3-decision-trees-and-knn)\n4. Linear Classification and Regression [:uk:](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-4-linear-classification-and-regression-44a41b9b5220) [:ru:](https://habrahabr.ru/company/ods/blog/323890/) [:cn:](http://nbviewer.ipython.org/urls/raw.github.com/Yorko/mlcourse.ai/master/jupyter_chinese/topic04-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%92%8C%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB%E5%99%A8.ipynb), Kaggle Notebooks: [part1](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-1-ols), [part2](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-2-classification), [part3](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-3-regularization), [part4](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-4-more-of-logit), [part5](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-5-validation)\n5. Bagging and Random Forest [:uk:](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-5-ensembles-of-algorithms-and-random-forest-8e05246cbba7) [:ru:](https://habrahabr.ru/company/ods/blog/324402/) [:cn:](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/master/jupyter_chinese/topic05-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E5%92%8C%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E6%96%B9%E6%B3%95.ipynb), Kaggle Notebooks: [part1](https://www.kaggle.com/kashnitsky/topic-5-ensembles-part-1-bagging), [part2](https://www.kaggle.com/kashnitsky/topic-5-ensembles-part-2-random-forest), [part3](https://www.kaggle.com/kashnitsky/topic-5-ensembles-part-3-feature-importance)\n6. Feature Engineering and Feature Selection [:uk:](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-6-feature-engineering-and-feature-selection-8b94f870706a) [:ru:](https://habrahabr.ru/company/ods/blog/325422/) [:cn:](http://nbviewer.ipython.org/urls/raw.github.com/Yorko/mlcourse.ai/master/jupyter_chinese/topic06-%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E5%92%8C%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9.ipynb), [Kaggle Notebook](https://www.kaggle.com/kashnitsky/topic-6-feature-engineering-and-feature-selection)\n7. Unsupervised Learning: Principal Component Analysis and Clustering [:uk:](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-7-unsupervised-learning-pca-and-clustering-db7879568417) [:ru:](https://habrahabr.ru/company/ods/blog/325654/) [:cn:](http://nbviewer.ipython.org/urls/raw.github.com/Yorko/mlcourse.ai/master/jupyter_chinese/topic07-%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90%E5%92%8C%E8%81%9A%E7%B1%BB.ipynb), [Kaggle Notebook](https://www.kaggle.com/kashnitsky/topic-7-unsupervised-learning-pca-and-clustering)\n8. Vowpal Wabbit: Learning with Gigabytes of Data [:uk:](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-8-vowpal-wabbit-fast-learning-with-gigabytes-of-data-60f750086237) [:ru:](https://habrahabr.ru/company/ods/blog/326418/) [:cn:](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/master/jupyter_chinese/topic08-%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%92%8C%E7%8B%AC%E7%83%AD%E7%BC%96%E7%A0%81.ipynb), [Kaggle Notebook](https://www.kaggle.com/kashnitsky/topic-8-online-learning-and-vowpal-wabbit)\n9. Time Series Analysis with Python, part 1 [:uk:](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-9-time-series-analysis-in-python-a270cb05e0b3) [:ru:](https://habrahabr.ru/company/ods/blog/327242/) [:cn:](http://nbviewer.ipython.org/urls/raw.github.com/Yorko/mlcourse.ai/master/jupyter_chinese/topic09-%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%A4%84%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8.ipynb). Predicting future with Facebook Prophet, part 2 [:uk:](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-9-part-3-predicting-the-future-with-facebook-prophet-3f3af145cdc), [:cn:](http://nbviewer.ipython.org/urls/raw.github.com/Yorko/mlcourse.ai/master/jupyter_chinese/topic09-%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%A4%84%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8.ipynb) Kaggle Notebooks: [part1](https://www.kaggle.com/kashnitsky/topic-9-part-1-time-series-analysis-in-python), [part2](https://www.kaggle.com/kashnitsky/topic-9-part-2-time-series-with-facebook-prophet)\n10. Gradient Boosting [:uk:](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-10-gradient-boosting-c751538131ac) [:ru:](https://habrahabr.ru/company/ods/blog/327250/), [:cn:](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/master/jupyter_chinese/topic05-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E5%92%8C%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E6%96%B9%E6%B3%95.ipynb), [Kaggle Notebook](https://www.kaggle.com/kashnitsky/topic-10-gradient-boosting)\n\n### Lectures\nVideolectures are uploaded to [this](https://bit.ly/2zY6Xe2) YouTube playlist.\nIntroduction, [video](https://www.youtube.com/watch?v=DrohHdQa8u8), [slides](https://www.slideshare.net/festline/mlcourseai-fall2019-live-session-0)\n\n1. Exploratory data analysis with Pandas, [video](https://youtu.be/fwWCw_cE5aI)\n2. Visualization, main plots for EDA, [video](https://www.youtube.com/watch?v=WNoQTNOME5g)\n3. Decision trees: [theory](https://youtu.be/H4XlBTPv5rQ) and [practical part](https://youtu.be/RrVYO6Td9Js)\n4. Logistic regression: [theoretical foundations](https://www.youtube.com/watch?v=l3jiw-N544s), [practical part](https://www.youtube.com/watch?v=7o0SWgY89i8) (baselines in the ""Alice"" competition)\n5. Ensembles and Random Forest \xe2\x80\x93 [part 1](https://www.youtube.com/watch?v=neXJL-AqI_c). Classification metrics \xe2\x80\x93 [part 2](https://www.youtube.com/watch?v=aBOMYqGUlWQ). Example of a business task, predicting a customer payment \xe2\x80\x93 [part 3](https://www.youtube.com/watch?v=FmKU-1LZGoE) \n6. Linear regression and regularization - [theory](https://youtu.be/ne-MfRfYs_c), LASSO & Ridge, LTV prediction - [practice](https://youtu.be/B8yIaIEMyIc)\n7. Unsupervised learning - [Principal Component Analysis](https://youtu.be/-AswHf7h0I4) and [Clustering](https://youtu.be/eVplCo-w4XE)\n8. Stochastic Gradient Descent for classification and regression - [part 1](https://youtu.be/EUSXbdzaQE8), part 2 TBA\n9. Time series analysis with Python (ARIMA, Prophet) - [video](https://youtu.be/_9lBwXnbOd8)\n10. Gradient boosting: basic ideas - [part 1](https://youtu.be/g0ZOtzZqdqk), key ideas behind Xgboost, LightGBM, and CatBoost + practice - [part 2](https://youtu.be/V5158Oug4W8)\n\n### Assignments\n\n1. Exploratory data analysis with Pandas, [nbviewer](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/master/jupyter_english/assignments_demo/assignment01_pandas_uci_adult.ipynb?flush_cache=true), [Kaggle Notebook](https://www.kaggle.com/kashnitsky/assignment-1-pandas-and-uci-adult-dataset), [solution](https://www.kaggle.com/kashnitsky/a1-demo-pandas-and-uci-adult-dataset-solution)\n2. Analyzing cardiovascular disease data, [nbviewer](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/master/jupyter_english/assignments_demo/assignment02_analyzing_cardiovascular_desease_data.ipynb?flush_cache=true), [Kaggle Notebook](https://www.kaggle.com/kashnitsky/assignment-2-analyzing-cardiovascular-data), [solution](https://www.kaggle.com/kashnitsky/a2-demo-analyzing-cardiovascular-data-solution)\n3. Decision trees with a toy task and the UCI Adult dataset, [nbviewer](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/master/jupyter_english/assignments_demo/assignment03_decision_trees.ipynb?flush_cache=true), [Kaggle Notebook](https://www.kaggle.com/kashnitsky/assignment-3-decision-trees), [solution](https://www.kaggle.com/kashnitsky/a3-demo-decision-trees-solution)\n4. Sarcasm detection, [Kaggle Notebook](https://www.kaggle.com/kashnitsky/a4-demo-sarcasm-detection-with-logit), [solution](https://www.kaggle.com/kashnitsky/a4-demo-sarcasm-detection-with-logit-solution). Linear Regression as an optimization problem, [nbviewer](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/master/jupyter_english/assignments_demo/assignment04_linreg_optimization.ipynb?flush_cache=true), [Kaggle Notebook](https://www.kaggle.com/kashnitsky/assignment-4-linear-regression-as-optimization)\n5. Logistic Regression and Random Forest in the credit scoring problem, [nbviewer](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/master/jupyter_english/assignments_demo/assignment05_logit_rf_credit_scoring.ipynb?flush_cache=true), [Kaggle Notebook](https://www.kaggle.com/kashnitsky/assignment-5-logit-and-rf-for-credit-scoring), [solution](https://www.kaggle.com/kashnitsky/a5-demo-logit-and-rf-for-credit-scoring-sol)\n6. Exploring OLS, Lasso and Random Forest in a regression task, [nbviewer](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/master/jupyter_english/assignments_demo/assignment06_regression_wine.ipynb?flush_cache=true), [Kaggle Notebook](https://www.kaggle.com/kashnitsky/assignment-6-linear-models-and-rf-for-regression), [solution](https://www.kaggle.com/kashnitsky/a6-demo-regression-solution)\n7. Unsupervised learning, [nbviewer](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/master/jupyter_english/assignments_demo/assignment07_unsupervised_learning.ipynb?flush_cache=true), [Kaggle Notebook](https://www.kaggle.com/kashnitsky/assignment-7-unupervised-learning), [solution](https://www.kaggle.com/kashnitsky/a7-demo-unsupervised-learning-solution)\n8. Implementing online regressor, [nbviewer](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/master/jupyter_english/assignments_demo/assignment08_implement_sgd_regressor.ipynb?flush_cache=true), [Kaggle Notebook](https://www.kaggle.com/kashnitsky/assignment-8-implementing-online-regressor), [solution](https://www.kaggle.com/kashnitsky/a8-demo-implementing-online-regressor-solution)\n9. Time series analysis, [nbviewer](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/master/jupyter_english/assignments_demo/assignment09_time_series.ipynb?flush_cache=true), [Kaggle Notebook](https://www.kaggle.com/kashnitsky/assignment-9-time-series-analysis), [solution](https://www.kaggle.com/kashnitsky/a9-demo-time-series-analysis-solution)\n10. Beating baseline in a competition, [Kaggle Notebook](https://www.kaggle.com/kashnitsky/assignment-10-gradient-boosting-and-flight-delays)\n\n### Kaggle competitions\n1. Catch Me If You Can: Intruder Detection through Webpage Session Tracking. [Kaggle Inclass](https://www.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2)\n2. DotA 2 winner prediction. [Kaggle Inclass](https://www.kaggle.com/c/mlcourse-dota2-win-prediction)\n\n### Community\nDiscussions are held in the **#mlcourse_ai** channel of the [OpenDataScience (ods.ai)](https://ods.ai) Slack team.\n\n*The course is free but you can support organizers by making a pledge on [Patreon](https://www.patreon.com/ods_mlcourse) (monthly support) or a one-time payment on [Ko-fi](https://ko-fi.com/mlcourse_ai). Thus you\'ll foster the spread of Machine Learning in the world!*\n\n[![Donate](https://img.shields.io/badge/support-patreon-red)](https://www.patreon.com/ods_mlcourse)\n[![Donate](https://img.shields.io/badge/support-ko--fi-red)](https://ko-fi.com/mlcourse_ai)\n'"
20,tensorflow/tensorflow,tensorflow,An Open Source Machine Learning Framework for Everyone,2015-11-07 01:19:20,2020-06-18 21:01:24,C++,81682,145652,"b'<div align=""center"">\n  <img src=""https://www.tensorflow.org/images/tf_logo_social.png"">\n</div>\n\n[![Python](https://img.shields.io/pypi/pyversions/tensorflow.svg?style=plastic)](https://badge.fury.io/py/tensorflow)\n[![PyPI](https://badge.fury.io/py/tensorflow.svg)](https://badge.fury.io/py/tensorflow)\n\n\n**`Documentation`** |\n------------------- |\n[![Documentation](https://img.shields.io/badge/api-reference-blue.svg)](https://www.tensorflow.org/api_docs/) |\n\n[TensorFlow](https://www.tensorflow.org/) is an end-to-end open source platform\nfor machine learning. It has a comprehensive, flexible ecosystem of\n[tools](https://www.tensorflow.org/resources/tools),\n[libraries](https://www.tensorflow.org/resources/libraries-extensions), and\n[community](https://www.tensorflow.org/community) resources that lets\nresearchers push the state-of-the-art in ML and developers easily build and\ndeploy ML-powered applications.\n\nTensorFlow was originally developed by researchers and engineers working on the\nGoogle Brain team within Google\'s Machine Intelligence Research organization to\nconduct machine learning and deep neural networks research. The system is\ngeneral enough to be applicable in a wide variety of other domains, as well.\n\nTensorFlow provides stable [Python](https://www.tensorflow.org/api_docs/python)\nand [C++](https://www.tensorflow.org/api_docs/cc) APIs, as well as\nnon-guaranteed backward compatible API for\n[other languages](https://www.tensorflow.org/api_docs).\n\nKeep up-to-date with release announcements and security updates by subscribing\nto\n[announce@tensorflow.org](https://groups.google.com/a/tensorflow.org/forum/#!forum/announce).\nSee all the [mailing lists](https://www.tensorflow.org/community/forums).\n\n## Install\n\nSee the [TensorFlow install guide](https://www.tensorflow.org/install) for the\n[pip package](https://www.tensorflow.org/install/pip), to\n[enable GPU support](https://www.tensorflow.org/install/gpu), use a\n[Docker container](https://www.tensorflow.org/install/docker), and\n[build from source](https://www.tensorflow.org/install/source).\n\nTo install the current release, which includes support for\n[CUDA-enabled GPU cards](https://www.tensorflow.org/install/gpu) *(Ubuntu and\nWindows)*:\n\n```\n$ pip install tensorflow\n```\n\nA smaller CPU-only package is also available:\n\n```\n$ pip install tensorflow-cpu\n```\n\nTo update TensorFlow to the latest version, add `--upgrade` flag to the above\ncommands.\n\n*Nightly binaries are available for testing using the\n[tf-nightly](https://pypi.python.org/pypi/tf-nightly) and\n[tf-nightly-cpu](https://pypi.python.org/pypi/tf-nightly-cpu) packages on PyPi.*\n#### *Try your first TensorFlow program*\n\n```shell\n$ python\n```\n\n```python\n>>> import tensorflow as tf\n>>> tf.add(1, 2).numpy()\n3\n>>> hello = tf.constant(\'Hello, TensorFlow!\')\n>>> hello.numpy()\nb\'Hello, TensorFlow!\'\n```\n\nFor more examples, see the\n[TensorFlow tutorials](https://www.tensorflow.org/tutorials/).\n\n## Contribution guidelines\n\n**If you want to contribute to TensorFlow, be sure to review the\n[contribution guidelines](CONTRIBUTING.md). This project adheres to TensorFlow\'s\n[code of conduct](CODE_OF_CONDUCT.md). By participating, you are expected to\nuphold this code.**\n\n**We use [GitHub issues](https://github.com/tensorflow/tensorflow/issues) for\ntracking requests and bugs, please see\n[TensorFlow Discuss](https://groups.google.com/a/tensorflow.org/forum/#!forum/discuss)\nfor general questions and discussion, and please direct specific questions to\n[Stack Overflow](https://stackoverflow.com/questions/tagged/tensorflow).**\n\nThe TensorFlow project strives to abide by generally accepted best practices in\nopen-source software development:\n\n[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/tensorflow.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:tensorflow)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/1486/badge)](https://bestpractices.coreinfrastructure.org/projects/1486)\n[![Contributor Covenant](https://img.shields.io/badge/Contributor%20Covenant-v1.4%20adopted-ff69b4.svg)](CODE_OF_CONDUCT.md)\n\n## Continuous build status\n\n### Official Builds\n\nBuild Type               | Status                                                                                                                                                                           | Artifacts\n------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------\n**Linux CPU**            | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/ubuntu-cc.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/ubuntu-cc.html)           | [PyPI](https://pypi.org/project/tf-nightly/)\n**Linux GPU**            | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/ubuntu-gpu-py3.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/ubuntu-gpu-py3.html) | [PyPI](https://pypi.org/project/tf-nightly-gpu/)\n**Linux XLA**            | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/ubuntu-xla.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/ubuntu-xla.html)         | TBA\n**macOS**                | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/macos-py2-cc.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/macos-py2-cc.html)     | [PyPI](https://pypi.org/project/tf-nightly/)\n**Windows CPU**          | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/windows-cpu.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/windows-cpu.html)       | [PyPI](https://pypi.org/project/tf-nightly/)\n**Windows GPU**          | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/windows-gpu.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/windows-gpu.html)       | [PyPI](https://pypi.org/project/tf-nightly-gpu/)\n**Android**              | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/android.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/android.html)               | [![Download](https://api.bintray.com/packages/google/tensorflow/tensorflow/images/download.svg)](https://bintray.com/google/tensorflow/tensorflow/_latestVersion)\n**Raspberry Pi 0 and 1** | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/rpi01-py3.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/rpi01-py3.html)           | [Py3](https://storage.googleapis.com/tensorflow-nightly/tensorflow-1.10.0-cp34-none-linux_armv6l.whl)\n**Raspberry Pi 2 and 3** | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/rpi23-py3.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/rpi23-py3.html)           | [Py3](https://storage.googleapis.com/tensorflow-nightly/tensorflow-1.10.0-cp34-none-linux_armv7l.whl)\n**Libtensorflow MacOS CPU** | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/libtensorflow-mac-cpu.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/libtensorflow-mac-cpu.html)           | [GCS](https://storage.googleapis.com/libtensorflow-nightly)\n**Libtensorflow Linux CPU** | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/libtensorflow-linux-cpu.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/libtensorflow-linux-cpu.html)           | [GCS](https://storage.googleapis.com/libtensorflow-nightly)\n**Libtensorflow Linux GPU** | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/libtensorflow-linux-gpu.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/libtensorflow-linux-gpu.html)           | [GCS](https://storage.googleapis.com/libtensorflow-nightly)\n**Libtensorflow Windows CPU** | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/libtensorflow-win-cpu.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/libtensorflow-win-cpu.html)           | [GCS](https://storage.googleapis.com/libtensorflow-nightly)\n**Libtensorflow Windows GPU** | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/libtensorflow-win-gpu.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/libtensorflow-win-gpu.html)           | [GCS](https://storage.googleapis.com/libtensorflow-nightly)\n\n\n### Community Supported Builds\n\nBuild Type                                                        | Status                                                                                                                                                                                        | Artifacts\n----------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------\n**Linux AMD ROCm GPU** Nightly                                    | [![Build Status](http://ml-ci.amd.com:21096/job/tensorflow-rocm-nightly/badge/icon)](http://ml-ci.amd.com:21096/job/tensorflow-rocm-nightly)                                                  | [Nightly](http://ml-ci.amd.com:21096/job/tensorflow-rocm-nightly/lastSuccessfulBuild/)\n**Linux AMD ROCm GPU** Stable Release                             | [![Build Status](http://ml-ci.amd.com:21096/job/tensorflow-rocm-release/badge/icon)](http://ml-ci.amd.com:21096/job/tensorflow-rocm-release/)                                                 | Release [1.15](http://ml-ci.amd.com:21096/job/tensorflow-rocm-release/lastSuccessfulBuild/) / [2.x](http://ml-ci.amd.com:21096/job/tensorflow-rocm-v2-release/lastSuccessfulBuild/)\n**Linux s390x** Nightly                                           | [![Build Status](http://ibmz-ci.osuosl.org/job/TensorFlow_IBMZ_CI/badge/icon)](http://ibmz-ci.osuosl.org/job/TensorFlow_IBMZ_CI/)                                                             | [Nightly](http://ibmz-ci.osuosl.org/job/TensorFlow_IBMZ_CI/)\n**Linux s390x CPU** Stable Release                                | [![Build Status](http://ibmz-ci.osuosl.org/job/TensorFlow_IBMZ_Release_Build/badge/icon)](https://ibmz-ci.osuosl.org/job/TensorFlow_IBMZ_Release_Build/)                                      | [Release](https://ibmz-ci.osuosl.org/job/TensorFlow_IBMZ_Release_Build/)\n**Linux ppc64le CPU** Nightly                                     | [![Build Status](https://powerci.osuosl.org/job/TensorFlow_PPC64LE_CPU_Build/badge/icon)](https://powerci.osuosl.org/job/TensorFlow_PPC64LE_CPU_Build/)                                       | [Nightly](https://powerci.osuosl.org/job/TensorFlow_PPC64LE_CPU_Nightly_Artifact/)\n**Linux ppc64le CPU** Stable Release                              | [![Build Status](https://powerci.osuosl.org/job/TensorFlow_PPC64LE_CPU_Release_Build/badge/icon)](https://powerci.osuosl.org/job/TensorFlow_PPC64LE_CPU_Release_Build/)                       | Release [1.15](https://powerci.osuosl.org/job/TensorFlow_PPC64LE_CPU_Release_Build/) / [2.x](https://powerci.osuosl.org/job/TensorFlow2_PPC64LE_CPU_Release_Build/)\n**Linux ppc64le GPU** Nightly                                     | [![Build Status](https://powerci.osuosl.org/job/TensorFlow_PPC64LE_GPU_Build/badge/icon)](https://powerci.osuosl.org/job/TensorFlow_PPC64LE_GPU_Build/)                                       | [Nightly](https://powerci.osuosl.org/job/TensorFlow_PPC64LE_GPU_Nightly_Artifact/)\n**Linux ppc64le GPU** Stable Release                              | [![Build Status](https://powerci.osuosl.org/job/TensorFlow_PPC64LE_GPU_Release_Build/badge/icon)](https://powerci.osuosl.org/job/TensorFlow_PPC64LE_GPU_Release_Build/)                       | Release [1.15](https://powerci.osuosl.org/job/TensorFlow_PPC64LE_GPU_Release_Build/) / [2.x](https://powerci.osuosl.org/job/TensorFlow2_PPC64LE_GPU_Release_Build/)\n**Linux CPU with Intel\xc2\xae MKL-DNN** Nightly                         | [![Build Status](https://tensorflow-ci.intel.com/job/tensorflow-mkl-build-whl-nightly/badge/icon)](https://tensorflow-ci.intel.com/job/tensorflow-mkl-build-whl-nightly/)                     | [Nightly](https://tensorflow-ci.intel.com/job/tensorflow-mkl-build-whl-nightly/)\n**Linux CPU with Intel\xc2\xae MKL-DNN** Stable Release                  | ![Build Status](https://tensorflow-ci.intel.com/job/tensorflow-mkl-build-release-whl/badge/icon)                                                                                              | Release [1.15](https://pypi.org/project/intel-tensorflow/1.15.0/) / [2.x](https://pypi.org/project/intel-tensorflow/)\n**Red Hat\xc2\xae Enterprise Linux\xc2\xae 7.6 CPU & GPU** <br> Python 2.7, 3.6 | [![Build Status](https://jenkins-tensorflow.apps.ci.centos.org/buildStatus/icon?job=tensorflow-rhel7-3.6&build=2)](https://jenkins-tensorflow.apps.ci.centos.org/job/tensorflow-rhel7-3.6/2/) | [1.13.1 PyPI](https://tensorflow.pypi.thoth-station.ninja/index/)\n\n## Resources\n\n*   [TensorFlow.org](https://www.tensorflow.org)\n*   [TensorFlow Tutorials](https://www.tensorflow.org/tutorials/)\n*   [TensorFlow Official Models](https://github.com/tensorflow/models/tree/master/official)\n*   [TensorFlow Examples](https://github.com/tensorflow/examples)\n*   [TensorFlow in Practice from Coursera](https://www.coursera.org/specializations/tensorflow-in-practice)\n*   [TensorFlow: Data and Deployment from Coursera](https://www.coursera.org/specializations/tensorflow-data-and-deployment)\n*   [Getting Started with TensorFlow 2 from Coursera](https://www.coursera.org/learn/getting-started-with-tensor-flow2)\n*   [Intro to TensorFlow for Deep Learning from Udacity](https://www.udacity.com/course/intro-to-tensorflow-for-deep-learning--ud187)\n*   [Introduction to TensorFlow Lite from Udacity](https://www.udacity.com/course/intro-to-tensorflow-lite--ud190)\n*   [Machine Learning with TensorFlow on GCP](https://www.coursera.org/specializations/machine-learning-tensorflow-gcp)\n*   [TensorFlow Blog](https://blog.tensorflow.org)\n*   [Learn ML with TensorFlow](https://www.tensorflow.org/resources/learn-ml)\n*   [TensorFlow Twitter](https://twitter.com/tensorflow)\n*   [TensorFlow YouTube](https://www.youtube.com/channel/UC0rqucBdTuFTjJiefW5t-IQ)\n*   [TensorFlow Roadmap](https://www.tensorflow.org/community/roadmap)\n*   [TensorFlow White Papers](https://www.tensorflow.org/about/bib)\n*   [TensorBoard Visualization Toolkit](https://github.com/tensorflow/tensorboard)\n\nLearn more about the\n[TensorFlow community](https://www.tensorflow.org/community) and how to\n[contribute](https://www.tensorflow.org/community/contribute).\n\n## License\n\n[Apache License 2.0](LICENSE)\n'"
21,carefree0910/MachineLearning,carefree0910,Machine learning algorithms implemented by pure numpy,2016-09-18 09:37:01,2020-06-18 16:59:29,Jupyter Notebook,633,836,b'# MachineLearning\n\n#### Update! (2020.05.31)\nA simplified (and more elegant) version: [carefree-ml](https://github.com/carefree0910/carefree-ml)\n\n---\n\nA Python ML package mainly for educational use.\n\nImplemented with `Numpy`\n\nImplemented `Tensorflow` & `PyTorch` backend for [NN](https://github.com/carefree0910/MachineLearning/tree/master/NN) & [SVM](https://github.com/carefree0910/MachineLearning/tree/master/e_SVM)\n\n\xe2\x80\x9c\xe6\x96\x87\xe6\xa1\xa3\xe2\x80\x9d\xe5\x8f\xaf\xe4\xbb\xa5\xe5\x8f\x82\xe8\xa7\x81[\xe7\x9f\xa5\xe4\xb9\x8e\xe4\xb8\x93\xe6\xa0\x8f](https://zhuanlan.zhihu.com/carefree0910-pyml)\xe6\x88\x96[\xe5\x8d\x9a\xe5\xae\xa2](https://mlblog.carefree0910.me)\n'
22,deeplearning-ai/machine-learning-yearning-cn,deeplearning-ai,Machine Learning Yearning 中文版 - 《机器学习训练秘籍》 - Andrew Ng 著,2018-06-19 19:26:39,2020-06-18 14:13:29,CSS,1311,6092,"b'# Machine Learning Yearning \xe4\xb8\xad\xe6\x96\x87\xe7\x89\x88\n\n[\xe8\xae\xbf\xe9\x97\xae\xe6\xad\xa4\xe5\xa4\x84](https://deeplearning-ai.github.io/machine-learning-yearning-cn/) \xe5\xbc\x80\xe5\xa7\x8b\xe5\x9c\xa8\xe7\xba\xbf\xe9\x98\x85\xe8\xaf\xbb\xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xae\xad\xe7\xbb\x83\xe7\xa7\x98\xe7\xb1\x8d\xe3\x80\x8b\xe6\xa0\xb7\xe7\xa8\xbf\xef\xbc\x8c\xe5\xb8\x8c\xe6\x9c\x9b\xe8\xbf\x99\xe6\x9c\xac\xe4\xb9\xa6\xe5\xaf\xb9\xe4\xbd\xa0\xe4\xbb\xac\xe6\x9c\x89\xe6\x89\x80\xe5\xb8\xae\xe5\x8a\xa9\xef\xbc\x81\xe5\xbd\x93\xe5\x89\x8d\xe6\xa0\xb7\xe7\xa8\xbf\xe4\xbb\x85\xe4\xbe\x9b\xe5\x86\x85\xe5\xae\xb9\xe9\xa2\x84\xe8\xa7\x88\xef\xbc\x8c\xe9\x9d\x9e\xe6\x9c\x80\xe7\xbb\x88\xe7\x89\x88\xe6\x9c\xac\xef\xbc\x88\xe5\x8e\x86\xe5\x8f\xb2\xe7\x89\x88\xe6\x9c\xac\xe5\x8f\xaf\xe4\xbb\xa5\xe5\x9c\xa8 [release](https://github.com/deeplearning-ai/machine-learning-yearning-cn/releases) \xe4\xb8\xad\xe6\x89\xbe\xe5\x88\xb0\xef\xbc\x89\xe3\x80\x82\n\n## \xe5\x90\x88\xe4\xbd\x9c\xe6\x94\xb9\xe5\x96\x84\xe7\xbf\xbb\xe8\xaf\x91\xe8\xb4\xa8\xe9\x87\x8f\n\n\xe8\xaf\x91\xe8\x80\x85\xe6\xb0\xb4\xe5\xb9\xb3\xe6\x9c\x89\xe9\x99\x90\xef\xbc\x8c\xe5\xa6\x82\xe6\x9c\x89\xe7\xbf\xbb\xe8\xaf\x91\xe4\xb8\x8d\xe5\xbd\x93\xe4\xb9\x8b\xe5\xa4\x84\xef\xbc\x8c\xe6\x81\xb3\xe8\xaf\xb7\xe8\xaf\xbb\xe8\x80\x85\xe5\xb8\xae\xe5\x8a\xa9\xe6\x96\xa7\xe6\xad\xa3\xef\xbc\x8c\xe9\x80\x94\xe5\xbe\x84\xe4\xb8\xba\xef\xbc\x9a\n\n1. \xe5\x9c\xa8\xe9\xa1\xb9\xe7\x9b\xae\xe7\x9a\x84 Issues \xe5\x8c\xba\xe5\x88\x9b\xe5\xbb\xba\xe6\x96\xb0\xe7\x9a\x84\xe8\xae\xa8\xe8\xae\xba\xe5\x86\x85\xe5\xae\xb9\xef\xbc\x9b\xef\xbc\x88\xe6\x8e\xa8\xe8\x8d\x90\xef\xbc\x89\n2. \xe5\x9c\xa8\xe7\xbd\x91\xe9\xa1\xb5\xe7\x82\xb9\xe5\x87\xbb \xe2\x80\x9c\xe6\x94\xb9\xe8\xbf\x9b\xe5\xbd\x93\xe5\x89\x8d\xe9\xa1\xb5\xe9\x9d\xa2\xe2\x80\x9d\xef\xbc\x8c\xe4\xbf\xae\xe6\x94\xb9\xe5\x90\x8e\xe5\x8f\x91\xe8\xb5\xb7 Pull Request\xef\xbc\x9b\n3. [\xe5\x8f\x91\xe9\x80\x81\xe9\x82\xae\xe4\xbb\xb6](mailto:xiaowei@deeplearning.ai) \xe8\xbf\x9b\xe8\xa1\x8c\xe5\x8f\x8d\xe9\xa6\x88\xef\xbc\x8c\xe4\xb8\xbb\xe9\xa2\x98\xe5\xb8\xa6\xe6\x9c\x89 \xe2\x80\x9cMLY \xe7\xbf\xbb\xe8\xaf\x91\xe2\x80\x9d\xe3\x80\x82\n\n\xe6\xb3\xa8\xef\xbc\x9a\xe6\x89\x80\xe6\x9c\x89\xe5\x9b\xbe\xe7\x89\x87\xe6\x94\xbe\xe5\x9c\xa8 `img` \xe8\xb7\xaf\xe5\xbe\x84\xe4\xb8\x8b\xef\xbc\x8c\xe6\x9c\xac\xe5\x9c\xb0\xe6\x97\xa0\xe6\xb3\x95\xe9\xa2\x84\xe8\xa7\x88\xef\xbc\x8c\xe5\x9c\xa8\xe6\x96\x87\xe7\xa8\xbf\xe4\xb8\xad\xe7\x9a\x84\xe6\x8f\x92\xe5\x85\xa5\xe6\x96\xb9\xe5\xbc\x8f\xe4\xb8\xba\xef\xbc\x9a\n```\n <img src=""{{""pic_name.jpg "" | prepend: site.imgurl }}"">\n```\n\n## \xe7\x9b\xb8\xe5\x85\xb3\xe7\x89\x88\xe6\x9d\x83\xe5\xa3\xb0\xe6\x98\x8e\n\n\xe6\x9c\xac\xe9\xa1\xb9\xe7\x9b\xae\xe9\x81\xb5\xe5\xbe\xaa \xe2\x80\x9c\xe7\xbd\xb2\xe5\x90\x8d-\xe9\x9d\x9e\xe5\x95\x86\xe4\xb8\x9a\xe6\x80\xa7\xe4\xbd\xbf\xe7\x94\xa8-\xe7\x9b\xb8\xe5\x90\x8c\xe6\x96\xb9\xe5\xbc\x8f\xe5\x85\xb1\xe4\xba\xab 4.0 \xe5\x9b\xbd\xe9\x99\x85 (CC BY-NC-SA 4.0)\xe2\x80\x9d \xe5\x8d\x8f\xe8\xae\xae\xe3\x80\x82\xe8\xbf\x99\xe6\x98\xaf\xe4\xb8\x80\xe4\xbb\xbd\xe6\x99\xae\xe9\x80\x9a\xe4\xba\xba\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x90\x86\xe8\xa7\xa3\xe7\x9a\x84[\xe8\xae\xb8\xe5\x8f\xaf\xe5\x8d\x8f\xe8\xae\xae](https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode.zh-Hans)\xe6\xa6\x82\xe8\xa6\x81 (\xe4\xbd\x86\xe4\xb8\x8d\xe6\x98\xaf\xe6\x9b\xbf\xe4\xbb\xa3) \xe3\x80\x82 [\xe5\x85\x8d\xe8\xb4\xa3\xe5\xa3\xb0\xe6\x98\x8e](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh#).\n\n\xe6\x82\xa8\xe5\x8f\xaf\xe4\xbb\xa5\xe8\x87\xaa\xe7\x94\xb1\xe5\x9c\xb0\xef\xbc\x9a\n\n- **\xe5\x85\xb1\xe4\xba\xab** \xe2\x80\x94 \xe5\x9c\xa8\xe4\xbb\xbb\xe4\xbd\x95\xe5\xaa\x92\xe4\xbb\x8b\xe4\xbb\xa5\xe4\xbb\xbb\xe4\xbd\x95\xe5\xbd\xa2\xe5\xbc\x8f\xe5\xa4\x8d\xe5\x88\xb6\xe3\x80\x81\xe5\x8f\x91\xe8\xa1\x8c\xe6\x9c\xac\xe4\xbd\x9c\xe5\x93\x81\n- **\xe6\xbc\x94\xe7\xbb\x8e** \xe2\x80\x94 \xe4\xbf\xae\xe6\x94\xb9\xe3\x80\x81\xe8\xbd\xac\xe6\x8d\xa2\xe6\x88\x96\xe4\xbb\xa5\xe6\x9c\xac\xe4\xbd\x9c\xe5\x93\x81\xe4\xb8\xba\xe5\x9f\xba\xe7\xa1\x80\xe8\xbf\x9b\xe8\xa1\x8c\xe5\x88\x9b\xe4\xbd\x9c\n\n\xe5\x8f\xaa\xe8\xa6\x81\xe4\xbd\xa0\xe9\x81\xb5\xe5\xae\x88\xe8\xae\xb8\xe5\x8f\xaf\xe5\x8d\x8f\xe8\xae\xae\xe6\x9d\xa1\xe6\xac\xbe\xef\xbc\x8c\xe8\xae\xb8\xe5\x8f\xaf\xe4\xba\xba\xe5\xb0\xb1\xe6\x97\xa0\xe6\xb3\x95\xe6\x94\xb6\xe5\x9b\x9e\xe4\xbd\xa0\xe7\x9a\x84\xe8\xbf\x99\xe4\xba\x9b\xe6\x9d\x83\xe5\x88\xa9\xe3\x80\x82\n\xe6\x83\x9f\xe9\xa1\xbb\xe9\x81\xb5\xe5\xae\x88\xe4\xb8\x8b\xe5\x88\x97\xe6\x9d\xa1\xe4\xbb\xb6\xef\xbc\x9a\n\n- **\xe7\xbd\xb2\xe5\x90\x8d** \xe2\x80\x94 \xe6\x82\xa8\xe5\xbf\x85\xe9\xa1\xbb\xe7\xbb\x99\xe5\x87\xba[\xe9\x80\x82\xe5\xbd\x93\xe7\x9a\x84\xe7\xbd\xb2\xe5\x90\x8d](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh#)\xef\xbc\x8c\xe6\x8f\x90\xe4\xbe\x9b\xe6\x8c\x87\xe5\x90\x91\xe6\x9c\xac\xe8\xae\xb8\xe5\x8f\xaf\xe5\x8d\x8f\xe8\xae\xae\xe7\x9a\x84\xe9\x93\xbe\xe6\x8e\xa5\xef\xbc\x8c\xe5\x90\x8c\xe6\x97\xb6[\xe6\xa0\x87\xe6\x98\x8e\xe6\x98\xaf\xe5\x90\xa6\xef\xbc\x88\xe5\xaf\xb9\xe5\x8e\x9f\xe5\xa7\x8b\xe4\xbd\x9c\xe5\x93\x81\xef\xbc\x89\xe4\xbd\x9c\xe4\xba\x86\xe4\xbf\xae\xe6\x94\xb9](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh#)\xe3\x80\x82\xe6\x82\xa8\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x94\xa8\xe4\xbb\xbb\xe4\xbd\x95\xe5\x90\x88\xe7\x90\x86\xe7\x9a\x84\xe6\x96\xb9\xe5\xbc\x8f\xe6\x9d\xa5\xe7\xbd\xb2\xe5\x90\x8d\xef\xbc\x8c\xe4\xbd\x86\xe6\x98\xaf\xe4\xb8\x8d\xe5\xbe\x97\xe4\xbb\xa5\xe4\xbb\xbb\xe4\xbd\x95\xe6\x96\xb9\xe5\xbc\x8f\xe6\x9a\x97\xe7\xa4\xba\xe8\xae\xb8\xe5\x8f\xaf\xe4\xba\xba\xe4\xb8\xba\xe6\x82\xa8\xe6\x88\x96\xe6\x82\xa8\xe7\x9a\x84\xe4\xbd\xbf\xe7\x94\xa8\xe8\x83\x8c\xe4\xb9\xa6\xe3\x80\x82\n- **\xe9\x9d\x9e\xe5\x95\x86\xe4\xb8\x9a\xe6\x80\xa7\xe4\xbd\xbf\xe7\x94\xa8** \xe2\x80\x94 \xe6\x82\xa8\xe4\xb8\x8d\xe5\xbe\x97\xe5\xb0\x86\xe6\x9c\xac\xe4\xbd\x9c\xe5\x93\x81\xe7\x94\xa8\xe4\xba\x8e[\xe5\x95\x86\xe4\xb8\x9a\xe7\x9b\xae\xe7\x9a\x84](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh#)\xe3\x80\x82\n- **\xe7\x9b\xb8\xe5\x90\x8c\xe6\x96\xb9\xe5\xbc\x8f\xe5\x85\xb1\xe4\xba\xab** \xe2\x80\x94 \xe5\xa6\x82\xe6\x9e\x9c\xe6\x82\xa8\xe5\x86\x8d\xe6\xb7\xb7\xe5\x90\x88\xe3\x80\x81\xe8\xbd\xac\xe6\x8d\xa2\xe6\x88\x96\xe8\x80\x85\xe5\x9f\xba\xe4\xba\x8e\xe6\x9c\xac\xe4\xbd\x9c\xe5\x93\x81\xe8\xbf\x9b\xe8\xa1\x8c\xe5\x88\x9b\xe4\xbd\x9c\xef\xbc\x8c\xe6\x82\xa8\xe5\xbf\x85\xe9\xa1\xbb\xe5\x9f\xba\xe4\xba\x8e[\xe4\xb8\x8e\xe5\x8e\x9f\xe5\x85\x88\xe8\xae\xb8\xe5\x8f\xaf\xe5\x8d\x8f\xe8\xae\xae\xe7\x9b\xb8\xe5\x90\x8c\xe7\x9a\x84\xe8\xae\xb8\xe5\x8f\xaf\xe5\x8d\x8f\xe8\xae\xae](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh#) \xe5\x88\x86\xe5\x8f\x91\xe6\x82\xa8\xe8\xb4\xa1\xe7\x8c\xae\xe7\x9a\x84\xe4\xbd\x9c\xe5\x93\x81\xe3\x80\x82\n- **\xe6\xb2\xa1\xe6\x9c\x89\xe9\x99\x84\xe5\x8a\xa0\xe9\x99\x90\xe5\x88\xb6** \xe2\x80\x94 \xe6\x82\xa8\xe4\xb8\x8d\xe5\xbe\x97\xe9\x80\x82\xe7\x94\xa8\xe6\xb3\x95\xe5\xbe\x8b\xe6\x9c\xaf\xe8\xaf\xad\xe6\x88\x96\xe8\x80\x85 [\xe6\x8a\x80\xe6\x9c\xaf\xe6\x8e\xaa\xe6\x96\xbd](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh#) \xe4\xbb\x8e\xe8\x80\x8c\xe9\x99\x90\xe5\x88\xb6\xe5\x85\xb6\xe4\xbb\x96\xe4\xba\xba\xe5\x81\x9a\xe8\xae\xb8\xe5\x8f\xaf\xe5\x8d\x8f\xe8\xae\xae\xe5\x85\x81\xe8\xae\xb8\xe7\x9a\x84\xe4\xba\x8b\xe6\x83\x85\xe3\x80\x82\n'"
23,csuldw/MachineLearning,csuldw,"Machine learning resources，including algorithm, paper, dataset, example and so on.",2016-02-20 05:53:47,2020-06-18 04:49:49,Python,628,691,"b'## MachineLearning\n\n\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xae\x97\xe6\xb3\x95\xe4\xbb\xa3\xe7\xa0\x81\xe5\x8f\x8a\xe4\xb8\xaa\xe4\xba\xba\xe6\x80\xbb\xe7\xbb\x93\xe6\x95\xb4\xe7\x90\x86\xef\xbc\x8c\xe5\xaf\xb9\xe4\xba\x8e\xe7\xae\x97\xe6\xb3\x95\xe5\xae\x9e\xe7\x8e\xb0\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x8c\xe5\x9c\xa8\xe7\x9b\xb8\xe5\xba\x94\xe7\x9b\xae\xe5\xbd\x95\xe4\xb8\xad\xe9\x83\xbd\xe5\x8c\x85\xe5\x90\xab\xe6\x9c\x89\xe6\xba\x90\xe7\xa0\x81\xe5\x92\x8c\xe6\x95\xb0\xe6\x8d\xae\xe4\xbb\xa5\xe5\x8f\x8a\xe6\xb5\x8b\xe8\xaf\x95\xe5\xae\x9e\xe4\xbe\x8b\xef\xbc\x8c\xe5\x86\x85\xe5\xae\xb9\xe6\xad\xa3\xe5\x9c\xa8\xe4\xb8\x8d\xe6\x96\xad\xe5\xae\x8c\xe5\x96\x84\xe4\xb8\xad\xef\xbc\x81\xe5\xa6\x82\xe6\x9c\x89\xe9\x94\x99\xe8\xaf\xaf\xef\xbc\x8c\xe8\xbf\x98\xe6\x9c\x9b\xe8\xaf\xbb\xe8\x80\x85\xe6\x8c\x87\xe5\x87\xba\xef\xbc\x8c\xe9\x9d\x9e\xe5\xb8\xb8\xe6\x84\x9f\xe8\xb0\xa2\xef\xbc\x8c\xe8\x8b\xa5\xe6\x82\xa8\xe8\xa7\x89\xe5\xbe\x97\xe5\xaf\xb9\xe4\xbd\xa0\xe6\x9c\x89\xe5\xb8\xae\xe5\x8a\xa9\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe5\x9c\xa8\xe5\x8f\xb3\xe4\xb8\x8a\xe8\xa7\x92\xe7\xbb\x99\xe4\xb8\xaastar\xe5\x93\x88(#^.^#)\xe3\x80\x82PS:\xe6\x89\x80\xe6\x9c\x89\xe4\xbb\xa3\xe7\xa0\x81\xe5\x9d\x87\xe7\xac\xa6\xe5\x90\x88\xe6\x88\x91\xe4\xbb\xac\xe6\x95\xb4\xe7\x90\x86\xe5\x87\xba\xe6\x9d\xa5\xe7\x9a\x84\xe8\xbf\x99\xe4\xbb\xbd[\xe7\xbc\x96\xe7\xa0\x81\xe8\xa7\x84\xe8\x8c\x83](https://github.com/csuldw/MachineLearning/blob/master/Python-coding-standards.md).\n\n## Contents\n\n\xe7\xae\x97\xe6\xb3\x95\xe9\x83\xa8\xe5\x88\x86\xe7\x9b\xae\xe5\x89\x8d\xe4\xb8\xbb\xe8\xa6\x81\xe5\x8c\x85\xe5\x90\xab\xe5\xa6\x82\xe4\xb8\x8b\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\n\n- Logistic Regression (\xe4\xba\x8c\xe5\x88\x86\xe7\xb1\xbb):  [\xe6\xba\x90\xe7\xa0\x81\xe5\xae\x9e\xe7\x8e\xb0](https://github.com/csuldw/MachineLearning/tree/master/Logistic%20Regression) \xe3\x80\x82\xe5\x8c\x85\xe5\x90\xab\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x92\x8c\xe6\xba\x90\xe7\xa0\x81\xe3\x80\x82\n\n- Decision Tree: \xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xef\xbc\x8c[\xe6\xba\x90\xe7\xa0\x81\xe5\xae\x9e\xe7\x8e\xb0](https://github.com/csuldw/MachineLearning/tree/master/DecisionTree).\n\n- ROC: \xe7\x94\xa8\xe4\xba\x8e\xe7\xbb\x98\xe5\x88\xb6ROC\xe6\x9b\xb2\xe7\xba\xbf\xef\xbc\x8c[\xe6\xba\x90\xe7\xa0\x81\xe5\xae\x9e\xe7\x8e\xb0](https://github.com/csuldw/MachineLearning/tree/master/ROC).\n\n- Naive Bayes\xef\xbc\x9a\xe6\x9c\xb4\xe7\xb4\xa0\xe8\xb4\x9d\xe5\x8f\xb6\xe6\x96\xaf\xef\xbc\x8c[\xe6\xba\x90\xe7\xa0\x81\xe5\xae\x9e\xe7\x8e\xb0](https://github.com/csuldw/MachineLearning/tree/master/NaiveBayes).\n\n- K-NearestNeighbor\xef\xbc\x9aK\xe6\x9c\x80\xe8\xbf\x91\xe9\x82\xbb\xe7\xae\x97\xe6\xb3\x95\xef\xbc\x8c[\xe6\xba\x90\xe7\xa0\x81\xe5\xae\x9e\xe7\x8e\xb0](https://github.com/csuldw/MachineLearning/tree/master/KNN).\n\n- K-Means\xe5\x9d\x87\xe5\x80\xbc\xe8\x81\x9a\xe7\xb1\xbb\xef\xbc\x9a[\xe6\xba\x90\xe7\xa0\x81\xe5\xae\x9e\xe7\x8e\xb0](https://github.com/csuldw/MachineLearning/tree/master/Kmeans).\n\n- Adaboost\xe7\xbb\x84\xe5\x90\x88\xe7\xae\x97\xe6\xb3\x95\xef\xbc\x9a[\xe6\xba\x90\xe7\xa0\x81\xe9\x93\xbe\xe6\x8e\xa5](https://github.com/csuldw/MachineLearning/tree/master/Adaboost)\n\n- mRMR\xe7\x89\xb9\xe5\xbe\x81\xe9\x80\x89\xe6\x8b\xa9\xe6\x96\xb9\xe6\xb3\x95\xef\xbc\x8c[\xe8\xbd\xaf\xe4\xbb\xb6\xe4\xbd\xbf\xe7\x94\xa8\xe6\x96\xb9\xe6\xb3\x95](https://github.com/csuldw/MachineLearning/tree/master/mRMR)\n\n- \xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xae\x97\xe6\xb3\x95\xe4\xbb\xa3\xe7\xa0\x81\xe4\xbd\xbf\xe7\x94\xa8\xe6\xb1\x87\xe6\x80\xbb\xef\xbc\x8c[Python & R Codes](http://www.csuldw.com/2015/11/21/2015-11-21-machine-learning-algorithms/)\n\n- PCA\xe4\xb8\xbb\xe8\xa6\x81\xe6\x88\x90\xe5\x88\x86\xe5\x88\x86\xe6\x9e\x90, [Python\xe5\xae\x9e\xe7\x8e\xb0\xe6\xba\x90\xe7\xa0\x81](https://github.com/csuldw/MachineLearning/tree/master/PCA)\n\n- LDA\xe7\xba\xbf\xe6\x80\xa7\xe5\x88\xa4\xe5\x88\xab\xe5\x88\x86\xe6\x9e\x90\xef\xbc\x88Fisher\xe5\x88\xa4\xe5\x88\xab\xef\xbc\x89,[\xe6\xba\x90\xe7\xa0\x81\xe5\xae\x9e\xe7\x8e\xb0](https://github.com/csuldw/MachineLearning/blob/master/LDA/lda.ipynb)\n\n- spark-demo\xef\xbc\x9a\xe4\xbd\xbf\xe7\x94\xa8scala\xe7\xbc\x96\xe5\x86\x99\xe7\x9a\x84spark\xe5\xae\x9e\xe4\xbe\x8b.\n\t- invertedIndex, [Spark \xe5\x80\x92\xe6\x8e\x92\xe7\xb4\xa2\xe5\xbc\x95\xe5\xae\x9e\xe4\xbe\x8b\xe6\xba\x90\xe7\xa0\x81](https://github.com/csuldw/MachineLearning/tree/master/spark-demo/invertedIndex)\n\n## Supplementary\n\n- MNIST\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86[\xe5\x8a\xa0\xe8\xbd\xbd\xe6\x96\xb9\xe6\xb3\x95](https://github.com/csuldw/MachineLearning/tree/master/dataset/MNIST).\n\n\n## Contributor\n\n- \xe5\x88\x98\xe5\xb8\x9d\xe4\xbc\x9f, CSU\xe7\xa1\x95\xe5\xa3\xab\xe6\xaf\x95\xe4\xb8\x9a\xef\xbc\x8c\xe5\x85\xb3\xe6\xb3\xa8AI\xe3\x80\x81\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe3\x80\x81\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe6\x96\xb9\xe5\x90\x91\xef\xbc\x8c[HomePage](http://www.csuldw.com).\n\n\n## Contact\n\n\xe5\xa6\x82\xe6\x9e\x9c\xe6\x9c\x89\xe4\xbb\xbb\xe4\xbd\x95\xe7\x96\x91\xe9\x97\xae\xef\xbc\x8c\xe5\x8f\xaf\xe5\x9c\xa8\xe6\x88\x91\xe7\x9a\x84\xe5\xbe\xae\xe4\xbf\xa1\xe5\x85\xac\xe4\xbc\x97\xe5\x8f\xb7\xe5\x90\x8e\xe5\x8f\xb0\xe7\x95\x99\xe8\xa8\x80\xef\xbc\x9a\n\n<!-- ![](http://www.csuldw.com/assets/articleImg/2019/code-main-fun.png) -->\n\n<div style=""align: center"">\n<img src=""http://www.csuldw.com/assets/articleImg/2019/code-main-fun.png"" width=""50%"" height=""50%"">\n</div>\n\n\xe6\x88\x96\xe6\x98\xaf\xe5\x8f\x91\xe9\x82\xae\xe4\xbb\xb6\xe5\x90\xa7\xef\xbc\x9a\n\n- E-mail: csu.ldw@csu.edu.cn\n'"
24,machinelearningmindset/machine-learning-course,machinelearningmindset,:speech_balloon: Machine Learning Course with Python: ,2019-02-15 00:23:19,2020-06-18 11:44:35,Python,1140,6420,"b'\n\n###################################################\nA Machine Learning Course with Python\n###################################################\n\n.. image:: https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat\n    :target: https://github.com/pyairesearch/machine-learning-for-everybody/pulls\n.. image:: https://badges.frapsoft.com/os/v2/open-source.png?v=103\n    :target: https://github.com/ellerbrock/open-source-badge/\n.. image:: https://img.shields.io/badge/Made%20with-Python-1f425f.svg\n      :target: https://www.python.org/\n.. image:: https://img.shields.io/github/contributors/machinelearningmindset/machine-learning-course.svg\n      :target: https://github.com/machinelearningmindset/machine-learning-course/graphs/contributors\n.. image:: https://img.shields.io/badge/book-pdf-blue.svg\n   :target: https://machinelearningmindset.com/wp-content/uploads/2019/06/machine-learning-course.pdf\n.. image:: https://img.shields.io/badge/official-documentation-green.svg\n   :target: https://machine-learning-course.readthedocs.io/en/latest/\n.. image:: https://img.shields.io/twitter/follow/machinemindset.svg?label=Follow&style=social\n      :target: https://twitter.com/machinemindset\n\n\n\n\n\n\n##################\nTable of Contents\n##################\n.. contents::\n  :local:\n  :depth: 4\n\n\n================================================\nDownload Free Deep Learning Resource Guide\n================================================\n\n.. raw:: html\n\n   <div align=""center"">\n\n.. raw:: html\n\n  <a href=""https://www.machinelearningmindset.com/deep-learning-roadmap/"" target=""_blank"">\n    <img width=""723"" height=""400"" align=""center"" src=""_img/deeplearningresource.png""/>\n  </a>\n\n.. raw:: html\n\n   </div>\n   \n\n================================================\nSlack Group\n================================================\n\n.. raw:: html\n\n   <div align=""center"">\n\n.. raw:: html\n\n <a href=""https://www.machinelearningmindset.com/slack-group/"" target=""_blank"">\n  <img width=""1033"" height=""350"" align=""center"" src=""https://github.com/machinelearningmindset/TensorFlow-Course/blob/master/_img/0-welcome/joinslack.png""/>\n </a>\n\n.. raw:: html\n\n   </div>\n\n========================\nIntroduction\n========================\n\nThe purpose of this project is to provide a comprehensive and yet simple course in Machine Learning using Python.\n\n.. You can access to the full documentation with the following links: |Book| |Documentation|\n\n.. .. |Book| image:: https://img.shields.io/badge/book-pdf-blue.svg\n   :target: https://machinelearningmindset.com/wp-content/uploads/2019/06/machine-learning-course.pdf\n.. .. |Documentation| image:: https://img.shields.io/badge/official-documentation-green.svg\n   :target: https://machine-learning-course.readthedocs.io/en/latest/\n\n============\nMotivation\n============\n\n``Machine Learning``, as a tool for ``Artificial Intelligence``, is one of the most widely adopted\nscientific fields. A considerable amount of literature has been published on Machine Learning.\nThe purpose of this project is to provide the most important aspects of ``Machine Learning`` by presenting a\nseries of simple and yet comprehensive tutorials using ``Python``. In this project, we built our\ntutorials using many different well-known Machine Learning frameworks such as ``Scikit-learn``. In this project you will learn:\n\n* What is the definition of Machine Learning?\n* When it started and what is the trending evolution?\n* What are the Machine Learning categories and subcategories?\n* What are the mostly used Machine Learning algorithms and how to implement them?\n\n\n\n=====================\nMachine Learning\n=====================\n\n+--------------------------------------------------------------------+-------------------------------+\n| Title                                                              |    Document                   |\n+====================================================================+===============================+\n| An Introduction to Machine Learning                                |   `Overview <Intro_>`_        |\n+--------------------------------------------------------------------+-------------------------------+\n\n.. _Intro: docs/source/intro/intro.rst\n\n------------------------------------------------------------\nMachine Learning Basics\n------------------------------------------------------------\n\n.. figure:: _img/intro.png\n.. _lrtutorial: docs/source/content/overview/linear-regression.rst\n.. _lrcode: https://github.com/machinelearningmindset/machine-learning-course/blob/master/code/overview/linear_regression/linearRegressionOneVariable.ipynb\n\n.. _overtutorial: docs/source/content/overview/overfitting.rst\n.. _overcode: code/overview/overfitting\n\n.. _regtutorial: docs/source/content/overview/regularization.rst\n.. _regcode: code/overview/regularization\n\n.. _crosstutorial: docs/source/content/overview/crossvalidation.rst\n.. _crosscode: code/overview/cross-validation\n\n\n\n\n+--------------------------------------------------------------------+-------------------------------+--------------------------------+\n| Title                                                              |    Code                       |    Document                    |\n+====================================================================+===============================+================================+\n| Linear Regression                                                  | `Python <lrcode_>`_           | `Tutorial <lrtutorial_>`_      |\n+--------------------------------------------------------------------+-------------------------------+--------------------------------+\n| Overfitting / Underfitting                                         | `Python <overcode_>`_         | `Tutorial <overtutorial_>`_    |\n+--------------------------------------------------------------------+-------------------------------+--------------------------------+\n| Regularization                                                     | `Python <regcode_>`_          | `Tutorial <regtutorial_>`_     |\n+--------------------------------------------------------------------+-------------------------------+--------------------------------+\n| Cross-Validation                                                   | `Python <crosscode_>`_        | `Tutorial <crosstutorial_>`_   |\n+--------------------------------------------------------------------+-------------------------------+--------------------------------+\n\n\n------------------------------------------------------------\nSupervised learning\n------------------------------------------------------------\n\n.. figure:: _img/supervised.gif\n\n.. _dtdoc: docs/source/content/supervised/decisiontrees.rst\n.. _dtcode: code/supervised/DecisionTree/decisiontrees.py\n\n.. _knndoc: docs/source/content/supervised/knn.rst\n.. _knncode: code/supervised/KNN/knn.py\n\n.. _nbdoc: docs/source/content/supervised/bayes.rst\n.. _nbcode: code/supervised/Naive_Bayes\n\n.. _logisticrdoc: docs/source/content/supervised/logistic_regression.rst\n.. _logisticrcode: supervised/Logistic_Regression/logistic_ex1.py\n\n.. _linearsvmdoc: docs/source/content/supervised/linear_SVM.rst\n.. _linearsvmcode: code/supervised/Linear_SVM/linear_svm.py\n\n\n\n+--------------------------------------------------------------------+-------------------------------+------------------------------+\n| Title                                                              |    Code                       |    Document                  |\n+====================================================================+===============================+==============================+\n| Decision Trees                                                     | `Python <dtcode_>`_           | `Tutorial <dtdoc_>`_         |\n+--------------------------------------------------------------------+-------------------------------+------------------------------+\n| K-Nearest Neighbors                                                | `Python <knncode_>`_          | `Tutorial <knndoc_>`_        |\n+--------------------------------------------------------------------+-------------------------------+------------------------------+\n| Naive Bayes                                                        | `Python <nbcode_>`_           |  `Tutorial <nbdoc_>`_        |\n+--------------------------------------------------------------------+-------------------------------+------------------------------+\n| Logistic Regression                                                | `Python <logisticrcode_>`_    |  `Tutorial <logisticrdoc_>`_ |\n+--------------------------------------------------------------------+-------------------------------+------------------------------+\n| Support Vector Machines                                            | `Python <linearsvmcode_>`_    | `Tutorial <linearsvmdoc_>`_  |\n+--------------------------------------------------------------------+-------------------------------+------------------------------+\n\n\n\n\n------------------------------------------------------------\nUnsupervised learning\n------------------------------------------------------------\n\n.. figure:: _img/unsupervised.gif\n\n.. _clusteringdoc: docs/source/content/unsupervised/clustering.rst\n.. _clusteringcode: code/unsupervised/Clustering\n\n.. _pcadoc: docs/source/content/unsupervised/pca.rst\n.. _pcacode: code/unsupervised/PCA\n\n+--------------------------------------------------------------------+-------------------------------+--------------------------------+\n| Title                                                              |    Code                       |    Document                    |\n+====================================================================+===============================+================================+\n| Clustering                                                         | `Python <clusteringcode_>`_   | `Tutorial <clusteringdoc_>`_   |\n+--------------------------------------------------------------------+-------------------------------+--------------------------------+\n| Principal Components Analysis                                      | `Python <pcacode_>`_          | `Tutorial <pcadoc_>`_          |\n+--------------------------------------------------------------------+-------------------------------+--------------------------------+\n\n\n\n\n------------------------------------------------------------\nDeep Learning\n------------------------------------------------------------\n\n.. figure:: _img/deeplearning.png\n\n.. _mlpdoc: docs/source/content/deep_learning/mlp.rst\n.. _mlpcode: code/deep_learning/mlp\n\n\n.. _cnndoc: docs/source/content/deep_learning/cnn.rst\n.. _cnncode: code/deep_learning/cnn\n\n.. _aedoc: docs/source/content/deep_learning/autoencoder.rst\n.. _aecode: code/deep_learning/autoencoder\n\n.. _rnndoc: code/deep_learning/rnn/rnn.ipynb\n.. _rnncode: code/deep_learning/rnn/rnn.py\n\n\n+--------------------------------------------------------------------+-------------------------------+---------------------------+\n| Title                                                              |    Code                       |    Document               |\n+====================================================================+===============================+===========================+\n| Neural Networks Overview                                           |    `Python <mlpcode_>`_       |  `Tutorial <mlpdoc_>`_    |\n+--------------------------------------------------------------------+-------------------------------+---------------------------+\n| Convolutional Neural Networks                                      |    `Python <cnncode_>`_       | `Tutorial <cnndoc_>`_     |\n+--------------------------------------------------------------------+-------------------------------+---------------------------+\n| Autoencoders                                                       |    `Python <aecode_>`_        | `Tutorial <aedoc_>`_      |\n+--------------------------------------------------------------------+-------------------------------+---------------------------+\n| Recurrent Neural Networks                                          |    `Python <rnncode_>`_       |  `IPython <rnndoc_>`_     |\n+--------------------------------------------------------------------+-------------------------------+---------------------------+\n\n\n\n========================\nPull Request Process\n========================\n\nPlease consider the following criterions in order to help us in a better way:\n\n1. The pull request is mainly expected to be a link suggestion.\n2. Please make sure your suggested resources are not obsolete or broken.\n3. Ensure any install or build dependencies are removed before the end of the layer when doing a\n   build and creating a pull request.\n4. Add comments with details of changes to the interface, this includes new environment\n   variables, exposed ports, useful file locations and container parameters.\n5. You may merge the Pull Request in once you have the sign-off of at least one other developer, or if you\n   do not have permission to do that, you may request the owner to merge it for you if you believe all checks are passed.\n\n========================\nFinal Note\n========================\n\nWe are looking forward to your kind feedback. Please help us to improve this open source project and make our work better.\nFor contribution, please create a pull request and we will investigate it promptly. Once again, we appreciate\nyour kind feedback and support.\n\n\n========================\nDevelopers\n========================\n\n**Creator**: Machine Learning Mindset [`Blog\n<https://machinelearningmindset.com/blog/>`_, `GitHub\n<https://github.com/machinelearningmindset>`_, `Twitter\n<https://twitter.com/machinemindset>`_]\n\n**Supervisor**: Amirsina Torfi [`GitHub\n<https://github.com/astorfi>`_, `Personal Website\n<https://astorfi.github.io/>`_, `Linkedin\n<https://www.linkedin.com/in/amirsinatorfi/>`_ ]\n\n**Developers**: Brendan Sherman\\*, James E Hopkins\\* [`Linkedin <https://www.linkedin.com/in/jhopk>`_], Zac Smith [`Linkedin <https://www.linkedin.com/in/zac-smith-a7bb60185/i>`_]\n\n**NOTE**: This project has been developed as a capstone project offered by [`CS 4624 Multimedia/ Hypertext course at Virginia Tech <https://vtechworks.lib.vt.edu/handle/10919/90655>`_] and\nSupervised and supported by [`Machine Learning Mindset <https://machinelearningmindset.com/>`_].\n\n\\*: equally contributed\n\n======================\nCitation\n======================\n\nIf you found this course useful, please kindly consider citing it as below:\n\n.. code:: shell\n\n    @software{amirsina_torfi_2019_3585763,\n      author       = {Amirsina Torfi and\n                      Brendan Sherman and\n                      Jay Hopkins and\n                      Eric Wynn and\n                      hokie45 and\n                      Frederik De Bleser and\n                      \xe6\x9d\x8e\xe6\x98\x8e\xe5\xb2\xb3 and\n                      Samuel Husso and\n                      Alain},\n      title        = {{machinelearningmindset/machine-learning-course: \n                       Machine Learning with Python}},\n      month        = dec,\n      year         = 2019,\n      publisher    = {Zenodo},\n      version      = {1.0},\n      doi          = {10.5281/zenodo.3585763},\n      url          = {https://doi.org/10.5281/zenodo.3585763}\n    }\n'"
25,JustFollowUs/Machine-Learning,JustFollowUs,,2016-12-16 06:32:18,2020-06-18 13:55:18,,829,2730,"b'# \xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0Machine-Learning\n\n## \xe4\xb8\xbb\xe8\xa6\x81\xe5\x86\x85\xe5\xae\xb9\n- [\xe5\x89\x8d\xe8\xa8\x80](#preparation) \n- [\xe8\xaf\xbe\xe7\xa8\x8b\xe5\x88\x97\xe8\xa1\xa8](#curriculum)\n- [\xe6\x8e\xa8\xe8\x8d\x90\xe5\xad\xa6\xe4\xb9\xa0\xe8\xb7\xaf\xe7\xba\xbf](#learning_route)\n - [\xe6\x95\xb0\xe5\xad\xa6\xe5\x9f\xba\xe7\xa1\x80\xe5\x88\x9d\xe7\xba\xa7](#math_basic)\n - [\xe7\xa8\x8b\xe5\xba\x8f\xe8\xaf\xad\xe8\xa8\x80\xe8\x83\xbd\xe5\x8a\x9b](#programming_basic) \n - [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xaf\xbe\xe7\xa8\x8b\xe5\x88\x9d\xe7\xba\xa7](#machine_learning_basic)\n - [\xe6\x95\xb0\xe5\xad\xa6\xe5\x9f\xba\xe7\xa1\x80\xe4\xb8\xad\xe7\xba\xa7](#math_median)\n - [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xaf\xbe\xe7\xa8\x8b\xe4\xb8\xad\xe7\xba\xa7](#machine_learning_median)\n\xc2\xa0\n- [\xe6\x8e\xa8\xe8\x8d\x90\xe4\xb9\xa6\xe7\xb1\x8d\xe5\x88\x97\xe8\xa1\xa8](#booklists)\n- [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe4\xb8\x93\xe9\xa1\xb9\xe9\xa2\x86\xe5\x9f\x9f\xe5\xad\xa6\xe4\xb9\xa0](#special_learning)\n- [\xe8\x87\xb4\xe8\xb0\xa2](#many_thanks)\n\n## <h2 id=""preparation"">\xe5\x89\x8d\xe8\xa8\x80</h2>\n \xc2\xa0 \xe6\x88\x91\xe4\xbb\xac\xe8\xa6\x81\xe6\xb1\x82\xe6\x8a\x8a\xe8\xbf\x99\xe4\xba\x9b\xe8\xaf\xbe\xe7\xa8\x8b\xe7\x9a\x84\xe6\x89\x80\xe6\x9c\x89Notes,Slides\xe4\xbb\xa5\xe5\x8f\x8a\xe4\xbd\x9c\xe8\x80\x85\xe5\xbc\xba\xe7\x83\x88\xe6\x8e\xa8\xe8\x8d\x90\xe7\x9a\x84\xe8\xae\xba\xe6\x96\x87\xe7\x9c\x8b\xe6\x87\x82\xe7\x9c\x8b\xe6\x98\x8e\xe7\x99\xbd\xef\xbc\x8c\xe5\xb9\xb6\xe5\xae\x8c\xe6\x88\x90\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe8\x80\x81\xe5\xb8\x88\xe5\xb8\x83\xe7\xbd\xae\xe7\x9a\x84\xe4\xb9\xa0\xe9\xa2\x98\xef\xbc\x8c\xe8\x80\x8c\xe6\x8e\xa8\xe8\x8d\x90\xe7\x9a\x84\xe4\xb9\xa6\xe7\xb1\x8d\xe6\x98\xaf\xe4\xb8\x8d\xe5\x81\x9a\xe8\xa6\x81\xe6\xb1\x82\xe7\x9a\x84\xef\xbc\x8c\xe5\xa6\x82\xe6\x9e\x9c\xe6\x9c\x89\xe4\xba\x9b\xe4\xb9\xa6\xe7\xb1\x8d\xe6\x98\xaf\xe9\x9c\x80\xe8\xa6\x81\xe7\x9c\x8b\xe5\xae\x8c\xe7\x9a\x84\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe4\xbc\x9a\xe8\xbf\x9b\xe8\xa1\x8c\xe9\xa2\x9d\xe5\xa4\x96\xe7\x9a\x84\xe8\xaf\xb4\xe6\x98\x8e\xe3\x80\x82\n\n## <h2 id=""curriculum"">\xe8\xaf\xbe\xe7\xa8\x8b\xe5\x88\x97\xe8\xa1\xa8</h2>\n\n\xe8\xaf\xbe\xe7\xa8\x8b | \xe6\x9c\xba\xe6\x9e\x84 | \xe5\x8f\x82\xe8\x80\x83\xe4\xb9\xa6 | Notes\xe7\xad\x89\xe5\x85\xb6\xe4\xbb\x96\xe8\xb5\x84\xe6\x96\x99\n:-- | :--: | :--: | :--:\n[\xe5\x8d\x95\xe5\x8f\x98\xe9\x87\x8f\xe5\xbe\xae\xe7\xa7\xaf\xe5\x88\x86](http://open.163.com/movie/2006/8/M/L/M6GLI5A07_M6GLJH1ML.html) |  MIT | [Calculus with Analytic Geometry](https://www.amazon.com/exec/obidos/ASIN/0070576424/ref=nosim/mitopencourse-20)  | [\xe9\x93\xbe\xe6\x8e\xa5](https://ocw.mit.edu/courses/mathematics/18-01-single-variable-calculus-fall-2006/)\xc2\xa0\n[\xe5\xa4\x9a\xe5\x8f\x98\xe9\x87\x8f\xe5\xbe\xae\xe7\xa7\xaf\xe5\x88\x86](http://open.163.com/special/opencourse/multivariable.html)  |  MIT | [Multivariable Calculus](https://www.amazon.com/exec/obidos/ASIN/0130339679/ref=nosim/mitopencourse-20) | [\xe9\x93\xbe\xe6\x8e\xa5](https://ocw.mit.edu/courses/mathematics/18-02-multivariable-calculus-fall-2007/)\n[\xe7\xba\xbf\xe6\x80\xa7\xe4\xbb\xa3\xe6\x95\xb0](http://open.163.com/special/opencourse/daishu.html)| MIT | [Introduction to Linear Algebra](http://math.mit.edu/~gs/linearalgebra/) |  [\xe9\x93\xbe\xe6\x8e\xa5](https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/study-materials/)\n[\xe7\xbb\x9f\xe8\xae\xa1\xe5\x85\xa5\xe9\x97\xa8](http://open.163.com/movie/2011/6/6/0/M82IC6GQU_M83J9IK60.html) | \xe5\x8f\xaf\xe6\xb1\x97\xe5\xad\xa6\xe9\x99\xa2 | \xe6\x9a\x82\xe6\x97\xa0 | \xe6\x9a\x82\xe6\x97\xa0\n\xe6\xa6\x82\xe7\x8e\x87\xe8\xae\xba\xe5\x85\xa5\xe9\x97\xa8: [\xe9\x93\xbe\xe6\x8e\xa51](http://mooc.guokr.com/course/461/%E6%A9%9F%E7%8E%87/),[\xe9\x93\xbe\xe6\x8e\xa52](https://www.youtube.com/watch?v=GwSEguqJj6U&index=1&list=PLtvno3VRDR_jMAJcNY1n4pnP5kXtPOmVk)| NTU | \xe6\x9a\x82\xe6\x97\xa0 | \xe6\x9a\x82\xe6\x97\xa0\n[\xe6\xa6\x82\xe7\x8e\x87\xe4\xb8\x8e\xe7\xbb\x9f\xe8\xae\xa1](https://www.youtube.com/watch?v=j9WZyLZCBzs&list=PLQ3khvAsNhargDx0dG1cQXOrA2u3JsFKc)| MIT | [Introduction to Probability](https://www.amazon.com/exec/obidos/ASIN/188652923X/ref=nosim/mitopencourse-20) | [\xe9\x93\xbe\xe6\x8e\xa5](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-041-probabilistic-systems-analysis-and-applied-probability-fall-2010/tutorials/)\n\xe7\x9f\xa9\xe9\x98\xb5\xe8\xae\xba | \xe6\x9a\x82\xe6\x97\xa0 | [\xe7\x9f\xa9\xe9\x98\xb5\xe8\xae\xba](https://www.amazon.cn/%E7%9F%A9%E9%98%B5%E8%AE%BA-%E6%88%B4%E5%8D%8E/dp/B00116BRO0/ref=sr_1_1?s=books&ie=UTF8&qid=1478614198&sr=1-1&keywords=%E6%88%B4%E5%8D%8E%EF%BC%8C+%E7%9F%A9%E9%98%B5%E8%AE%BA) | \xe6\x9a\x82\xe6\x97\xa0 \n[\xe5\x87\xb8\xe4\xbc\x98\xe5\x8c\x961](https://lagunita.stanford.edu/courses/Engineering/CVX101/Winter2014/about)| Stanford | [Convex Optimization](http://www.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf) | [\xe9\x93\xbe\xe6\x8e\xa5](http://stanford.edu/class/ee364a/index.html)\n[\xe5\x87\xb8\xe4\xbc\x98\xe5\x8c\x962](https://www.youtube.com/watch?v=U3lJAObbMFI&list=PL3940DD956CDF0622&index=20)| Stanford | \xe6\x9a\x82\xe6\x97\xa0 |  [\xe9\x93\xbe\xe6\x8e\xa5](http://stanford.edu/class/ee364b/)\n[\xe7\xbb\x9f\xe8\xae\xa1\xe5\xad\xa6\xe4\xb9\xa0\xe5\x85\xa5\xe9\x97\xa8](https://lagunita.stanford.edu/courses/HumanitiesSciences/StatLearning/Winter2016/about)| Stanford | [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/) | [\xe9\x93\xbe\xe6\x8e\xa5](https://lagunita.stanford.edu/courses/HumanitiesSciences/StatLearning/Winter2016/about)\n[\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x9f\xba\xe7\x9f\xb3](https://www.coursera.org/instructor/htlin)| NTU | [Learning from Data](https://www.amazon.com/gp/product/1600490069) | [\xe9\x93\xbe\xe6\x8e\xa5](https://www.csie.ntu.edu.tw/~htlin/course/mlfound16fall/)\n[\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x8a\x80\xe6\xb3\x95](https://www.coursera.org/instructor/htlin)| NTU | \xe6\x9a\x82\xe6\x97\xa0 | [\xe9\x93\xbe\xe6\x8e\xa5](https://www.csie.ntu.edu.tw/~htlin/course/ml15fall/)\n[\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0](https://www.youtube.com/watch?v=mbyG85GZ0PI&index=1&list=PLD63A284B7615313A)| Caltech | [Learning from Data](https://www.amazon.com/gp/product/1600490069) | [\xe9\x93\xbe\xe6\x8e\xa5](http://work.caltech.edu/lectures.html)\n[\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0(matlab)](http://open.163.com/movie/2008/1/M/C/M6SGF6VB4_M6SGHFBMC.html)| Stanford |\xe6\x9a\x82\xe6\x97\xa0| [\xe9\x93\xbe\xe6\x8e\xa5](http://cs229.stanford.edu/materials.html)\nPython\xe7\xa8\x8b\xe5\xba\x8f\xe8\xaf\xad\xe8\xa8\x80\xe8\xae\xbe\xe8\xae\xa1| \xe6\x9a\x82\xe6\x97\xa0 | \xe6\x9a\x82\xe6\x97\xa0 | \xe6\x9a\x82\xe6\x97\xa0\nMatlab\xe7\xa8\x8b\xe5\xba\x8f\xe8\xaf\xad\xe8\xa8\x80\xe8\xae\xbe\xe8\xae\xa1| \xe6\x9a\x82\xe6\x97\xa0 | \xe6\x9a\x82\xe6\x97\xa0 | \xe6\x9a\x82\xe6\x97\xa0\n\n## <h2 id=""learning_route"">\xe6\x8e\xa8\xe8\x8d\x90\xe5\xad\xa6\xe4\xb9\xa0\xe8\xb7\xaf\xe7\xba\xbf</h2>\n### <h3 id=""math_basic"">\xe6\x95\xb0\xe5\xad\xa6\xe5\x9f\xba\xe7\xa1\x80\xe5\x88\x9d\xe7\xba\xa7</h3>\n\n\xe8\xaf\xbe\xe7\xa8\x8b | \xe6\x9c\xba\xe6\x9e\x84 | \xe5\x8f\x82\xe8\x80\x83\xe4\xb9\xa6 | Notes\xe7\xad\x89\xe5\x85\xb6\xe4\xbb\x96\xe8\xb5\x84\xe6\x96\x99\n:-- | :--: | :--: | :--:\n[\xe5\x8d\x95\xe5\x8f\x98\xe9\x87\x8f\xe5\xbe\xae\xe7\xa7\xaf\xe5\x88\x86](http://open.163.com/movie/2006/8/M/L/M6GLI5A07_M6GLJH1ML.html) |  MIT | [Calculus with Analytic Geometry](https://www.amazon.com/exec/obidos/ASIN/0070576424/ref=nosim/mitopencourse-20)  | [\xe9\x93\xbe\xe6\x8e\xa5](https://ocw.mit.edu/courses/mathematics/18-01-single-variable-calculus-fall-2006/)\xc2\xa0\n[\xe5\xa4\x9a\xe5\x8f\x98\xe9\x87\x8f\xe5\xbe\xae\xe7\xa7\xaf\xe5\x88\x86](http://open.163.com/special/opencourse/multivariable.html)  |  MIT | [Multivariable Calculus](https://www.amazon.com/exec/obidos/ASIN/0130339679/ref=nosim/mitopencourse-20) | [\xe9\x93\xbe\xe6\x8e\xa5](https://ocw.mit.edu/courses/mathematics/18-02-multivariable-calculus-fall-2007/)\n[\xe7\xba\xbf\xe6\x80\xa7\xe4\xbb\xa3\xe6\x95\xb0](http://open.163.com/special/opencourse/daishu.html)| MIT | [Introduction to Linear Algebra](http://math.mit.edu/~gs/linearalgebra/) |  [\xe9\x93\xbe\xe6\x8e\xa5](https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/study-materials/)\n[\xe7\xbb\x9f\xe8\xae\xa1\xe5\x85\xa5\xe9\x97\xa8](http://open.163.com/movie/2011/6/6/0/M82IC6GQU_M83J9IK60.html) | \xe5\x8f\xaf\xe6\xb1\x97\xe5\xad\xa6\xe9\x99\xa2 | \xe6\x9a\x82\xe6\x97\xa0 | \xe6\x9a\x82\xe6\x97\xa0\n\xe6\xa6\x82\xe7\x8e\x87\xe8\xae\xba\xe5\x85\xa5\xe9\x97\xa8: [\xe9\x93\xbe\xe6\x8e\xa51](http://mooc.guokr.com/course/461/%E6%A9%9F%E7%8E%87/),[\xe9\x93\xbe\xe6\x8e\xa52](https://www.youtube.com/watch?v=GwSEguqJj6U&index=1&list=PLtvno3VRDR_jMAJcNY1n4pnP5kXtPOmVk)| NTU | \xe6\x9a\x82\xe6\x97\xa0 | \xe6\x9a\x82\xe6\x97\xa0\n[\xe6\xa6\x82\xe7\x8e\x87\xe4\xb8\x8e\xe7\xbb\x9f\xe8\xae\xa1](https://www.youtube.com/watch?v=j9WZyLZCBzs&list=PLQ3khvAsNhargDx0dG1cQXOrA2u3JsFKc)| MIT | [Introduction to Probability](https://www.amazon.com/exec/obidos/ASIN/188652923X/ref=nosim/mitopencourse-20) | [\xe9\x93\xbe\xe6\x8e\xa5](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-041-probabilistic-systems-analysis-and-applied-probability-fall-2010/tutorials/)\n\n\n### <h3 id=""programming_basic"">\xe7\xa8\x8b\xe5\xba\x8f\xe8\xaf\xad\xe8\xa8\x80\xe8\x83\xbd\xe5\x8a\x9b</h3>\n\xe8\x80\x83\xe8\x99\x91\xe5\x88\xb0\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9a\x84\xe6\xa0\xb8\xe5\xbf\x83\xe6\x98\xaf\xe9\x87\x8c\xe9\x9d\xa2\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\xa6\xe5\x8e\x9f\xe7\x90\x86\xe5\x92\x8c\xe7\xae\x97\xe6\xb3\x95\xe6\x80\x9d\xe6\x83\xb3\xef\xbc\x8c\xe7\xa8\x8b\xe5\xba\x8f\xe8\xaf\xad\xe8\xa8\x80\xe7\x9b\xae\xe5\x89\x8d\xe4\xb8\xbb\xe8\xa6\x81\xe6\x98\xaf\xe5\xb8\xae\xe5\x8a\xa9\xe5\xa4\xa7\xe5\xae\xb6\xe8\xbe\x83\xe5\xa5\xbd\xe7\x9a\x84\xe5\xae\x8c\xe6\x88\x90\xe8\xaf\xbe\xe5\x90\x8e\xe4\xbd\x9c\xe4\xb8\x9a\xe4\xbb\xa5\xe5\x8f\x8a\xe5\xae\x9e\xe7\x8e\xb0\xe8\x87\xaa\xe5\xb7\xb1\xe7\x9a\x84\xe4\xb8\x80\xe4\xba\x9bidea\xef\xbc\x8c\xe6\xad\xa4\xe5\xa4\x84\xe6\x88\x91\xe4\xbb\xac\xe4\xbb\x85\xe4\xbb\x85\xe7\xbb\x99\xe5\x87\xba\xe6\x8e\xa8\xe8\x8d\x90\xe7\x9a\x84\xe5\x8f\x82\xe8\x80\x83\xe5\xad\xa6\xe4\xb9\xa0\xe9\x93\xbe\xe6\x8e\xa5\xef\xbc\x8c\xe5\xa4\xa7\xe5\xae\xb6\xe6\x8e\x8c\xe6\x8f\xa1\xe4\xb8\x80\xe4\xba\x9b\xe5\xb8\xb8\xe7\x94\xa8\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9d\x97\xe5\x8d\xb3\xe5\x8f\xaf\xef\xbc\x8c\xe5\x8d\xb3\xe5\xae\x8c\xe6\x88\x90\xe5\x8f\x82\xe8\x80\x83\xe5\xad\xa6\xe4\xb9\xa0\xe9\x93\xbe\xe6\x8e\xa5\xe9\x83\xa8\xe5\x88\x86\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9\xe5\x8d\xb3\xe5\x8f\xaf\xef\xbc\x8c\xe6\x8e\xa8\xe8\x8d\x90\xe4\xb9\xa6\xe7\xb1\x8d\xe6\xaf\x94\xe8\xbe\x83\xe7\xbb\x8f\xe5\x85\xb8\xef\xbc\x8c\xe4\xbd\x86\xe4\xb8\x8d\xe5\x81\x9a\xe8\xa6\x81\xe6\xb1\x82\xe3\x80\x82\n\n\xe8\xaf\xbe\xe7\xa8\x8b | \xe5\x8f\x82\xe8\x80\x83\xe5\xad\xa6\xe4\xb9\xa0\xe9\x93\xbe\xe6\x8e\xa5 | \xe6\x8e\xa8\xe8\x8d\x90\xe4\xb9\xa6\xe7\xb1\x8d\n:-- | :--: | :--:\nPython\xe7\xa8\x8b\xe5\xba\x8f\xe8\xaf\xad\xe8\xa8\x80\xe8\xae\xbe\xe8\xae\xa1| [\xe9\x93\xbe\xe6\x8e\xa5](http://cs231n.github.io/python-numpy-tutorial/) | \xe6\x9a\x82\xe6\x97\xa0 \xc2\xa0\nMatlab\xe7\xa8\x8b\xe5\xba\x8f\xe8\xaf\xad\xe8\xa8\x80\xe8\xae\xbe\xe8\xae\xa1| \xe6\x9a\x82\xe6\x97\xa0 | \xe6\x9a\x82\xe6\x97\xa0 \nR\xe7\xa8\x8b\xe5\xba\x8f\xe8\xaf\xad\xe8\xa8\x80\xe8\xae\xbe\xe8\xae\xa1| \xe6\x9a\x82\xe6\x97\xa0 | \xe6\x9a\x82\xe6\x97\xa0 \n\n\n### <h3 id=""machine_learning_basic"">\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xaf\xbe\xe7\xa8\x8b\xe5\x88\x9d\xe7\xba\xa7</h3>\n\xe8\xaf\xbe\xe7\xa8\x8b | \xe6\x9c\xba\xe6\x9e\x84 | \xe5\x8f\x82\xe8\x80\x83\xe4\xb9\xa6 | Notes\xe7\xad\x89\xe5\x85\xb6\xe4\xbb\x96\xe8\xb5\x84\xe6\x96\x99\n:-- | :--: | :--: | :--:\n[\xe7\xbb\x9f\xe8\xae\xa1\xe5\xad\xa6\xe4\xb9\xa0\xe5\x85\xa5\xe9\x97\xa8](https://lagunita.stanford.edu/courses/HumanitiesSciences/StatLearning/Winter2016/about)| Stanford | [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/) | [\xe9\x93\xbe\xe6\x8e\xa5](https://lagunita.stanford.edu/courses/HumanitiesSciences/StatLearning/Winter2016/about)\n[\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x85\xa5\xe9\x97\xa8](https://www.coursera.org/learn/machine-learning) | Coursera | \xe6\x9a\x82\xe6\x97\xa0 | [\xe9\x93\xbe\xe6\x8e\xa5](https://www.coursera.org/learn/machine-learning)\n\n\n### <h3 id=""math_median"">\xe6\x95\xb0\xe5\xad\xa6\xe5\x9f\xba\xe7\xa1\x80\xe4\xb8\xad\xe7\xba\xa7</h3>\n\n\xe8\xaf\xbe\xe7\xa8\x8b | \xe6\x9c\xba\xe6\x9e\x84 | \xe5\x8f\x82\xe8\x80\x83\xe4\xb9\xa6 | Notes\xe7\xad\x89\xe5\x85\xb6\xe4\xbb\x96\xe8\xb5\x84\xe6\x96\x99\n:-- | :--: | :--: | :--:\n\xe7\x9f\xa9\xe9\x98\xb5\xe8\xae\xba | \xe6\x9a\x82\xe6\x97\xa0 | [\xe7\x9f\xa9\xe9\x98\xb5\xe8\xae\xba](https://www.amazon.cn/%E7%9F%A9%E9%98%B5%E8%AE%BA-%E6%88%B4%E5%8D%8E/dp/B00116BRO0/ref=sr_1_1?s=books&ie=UTF8&qid=1478614198&sr=1-1&keywords=%E6%88%B4%E5%8D%8E%EF%BC%8C+%E7%9F%A9%E9%98%B5%E8%AE%BA) | \xe6\x9a\x82\xe6\x97\xa0 \n[\xe5\x87\xb8\xe4\xbc\x98\xe5\x8c\x961](https://lagunita.stanford.edu/courses/Engineering/CVX101/Winter2014/about)| Stanford | [Convex Optimization](http://www.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf) | [\xe9\x93\xbe\xe6\x8e\xa5](http://stanford.edu/class/ee364a/index.html)\n[\xe5\x87\xb8\xe4\xbc\x98\xe5\x8c\x962](https://www.youtube.com/watch?v=U3lJAObbMFI&list=PL3940DD956CDF0622&index=20)| Stanford | \xe6\x9a\x82\xe6\x97\xa0 |  [\xe9\x93\xbe\xe6\x8e\xa5](http://stanford.edu/class/ee364b/)\n\n\xe4\xb8\x8b\xe9\x9d\xa2\xe8\xbf\x99\xe4\xb8\xaa\xe6\xa6\x82\xe8\xbf\xb0\xe5\xbf\x85\xe9\xa1\xbb\xe7\x9c\x8b\xe5\xae\x8c\xe3\x80\x82\n- [Convex Optimization: Algorithms and Complexity](https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1405.4980)\n\n### <h3 id=""machine_learning_median"">\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xaf\xbe\xe7\xa8\x8b\xe4\xb8\xad\xe7\xba\xa7</h3>\n \xc2\xa0 \xe6\xad\xa4\xe5\xa4\x84NTU\xe5\x92\x8cCaltech\xe4\xb8\xa4\xe4\xb8\xaa\xe5\xa4\xa7\xe5\xad\xa6\xe7\x9a\x84\xe8\xaf\xbe\xe7\xa8\x8b\xe6\x98\xaf\xe7\x94\xb1\xe3\x80\x8aLearning from Data\xe3\x80\x8b\xe4\xb8\x80\xe4\xb9\xa6\xe7\x9a\x84\xe4\xb8\xa4\xe4\xb8\xaa\xe4\xb8\x8d\xe5\x90\x8c\xe7\x9a\x84\xe4\xbd\x9c\xe8\x80\x85\xe8\xae\xb2\xe7\x9a\x84\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xe4\xbb\x85\xe4\xbb\x85\xe5\x8f\xaa\xe9\x9c\x80\xe9\x80\x89\xe6\x8b\xa9\xe4\xb8\x80\xe4\xb8\xaa\xe5\xae\x8c\xe6\x88\x90\xe5\x8d\xb3\xe5\x8f\xaf\xef\xbc\x8c\xe6\xb3\xa8\xe6\x84\x8f\xef\xbc\x9a\xe5\xa6\x82\xe6\x9e\x9c\xe9\x80\x89\xe6\x8b\xa9\xe5\xae\x8c\xe6\x88\x90NTU\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xaf\xbe\xe7\xa8\x8b\xef\xbc\x8c\xe5\x88\x99**NTU\xe7\x9a\x84\xe2\x80\x9c\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x9f\xba\xe7\x9f\xb3\xe2\x80\x9d\xe5\x92\x8c\xe2\x80\x9c\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x8a\x80\xe6\xb3\x95\xe2\x80\x9d\xe9\x9c\x80\xe5\x90\x8c\xe6\x97\xb6\xe5\xae\x8c\xe6\x88\x90\xe3\x80\x82**\xe3\x80\x82\n\n\xe8\xaf\xbe\xe7\xa8\x8b | \xe6\x9c\xba\xe6\x9e\x84 | \xe5\x8f\x82\xe8\x80\x83\xe4\xb9\xa6 | Notes\xe7\xad\x89\xe5\x85\xb6\xe4\xbb\x96\xe8\xb5\x84\xe6\x96\x99\n:-- | :--: | :--: | :--:\n[\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x9f\xba\xe7\x9f\xb3](https://www.coursera.org/instructor/htlin)| NTU | [Learning from Data](https://www.amazon.com/gp/product/1600490069) | [\xe9\x93\xbe\xe6\x8e\xa5](https://www.csie.ntu.edu.tw/~htlin/course/mlfound16fall/)\n[\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x8a\x80\xe6\xb3\x95](https://www.coursera.org/instructor/htlin)| NTU | \xe6\x9a\x82\xe6\x97\xa0 | [\xe9\x93\xbe\xe6\x8e\xa5](https://www.csie.ntu.edu.tw/~htlin/course/ml15fall/)\n[\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0](http://open.163.com/movie/2008/1/M/C/M6SGF6VB4_M6SGHFBMC.html)| Stanford |\xe6\x9a\x82\xe6\x97\xa0| [\xe9\x93\xbe\xe6\x8e\xa5](http://cs229.stanford.edu/materials.html)\n[\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0](https://www.youtube.com/watch?v=mbyG85GZ0PI&index=1&list=PLD63A284B7615313A)| Caltech | [Learning from Data](https://www.amazon.com/gp/product/1600490069) | [\xe9\x93\xbe\xe6\x8e\xa5](http://work.caltech.edu/lectures.html)\n\n\n## <h2 id=""booklists"">\xe6\x8e\xa8\xe8\x8d\x90\xe4\xb9\xa6\xe7\xb1\x8d\xe5\x88\x97\xe8\xa1\xa8</h2>\n \xc2\xa0 \xe4\xbb\xa5\xe4\xb8\x8b\xe6\x8e\xa8\xe8\x8d\x90\xe7\x9a\x84\xe4\xb9\xa6\xe7\xb1\x8d\xe9\x83\xbd\xe6\x98\xaf\xe5\x85\xac\xe8\xae\xa4\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe9\xa2\x86\xe5\x9f\x9f\xe7\x95\x8c\xe7\x9a\x84\xe5\xa5\xbd\xe4\xb9\xa6\xef\xbc\x8c\xe5\xbb\xba\xe8\xae\xae**\xe4\xb8\x80\xe8\x88\xac\xe9\x9a\xbe\xe5\xba\xa6\xe7\x9a\x84\xe4\xb9\xa6\xe7\xb1\x8d\xe8\x87\xb3\xe5\xb0\x91\xe8\xaf\xa6\xe7\xbb\x86\xe9\x98\x85\xe8\xaf\xbb\xe4\xb8\x80\xe6\x9c\xac\xef\xbc\x8c\xe5\xbb\xba\xe8\xae\xae\xe7\x9c\x8b\xe4\xb8\xa4\xe6\x9c\xac**\xef\xbc\x8c\xe8\x80\x8c\xe8\xbe\x83\xe9\x9a\xbe\xe7\x9a\x84\xe4\xb9\xa6\xe7\xb1\x8d\xe4\xb8\x8d\xe5\x81\x9a\xe4\xbb\xbb\xe4\xbd\x95\xe8\xa6\x81\xe6\xb1\x82\xef\xbc\x8c\xe5\xa4\xa7\xe5\xae\xb6\xe5\x8f\xaf\xe4\xbb\xa5\xe5\x9c\xa8\xe5\xad\xa6\xe6\x9c\x89\xe4\xbd\x99\xe5\x8a\x9b\xe6\x97\xb6\xe7\xbb\x86\xe7\xbb\x86\xe5\x93\x81\xe5\x91\xb3\xe7\xbb\x8f\xe5\x85\xb8\xe3\x80\x82\n\n\xe4\xb9\xa6\xe5\x90\x8d | \xe9\x9a\xbe\xe5\xba\xa6\n:-- | :--: \n[\xe7\xbb\x9f\xe8\xae\xa1\xe5\xad\xa6\xe4\xb9\xa0\xe6\x96\xb9\xe6\xb3\x95](https://www.amazon.cn/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E6%9D%8E%E8%88%AA/dp/B007TSFMTA) | \xe4\xb8\x80\xe8\x88\xac\n [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/) | \xe4\xb8\x80\xe8\x88\xac\n[Machine Learning](https://www.amazon.com/gp/product/0071154671?ie=UTF8&tag=jefork-20&linkCode=as2&camp=1789&creative=9325&creativeASIN=0071154671) | \xe4\xb8\x80\xe8\x88\xac\n[Learning from Data](https://www.amazon.com/gp/product/1600490069) | \xe4\xb8\x80\xe8\x88\xac\xef\xbc\x8c[\xe9\x85\x8d\xe5\xa5\x97\xe8\xae\xb2\xe4\xb9\x89](https://work.caltech.edu/telecourse.html)\n[Pattern Recognition and Machine Learning](https://www.amazon.com/Pattern-Recognition-Learning-Information-Statistics/dp/0387310738/ref=pd_sim_14_1?ie=UTF8&dpID=61f0EXfMRvL&dpSrc=sims&preST=_AC_UL160_SR118%2C160_&refRID=119X50P5F0DFA339S9DR) | \xe8\xbe\x83\xe9\x9a\xbe(\xe5\x81\x8f\xe8\xb4\x9d\xe5\x8f\xb6\xe6\x96\xaf),[\xe9\x85\x8d\xe5\xa5\x97\xe8\xae\xb2\xe4\xb9\x89](http://cs.brown.edu/courses/csci1420/lectures.html)\n[The Elements of Statistical Learning](https://www.amazon.com/The-Elements-Statistical-Learning-Prediction/dp/0387848576/ref=pd_sim_14_2?ie=UTF8&dpID=41LeU3HcBdL&dpSrc=sims&preST=_AC_UL160_SR103%2C160_&refRID=119X50P5F0DFA339S9DR) | \xe8\xbe\x83\xe9\x9a\xbe\n[Understanding Machine Learning:From Theory to Algorithms](http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf) | \xe8\xbe\x83\xe9\x9a\xbe\n[Machine Learning: A probabilistic approach](https://www.amazon.com/Machine-Learning-Probabilistic-Perspective-Computation/dp/0262018020) | \xe8\xbe\x83\xe9\x9a\xbe\n\n## <h3 id=""special_learning"">\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe4\xb8\x93\xe9\xa1\xb9\xe9\xa2\x86\xe5\x9f\x9f\xe5\xad\xa6\xe4\xb9\xa0</h3>\n\xe5\xa6\x82\xe6\x9e\x9c\xe6\x82\xa8\xe5\xb7\xb2\xe7\xbb\x8f\xe5\xae\x8c\xe6\x88\x90\xe4\xba\x86\xe4\xb8\x8a\xe8\xbf\xb0\xe7\x9a\x84\xe6\x89\x80\xe6\x9c\x89\xe7\xa7\x91\xe7\x9b\xae\xef\xbc\x8c\xe6\x81\xad\xe5\x96\x9c\xe6\x82\xa8\xe5\xb7\xb2\xe7\xbb\x8f\xe6\x8b\xa5\xe6\x9c\x89\xe5\x8d\x81\xe5\x88\x86\xe6\x89\x8e\xe5\xae\x9e\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x9f\xba\xe7\xa1\x80\xe4\xba\x86\xef\xbc\x8c\xe5\xb7\xb2\xe7\xbb\x8f\xe6\x98\xaf\xe4\xb8\x80\xe5\x90\x8d\xe5\x90\x88\xe6\xa0\xbc\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x88\x90\xe5\x91\x98\xe4\xba\x86\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe8\xbe\x83\xe4\xb8\xba\xe9\xa1\xba\xe5\x88\xa9\xe7\x9a\x84\xe8\xbf\x9b\xe5\x85\xa5\xe4\xb8\x8b\xe9\x9d\xa2\xe6\x9f\x90\xe4\xb8\x80\xe4\xb8\x93\xe9\xa1\xb9\xe9\xa2\x86\xe5\x9f\x9f\xe8\xbf\x9b\xe8\xa1\x8c\xe8\xbe\x83\xe4\xb8\xba\xe6\xb7\xb1\xe5\x85\xa5\xe7\xa0\x94\xe7\xa9\xb6,\xe5\x9b\xa0\xe4\xb8\xba\xe5\xb9\xb6\xe4\xb8\x8d\xe6\x98\xaf\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe4\xb8\x93\xe9\xa1\xb9\xe9\xa2\x86\xe5\x9f\x9f\xe9\x83\xbd\xe6\x9c\x89\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe8\xaf\xbe\xe7\xa8\x8b\xe6\x88\x96\xe8\x80\x85\xe4\xb9\xa6\xe7\xb1\x8d\xe7\xad\x89\xe5\xad\xa6\xe4\xb9\xa0\xe8\xb5\x84\xe6\x96\x99\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xe6\xad\xa4\xe5\xa4\x84\xe6\x88\x91\xe4\xbb\xac\xe4\xbb\x85\xe5\x88\x97\xe4\xb8\xbe\xe4\xb8\x80\xe4\xba\x9b\xe6\x88\x91\xe4\xbb\xac\xe7\x9f\xa5\xe9\x81\x93\xe7\x9a\x84\xe4\xb8\x93\xe9\xa1\xb9\xe9\xa2\x86\xe5\x9f\x9f\xe7\x9a\x84\xe5\xad\xa6\xe4\xb9\xa0\xe8\xb5\x84\xe6\x96\x99\xef\xbc\x8c\xe5\xbd\x93\xe7\x84\xb6\xe8\xbf\x99\xe4\xba\x9b\xe9\xa2\x86\xe5\x9f\x9f\xe4\xb8\x8d\xe8\x83\xbd\xe6\xb6\xb5\xe7\x9b\x96\xe6\x89\x80\xe6\x9c\x89\xef\xbc\x8c\xe8\xbf\x98\xe6\x9c\x89\xe5\xbe\x88\xe5\xa4\x9a\xe9\xa2\x86\xe5\x9f\x9f\xe6\xb2\xa1\xe6\x9c\x89\xe6\x95\xb4\xe7\x90\x86\xef\xbc\x88\xe5\xb8\x8c\xe6\x9c\x9b\xe5\xa4\xa7\xe5\xae\xb6\xe4\xb8\x80\xe8\xb5\xb7\xe5\xae\x8c\xe5\x96\x84\xef\xbc\x89\xef\xbc\x8c\xe5\xa6\x82\xe6\x9e\x9c\xe8\xbf\x99\xe4\xba\x9b\xe9\xa2\x86\xe5\x9f\x9f\xe9\x80\x82\xe5\x90\x88\xe4\xbd\xa0\xef\xbc\x8c\xe9\x82\xa3\xe5\xb0\xb1\xe7\xbb\xa7\xe7\xbb\xad\xe5\x8a\xa0\xe6\xb2\xb9\xef\xbc\x81\xe5\xa6\x82\xe6\x9e\x9c\xe4\xb8\x8d\xe6\xb8\x85\xe6\xa5\x9a\xef\xbc\x8c\xe9\x82\xa3\xe4\xb9\x88\xe5\xa4\xa7\xe5\xae\xb6\xe5\x8f\xaf\xe4\xbb\xa5\xe5\x8e\xbb\xe4\xb8\x8b\xe9\x9d\xa2\xe5\x88\x97\xe4\xb8\xbe\xe7\x9a\x84\xe9\xab\x98\xe7\xba\xa7\xe4\xbc\x9a\xe8\xae\xae\xe6\x9c\x9f\xe5\x88\x8a\xe4\xb8\x8a\xe5\x8e\xbb\xe5\xaf\xbb\xe6\x89\xbe\xe8\x87\xaa\xe5\xb7\xb1\xe6\x84\x9f\xe5\x85\xb4\xe8\xb6\xa3\xe7\x9a\x84\xe8\xaf\x9d\xe9\xa2\x98\xe8\xbf\x9b\xe8\xa1\x8c\xe5\xad\xa6\xe4\xb9\xa0\xe7\xa0\x94\xe7\xa9\xb6\xe3\x80\x82\n\n### <h3 id=""special_learning_data"">\xe4\xb8\x80\xe4\xba\x9b\xe4\xb8\x93\xe9\xa1\xb9\xe9\xa2\x86\xe5\x9f\x9f\xe8\xb5\x84\xe6\x96\x99</h3>\n- [\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0](https://github.com/JustFollowUs/Deep-Learning)\n- [\xe5\x9b\xbe\xe6\xa8\xa1\xe5\x9e\x8b](https://github.com/JustFollowUs/Probabilistic-graphical-models)\n- [\xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0](https://github.com/JustFollowUs/Reinforcement-Learning)\n- [Hash](http://cs.nju.edu.cn/lwj/L2H.html)\xc2\xa0\n- [\xe7\x90\x86\xe8\xae\xba\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0](https://github.com/JustFollowUs/Theoretical-Machine-Learning/)\n- \xe5\x85\xb6\xe4\xbb\x96(\xe5\xb0\x9a\xe6\x9c\xaa\xe5\xae\x8c\xe5\x96\x84)\n\n### <h3 id=""special_learning_data"">\xe9\xa2\x86\xe5\x9f\x9f\xe4\xbc\x9a\xe8\xae\xae\xe6\x9c\x9f\xe5\x88\x8a</h3>\n- [NIPS](https://nips.cc/)\n- [ICML](http://icml.cc/)\n- [AAAI](http://www.aaai.org/)\n- [IJCAI](http://www.ijcai.org/)\n- [KDD](http://www.kdd.org/)\n- [ICDM](http://www.cs.uvm.edu/~icdm/)\n- [COLT](http://www.learningtheory.org/)\n- \xe5\x85\xb6\xe4\xbb\x96(\xe5\xb0\x9a\xe6\x9c\xaa\xe5\xae\x8c\xe5\x96\x84)\n\n\n## <h2 id=""many_thanks"">\xe8\x87\xb4\xe8\xb0\xa2</h2>\n \xc2\xa0\xe6\x84\x9f\xe8\xb0\xa2\xe5\x8d\x97\xe4\xba\xac\xe5\xa4\xa7\xe5\xad\xa6LAMDA\xe5\xae\x9e\xe9\xaa\x8c\xe7\xbb\x84\xe6\x9d\xa8\xe6\x9d\xa8\xe5\x8d\x9a\xe5\xa3\xab\xe7\x9a\x84\xe5\xbb\xba\xe8\xae\xae\xe4\xb8\x8e\xe8\xb5\x84\xe6\x96\x99\xe7\x9a\x84\xe5\x88\x86\xe4\xba\xab\xe3\x80\x82\n'"
26,timzhang642/3D-Machine-Learning,timzhang642,A resource repository for 3D machine learning,2017-08-12 15:20:54,2020-06-18 19:18:24,,1175,5250,"b'# 3D Machine Learning\nIn recent years, tremendous amount of progress is being made in the field of 3D Machine Learning, which is an interdisciplinary field that fuses computer vision, computer graphics and machine learning. This repo is derived from my study notes and will be used as a place for triaging new research papers. \n\nI\'ll use the following icons to differentiate 3D representations:\n* :camera: Multi-view Images\n* :space_invader: Volumetric\n* :game_die: Point Cloud\n* :gem: Polygonal Mesh\n* :pill: Primitive-based\n\nTo find related papers and their relationships, check out [Connected Papers](https://www.connectedpapers.com/), which provides a neat way to visualize the academic field in a graph representation. \n\n## Get Involved\nTo contribute to this Repo, you may add content through pull requests or open an issue to let me know. \n\n:star:  :star:  :star:  :star:  :star:  :star:  :star:  :star:  :star:  :star:  :star:  :star:<br>\nWe have also created a Slack workplace for people around the globe to ask questions, share knowledge and facilitate collaborations. Together, I\'m sure we can advance this field as a collaborative effort. Join the community with [this link](https://join.slack.com/t/3d-machine-learning/shared_invite/enQtMzUyMTgyNzgwOTgzLTFiYTM4YWFjMTcxY2Q3YjQwMTA3ZGE2OTYwNDRlMDA5NGFmNDU5Njg4ODJhN2YwNmZkMDM4ZTllZWQzNjRjNDc).\n<br>:star:  :star:  :star:  :star:  :star:  :star:  :star:  :star:  :star:  :star:  :star:  :star:\n\n## Table of Contents\n- [Courses](#courses)\n- [Datasets](#datasets)\n  - [3D Models](#3d_models)\n  - [3D Scenes](#3d_scenes)\n- [3D Pose Estimation](#pose_estimation)\n- [Single Object Classification](#single_classification)\n- [Multiple Objects Detection](#multiple_detection)\n- [Scene/Object Semantic Segmentation](#segmentation)\n- [3D Geometry Synthesis/Reconstruction](#3d_synthesis)\n  - [Parametric Morphable Model-based methods](#3d_synthesis_model_based)\n  - [Part-based Template Learning methods](#3d_synthesis_template_based)\n  - [Deep Learning Methods](#3d_synthesis_dl_based)\n- [Texture/Material Analysis and Synthesis](#material_synthesis)\n- [Style Learning and Transfer](#style_transfer)\n- [Scene Synthesis/Reconstruction](#scene_synthesis)\n- [Scene Understanding](#scene_understanding)\n\n<a name=""courses"" />\n\n## Available Courses\n[Stanford CS231A: Computer Vision-From 3D Reconstruction to Recognition (Winter 2018)](http://web.stanford.edu/class/cs231a/)\n\n[UCSD CSE291-I00: Machine Learning for 3D Data (Winter 2018)](https://cse291-i.github.io/index.html)\n\n[Stanford CS468: Machine Learning for 3D Data (Spring 2017)](http://graphics.stanford.edu/courses/cs468-17-spring/)\n\n[MIT 6.838: Shape Analysis (Spring 2017)](http://groups.csail.mit.edu/gdpgroup/6838_spring_2017.html)\n\n[Princeton COS 526: Advanced Computer Graphics  (Fall 2010)](https://www.cs.princeton.edu/courses/archive/fall10/cos526/syllabus.php)\n\n[Princeton CS597: Geometric Modeling and Analysis (Fall 2003)](https://www.cs.princeton.edu/courses/archive/fall03/cs597D/)\n\n[Geometric Deep Learning](http://geometricdeeplearning.com/)\n\n[Paper Collection for 3D Understanding](https://www.cs.princeton.edu/courses/archive/spring15/cos598A/cos598A.html#Estimating)\n\n[CreativeAI: Deep Learning for Graphics](http://geometry.cs.ucl.ac.uk/creativeai/)\n\n<a name=""datasets"" />\n\n## Datasets\nTo see a survey of RGBD datasets, check out Michael Firman\'s [collection](http://www0.cs.ucl.ac.uk/staff/M.Firman//RGBDdatasets/) as well as the associated paper, [RGBD Datasets: Past, Present and Future](https://arxiv.org/pdf/1604.00999.pdf). Point Cloud Library also has a good dataset [catalogue](http://pointclouds.org/media/). \n\n<a name=""3d_models"" />\n\n### 3D Models\n<b>Princeton Shape Benchmark (2003)</b> [[Link]](http://shape.cs.princeton.edu/benchmark/)\n<br>1,814 models collected from the web in .OFF format. Used to evaluating shape-based retrieval and analysis algorithms.\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Princeton%20Shape%20Benchmark%20(2003).jpeg"" /></p>\n\n<b>Dataset for IKEA 3D models and aligned images (2013)</b> [[Link]](http://ikea.csail.mit.edu/)\n<br>759 images and 219 models including Sketchup (skp) and Wavefront (obj) files, good for pose estimation.\n<p align=""center""><img width=""50%"" src=""http://ikea.csail.mit.edu/web_img/ikea_object.png"" /></p>\n\n<b>Open Surfaces: A Richly Annotated Catalog of Surface Appearance (SIGGRAPH 2013)</b> [[Link]](http://opensurfaces.cs.cornell.edu/)\n<br>OpenSurfaces is a large database of annotated surfaces created from real-world consumer photographs. Our annotation framework draws on crowdsourcing to segment surfaces from photos, and then annotate them with rich surface properties, including material, texture and contextual information.\n<p align=""center""><img width=""50%"" src=""http://opensurfaces.cs.cornell.edu/static/img/teaser4-web.jpg"" /></p>\n\n<b>PASCAL3D+ (2014)</b> [[Link]](http://cvgl.stanford.edu/projects/pascal3d.html)\n<br>12 categories, on average 3k+ objects per category, for 3D object detection and pose estimation.\n<p align=""center""><img width=""50%"" src=""http://cvgl.stanford.edu/projects/pascal3d+/pascal3d.png"" /></p>\n\n<b>ModelNet (2015)</b> [[Link]](http://modelnet.cs.princeton.edu/#)\n<br>127915 3D CAD models from 662 categories\n<br>ModelNet10: 4899 models from 10 categories\n<br>ModelNet40: 12311 models from 40 categories, all are uniformly orientated\n<p align=""center""><img width=""50%"" src=""http://3dvision.princeton.edu/projects/2014/ModelNet/thumbnail.jpg"" /></p>\n\n<b>ShapeNet (2015)</b> [[Link]](https://www.shapenet.org/)\n<br>3Million+ models and 4K+ categories. A dataset that is large in scale, well organized and richly annotated.\n<br>ShapeNetCore [[Link]](http://shapenet.cs.stanford.edu/shrec16/): 51300 models for 55 categories.\n<p align=""center""><img width=""50%"" src=""http://msavva.github.io/files/shapenet.png"" /></p>\n\n<b>A Large Dataset of Object Scans (2016)</b> [[Link]](http://redwood-data.org/3dscan/index.html)\n<br>10K scans in RGBD + reconstructed 3D models in .PLY format.\n<p align=""center""><img width=""50%"" src=""http://redwood-data.org/3dscan/img/teaser.jpg"" /></p>\n\n<b>ObjectNet3D: A Large Scale Database for 3D Object Recognition (2016)</b> [[Link]](http://cvgl.stanford.edu/projects/objectnet3d/)\n<br>100 categories, 90,127 images, 201,888 objects in these images and 44,147 3D shapes. \n<br>Tasks: region proposal generation, 2D object detection, joint 2D detection and 3D object pose estimation, and image-based 3D shape retrieval\n<p align=""center""><img width=""50%"" src=""http://cvgl.stanford.edu/projects/objectnet3d/ObjectNet3D.png"" /></p>\n\n<b>Thingi10K: A Dataset of 10,000 3D-Printing Models (2016)</b> [[Link]](https://ten-thousand-models.appspot.com/)\n<br>10,000 models from featured \xe2\x80\x9cthings\xe2\x80\x9d on thingiverse.com, suitable for testing 3D printing techniques such as structural analysis , shape optimization, or solid geometry operations.\n<p align=""center""><img width=""50%"" src=""https://pbs.twimg.com/media/DRbxWnqXkAEEH0g.jpg:large"" /></p>\n\n<b>ABC: A Big CAD Model Dataset For Geometric Deep Learning</b> [[Link]](https://cs.nyu.edu/~zhongshi/publication/abc-dataset/)[[Paper]](https://arxiv.org/abs/1812.06216)\n<br>This work introduce a dataset for geometric deep learning consisting of over 1 million individual (and high quality) geometric models, each associated with accurate ground truth information on the decomposition into patches, explicit sharp feature annotations, and analytic differential properties.<br>\n<p align=""center""><img width=""50%"" src=""https://cs.nyu.edu/~zhongshi/img/abc-dataset.png"" /></p>\n\n:game_die: <b>ScanObjectNN: A New Benchmark Dataset and Classification Model on Real-World Data (ICCV 2019)</b> [[Link]](https://hkust-vgd.github.io/scanobjectnn/)\n<br>\nThis work introduce ScanObjectNN, a new real-world point cloud object dataset based on scanned indoor scene data. The comprehensive benchmark in this work shows that this dataset poses great challenges to existing point cloud classification techniques as objects from real-world scans are often cluttered with background and/or are partial due to occlusions. Three key open problems for point cloud object classification are identified, and a new point cloud classification neural network that achieves state-of-the-art performance on classifying objects with cluttered background is proposed.\n<br>\n<p align=""center""><img width=""50%"" src=""https://hkust-vgd.github.io/scanobjectnn/images/objects_teaser.png"" /></p>\n\n<b>VOCASET: Speech-4D Head Scan Dataset (2019(</b> [[Link]](https://voca.is.tue.mpg.de/)[[Paper]](https://ps.is.tuebingen.mpg.de/uploads_file/attachment/attachment/510/paper_final.pdf)\n<br>[VOCASET](https://voca.is.tue.mpg.de/), is a 4D face dataset with about 29 minutes of 4D scans captured at 60 fps and synchronized audio. The dataset has 12 subjects and 480 sequences of about 3-4 seconds each with sentences chosen from an array of standard protocols that maximize  phonetic  diversity. \n<p align=""center""><img width=""50%"" src=""https://github.com/TimoBolkart/voca/blob/master/gif/vocaset.gif"" /></p>\n\n<a name=""3d_scenes"" />\n\n### 3D Scenes\n<b>NYU Depth Dataset V2 (2012)</b> [[Link]](https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html)\n<br>1449 densely labeled pairs of aligned RGB and depth images from Kinect video sequences for a variety of indoor scenes.\n<p align=""center""><img width=""50%"" src=""https://cs.nyu.edu/~silberman/images/nyu_depth_v2_labeled.jpg"" /></p>\n\n<b>SUNRGB-D 3D Object Detection Challenge</b> [[Link]](http://rgbd.cs.princeton.edu/challenge.html)\n<br>19 object categories for predicting a 3D bounding box in real world dimension\n<br>Training set: 10,355 RGB-D scene images, Testing set: 2860 RGB-D images\n<p align=""center""><img width=""50%"" src=""http://rgbd.cs.princeton.edu/3dbox.png"" /></p>\n\n<b>SceneNN (2016)</b> [[Link]](http://www.scenenn.net/)\n<br>100+ indoor scene meshes with per-vertex and per-pixel annotation.\n<p align=""center""><img width=""50%"" src=""https://cdn-ak.f.st-hatena.com/images/fotolife/r/robonchu/20170611/20170611155625.png"" /></p>\n\n<b>ScanNet (2017)</b> [[Link]](http://www.scan-net.org/)\n<br>An RGB-D video dataset containing 2.5 million views in more than 1500 scans, annotated with 3D camera poses, surface reconstructions, and instance-level semantic segmentations.\n<p align=""center""><img width=""50%"" src=""http://www.scan-net.org/img/annotations.png"" /></p>\n\n<b>Matterport3D: Learning from RGB-D Data in Indoor Environments (2017)</b> [[Link]](https://niessner.github.io/Matterport/)\n<br>10,800 panoramic views (in both RGB and depth) from 194,400 RGB-D images of 90 building-scale scenes of private rooms. Instance-level semantic segmentations are provided for region (living room, kitchen) and object (sofa, TV) categories. \n<p align=""center""><img width=""50%"" src=""https://niessner.github.io/Matterport/teaser.png"" /></p>\n\n<b>SUNCG: A Large 3D Model Repository for Indoor Scenes (2017)</b> [[Link]](http://suncg.cs.princeton.edu/)\n<br>The dataset contains over 45K different scenes with manually created realistic room and furniture layouts. All of the scenes are semantically annotated at the object level.\n<p align=""center""><img width=""50%"" src=""http://suncg.cs.princeton.edu/figures/data_full.png"" /></p>\n\n<b>MINOS: Multimodal Indoor Simulator (2017)</b> [[Link]](https://github.com/minosworld/minos)\n<br>MINOS is a simulator designed to support the development of multisensory models for goal-directed navigation in complex indoor environments. MINOS leverages large datasets of complex 3D environments and supports flexible configuration of multimodal sensor suites. MINOS supports SUNCG and Matterport3D scenes.\n<p align=""center""><img width=""50%"" src=""http://vladlen.info/wp-content/uploads/2017/12/MINOS.jpg"" /></p>\n\n<b>Facebook House3D: A Rich and Realistic 3D Environment (2017)</b> [[Link]](https://github.com/facebookresearch/House3D)\n<br>House3D is a virtual 3D environment which consists of 45K indoor scenes equipped with a diverse set of scene types, layouts and objects sourced from the SUNCG dataset. All 3D objects are fully annotated with category labels. Agents in the environment have access to observations of multiple modalities, including RGB images, depth, segmentation masks and top-down 2D map views.\n<p align=""center""><img width=""50%"" src=""https://user-images.githubusercontent.com/1381301/33509559-87c4e470-d6b7-11e7-8266-27c940d5729a.jpg"" /></p>\n\n<b>HoME: a Household Multimodal Environment (2017)</b> [[Link]](https://home-platform.github.io/)\n<br>HoME integrates over 45,000 diverse 3D house layouts based on the SUNCG dataset, a scale which may facilitate learning, generalization, and transfer. HoME is an open-source, OpenAI Gym-compatible platform extensible to tasks in reinforcement learning, language grounding, sound-based navigation, robotics, multi-agent learning.\n<p align=""center""><img width=""50%"" src=""https://home-platform.github.io/assets/overview.png"" /></p>\n\n<b>AI2-THOR: Photorealistic Interactive Environments for AI Agents</b> [[Link]](http://ai2thor.allenai.org/)\n<br>AI2-THOR is a photo-realistic interactable framework for AI agents. There are a total 120 scenes in version 1.0 of the THOR environment covering four different room categories: kitchens, living rooms, bedrooms, and bathrooms. Each room has a number of actionable objects.\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/AI2-Thor.jpeg"" /></p>\n\n<b>UnrealCV: Virtual Worlds for Computer Vision (2017)</b> [[Link]](http://unrealcv.org/)[[Paper]](http://www.idm.pku.edu.cn/staff/wangyizhou/papers/ACMMM2017_UnrealCV.pdf)\n<br>An open source project to help computer vision researchers build virtual worlds using Unreal Engine 4.\n<p align=""center""><img width=""50%"" src=""http://unrealcv.org/images/homepage_teaser.png"" /></p>\n\n<b>Gibson Environment: Real-World Perception for Embodied Agents (2018 CVPR) </b> [[Link]](http://gibsonenv.stanford.edu/)\n<br>This platform provides RGB from 1000 point clouds, as well as multimodal sensor data: surface normal, depth, and for a fraction of the spaces, semantics object annotations. The environment is also RL ready with physics integrated. Using such datasets can further narrow down the discrepency between virtual environment and real world.\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Gibson%20Environment-%20Real-World%20Perception%20for%20Embodied%20Agents%20(2018%20CVPR)%20.jpeg"" /></p>\n\n<b>InteriorNet: Mega-scale Multi-sensor Photo-realistic Indoor Scenes Dataset</b> [[Link]](https://interiornet.org/)\n<br>System Overview: an end-to-end pipeline to render an RGB-D-inertial benchmark for large scale interior scene understanding and mapping. Our dataset contains 20M images created by pipeline: (A) We collect around 1 million CAD models provided by world-leading furniture manufacturers. These models have been used in the real-world production. (B) Based on those models, around 1,100 professional designers create around 22 million interior layouts. Most of such layouts have been used in real-world decorations. (C) For each layout, we generate a number of configurations to represent different random lightings and simulation of scene change over time in daily life. (D) We provide an interactive simulator (ViSim) to help for creating ground truth IMU, events, as well as monocular or stereo camera trajectories including hand-drawn, random walking and neural network based realistic trajectory. (E) All supported image sequences and ground truth.\n<p align=""center""><img width=""50%"" src=""https://interiornet.org/items/InteriorNet.jpg"" /></p>\n\n<b>Semantic3D</b>[[Link]](http://www.semantic3d.net/)\n<br>Large-Scale Point Cloud Classification Benchmark, which provides a large labelled 3D point cloud data set of natural scenes with over 4 billion points in total, and also covers a range of diverse urban scenes.\n<p align=""center""><img width=""50%"" src=""http://www.semantic3d.net/img/full_resolution/sg27_8.jpg"" /></p>\n\n<b>Structured3D: A Large Photo-realistic Dataset for Structured 3D Modeling</b> [[Link]](https://structured3d-dataset.org/)\n<p align=""center""><img width=""50%"" src=""https://structured3d-dataset.org/static/img/teaser.png"" /></p>\n\n<a name=""pose_estimation"" />\n\n## 3D Pose Estimation\n<b>Category-Specific Object Reconstruction from a Single Image (2014)</b> [[Paper]](https://people.eecs.berkeley.edu/~akar/categoryshapes.pdf)\n<p align=""center""><img width=""50%"" src=""http://people.eecs.berkeley.edu/~akar/basisshapes_highres.png"" /></p>\n\n<b>Viewpoints and Keypoints (2015)</b> [[Paper]](https://people.eecs.berkeley.edu/~shubhtuls/papers/cvpr15vpsKps.pdf)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Viewpoints%20and%20Keypoints.jpeg"" /></p>\n\n<b>Render for CNN: Viewpoint Estimation in Images Using CNNs Trained with Rendered 3D Model Views (2015 ICCV)</b> [[Paper]](https://shapenet.cs.stanford.edu/projects/RenderForCNN/)\n<p align=""center""><img width=""50%"" src=""https://shapenet.cs.stanford.edu/projects/RenderForCNN/images/teaser.jpg"" /></p>\n\n<b>PoseNet: A Convolutional Network for Real-Time 6-DOF Camera Relocalization (2015)</b> [[Paper]](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Kendall_PoseNet_A_Convolutional_ICCV_2015_paper.pdf)\n<p align=""center""><img width=""50%"" src=""http://mi.eng.cam.ac.uk/projects/relocalisation/images/map.png"" /></p>\n\n<b>Modeling Uncertainty in Deep Learning for Camera Relocalization (2016)</b> [[Paper]](https://arxiv.org/pdf/1509.05909.pdf)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Modeling%20Uncertainty%20in%20Deep%20Learning%20for%20Camera%20Relocalization.jpeg"" /></p>\n\n<b>Robust camera pose estimation by viewpoint classification using deep learning (2016)</b> [[Paper]](https://link.springer.com/article/10.1007/s41095-016-0067-z)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Robust%20camera%20pose%20estimation%20by%20viewpoint%20classification%20using%20deep%20learning.jpeg"" /></p>\n\n<b>Geometric loss functions for camera pose regression with deep learning (2017 CVPR)</b> [[Paper]](https://arxiv.org/pdf/1704.00390.pdf)\n<p align=""center""><img width=""50%"" src=""http://mi.eng.cam.ac.uk/~cipolla/images/pose-net.png"" /></p>\n\n<b>Generic 3D Representation via Pose Estimation and Matching (2017)</b> [[Paper]](http://3drepresentation.stanford.edu/)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Generic%203D%20Representation%20via%20Pose%20Estimation%20and%20Matching.jpeg"" /></p>\n\n<b>3D Bounding Box Estimation Using Deep Learning and Geometry (2017)</b> [[Paper]](https://arxiv.org/pdf/1612.00496.pdf)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/3D%20Bounding%20Box%20Estimation%20Using%20Deep%20Learning%20and%20Geometry.png"" /></p>\n\n<b>6-DoF Object Pose from Semantic Keypoints (2017)</b> [[Paper]](https://www.seas.upenn.edu/~pavlakos/projects/object3d/)\n<p align=""center""><img width=""50%"" src=""https://www.seas.upenn.edu/~pavlakos/projects/object3d/files/object3d-teaser.png"" /></p>\n\n<b>Relative Camera Pose Estimation Using Convolutional Neural Networks (2017)</b> [[Paper]](https://arxiv.org/pdf/1702.01381.pdf)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Relative%20Camera%20Pose%20Estimation%20Using%20Convolutional%20Neural%20Networks.png"" /></p>\n\n<b>3DMatch: Learning Local Geometric Descriptors from RGB-D Reconstructions (2017)</b> [[Paper]](http://3dmatch.cs.princeton.edu/)\n<p align=""center""><img width=""50%"" src=""http://3dmatch.cs.princeton.edu/img/overview.jpg"" /></p>\n\n<b>Single Image 3D Interpreter Network (2016)</b> [[Paper]](http://3dinterpreter.csail.mit.edu/) [[Code]](https://github.com/jiajunwu/3dinn)\n<p align=""center""><img width=""50%"" src=""http://3dinterpreter.csail.mit.edu/images/spotlight_3dinn_large.jpg"" /></p>\n\n<b>Multi-view Consistency as Supervisory Signal  for Learning Shape and Pose Prediction (2018 CVPR)</b> [[Paper]](https://shubhtuls.github.io/mvcSnP/)\n<p align=""center""><img width=""50%"" src=""https://shubhtuls.github.io/mvcSnP/resources/images/teaser.png"" /></p>\n\n<b>PoseCNN: A Convolutional Neural Network for 6D Object Pose Estimation in Cluttered Scenes (2018)</b> [[Paper]](https://rse-lab.cs.washington.edu/projects/posecnn/)\n<p align=""center""><img width=""50%"" src=""https://yuxng.github.io/PoseCNN.png"" /></p>\n\n<b>Feature Mapping for Learning Fast and Accurate 3D Pose Inference from Synthetic Images (2018 CVPR)</b> [[Paper]](https://arxiv.org/pdf/1712.03904.pdf)\n<p align=""center""><img width=""40%"" src=""https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTnpyajEhbhrPMc0YpEQzqE8N9E7CW_EVWYA3Bxg46oUEYFf9XvkA"" /></p>\n\n<b>Pix3D: Dataset and Methods for Single-Image 3D Shape Modeling (2018 CVPR)</b> [[Paper]](http://pix3d.csail.mit.edu/)\n<p align=""center""><img width=""50%"" src=""http://pix3d.csail.mit.edu/images/spotlight_pix3d.jpg"" /></p>\n\n<b>3D Pose Estimation and 3D Model Retrieval for Objects in the Wild (2018 CVPR)</b> [[Paper]](https://arxiv.org/pdf/1803.11493.pdf)\n<p align=""center""><img width=""50%"" src=""https://www.tugraz.at/fileadmin/user_upload/Institute/ICG/Documents/team_lepetit/images/grabner/pose_retrieval_overview.png"" /></p>\n\n<b>Deep Object Pose Estimation for Semantic Robotic Grasping of Household Objects (2018)</b> [[Paper]](https://research.nvidia.com/publication/2018-09_Deep-Object-Pose)\n<p align=""center""><img width=""50%"" src=""https://research.nvidia.com/sites/default/files/publications/forwebsite1_0.png"" /></p>\n\n<a name=""single_classification"" />\n\n## Single Object Classification\n:space_invader: <b>3D ShapeNets: A Deep Representation for Volumetric Shapes (2015)</b> [[Paper]](http://3dshapenets.cs.princeton.edu/)\n<p align=""center""><img width=""50%"" src=""https://ai2-s2-public.s3.amazonaws.com/figures/2016-11-08/3ed23386284a5639cb3e8baaecf496caa766e335/1-Figure1-1.png"" /></p>\n\n:space_invader: <b>VoxNet: A 3D Convolutional Neural Network for Real-Time Object Recognition (2015)</b> [[Paper]](http://www.dimatura.net/publications/voxnet_maturana_scherer_iros15.pdf) [[Code]](https://github.com/dimatura/voxnet)\n<p align=""center""><img width=""50%"" src=""http://www.dimatura.net/research/voxnet/car_voxnet_side.png"" /></p>\n\n:camera: <b>Multi-view Convolutional Neural Networks  for 3D Shape Recognition (2015)</b> [[Paper]](http://vis-www.cs.umass.edu/mvcnn/)\n<p align=""center""><img width=""50%"" src=""http://vis-www.cs.umass.edu/mvcnn/images/mvcnn.png"" /></p>\n\n:camera: <b>DeepPano: Deep Panoramic Representation for 3-D Shape Recognition (2015)</b> [[Paper]](http://mclab.eic.hust.edu.cn/UpLoadFiles/Papers/DeepPano_SPL2015.pdf)\n<p align=""center""><img width=""30%"" src=""https://ai2-s2-public.s3.amazonaws.com/figures/2016-11-08/5a1b5d31905d8cece7b78510f51f3d8bbb063063/1-Figure3-1.png"" /></p>\n\n:space_invader::camera: <b>FusionNet: 3D Object Classification Using Multiple Data Representations (2016)</b> [[Paper]](https://stanford.edu/~rezab/papers/fusionnet.pdf)\n<p align=""center""><img width=""30%"" src=""https://ai2-s2-public.s3.amazonaws.com/figures/2016-11-08/0aab8fbcef1f0a14f5653d170ca36f4e5aae8010/6-Figure5-1.png"" /></p>\n\n:space_invader::camera: <b>Volumetric and Multi-View CNNs for Object Classification on 3D Data (2016)</b> [[Paper]](https://arxiv.org/pdf/1604.03265.pdf) [[Code]](https://github.com/charlesq34/3dcnn.torch)\n<p align=""center""><img width=""40%"" src=""http://graphics.stanford.edu/projects/3dcnn/teaser.jpg"" /></p>\n\n:space_invader: <b>Generative and Discriminative Voxel Modeling with Convolutional Neural Networks (2016)</b> [[Paper]](https://arxiv.org/pdf/1608.04236.pdf) [[Code]](https://github.com/ajbrock/Generative-and-Discriminative-Voxel-Modeling)\n<p align=""center""><img width=""50%"" src=""http://davidstutz.de/wordpress/wp-content/uploads/2017/02/brock_vae.png"" /></p>\n\n:gem: <b>Geometric deep learning on graphs and manifolds using mixture model CNNs (2016)</b> [[Link]](https://arxiv.org/pdf/1611.08402.pdf)\n<p align=""center""><img width=""50%"" src=""https://i2.wp.com/preferredresearch.jp/wp-content/uploads/2017/08/monet.png?resize=581%2C155&ssl=1"" /></p>\n\n:space_invader: <b>3D GAN: Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling (2016)</b> [[Paper]](https://arxiv.org/pdf/1610.07584.pdf) [[Code]](https://github.com/zck119/3dgan-release)\n<p align=""center""><img width=""50%"" src=""http://3dgan.csail.mit.edu/images/model.jpg"" /></p>\n\n:space_invader: <b>Generative and Discriminative Voxel Modeling with Convolutional Neural Networks (2017)</b> [[Paper]](https://github.com/ajbrock/Generative-and-Discriminative-Voxel-Modeling)\n<p align=""center""><img width=""50%"" src=""https://github.com/ajbrock/Generative-and-Discriminative-Voxel-Modeling/blob/master/doc/GUI3.png"" /></p>\n\n:space_invader: <b>FPNN: Field Probing Neural Networks for 3D Data (2016)</b> [[Paper]](http://yangyanli.github.io/FPNN/) [[Code]](https://github.com/yangyanli/FPNN)\n<p align=""center""><img width=""30%"" src=""https://ai2-s2-public.s3.amazonaws.com/figures/2016-11-08/15ca7adccf5cd4dc309cdcaa6328f4c429ead337/1-Figure2-1.png"" /></p>\n\n:space_invader: <b>OctNet: Learning Deep 3D Representations at High Resolutions (2017)</b> [[Paper]](https://arxiv.org/pdf/1611.05009.pdf) [[Code]](https://github.com/griegler/octnet)\n<p align=""center""><img width=""30%"" src=""https://is.tuebingen.mpg.de/uploads/publication/image/18921/img03.png"" /></p>\n\n:space_invader: <b>O-CNN: Octree-based Convolutional Neural Networks for 3D Shape Analysis (2017)</b> [[Paper]](http://wang-ps.github.io/O-CNN) [[Code]](https://github.com/Microsoft/O-CNN)\n<p align=""center""><img width=""50%"" src=""http://wang-ps.github.io/O-CNN_files/teaser.png"" /></p>\n\n:space_invader: <b>Orientation-boosted voxel nets for 3D object recognition (2017)</b> [[Paper]](https://lmb.informatik.uni-freiburg.de/Publications/2017/SZB17a/) [[Code]](https://github.com/lmb-freiburg/orion)\n<p align=""center""><img width=""50%"" src=""https://lmb.informatik.uni-freiburg.de/Publications/2017/SZB17a/teaser_w.png"" /></p>\n\n:game_die: <b>PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation (2017)</b> [[Paper]](http://stanford.edu/~rqi/pointnet/) [[Code]](https://github.com/charlesq34/pointnet)\n<p align=""center""><img width=""40%"" src=""https://web.stanford.edu/~rqi/papers/pointnet.png"" /></p>\n\n:game_die: <b>PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space (2017)</b> [[Paper]](https://arxiv.org/pdf/1706.02413.pdf) [[Code]](https://github.com/charlesq34/pointnet2)\n<p align=""center""><img width=""40%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/PointNet%2B%2B-%20Deep%20Hierarchical%20Feature%20Learning%20on%20Point%20Sets%20in%20a%20Metric%20Space.png"" /></p>\n\n:camera: <b>Feedback Networks (2017)</b> [[Paper]](http://feedbacknet.stanford.edu/) [[Code]](https://github.com/amir32002/feedback-networks)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Feedback%20Networks.png"" /></p>\n\n:game_die: <b>Escape from Cells: Deep Kd-Networks for The Recognition of 3D Point Cloud Models (2017)</b> [[Paper]](http://www.arxiv.org/pdf/1704.01222.pdf)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Escape From Cells.png"" /></p>\n\n:game_die: <b>Dynamic Graph CNN for Learning on Point Clouds (2018)</b> [[Paper]](https://arxiv.org/pdf/1801.07829.pdf)\n<p align=""center""><img width=""50%"" src=""https://liuziwei7.github.io/homepage_files/dynamicgcnn_logo.png"" /></p>\n\n:game_die: <b>PointCNN (2018)</b> [[Paper]](https://yangyanli.github.io/PointCNN/)\n<p align=""center""><img width=""50%"" src=""http://yangyan.li/images/paper/pointcnn.png"" /></p>\n\n:game_die::camera: <b>A Network Architecture for Point Cloud Classification via Automatic Depth Images Generation (2018 CVPR)</b> [[Paper]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Roveri_A_Network_Architecture_CVPR_2018_paper.pdf)\n<p align=""center""><img width=""50%"" src=""https://s3-us-west-1.amazonaws.com/disneyresearch/wp-content/uploads/20180619114732/A-Network-Architecture-for-Point-Cloud-Classification-via-Automatic-Depth-Images-Generation-Image-600x317.jpg"" /></p>\n\n:game_die::space_invader: <b>PointGrid: A Deep Network for 3D Shape Understanding (CVPR 2018) </b> [[Paper]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Le_PointGrid_A_Deep_CVPR_2018_paper.pdf) [[Code]](https://github.com/trucleduc/PointGrid)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/PointGrid-%20A%20Deep%20Network%20for%203D%20Shape%20Understanding%20(2018).jpeg"" /></p>\n\n:gem: <b> MeshNet: Mesh Neural Network for 3D Shape Representation (AAAI 2019) </b> [[Paper]](https://arxiv.org/pdf/1811.11424.pdf) [[Code]](https://github.com/Yue-Group/MeshNet)\n<p align=""center""><img width=""50%"" src=""http://www.gaoyue.org/en_tsinghua/resrc/meshnet.jpg"" /></p>\n\n:game_die: <b>SpiderCNN (2018)</b> [[Paper]](https://github.com/xyf513/SpiderCNN)[[Code]](https://github.com/xyf513/SpiderCNN)\n<p align=""center""><img width=""50%"" src=""http://5b0988e595225.cdn.sohucs.com/images/20181109/45c3b670e67f43b288791c650fb7fb0b.jpeg"" /></p>\n\n:game_die: <b>PointConv (2018)</b> [[Paper]](https://github.com/DylanWusee/pointconv/tree/master/imgs)[[Code]](https://github.com/DylanWusee/pointconv/tree/master/imgs)\n<p align=""center""><img width=""50%"" src=""https://pics4.baidu.com/feed/8b82b9014a90f603272fe29f88ef061fb251ed49.jpeg?token=b23e1dbbaeaf12ffe3d168bd997a8d66&s=01307D328FE07C010C69C1CE0000D0B3"" /></p>\n\n:gem: <b>MeshCNN (SIGGRAPH 2019)</b> [[Paper]](https://bit.ly/meshcnn)[[Code]](https://github.com/ranahanocka/MeshCNN)\n<p align=""center""><img width=""50%"" src=""https://github.com/ranahanocka/MeshCNN/blob/master/docs/imgs/alien.gif?raw=true"" /></p>\n\n:game_die: <b>SampleNet: Differentiable Point Cloud Sampling (CVPR 2020)</b> [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Lang_SampleNet_Differentiable_Point_Cloud_Sampling_CVPR_2020_paper.pdf) [[Code]](https://github.com/itailang/SampleNet)\n<p align=""center""><img width=""50%"" src=""https://github.com/itailang/SampleNet/blob/master/doc/teaser.png"" /></p>\n\n<a name=""multiple_detection"" />\n\n\n## Multiple Objects Detection\n<b>Sliding Shapes for 3D Object Detection in Depth Images (2014)</b> [[Paper]](http://slidingshapes.cs.princeton.edu/)\n<p align=""center""><img width=""50%"" src=""http://slidingshapes.cs.princeton.edu/teaser.jpg"" /></p>\n\n<b>Object Detection in 3D Scenes Using CNNs in Multi-view Images (2016)</b> [[Paper]](https://stanford.edu/class/ee367/Winter2016/Qi_Report.pdf)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Object%20Detection%20in%203D%20Scenes%20Using%20CNNs%20in%20Multi-view%20Images.png"" /></p>\n\n<b>Deep Sliding Shapes for Amodal 3D Object Detection in RGB-D Images (2016)</b> [[Paper]](http://dss.cs.princeton.edu/) [[Code]](https://github.com/shurans/DeepSlidingShape)\n<p align=""center""><img width=""50%"" src=""http://3dvision.princeton.edu/slide/DSS.jpg"" /></p>\n\n<b>Three-Dimensional Object Detection and Layout Prediction using Clouds of Oriented Gradients (2016)</b> [[CVPR \'16 Paper]](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Ren_Three-Dimensional_Object_Detection_CVPR_2016_paper.pdf) [[CVPR \'18 Paper]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Ren_3D_Object_Detection_CVPR_2018_paper.pdf) [[T-PAMI \'19 Paper]](https://arxiv.org/pdf/1906.04725) \n<p align=""center""><img width=""50%"" src=""https://github.com/luvegood/3D-Machine-Learning/blob/master/imgs/Three-Dimensional%20Object%20Detection%20and%20Layout%20Prediction%20using%20Clouds%20of%20Oriented%20Gradients.png"" /></p>\n\n<b>DeepContext: Context-Encoding Neural Pathways  for 3D Holistic Scene Understanding (2016)</b> [[Paper]](http://deepcontext.cs.princeton.edu/)\n<p align=""center""><img width=""50%"" src=""http://deepcontext.cs.princeton.edu/teaser.png"" /></p>\n\n<b>SUN RGB-D: A RGB-D Scene Understanding Benchmark Suite (2017)</b> [[Paper]](http://rgbd.cs.princeton.edu/)\n<p align=""center""><img width=""50%"" src=""http://rgbd.cs.princeton.edu/teaser.jpg"" /></p>\n\n<b>VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection (2017)</b> [[Paper]](https://arxiv.org/pdf/1711.06396.pdf)\n<p align=""center""><img width=""50%"" src=""https://pbs.twimg.com/media/DPMtLhHXUAcQUj2.jpg"" /></p>\n\n<b>Frustum PointNets for 3D Object Detection from RGB-D Data (CVPR2018)</b> [[Paper]](https://arxiv.org/pdf/1711.08488.pdf)\n\n<p align=""center""><img width=""50%"" src=""http://stanford.edu/~rqi/frustum-pointnets/images/teaser.jpg"" /></p>\n\n<b>A^2-Net: Molecular Structure Estimation from Cryo-EM Density Volumes (AAAI2019)</b> [[Paper]](https://arxiv.org/abs/1901.00785)\n\n<p align=""center""><img width=""50%"" src=""imgs/a-square-net-min.jpg"" /></p>\n\n<b>Stereo R-CNN based 3D Object Detection for Autonomous Driving (CVPR2019)</b> [[Paper]](https://arxiv.org/abs/1902.09738v1)\n\n<p align=""center""><img width=""50%"" src=""https://www.groundai.com/media/arxiv_projects/515338/system_newnew.png"" /></p>\n\n<b>Deep Hough Voting for 3D Object Detection in Point Clouds (ICCV2019)</b> [[Paper]](https://arxiv.org/pdf/1904.09664.pdf) [[code]](https://github.com/facebookresearch/votenet)\n<p align=""center""><img width=""50%"" src=""https://github.com/facebookresearch/votenet/blob/master/doc/teaser.jpg"" /></p>\n\n<a name=""segmentation"" />\n\n## Scene/Object Semantic Segmentation\n<b>Learning 3D Mesh Segmentation and Labeling (2010)</b> [[Paper]](https://people.cs.umass.edu/~kalo/papers/LabelMeshes/LabelMeshes.pdf)\n<p align=""center""><img width=""50%"" src=""https://ai2-s2-public.s3.amazonaws.com/figures/2016-11-08/0bf390e2a14f74bcc8838d5fb1c0c4cc60e92eb7/7-Figure7-1.png"" /></p>\n\n<b>Unsupervised Co-Segmentation of a Set of Shapes via Descriptor-Space Spectral Clustering (2011)</b> [[Paper]](https://www.cs.sfu.ca/~haoz/pubs/sidi_siga11_coseg.pdf)\n<p align=""center""><img width=""30%"" src=""http://people.scs.carleton.ca/~olivervankaick/cosegmentation/results6.png"" /></p>\n\n<b>Single-View Reconstruction via Joint Analysis of Image and Shape Collections (2015)</b> [[Paper]](https://www.cs.utexas.edu/~huangqx/modeling_sig15.pdf) [[Code]](https://github.com/huangqx/image_shape_align)\n<p align=""center""><img width=""50%"" src=""http://vladlen.info/wp-content/uploads/2015/05/single-view.png"" /></p>\n\n<b>3D Shape Segmentation with Projective Convolutional Networks (2017)</b> [[Paper]](http://people.cs.umass.edu/~kalo/papers/shapepfcn/) [[Code]](https://github.com/kalov/ShapePFCN)\n<p align=""center""><img width=""50%"" src=""http://people.cs.umass.edu/~kalo/papers/shapepfcn/teaser.jpg"" /></p>\n\n<b>Learning Hierarchical Shape Segmentation and Labeling from Online Repositories (2017)</b> [[Paper]](http://cs.stanford.edu/~ericyi/project_page/hier_seg/index.html)\n<p align=""center""><img width=""50%"" src=""http://cs.stanford.edu/~ericyi/project_page/hier_seg/figures/teaser.jpg"" /></p>\n\n:space_invader: <b>ScanNet (2017)</b> [[Paper]](https://arxiv.org/pdf/1702.04405.pdf) [[Code]](https://github.com/scannet/scannet)\n<p align=""center""><img width=""50%"" src=""http://www.scan-net.org/img/voxel-predictions.jpg"" /></p>\n\n:game_die: <b>PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation (2017)</b> [[Paper]](http://stanford.edu/~rqi/pointnet/) [[Code]](https://github.com/charlesq34/pointnet)\n<p align=""center""><img width=""40%"" src=""https://web.stanford.edu/~rqi/papers/pointnet.png"" /></p>\n\n:game_die: <b>PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space (2017)</b> [[Paper]](https://arxiv.org/pdf/1706.02413.pdf) [[Code]](https://github.com/charlesq34/pointnet2)\n<p align=""center""><img width=""40%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/PointNet%2B%2B-%20Deep%20Hierarchical%20Feature%20Learning%20on%20Point%20Sets%20in%20a%20Metric%20Space.png"" /></p>\n\n:game_die: <b>3D Graph Neural Networks for RGBD Semantic Segmentation (2017)</b> [[Paper]](http://www.cs.toronto.edu/~rjliao/papers/iccv_2017_3DGNN.pdf)\n<p align=""center""><img width=""40%"" src=""http://www.fonow.com/Images/2017-10-18/66372-20171018115809740-2125227250.jpg"" /></p>\n\n:game_die: <b>3DCNN-DQN-RNN: A Deep Reinforcement Learning Framework for Semantic\nParsing of Large-scale 3D Point Clouds (2017)</b> [[Paper]](https://arxiv.org/pdf/1707.06783.pdf)\n<p align=""center""><img width=""40%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/3DCNN-DQN-RNN.png"" /></p>\n\n:game_die::space_invader: <b>Semantic Segmentation of Indoor Point Clouds using Convolutional Neural Networks (2017)</b> [[Paper]](https://www.isprs-ann-photogramm-remote-sens-spatial-inf-sci.net/IV-4-W4/101/2017/isprs-annals-IV-4-W4-101-2017.pdf)\n<p align=""center""><img width=""55%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Semantic Segmentation of Indoor Point Clouds using Convolutional Neural Networks.png"" /></p>\n\n:game_die::space_invader: <b>SEGCloud: Semantic Segmentation of 3D Point Clouds (2017)</b> [[Paper]](https://arxiv.org/pdf/1710.07563.pdf)\n<p align=""center""><img width=""55%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/SEGCloud.png"" /></p>\n\n:game_die::space_invader: <b>Large-Scale 3D Shape Reconstruction and Segmentation from ShapeNet Core55 (2017)</b> [[Paper]](https://arxiv.org/pdf/1710.06104.pdf)\n<p align=""center""><img width=""40%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Core55.png"" /></p>\n\n:game_die: <b>Pointwise Convolutional Neural Networks (CVPR 2018)</b> [[Link]](http://pointwise.scenenn.net/)\n<br>\nWe propose pointwise convolution that performs on-the-fly voxelization for learning local features of a point cloud.\n<p align=""center""><img width=""50%"" src=""http://pointwise.scenenn.net/images/teaser.png"" /></p>\n\n:game_die: <b>Dynamic Graph CNN for Learning on Point Clouds (2018)</b> [[Paper]](https://arxiv.org/pdf/1801.07829.pdf)\n<p align=""center""><img width=""50%"" src=""https://liuziwei7.github.io/homepage_files/dynamicgcnn_logo.png"" /></p>\n\n:game_die: <b>PointCNN (2018)</b> [[Paper]](https://yangyanli.github.io/PointCNN/)\n<p align=""center""><img width=""50%"" src=""http://yangyan.li/images/paper/pointcnn.png"" /></p>\n\n:camera::space_invader: <b>3DMV: Joint 3D-Multi-View Prediction for 3D Semantic Scene Segmentation (2018)</b> [[Paper]](https://arxiv.org/pdf/1803.10409.pdf)\n<p align=""center""><img width=""50%"" src=""https://github.com/angeladai/3DMV/blob/master/images/teaser.jpg"" /></p>\n\n:space_invader: <b>ScanComplete: Large-Scale Scene Completion and Semantic Segmentation for 3D Scans (2018)</b> [[Paper]](https://arxiv.org/pdf/1712.10215.pdf) \n<p align=""center""><img width=""50%"" src=""https://github.com/angeladai/ScanComplete/blob/master/images/teaser_mesh.jpg"" /></p>\n\n:game_die::camera: <b>SPLATNet: Sparse Lattice Networks for Point Cloud Processing (2018)</b> [[Paper]](https://arxiv.org/pdf/1802.08275.pdf)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/SPLATNet-%20Sparse%20Lattice%20Networks%20for%20Point%20Cloud%20Processing.jpeg"" /></p>\n\n:game_die::space_invader: <b>PointGrid: A Deep Network for 3D Shape Understanding (CVPR 2018) </b> [[Paper]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Le_PointGrid_A_Deep_CVPR_2018_paper.pdf) [[Code]](https://github.com/trucleduc/PointGrid)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/PointGrid-%20A%20Deep%20Network%20for%203D%20Shape%20Understanding%20(2018).jpeg"" /></p>\n\n:game_die: <b>PointConv (2018)</b> [[Paper]](https://github.com/DylanWusee/pointconv/tree/master/imgs)[[Code]](https://github.com/DylanWusee/pointconv/tree/master/imgs)\n<p align=""center""><img width=""50%"" src=""https://pics4.baidu.com/feed/8b82b9014a90f603272fe29f88ef061fb251ed49.jpeg?token=b23e1dbbaeaf12ffe3d168bd997a8d66&s=01307D328FE07C010C69C1CE0000D0B3"" /></p>\n\n:game_die: <b>SpiderCNN (2018)</b> [[Paper]](https://github.com/xyf513/SpiderCNN)[[Code]](https://github.com/xyf513/SpiderCNN)\n<p align=""center""><img width=""50%"" src=""http://5b0988e595225.cdn.sohucs.com/images/20181109/45c3b670e67f43b288791c650fb7fb0b.jpeg"" /></p>\n\n:space_invader: <b>3D-SIS: 3D Semantic Instance Segmentation of RGB-D Scans (CVPR 2019)</b> [[Paper]](https://arxiv.org/pdf/1812.07003.pdf)[[Code]](https://github.com/Sekunde/3D-SIS)\n<p align=""center""><img width=""50%"" src=""http://www.niessnerlab.org/papers/2019/6sis/teaser.jpg"" /></p>\n\n:game_die: <b>Real-time Progressive 3D Semantic Segmentation for Indoor Scenes (WACV 2019)</b> [[Link]](https://pqhieu.github.io/research/proseg/)\n<br>\nWe propose an efficient yet robust technique for on-the-fly dense reconstruction and semantic segmentation of 3D indoor scenes. Our method is built atop an efficient super-voxel clustering method and a conditional random field with higher-order constraints from structural and object cues, enabling progressive dense semantic segmentation without any precomputation.\n<p align=""center""><img width=""50%"" src=""https://pqhieu.github.io/media/images/wacv19/thumbnail.gif"" /></p>\n \n\n:game_die: <b>JSIS3D: Joint Semantic-Instance Segmentation of 3D Point Clouds (CVPR 2019)</b> [[Link]](https://pqhieu.github.io/research/jsis3d/)\n<br>\nWe jointly address the problems of semantic and instance segmentation of 3D point clouds with a multi-task pointwise network that simultaneously performs two tasks: predicting the semantic classes of 3D points and embedding the points into high-dimensional vectors so that points of the same object instance are represented by similar embeddings. We then propose a multi-value conditional random field model to incorporate the semantic and instance labels and formulate the problem of semantic and instance segmentation as jointly optimising labels in the field model.\n<p align=""center""><img width=""50%"" src=""./imgs/jsis3d.png"" /></p>\n\n\n:game_die: <b>ShellNet: Efficient Point Cloud Convolutional Neural Networks using Concentric Shells Statistics (ICCV 2019)</b> [[Link]](https://hkust-vgd.github.io/shellnet/)\n<br>\nWe propose an efficient end-to-end permutation invariant convolution for point cloud deep learning. We use statistics from concentric spherical shells to define representative features and resolve the point order ambiguity, allowing traditional convolution to perform efficiently on such features. \n<p align=""center""><img width=""50%"" src=""https://hkust-vgd.github.io/shellnet/images/shellconv_new.png"" /></p>\n\n:game_die: <b>Rotation Invariant Convolutions for 3D Point Clouds Deep Learning (3DV 2019)</b> [[Link]](https://hkust-vgd.github.io/riconv/)\n<br>\nWe introduce a novel convolution operator for point clouds that achieves rotation invariance. Our core idea is to use low-level rotation invariant geometric features such as distances and angles to design a convolution operator for point cloud learning. \n<p align=""center""><img width=""50%"" src=""https://hkust-vgd.github.io/riconv/images/RIO_cam.png"" /></p>\n\n\n<a name=""3d_synthesis"" />\n\n## 3D Model Synthesis/Reconstruction\n\n<a name=""3d_synthesis_model_based"" />\n\n_Parametric Morphable Model-based methods_\n\n<b>A Morphable Model For The Synthesis Of 3D Faces (1999)</b> [[Paper]](http://gravis.dmi.unibas.ch/publications/Sigg99/morphmod2.pdf)[[Code]](https://github.com/MichaelMure/3DMM)\n<p align=""center""><img width=""40%"" src=""http://mblogthumb3.phinf.naver.net/MjAxNzAzMTdfMjcz/MDAxNDg5NzE3MzU0ODI3.9lQioLxwoGmtoIVXX9sbVOzhezoqgKMKiTovBnbUFN0g.sXN5tG4Kohgk7OJEtPnux-mv7OAoXVxxCyo3SGZMc6Yg.PNG.atelierjpro/031717_0222_DataDrivenS4.png?type=w420"" /></p>\n\n<b>FLAME: Faces Learned with an Articulated Model and Expressions (2017)</b> [[Paper]](https://ps.is.tuebingen.mpg.de/uploads_file/attachment/attachment/400/paper.pdf)[[Code (Chumpy)]](https://github.com/Rubikplayer/flame-fitting)[[Code (TF)]](https://github.com/TimoBolkart/TF_FLAME)\n<br>[FLAME](http://flame.is.tue.mpg.de/) is a lightweight and expressive generic head model learned from over 33,000 of accurately aligned 3D scans. The model combines a linear identity shape space (trained from 3800 scans of human heads) with an articulated neck, jaw, and eyeballs, pose-dependent corrective blendshapes, and additional global expression blendshapes.\nThe code demonstrates how to 1) reconstruct textured 3D faces from images, 2) fit the model to 3D landmarks or registered 3D meshes, or 3) generate 3D face templates for [speech-driven facial animation](https://github.com/TimoBolkart/voca).\n<p align=""center""> <img width=""50%"" src=""https://github.com/TimoBolkart/TF_FLAME/blob/master/gifs/model_variations.gif""></p>\n\n<b>The Space of Human Body Shapes: Reconstruction and Parameterization from Range Scans (2003)</b> [[Paper]](http://grail.cs.washington.edu/projects/digital-human/pub/allen03space-submit.pdf)\n<p align=""center""><img width=""50%"" src=""https://ai2-s2-public.s3.amazonaws.com/figures/2016-11-08/46d39b0e21ae956e4bcb7a789f92be480d45ee12/7-Figure10-1.png"" /></p>\n\n<b>SMPL-X: Expressive Body Capture: 3D Hands, Face, and Body from a Single Image (2019)</b> [[Paper]](https://ps.is.tuebingen.mpg.de/uploads_file/attachment/attachment/497/SMPL-X.pdf)[[Video]](https://youtu.be/XyXIEmapWkw)[[Code]](https://github.com/vchoutas/smplify-x)\n<p align=""center""> <img width=""50%"" src=""https://github.com/vchoutas/smplify-x/blob/master/images/teaser_fig.png""></p>\n\n<b>Category-Specific Object Reconstruction from a Single Image (2014)</b> [[Paper]](https://people.eecs.berkeley.edu/~akar/categoryshapes.pdf)\n<p align=""center""><img width=""50%"" src=""http://people.eecs.berkeley.edu/~akar/categoryShapes/images/teaser.png"" /></p>\n\n:game_die: <b>DeformNet: Free-Form Deformation Network for 3D Shape Reconstruction from a Single Image (2017)</b> [[Paper]](http://ai.stanford.edu/~haosu/papers/SI2PC_arxiv_submit.pdf)\n<p align=""center""><img width=""50%"" src=""https://chrischoy.github.io/images/publication/deformnet/model.png"" /></p>\n\n:gem: <b>Mesh-based Autoencoders for Localized Deformation Component Analysis (2017)</b> [[Paper]](https://arxiv.org/pdf/1709.04304.pdf)\n<p align=""center""><img width=""50%"" src=""http://qytan.com/img/point_conv.jpg"" /></p>\n\n:gem: <b>Exploring Generative 3D Shapes Using Autoencoder Networks (Autodesk 2017)</b> [[Paper]](https://www.autodeskresearch.com/publications/exploring_generative_3d_shapes)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Exploring%20Generative%203D%20Shapes%20Using%20Autoencoder%20Networks.jpeg"" /></p>\n\n:gem: <b>Using Locally Corresponding CAD Models for\nDense 3D Reconstructions from a Single Image (2017)</b> [[Paper]](http://ci2cv.net/media/papers/chenkong_cvpr_2017.pdf)\n<p align=""center""><img width=""50%"" src=""https://chenhsuanlin.bitbucket.io/images/rp/r02.png"" /></p>\n\n:gem: <b>Compact Model Representation for 3D Reconstruction (2017)</b> [[Paper]](https://jhonykaesemodel.com/publication/3dv2017/)\n<p align=""center""><img width=""50%"" src=""https://jhonykaesemodel.com/img/headers/overview.png"" /></p>\n\n:gem: <b>Image2Mesh: A Learning Framework for Single Image 3D Reconstruction (2017)</b> [[Paper]](https://arxiv.org/pdf/1711.10669.pdf)\n<p align=""center""><img width=""50%"" src=""https://pbs.twimg.com/media/DW5VhjpW4AAESHO.jpg"" /></p>\n\n:gem: <b>Learning free-form deformations for 3D object reconstruction (2018)</b> [[Paper]](https://jhonykaesemodel.com/publication/learning_ffd/)\n<p align=""center""><img width=""50%"" src=""https://jhonykaesemodel.com/learning_ffd_overview.png"" /></p>\n\n:gem: <b>Variational Autoencoders for Deforming 3D Mesh Models(2018 CVPR)</b> [[Paper]](http://qytan.com/publication/vae/)\n<p align=""center""><img width=""50%"" src=""http://humanmotion.ict.ac.cn/papers/2018P5_VariationalAutoencoders/TeaserImage.jpg"" /></p>\n\n:gem: <b>Lions and Tigers and Bears: Capturing Non-Rigid, 3D, Articulated Shape from Images (2018 CVPR)</b> [[Paper]](http://files.is.tue.mpg.de/black/papers/zuffiCVPR2018.pdf)\n<p align=""center""><img width=""50%"" src=""https://3c1703fe8d.site.internapcdn.net/newman/gfx/news/hires/2018/realisticava.jpg"" /></p>\n\n<a name=""3d_synthesis_template_based"" />\n\n_Part-based Template Learning methods_\n\n<b>Modeling by Example (2004)</b> [[Paper]](http://www.cs.princeton.edu/~funk/sig04a.pdf)\n<p align=""center""><img width=""20%"" src=""http://gfx.cs.princeton.edu/pubs/Funkhouser_2004_MBE/chair.jpg"" /></p>\n\n<b>Model Composition from Interchangeable Components (2007)</b> [[Paper]](http://www.cs.princeton.edu/courses/archive/spring11/cos598A/pdfs/Kraevoy07.pdf)\n<p align=""center""><img width=""40%"" src=""http://www.cs.ubc.ca/labs/imager/tr/2007/Vlad_Shuffler/teaser.jpg"" /></p>\n\n<b>Data-Driven Suggestions for Creativity Support in 3D Modeling (2010)</b> [[Paper]](http://vladlen.info/publications/data-driven-suggestions-for-creativity-support-in-3d-modeling/)\n<p align=""center""><img width=""50%"" src=""http://vladlen.info/wp-content/uploads/2011/12/creativity.png"" /></p>\n\n<b>Photo-Inspired Model-Driven 3D Object Modeling (2011)</b> [[Paper]](http://kevinkaixu.net/projects/photo-inspired.html)\n<p align=""center""><img width=""50%"" src=""http://kevinkaixu.net/projects/photo-inspired/overview.PNG"" /></p>\n\n<b>Probabilistic Reasoning for Assembly-Based 3D Modeling (2011)</b> [[Paper]](https://people.cs.umass.edu/~kalo/papers/assembly/ProbReasoningShapeModeling.pdf)\n<p align=""center""><img width=""50%"" src=""http://vladlen.info/wp-content/uploads/2011/12/highlight9.png"" /></p>\n\n<b>A Probabilistic Model for Component-Based Shape Synthesis (2012)</b> [[Paper]](https://people.cs.umass.edu/~kalo/papers/ShapeSynthesis/ShapeSynthesis.pdf)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/test1/blob/master/imgs/A%20Probabilistic%20Model%20for%20Component-Based%20Shape%20Synthesis.png"" /></p>\n\n<b>Structure Recovery by Part Assembly (2012)</b> [[Paper]](http://cg.cs.tsinghua.edu.cn/StructureRecovery/)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/test1/blob/master/imgs/Structure%20Recovery%20by%20Part%20Assembly.png"" /></p>\n\n<b>Fit and Diverse: Set Evolution for Inspiring 3D Shape Galleries (2012)</b> [[Paper]](http://kevinkaixu.net/projects/civil.html)\n<p align=""center""><img width=""50%"" src=""http://kevinkaixu.net/projects/civil/teaser.png"" /></p>\n\n<b>AttribIt: Content Creation with Semantic Attributes (2013)</b> [[Paper]](https://people.cs.umass.edu/~kalo/papers/attribit/AttribIt.pdf)\n<p align=""center""><img width=""30%"" src=""http://gfx.cs.princeton.edu/gfx/pubs/Chaudhuri_2013_ACC/teaser.jpg"" /></p>\n\n<b>Learning Part-based Templates from Large Collections of 3D Shapes (2013)</b> [[Paper]](http://shape.cs.princeton.edu/vkcorrs/papers/13_SIGGRAPH_CorrsTmplt.pdf)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/test1/blob/master/imgs/Learning%20Part-based%20Templates%20from%20Large%20Collections%20of%203D%20Shapes.png"" /></p>\n\n<b>Topology-Varying 3D Shape Creation via Structural Blending (2014)</b> [[Paper]](http://gruvi.cs.sfu.ca/project/topo/)\n<p align=""center""><img width=""50%"" src=""https://i.ytimg.com/vi/Xc4qf7v6a-w/maxresdefault.jpg"" /></p>\n\n<b>Estimating Image Depth using Shape Collections (2014)</b> [[Paper]](http://vecg.cs.ucl.ac.uk/Projects/SmartGeometry/image_shape_net/imageShapeNet_sigg14.html)\n<p align=""center""><img width=""50%"" src=""http://vecg.cs.ucl.ac.uk/Projects/SmartGeometry/image_shape_net/paper_docs/pipeline.jpg"" /></p>\n\n<b>Single-View Reconstruction via Joint Analysis of Image and Shape Collections (2015)</b> [[Paper]](https://www.cs.utexas.edu/~huangqx/modeling_sig15.pdf)\n<p align=""center""><img width=""50%"" src=""http://vladlen.info/wp-content/uploads/2015/05/single-view.png"" /></p>\n\n<b>Interchangeable Components for Hands-On Assembly Based Modeling (2016)</b> [[Paper]](http://www.cs.umb.edu/~craigyu/papers/handson_low_res.pdf)\n<p align=""center""><img width=""30%"" src=""https://github.com/timzhang642/test1/blob/master/imgs/Interchangeable%20Components%20for%20Hands-On%20Assembly%20Based%20Modeling.png"" /></p>\n\n<b>Shape Completion from a Single RGBD Image (2016)</b> [[Paper]](http://www.kunzhou.net/2016/shapecompletion-tvcg16.pdf)\n<p align=""center""><img width=""40%"" src=""http://tianjiashao.com/Images/2015/completion.jpg"" /></p>\n\n<a name=""3d_synthesis_dl_based"" />\n\n_Deep Learning Methods_\n\n:camera: <b>Learning to Generate Chairs, Tables and Cars with Convolutional Networks (2014)</b> [[Paper]](https://arxiv.org/pdf/1411.5928.pdf)\n<p align=""center""><img width=""50%"" src=""https://zo7.github.io/img/2016-09-25-generating-faces/chairs-model.png"" /></p>\n\n:camera: <b>Weakly-supervised Disentangling with Recurrent Transformations for 3D View Synthesis (2015, NIPS)</b> [[Paper]](https://papers.nips.cc/paper/5639-weakly-supervised-disentangling-with-recurrent-transformations-for-3d-view-synthesis.pdf)\n<p align=""center""><img width=""50%"" src=""https://github.com/jimeiyang/deepRotator/blob/master/demo_img.png"" /></p>\n\n:game_die: <b>Analysis and synthesis of 3D shape families via deep-learned generative models of surfaces (2015)</b> [[Paper]](https://people.cs.umass.edu/~hbhuang/publications/bsm/)\n<p align=""center""><img width=""50%"" src=""https://people.cs.umass.edu/~hbhuang/publications/bsm/bsm_teaser.jpg"" /></p>\n\n:camera: <b>Weakly-supervised Disentangling with Recurrent Transformations for 3D View Synthesis (2015)</b> [[Paper]](https://papers.nips.cc/paper/5639-weakly-supervised-disentangling-with-recurrent-transformations-for-3d-view-synthesis.pdf) [[Code]](https://github.com/jimeiyang/deepRotator)\n<p align=""center""><img width=""50%"" src=""https://ai2-s2-public.s3.amazonaws.com/figures/2016-11-08/042993c46294a542946c9c1706b7b22deb1d7c43/2-Figure1-1.png"" /></p>\n\n:camera: <b>Multi-view 3D Models from Single Images with a Convolutional Network (2016)</b> [[Paper]](https://arxiv.org/pdf/1511.06702.pdf) [[Code]](https://github.com/lmb-freiburg/mv3d)\n<p align=""center""><img width=""50%"" src=""https://ai2-s2-public.s3.amazonaws.com/figures/2016-11-08/3d7ca5ad34f23a5fab16e73e287d1a059dc7ef9a/4-Figure2-1.png"" /></p>\n\n:camera: <b>View Synthesis by Appearance Flow (2016)</b> [[Paper]](https://people.eecs.berkeley.edu/~tinghuiz/papers/eccv16_appflow.pdf) [[Code]](https://github.com/tinghuiz/appearance-flow)\n<p align=""center""><img width=""50%"" src=""https://ai2-s2-public.s3.amazonaws.com/figures/2016-11-08/12280506dc8b5c3ca2db29fc3be694d9a8bef48c/6-Figure2-1.png"" /></p>\n\n:space_invader: <b>Voxlets: Structured Prediction of Unobserved Voxels From a Single Depth Image (2016)</b> [[Paper]](http://visual.cs.ucl.ac.uk/pubs/depthPrediction/http://visual.cs.ucl.ac.uk/pubs/depthPrediction/) [[Code]](https://github.com/mdfirman/voxlets)\n<p align=""center""><img width=""30%"" src=""https://i.ytimg.com/vi/1wy4y2GWD5o/maxresdefault.jpg"" /></p>\n\n:space_invader: <b>3D-R2N2: 3D Recurrent Reconstruction Neural Network (2016)</b> [[Paper]](http://cvgl.stanford.edu/3d-r2n2/) [[Code]](https://github.com/chrischoy/3D-R2N2)\n<p align=""center""><img width=""50%"" src=""http://3d-r2n2.stanford.edu/imgs/overview.png"" /></p>\n\n:space_invader: <b>Perspective Transformer Nets: Learning Single-View 3D Object Reconstruction without 3D Supervision (2016)</b> [[Paper]](https://eng.ucmerced.edu/people/jyang44/papers/nips16_ptn.pdf)\n<p align=""center""><img width=""70%"" src=""https://sites.google.com/site/skywalkeryxc/_/rsrc/1481104596238/perspective_transformer_nets/network_arch.png"" /></p>\n\n:space_invader: <b>TL-Embedding Network: Learning a Predictable and Generative Vector Representation for Objects (2016)</b> [[Paper]](https://arxiv.org/pdf/1603.08637.pdf)\n<p align=""center""><img width=""50%"" src=""https://rohitgirdhar.github.io/GenerativePredictableVoxels/assets/webteaser.jpg"" /></p>\n\n:space_invader: <b>3D GAN: Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling (2016)</b> [[Paper]](https://arxiv.org/pdf/1610.07584.pdf)\n<p align=""center""><img width=""50%"" src=""http://3dgan.csail.mit.edu/images/model.jpg"" /></p>\n\n:space_invader: <b>3D Shape Induction from 2D Views of Multiple Objects (2016)</b> [[Paper]](https://arxiv.org/pdf/1612.05872.pdf)\n<p align=""center""><img width=""50%"" src=""https://ai2-s2-public.s3.amazonaws.com/figures/2016-11-08/e78572eeef8b967dec420013c65a6684487c13b2/2-Figure2-1.png"" /></p>\n\n:camera: <b>Unsupervised Learning of 3D Structure from Images (2016)</b> [[Paper]](https://arxiv.org/pdf/1607.00662.pdf)\n<p align=""center""><img width=""50%"" src=""https://adriancolyer.files.wordpress.com/2016/12/unsupervised-3d-fig-10.jpeg?w=600"" /></p>\n\n:space_invader: <b>Generative and Discriminative Voxel Modeling with Convolutional Neural Networks (2016)</b> [[Paper]](https://arxiv.org/pdf/1608.04236.pdf) [[Code]](https://github.com/ajbrock/Generative-and-Discriminative-Voxel-Modeling)\n<p align=""center""><img width=""50%"" src=""http://davidstutz.de/wordpress/wp-content/uploads/2017/02/brock_vae.png"" /></p>\n\n:camera: <b>Multi-view Supervision for Single-view Reconstruction via Differentiable Ray Consistency (2017)</b> [[Paper]](https://shubhtuls.github.io/drc/)\n<p align=""center""><img width=""50%"" src=""https://shubhtuls.github.io/drc/resources/images/teaserChair.png"" /></p>\n\n:camera: <b>Synthesizing 3D Shapes via Modeling Multi-View Depth Maps and Silhouettes with Deep Generative Networks (2017)</b> [[Paper]](http://openaccess.thecvf.com/content_cvpr_2017/papers/Soltani_Synthesizing_3D_Shapes_CVPR_2017_paper.pdf)  [[Code]](https://github.com/Amir-Arsalan/Synthesize3DviaDepthOrSil)\n<p align=""center""><img width=""50%"" src=""https://jiajunwu.com/images/spotlight_3dvae.jpg"" /></p>\n\n:space_invader: <b>Shape Completion using 3D-Encoder-Predictor CNNs and Shape Synthesis (2017)</b> [[Paper]](https://arxiv.org/pdf/1612.00101.pdf) [[Code]](https://github.com/angeladai/cnncomplete)\n<p align=""center""><img width=""50%"" src=""http://graphics.stanford.edu/projects/cnncomplete/teaser.jpg"" /></p>\n\n:space_invader: <b>Octree Generating Networks: Efficient Convolutional Architectures for High-resolution 3D Outputs (2017)</b> [[Paper]](https://arxiv.org/pdf/1703.09438.pdf) [[Code]](https://github.com/lmb-freiburg/ogn)\n<p align=""center""><img width=""50%"" src=""https://ai2-s2-public.s3.amazonaws.com/figures/2016-11-08/6c2a292bb018a8742cbb0bbc5e23dd0a454ffe3a/2-Figure2-1.png"" /></p>\n\n:space_invader: <b>Hierarchical Surface Prediction for 3D Object Reconstruction (2017)</b> [[Paper]](https://arxiv.org/pdf/1704.00710.pdf)\n<p align=""center""><img width=""50%"" src=""http://bair.berkeley.edu/blog/assets/hsp/image_2.png"" /></p>\n\n:space_invader: <b>OctNetFusion: Learning Depth Fusion from Data (2017)</b> [[Paper]](https://arxiv.org/pdf/1704.01047.pdf) [[Code]](https://github.com/griegler/octnetfusion)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/OctNetFusion-%20Learning%20Depth%20Fusion%20from%20Data.jpeg"" /></p>\n\n:game_die: <b>A Point Set Generation Network for 3D Object Reconstruction from a Single Image (2017)</b> [[Paper]](http://ai.stanford.edu/~haosu/papers/SI2PC_arxiv_submit.pdf) [[Code]](https://github.com/fanhqme/PointSetGeneration)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/A%20Point%20Set%20Generation%20Network%20for%203D%20Object%20Reconstruction%20from%20a%20Single%20Image%20(2017).jpeg"" /></p>\n\n:game_die: <b>Learning Representations and Generative Models for 3D Point Clouds (2017)</b> [[Paper]](https://arxiv.org/pdf/1707.02392.pdf) [[Code]](https://github.com/optas/latent_3d_points)\n<p align=""center""><img width=""50%"" src=""https://github.com/optas/latent_3d_points/blob/master/doc/images/teaser.jpg"" /></p>\n\n:game_die: <b>Shape Generation using Spatially Partitioned Point Clouds (2017)</b> [[Paper]](https://arxiv.org/pdf/1707.06267.pdf)\n<p align=""center""><img width=""50%"" src=""http://mgadelha.me/sppc/fig/abstract.png"" /></p>\n\n:game_die: <b>PCPNET Learning Local Shape Properties from Raw Point Clouds (2017)</b> [[Paper]](https://arxiv.org/pdf/1710.04954.pdf)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/PCPNET%20Learning%20Local%20Shape%20Properties%20from%20Raw%20Point%20Clouds%20(2017).jpeg"" /></p>\n\n:camera: <b>Transformation-Grounded Image Generation Network for Novel 3D View Synthesis (2017)</b> [[Paper]](http://www.cs.unc.edu/~eunbyung/tvsn/) [[Code]](https://github.com/silverbottlep/tvsn)\n<p align=""center""><img width=""50%"" src=""https://eng.ucmerced.edu/people/jyang44/pics/view_synthesis.gif"" /></p>\n\n:camera: <b>Tag Disentangled Generative Adversarial Networks for Object Image Re-rendering (2017)</b> [[Paper]](http://static.ijcai.org/proceedings-2017/0404.pdf)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Tag%20Disentangled%20Generative%20Adversarial%20Networks%20for%20Object%20Image%20Re-rendering.jpeg"" /></p>\n\n:camera: <b>3D Shape Reconstruction from Sketches via Multi-view Convolutional Networks (2017)</b> [[Paper]](http://people.cs.umass.edu/~zlun/papers/SketchModeling/) [[Code]](https://github.com/happylun/SketchModeling)\n<p align=""center""><img width=""50%"" src=""https://people.cs.umass.edu/~zlun/papers/SketchModeling/SketchModeling_teaser.png"" /></p>\n\n:space_invader: <b>Interactive 3D Modeling with a Generative Adversarial Network (2017)</b> [[Paper]](https://arxiv.org/pdf/1706.05170.pdf)\n<p align=""center""><img width=""50%"" src=""https://pbs.twimg.com/media/DCsPKLqXoAEBd-V.jpg"" /></p>\n\n:camera::space_invader: <b>Weakly supervised 3D Reconstruction with Adversarial Constraint (2017)</b> [[Paper]](https://arxiv.org/pdf/1705.10904.pdf) [[Code]](https://github.com/jgwak/McRecon)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Weakly%20supervised%203D%20Reconstruction%20with%20Adversarial%20Constraint%20(2017).jpeg"" /></p>\n\n:camera: <b>SurfNet: Generating 3D shape surfaces using deep residual networks (2017)</b> [[Paper]](https://arxiv.org/pdf/1703.04079.pdf)\n<p align=""center""><img width=""50%"" src=""https://3dadept.com/wp-content/uploads/2017/07/Screenshot-from-2017-07-26-145521-e1501077539723.png"" /></p>\n\n:pill: <b>GRASS: Generative Recursive Autoencoders for Shape Structures (SIGGRAPH 2017)</b> [[Paper]](http://kevinkaixu.net/projects/grass.html) [[Code]](https://github.com/junli-lj/grass) [[code]](https://github.com/kevin-kaixu/grass_pytorch)\n<p align=""center""><img width=""50%"" src=""http://kevinkaixu.net/projects/grass/teaser.jpg"" /></p>\n\n:pill: <b> 3D-PRNN: Generating Shape Primitives with Recurrent Neural Networks (2017)</b> [[Paper]](https://arxiv.org/pdf/1708.01648.pdf)[[code]](https://github.com/zouchuhang/3D-PRNN)\n<p align=""center""><img width=""50%"" src=""https://github.com/zouchuhang/3D-PRNN/blob/master/figs/teasor.jpg"" /></p>\n\n:gem: <b>Neural 3D Mesh Renderer (2017)</b> [[Paper]](http://hiroharu-kato.com/projects_en/neural_renderer.html) [[Code]](https://github.com/hiroharu-kato/neural_renderer.git)\n<p align=""center""><img width=""50%"" src=""https://pbs.twimg.com/media/DPSm-4HWkAApEZd.jpg"" /></p>\n\n:game_die::space_invader: <b>Large-Scale 3D Shape Reconstruction and Segmentation from ShapeNet Core55 (2017)</b> [[Paper]](https://arxiv.org/pdf/1710.06104.pdf)\n<p align=""center""><img width=""40%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Core55.png"" /></p>\n\n:space_invader: <b>Pix2vox: Sketch-Based 3D Exploration with Stacked Generative Adversarial Networks (2017)</b> [[Code]](https://github.com/maxorange/pix2vox)\n<p align=""center""><img width=""50%"" src=""https://github.com/maxorange/pix2vox/blob/master/img/sample.gif"" /></p>\n\n:camera::space_invader: <b>What You Sketch Is What You Get: 3D Sketching using Multi-View Deep Volumetric Prediction (2017)</b> [[Paper]](https://arxiv.org/pdf/1707.08390.pdf)\n<p align=""center""><img width=""50%"" src=""https://arxiv-sanity-sanity-production.s3.amazonaws.com/render-output/31631/x1.png"" /></p>\n\n:camera::space_invader: <b>MarrNet: 3D Shape Reconstruction via 2.5D Sketches (2017)</b> [[Paper]](http://marrnet.csail.mit.edu/)\n<p align=""center""><img width=""50%"" src=""http://marrnet.csail.mit.edu/images/model.jpg"" /></p>\n\n:camera::space_invader::game_die: <b>Learning a Multi-View Stereo Machine (2017 NIPS)</b> [[Paper]](http://bair.berkeley.edu/blog/2017/09/05/unified-3d/) \n<p align=""center""><img width=""50%"" src=""http://bair.berkeley.edu/static/blog/unified-3d/Network.png"" /></p>\n\n:space_invader: <b>3DMatch: Learning Local Geometric Descriptors from RGB-D Reconstructions (2017)</b> [[Paper]](http://3dmatch.cs.princeton.edu/)\n<p align=""center""><img width=""50%"" src=""http://3dmatch.cs.princeton.edu/img/overview.jpg"" /></p>\n\n:space_invader: <b>Scaling CNNs for High Resolution Volumetric Reconstruction from a Single Image (2017)</b> [[Paper]](https://ieeexplore.ieee.org/document/8265323/)\n<p align=""center""><img width=""50%"" src=""https://github.com/frankhjwx/3D-Machine-Learning/blob/master/imgs/Scaling%20CNN%20Reconstruction.png"" /></p>\n\n:pill: <b>ComplementMe: Weakly-Supervised Component Suggestions for 3D Modeling (2017)</b> [[Paper]](https://arxiv.org/pdf/1708.01841.pdf)\n<p align=""center""><img width=""50%"" src=""https://mhsung.github.io/assets/images/complement-me/figure_2.png"" /></p>\n\n:game_die: <b>PU-Net: Point Cloud Upsampling Network (2018)</b> [[Paper]](https://arxiv.org/pdf/1801.06761.pdf) [[Code]](https://github.com/yulequan/PU-Net)\n<p align=""center""><img width=""50%"" src=""http://appsrv.cse.cuhk.edu.hk/~lqyu/indexpics/Pu-Net.png"" /></p> \n\n:camera::space_invader: <b>Multi-view Consistency as Supervisory Signal  for Learning Shape and Pose Prediction (2018 CVPR)</b> [[Paper]](https://shubhtuls.github.io/mvcSnP/)\n<p align=""center""><img width=""50%"" src=""https://shubhtuls.github.io/mvcSnP/resources/images/teaser.png"" /></p>\n\n:camera::game_die: <b>Object-Centric Photometric Bundle Adjustment with Deep Shape Prior (2018)</b> [[Paper]](http://ci2cv.net/media/papers/WACV18.pdf)\n<p align=""center""><img width=""50%"" src=""https://chenhsuanlin.bitbucket.io/images/rp/r06.png"" /></p>\n\n:camera::game_die: <b>Learning Efficient Point Cloud Generation for Dense 3D Object Reconstruction (2018 AAAI)</b> [[Paper]](https://chenhsuanlin.bitbucket.io/3D-point-cloud-generation/)\n<p align=""center""><img width=""50%"" src=""https://chenhsuanlin.bitbucket.io/images/rp/r05.png"" /></p>\n\n:gem: <b>Pixel2Mesh: Generating 3D Mesh Models from Single RGB Images (2018)</b> [[Paper]](https://github.com/nywang16/Pixel2Mesh)\n<p align=""center""><img width=""50%"" src=""https://www.groundai.com/media/arxiv_projects/188911/x2.png.750x0_q75_crop.png"" /></p>\n\n:gem: <b>AtlasNet: A Papier-M\xc3\xa2ch\xc3\xa9 Approach to Learning 3D Surface Generation (2018 CVPR)</b> [[Paper]](http://imagine.enpc.fr/~groueixt/atlasnet/) [[Code]](https://github.com/ThibaultGROUEIX/AtlasNet)\n<p align=""center""><img width=""50%"" src=""http://imagine.enpc.fr/~groueixt/atlasnet/imgs/teaser.small.png"" /></p>\n\n:space_invader::gem: <b>Deep Marching Cubes: Learning Explicit Surface Representations (2018 CVPR)</b> [[Paper]](http://www.cvlibs.net/publications/Liao2018CVPR.pdf)\n<p align=""center""><img width=""50%"" src=""https://github.com/frankhjwx/3D-Machine-Learning/blob/master/imgs/Deep%20Marching%20Cubes.png"" /></p>\n\n:space_invader: <b>Im2Avatar: Colorful 3D Reconstruction from a Single Image (2018)</b> [[Paper]](https://arxiv.org/pdf/1804.06375v1.pdf)\n<p align=""center""><img width=""50%"" src=""https://github.com/syb7573330/im2avatar/blob/master/misc/demo_teaser.png"" /></p>\n\n:gem: <b>Learning Category-Specific Mesh Reconstruction  from Image Collections (2018)</b> [[Paper]](https://akanazawa.github.io/cmr/#)\n<p align=""center""><img width=""50%"" src=""https://akanazawa.github.io/cmr/resources/images/teaser.png"" /></p>\n\n:pill: <b>CSGNet: Neural Shape Parser for Constructive Solid Geometry (2018)</b> [[Paper]](https://arxiv.org/pdf/1712.08290.pdf)\n<p align=""center""><img width=""50%"" src=""https://pbs.twimg.com/media/DR-RgbaU8AEyjeW.jpg"" /></p>\n\n:space_invader: <b>Text2Shape: Generating Shapes from Natural Language by Learning Joint Embeddings (2018)</b> [[Paper]](http://text2shape.stanford.edu/)\n<p align=""center""><img width=""50%"" src=""http://text2shape.stanford.edu/figures/pull.png"" /></p>\n\n:space_invader::gem::camera: <b>Multi-View Silhouette and Depth Decomposition for High Resolution 3D Object Representation (2018)</b>  [[Paper]](https://arxiv.org/abs/1802.09987) [[Code]](https://github.com/EdwardSmith1884/Multi-View-Silhouette-and-Depth-Decomposition-for-High-Resolution-3D-Object-Representation)\n<p align=""center""><img width=""60%"" src=""imgs/decomposition_new.png"" /> <img width=""60%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Multi-View%20Silhouette%20and%20Depth%20Decomposition%20for%20High%20Resolution%203D%20Object%20Representation.png"" /></p>\n\n:space_invader::gem::camera: <b>Pixels, voxels, and views: A study of shape representations for single view 3D object shape prediction (2018 CVPR)</b>  [[Paper]](https://arxiv.org/abs/1804.06032)\n<p align=""center""><img width=""60%"" src=""imgs/pixels-voxels-views-rgb2mesh.png"" /> </p>\n\n:camera::game_die: <b>Neural scene representation and rendering (2018)</b> [[Paper]](https://deepmind.com/blog/neural-scene-representation-and-rendering/)\n<p align=""center""><img width=""50%"" src=""http://www.arimorcos.com/static/images/publication_images/gqn_image.png"" /></p>\n\n:pill: <b>Im2Struct: Recovering 3D Shape Structure from a Single RGB Image (2018 CVPR)</b> [[Paper]](https://arxiv.org/pdf/1804.05469.pdf)\n<p align=""center""><img width=""50%"" src=""https://kevinkaixu.net/images/publications/niu_cvpr18.jpg"" /></p>\n\n:game_die: <b>FoldingNet: Point Cloud Auto-encoder via Deep Grid Deformation (2018 CVPR)</b> [[Paper]](https://arxiv.org/pdf/1712.07262.pdf)\n<p align=""center""><img width=""50%"" src=""http://simbaforrest.github.io/fig/FoldingNet.jpg"" /></p>\n\n:camera::space_invader: <b>Pix3D: Dataset and Methods for Single-Image 3D Shape Modeling (2018 CVPR)</b> [[Paper]](http://pix3d.csail.mit.edu/)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Pix3D%20-%20Dataset%20and%20Methods%20for%20Single-Image%203D%20Shape%20Modeling%20(2018%20CVPR).png"" /></p>\n\n:gem: <b>3D-RCNN: Instance-level 3D Object Reconstruction via Render-and-Compare (2018 CVPR)</b> [[Paper]](http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/1128.pdf)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/3D-RCNN-%20Instance-level%203D%20Object%20Reconstruction%20via%20Render-and-Compare%20(2018%20CVPR).jpeg"" /></p>\n\n:space_invader: <b>Matryoshka Networks: Predicting 3D Geometry via Nested Shape Layers (2018 CVPR)</b> [[Paper]](https://arxiv.org/pdf/1804.10975.pdf)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Matryoshka%20Networks-%20Predicting%203D%20Geometry%20via%20Nested%20Shape%20Layers%20(2018%20CVPR).jpeg"" /></p>\n\n:gem: <b>\t\nDeformable Shape Completion with Graph Convolutional Autoencoders (2018 CVPR)</b> [[Paper]](https://arxiv.org/pdf/1712.00268v1.pdf)\n<p align=""center""><img width=""50%"" src=""https://orlitany.github.io/OL_files/shapeComp.png"" /></p>\n\n:space_invader: <b>Global-to-Local Generative Model for 3D Shapes (SIGGRAPH Asia 2018)</b> [[Paper]](http://vcc.szu.edu.cn/research/2018/G2L)[[Code]](https://github.com/Hao-HUST/G2LGAN)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Global-to-Local%20Generative%20Model%20for%203D%20Shapes.jpg"" /></p>\n\n:gem::game_die::space_invader: <b>ALIGNet: Partial-Shape Agnostic Alignment via Unsupervised Learning (TOG 2018)</b> [[Paper]](https://bit.ly/alignet) [[Code]](https://github.com/ranahanocka/ALIGNet/)\n<p align=""center""><img width=""50%"" src=""https://github.com/ranahanocka/ALIGNet/blob/master/docs/rep.png"" /></p>\n\n:game_die::space_invader: <b>PointGrid: A Deep Network for 3D Shape Understanding (CVPR 2018) </b> [[Paper]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Le_PointGrid_A_Deep_CVPR_2018_paper.pdf) [[Code]](https://github.com/trucleduc/PointGrid)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/PointGrid-%20A%20Deep%20Network%20for%203D%20Shape%20Understanding%20(2018).jpeg"" /></p>\n\n:game_die: <b>GAL: Geometric Adversarial Loss for Single-View 3D-Object Reconstruction (2018)</b> [[Paper]](https://xjqi.github.io/GAL.pdf)\n<p align=""center""><img width=""50%"" src=""https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-030-01237-3_49/MediaObjects/474213_1_En_49_Fig2_HTML.gif"" /></p>\n\n:game_die: <b>Visual Object Networks: Image Generation with Disentangled 3D Representation (2018)</b> [[Paper]](https://papers.nips.cc/paper/7297-visual-object-networks-image-generation-with-disentangled-3d-representations.pdf)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Visual%20Object%20Networks-%20Image%20Generation%20with%20Disentangled%203D%20Representation%20(2018).jpeg"" /></p>\n\n:space_invader: <b>Learning to Infer and Execute 3D Shape Programs (2019))</b> [[Paper]](http://shape2prog.csail.mit.edu/)\n<p align=""center""><img width=""50%"" src=""http://shape2prog.csail.mit.edu/shape_files/teaser.jpg"" /></p>\n\n:space_invader: <b>Learning to Infer and Execute 3D Shape Programs (2019))</b> [[Paper]](https://arxiv.org/pdf/1901.05103.pdf)\n<p align=""center""><img width=""50%"" src=""https://pbs.twimg.com/media/DxFaW-mU8AEo9wc.jpg"" /></p>\n\n:gem: <b>Learning View Priors for Single-view 3D Reconstruction (CVPR 2019)</b> [[Paper]](http://hiroharu-kato.com/projects_en/view_prior_learning.html)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Learning%20View%20Priors%20for%20Single-view%203D%20Reconstruction.png"" /></p>\n\n:gem::game_die: <b>Learning Embedding of 3D models with Quadric Loss (BMVC 2019)</b> [[Paper]](https://arxiv.org/abs/1907.10250) [[Code]](https://github.com/nitinagarwal/QuadricLoss)\n<p align=""center""><img width=""50%"" src=""https://www.ics.uci.edu/~agarwal/bmvc_2019.png"" /></p>\n\n:game_die: <b>CompoNet: Learning to Generate the Unseen by Part Synthesis and Composition (ICCV 2019)</b> [[Paper]](https://arxiv.org/abs/1811.07441)[[Code]](https://github.com/nschor/CompoNet)\n<p align=""center""><img width=""50%"" src=""https://raw.githubusercontent.com/nschor/CompoNet/master/images/network_architecture.png"" /></p>\n\n<b>CoMA: Convolutional Mesh Autoencoders (2018)</b> [[Paper]](https://ps.is.tuebingen.mpg.de/uploads_file/attachment/attachment/439/1285.pdf)[[Code (TF)]](https://github.com/anuragranj/coma)[[Code (PyTorch)]](https://github.com/pixelite1201/pytorch_coma/)[[Code (PyTorch)]](https://github.com/sw-gong/coma)\n<br>[CoMA](https://coma.is.tue.mpg.de/) is a versatile model that learns a non-linear representation of a face using spectral convolutions on a mesh surface. CoMA introduces mesh sampling operations that enable a hierarchical mesh representation that captures non-linear variations in shape and expression at multiple scales within the model. \n<p align=""center""> <img width=""50%"" src=""https://coma.is.tue.mpg.de/uploads/ckeditor/pictures/91/content_coma_faces.jpg""></p>\n\n<b>RingNet: 3D Face Reconstruction from Single Images (2019)</b> [[Paper]](https://ps.is.tuebingen.mpg.de/uploads_file/attachment/attachment/509/paper_camera_ready.pdf)[[Code]](https://github.com/soubhiksanyal/RingNet)\n<p align=""center""> <img width=""50%"" src=""https://github.com/soubhiksanyal/RingNet/blob/master/gif/celeba_reconstruction.gif""></p>\n\n<b>VOCA: Voice Operated Character Animation (2019)</b> [[Paper]](https://ps.is.tuebingen.mpg.de/uploads_file/attachment/attachment/510/paper_final.pdf)[[Video]](https://youtu.be/XceCxf_GyW4)[[Code]](https://github.com/TimoBolkart/voca)\n<br>[VOCA](https://voca.is.tue.mpg.de/) is a simple and generic speech-driven facial animation framework that works across a range of identities. The codebase demonstrates how to synthesize realistic character animations given an arbitrary speech signal and a static character mesh.\n<p align=""center""> <img width=""50%"" src=""https://github.com/TimoBolkart/voca/blob/master/gif/speech_driven_animation.gif""></p>\n\n:gem: <b>Learning to Predict 3D Objects with an Interpolation-based Differentiable Renderer</b> [[Paper]](https://arxiv.org/abs/1908.01210)[[Site]](https://nv-tlabs.github.io/DIB-R/)[[Code]](https://github.com/nv-tlabs/DIB-R)\n<p align=""center""> <img width=""50%"" src=""https://nv-tlabs.github.io/DIB-R/figures/model2a-2.png""> </p>\n\n:gem: <b>Soft Rasterizer: A Differentiable Renderer for Image-based 3D Reasoning</b> [[Paper]](https://arxiv.org/abs/1904.01786)[[Code]](https://github.com/ShichenLiu/SoftRas)\n<p align=""center""> <img width=""50%"" src=""https://raw.githubusercontent.com/ShichenLiu/SoftRas/master/data/media/teaser/teaser.png""> </p>\n\n<b>NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis</b> [[Project]](http://www.matthewtancik.com/nerf)[[Paper]](https://arxiv.org/abs/2003.08934)[[Code]](https://github.com/bmild/nerf)\n<p align=""center""> <img width=""50%"" src=""https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/5e700ef6067b43821ed52768_pipeline_website-01-p-800.png""> </p>\n\n<a name=""material_synthesis"" />\n\n## Texture/Material Analysis and Synthesis\n<b>Texture Synthesis Using Convolutional Neural Networks (2015)</b> [[Paper]](https://arxiv.org/pdf/1505.07376.pdf)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Texture%20Synthesis%20Using%20Convolutional%20Neural%20Networks.jpeg"" /></p>\n\n<b>Two-Shot SVBRDF Capture for Stationary Materials (SIGGRAPH 2015)</b> [[Paper]](https://mediatech.aalto.fi/publications/graphics/TwoShotSVBRDF/)\n<p align=""center""><img width=""50%"" src=""https://mediatech.aalto.fi/publications/graphics/TwoShotSVBRDF/teaser.png"" /></p>\n\n<b>Reflectance Modeling by Neural Texture Synthesis (2016)</b> [[Paper]](https://mediatech.aalto.fi/publications/graphics/NeuralSVBRDF/)\n<p align=""center""><img width=""50%"" src=""https://mediatech.aalto.fi/publications/graphics/NeuralSVBRDF/teaser.png"" /></p>\n\n<b>Modeling Surface Appearance from a Single Photograph using Self-augmented Convolutional Neural Networks (2017)</b> [[Paper]](http://msraig.info/~sanet/sanet.htm)\n<p align=""center""><img width=""50%"" src=""http://msraig.info/~sanet/teaser.jpg"" /></p>\n\n<b>High-Resolution Multi-Scale Neural Texture Synthesis (2017)</b> [[Paper]](https://wxs.ca/research/multiscale-neural-synthesis/)\n<p align=""center""><img width=""50%"" src=""https://wxs.ca/research/multiscale-neural-synthesis/multiscale-gram-marble.jpg"" /></p>\n\n<b>Reflectance and Natural Illumination from Single Material Specular Objects Using Deep Learning (2017)</b> [[Paper]](https://homes.cs.washington.edu/~krematas/Publications/reflectance-natural-illumination.pdf)\n<p align=""center""><img width=""50%"" src=""http://www.vision.ee.ethz.ch/~georgous/images/tpami17_teaser2.png"" /></p>\n\n<b>Joint Material and Illumination Estimation from Photo Sets in the Wild (2017)</b> [[Paper]](https://arxiv.org/pdf/1710.08313.pdf)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Joint%20Material%20and%20Illumination%20Estimation%20from%20Photo%20Sets%20in%20the%20Wild.jpeg"" /></p>\n\n<b>JWhat Is Around The Camera? (2017)</b> [[Paper]](https://arxiv.org/pdf/1611.09325v2.pdf)\n<p align=""center""><img width=""50%"" src=""https://homes.cs.washington.edu/~krematas/my_images/arxiv16b_teaser.jpg"" /></p>\n\n<b>TextureGAN: Controlling Deep Image Synthesis with Texture Patches (2018 CVPR)</b> [[Paper]](https://arxiv.org/pdf/1706.02823.pdf)\n<p align=""center""><img width=""50%"" src=""http://texturegan.eye.gatech.edu/img/paper_figure.png"" /></p>\n\n<b>Gaussian Material Synthesis (2018 SIGGRAPH)</b> [[Paper]](https://users.cg.tuwien.ac.at/zsolnai/gfx/gaussian-material-synthesis/)\n<p align=""center""><img width=""50%"" src=""https://i.ytimg.com/vi/VM2ysCnD9GA/maxresdefault.jpg"" /></p>\n\n<b>Non-stationary Texture Synthesis by Adversarial Expansion (2018 SIGGRAPH)</b> [[Paper]](http://vcc.szu.edu.cn/research/2018/TexSyn)\n<p align=""center""><img width=""50%"" src=""https://github.com/jessemelpolio/non-stationary_texture_syn/blob/master/imgs/teaser.png"" /></p>\n\n<b>Synthesized Texture Quality Assessment via Multi-scale Spatial and Statistical Texture Attributes of Image and Gradient Magnitude Coefficients (2018 CVPR)</b> [[Paper]](https://arxiv.org/pdf/1804.08020.pdf)\n<p align=""center""><img width=""50%"" src=""https://user-images.githubusercontent.com/12434910/39275366-e18c7c1c-4899-11e8-8e61-05072618bbce.PNG"" /></p>\n\n<b>LIME: Live Intrinsic Material Estimation (2018 CVPR)</b> [[Paper]](https://gvv.mpi-inf.mpg.de/projects/LIME/)\n<p align=""center""><img width=""50%"" src=""https://web.stanford.edu/~zollhoef/papers/CVPR18_Material/teaser.png"" /></p>\n\n<b>Single-Image SVBRDF Capture with a Rendering-Aware Deep Network (2018)</b> [[Paper]](https://team.inria.fr/graphdeco/fr/projects/deep-materials/)\n<p align=""center""><img width=""50%"" src=""https://team.inria.fr/graphdeco/files/2018/08/teaser_v0.png"" /></p>\n\n<b>PhotoShape: Photorealistic Materials for Large-Scale Shape Collections (2018)</b> [[Paper]](https://keunhong.com/publications/photoshape/)\n<p align=""center""><img width=""50%"" src=""https://keunhong.com/publications/photoshape/teaser.jpg"" /></p>\n\n<b>Learning Material-Aware Local Descriptors for 3D Shapes (2018)</b> [[Paper]](http://www.vovakim.com/papers/18_3DV_ShapeMatFeat.pdf)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Learning%20Material-Aware%20Local%20Descriptors%20for%203D%20Shapes%20(2018).jpeg"" /></p>\n\n<b>FrankenGAN: Guided Detail Synthesis for Building Mass Models \nusing Style-Synchonized GANs (2018 SIGGRAPH Asia)</b> [[Paper]](http://geometry.cs.ucl.ac.uk/projects/2018/frankengan/)\n<p align=""center""><img width=""50%"" src=""http://geometry.cs.ucl.ac.uk/projects/2018/frankengan/paper_docs/teaser.jpg"" /></p>\n\n<a name=""style_transfer"" />\n\n## Style Learning and Transfer\n<b>Style-Content Separation by Anisotropic Part Scales (2010)</b> [[Paper]](https://www.cs.sfu.ca/~haoz/pubs/xu_siga10_style.pdf)\n<p align=""center""><img width=""50%"" src=""https://sites.google.com/site/kevinkaixu/_/rsrc/1472852123106/publications/style_b.jpg?height=145&width=400"" /></p>\n\n<b>Design Preserving Garment Transfer (2012)</b> [[Paper]](https://hal.inria.fr/hal-00695903/file/GarmentTransfer.pdf)\n<p align=""center""><img width=""30%"" src=""https://hal.inria.fr/hal-00695903v2/file/02_WomanToAll.jpg"" /></p>\n\n<b>Analogy-Driven 3D Style Transfer (2014)</b> [[Paper]](http://www.chongyangma.com/publications/st/index.html)\n<p align=""center""><img width=""50%"" src=""http://www.chongyangma.com/publications/st/2014_st_teaser.png"" /></p>\n\n<b>Elements of Style: Learning Perceptual Shape Style Similarity (2015)</b> [[Paper]](http://people.cs.umass.edu/~zlun/papers/StyleSimilarity/StyleSimilarity.pdf) [[Code]](https://github.com/happylun/StyleSimilarity)\n<p align=""center""><img width=""50%"" src=""https://people.cs.umass.edu/~zlun/papers/StyleSimilarity/StyleSimilarity_teaser.jpg"" /></p>\n\n<b>Functionality Preserving Shape Style Transfer (2016)</b> [[Paper]](http://people.cs.umass.edu/~zlun/papers/StyleTransfer/StyleTransfer.pdf) [[Code]](https://github.com/happylun/StyleTransfer)\n<p align=""center""><img width=""50%"" src=""https://people.cs.umass.edu/~zlun/papers/StyleTransfer/StyleTransfer_teaser.jpg"" /></p>\n\n<b>Unsupervised Texture Transfer from Images to Model Collections (2016)</b> [[Paper]](http://ai.stanford.edu/~haosu/papers/siga16_texture_transfer_small.pdf)\n<p align=""center""><img width=""50%"" src=""http://geometry.cs.ucl.ac.uk/projects/2016/texture_transfer/paper_docs/teaser.png"" /></p>\n\n<b>Learning Detail Transfer based on Geometric Features (2017)</b> [[Paper]](http://surfacedetails.cs.princeton.edu/)\n<p align=""center""><img width=""50%"" src=""http://surfacedetails.cs.princeton.edu/images/teaser.png"" /></p>\n\n<b>Co-Locating Style-Defining Elements on 3D Shapes (2017)</b> [[Paper]](http://people.scs.carleton.ca/~olivervankaick/pubs/style_elem.pdf)\n<p align=""center""><img width=""50%"" src=""http://s2017.siggraph.org/sites/default/files/styles/large/public/images/events/c118-e100-publicimage_0-itok=yO8OegQO.png"" /></p>\n\n<b>Neural 3D Mesh Renderer (2017)</b> [[Paper]](http://hiroharu-kato.com/projects_en/neural_renderer.html) [[Code]](https://github.com/hiroharu-kato/neural_renderer.git)\n<p align=""center""><img width=""50%"" src=""https://pbs.twimg.com/media/DPSm-4HWkAApEZd.jpg"" /></p>\n\n<b>Appearance Modeling via Proxy-to-Image Alignment (2018)</b> [[Paper]](http://vcc.szu.edu.cn/research/2018/AppMod)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Appearance%20Modeling%20via%20Proxy-to-Image%20Alignment.png"" /></p>\n\n:gem: <b>Pixel2Mesh: Generating 3D Mesh Models from Single RGB Images (2018)</b> [[Paper]](http://bigvid.fudan.edu.cn/pixel2mesh/)\n<p align=""center""><img width=""50%"" src=""https://pbs.twimg.com/media/DaIuEnfU0AAqesA.jpg"" /></p>\n\n<b>Automatic Unpaired Shape Deformation Transfer (SIGGRAPH Asia 2018)</b> [[Paper]](http://geometrylearning.com/ausdt/)\n<p align=""center""><img width=""50%"" src=""http://geometrylearning.com/ausdt/imgs/teaser.png"" /></p>\n\n<a name=""scene_synthesis"" />\n\n## Scene Synthesis/Reconstruction\n<b>Make It Home: Automatic Optimization of Furniture Arrangement (2011, SIGGRAPH)</b> [[Paper]](http://people.sutd.edu.sg/~saikit/projects/furniture/index.html)\n<p align=""center""><img width=""40%"" src=""https://www.cs.umb.edu/~craigyu/img/papers/furniture.gif"" /></p>\n\n<b>Interactive Furniture Layout Using Interior Design Guidelines (2011)</b> [[Paper]](http://graphics.stanford.edu/~pmerrell/furnitureLayout.htm)\n<p align=""center""><img width=""50%"" src=""http://vis.berkeley.edu/papers/furnitureLayout/furnitureBig.jpg"" /></p>\n\n<b>Synthesizing Open Worlds with Constraints using Locally Annealed Reversible Jump MCMC (2012)</b> [[Paper]](http://graphics.stanford.edu/~lfyg/owl.pdf)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Synthesizing%20Open%20Worlds%20with%20Constraints%20using%20Locally%20Annealed%20Reversible%20Jump%20MCMC%20(2012).jpeg"" /></p>\n\n<b>Example-based Synthesis of 3D Object Arrangements (2012 SIGGRAPH Asia)</b> [[Paper]](http://graphics.stanford.edu/projects/scenesynth/)\n<p align=""center""><img width=""60%"" src=""http://graphics.stanford.edu/projects/scenesynth/img/teaser.jpg"" /></p>\n\n<b>Sketch2Scene: Sketch-based Co-retrieval  and Co-placement of 3D Models  (2013)</b> [[Paper]](http://sweb.cityu.edu.hk/hongbofu/projects/sketch2scene_sig13/#.WWWge__ysb0)\n<p align=""center""><img width=""40%"" src=""http://sunweilun.github.io/images/paper/sketch2scene_thumb.jpg"" /></p>\n\n<b>Action-Driven 3D Indoor Scene Evolution (2016)</b> [[Paper]](https://www.cs.sfu.ca/~haoz/pubs/ma_siga16_action.pdf)\n<p align=""center""><img width=""50%"" src=""https://maruitx.github.io/project/adise/teaser.jpg"" /></p>\n\n<b>The Clutterpalette: An Interactive Tool for Detailing Indoor Scenes (2015)</b> [[Paper]](https://www.cs.umb.edu/~craigyu/papers/clutterpalette.pdf)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/The%20Clutterpalette-%20An%20Interactive%20Tool%20for%20Detailing%20Indoor%20Scenes.png"" /></p>\n\n<b>Relationship Templates for Creating Scene Variations (2016)</b> [[Paper]](http://geometry.cs.ucl.ac.uk/projects/2016/relationship-templates/)\n<p align=""center""><img width=""50%"" src=""http://geometry.cs.ucl.ac.uk/projects/2016/relationship-templates/paper_docs/teaser.png"" /></p>\n\n<b>IM2CAD (2017)</b> [[Paper]](http://homes.cs.washington.edu/~izadinia/im2cad.html)\n<p align=""center""><img width=""50%"" src=""http://i.imgur.com/KhtOeuB.jpg"" /></p>\n\n<b>Predicting Complete 3D Models of Indoor Scenes (2017)</b> [[Paper]](https://arxiv.org/pdf/1504.02437.pdf)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Predicting%20Complete%203D%20Models%20of%20Indoor%20Scenes.png"" /></p>\n\n<b>Complete 3D Scene Parsing from Single RGBD Image (2017)</b> [[Paper]](https://arxiv.org/pdf/1710.09490.pdf)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Complete%203D%20Scene%20Parsing%20from%20Single%20RGBD%20Image.jpeg"" /></p>\n\n<b>Raster-to-Vector: Revisiting Floorplan Transformation (2017, ICCV)</b> [[Paper]](http://www.cse.wustl.edu/~chenliu/floorplan-transformation.html) [[Code]](https://github.com/art-programmer/FloorplanTransformation)\n<p align=""center""><img width=""50%"" src=""https://www.cse.wustl.edu/~chenliu/floorplan-transformation/teaser.png"" /></p>\n\n<b>Fully Convolutional Refined Auto-Encoding Generative Adversarial Networks for 3D Multi Object Scenes (2017)</b> [[Blog]](https://becominghuman.ai/3d-multi-object-gan-7b7cee4abf80)\n<p align=""center""><img width=""50%"" src=""https://cdn-images-1.medium.com/max/1600/1*NckW2hfgbHhEP3P8Z5ZLjQ.png"" /></p>\n\n<b>Adaptive Synthesis of Indoor Scenes via Activity-Associated Object Relation Graphs (2017 SIGGRAPH Asia)</b> [[Paper]](http://arts.buaa.edu.cn/projects/sa17/)\n<p align=""center""><img width=""50%"" src=""https://sa2017.siggraph.org/images/events/c121-e45-publicimage.jpg"" /></p>\n\n<b>Automated Interior Design Using a Genetic Algorithm (2017)</b> [[Paper]](https://publik.tuwien.ac.at/files/publik_262718.pdf)\n<p align=""center""><img width=""50%"" src=""http://www.peterkan.com/pictures/teaserq.jpg"" /></p>\n\n<b>SceneSuggest: Context-driven 3D Scene Design (2017)</b> [[Paper]](https://arxiv.org/pdf/1703.00061.pdf)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/SceneSuggest%20-Context-driven%203D%20Scene%20Design%20(2017).png"" /></p>\n\n<b>A fully end-to-end deep learning approach for real-time simultaneous 3D reconstruction and material recognition (2017)</b> [[Paper]](https://arxiv.org/pdf/1703.04699v1.pdf)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/A%20fully%20end-to-end%20deep%20learning%20approach%20for%20real-time%20simultaneous%203D%20reconstruction%20and%20material%20recognition%20(2017).png"" /></p>\n\n<b>Human-centric Indoor Scene Synthesis Using Stochastic Grammar (2018, CVPR)</b>[[Paper]](http://web.cs.ucla.edu/~syqi/publications/cvpr2018synthesis/cvpr2018synthesis.pdf) [[Supplementary]](http://web.cs.ucla.edu/~syqi/publications/cvpr2018synthesis/cvpr2018synthesis_supplementary.pdf) [[Code]](https://github.com/SiyuanQi/human-centric-scene-synthesis)\n<p align=""center""><img width=""50%"" src=""http://web.cs.ucla.edu/~syqi/publications/thumbnails/cvpr2018synthesis.gif"" /></p>\n\n:camera::game_die: <b>FloorNet: A Unified Framework for Floorplan Reconstruction from 3D Scans (2018)</b> [[Paper]](https://arxiv.org/pdf/1804.00090.pdf) [[Code]](http://art-programmer.github.io/floornet.html)\n<p align=""center""><img width=""50%"" src=""http://art-programmer.github.io/floornet/teaser.png"" /></p>\n\n:space_invader: <b>ScanComplete: Large-Scale Scene Completion and Semantic Segmentation for 3D Scans (2018)</b> [[Paper]](https://arxiv.org/pdf/1712.10215.pdf) \n<p align=""center""><img width=""50%"" src=""https://niessnerlab.org/papers/2018/3scancomplete/teaser.jpg"" /></p>\n\n<b>Deep Convolutional Priors for Indoor Scene Synthesis (2018)</b> [[Paper]](https://kwang-ether.github.io/pdf/deepsynth.pdf) \n<p align=""center""><img width=""50%"" src=""http://msavva.github.io/files/deepsynth.png"" /></p>\n\n<b>Configurable 3D Scene Synthesis and 2D Image Rendering\nwith Per-Pixel Ground Truth using Stochastic Grammars (2018)</b> [[Paper]](https://arxiv.org/pdf/1704.00112.pdf) \n<p align=""center""><img width=""50%"" src=""https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs11263-018-1103-5/MediaObjects/11263_2018_1103_Fig5_HTML.jpg"" /></p>\n\n<b>Holistic 3D Scene Parsing and Reconstruction from a Single RGB Image (ECCV 2018)</b> [[Paper]](http://siyuanhuang.com/holistic_parsing/main.html) \n<p align=""center""><img width=""50%"" src=""http://web.cs.ucla.edu/~syqi/publications/thumbnails/eccv2018scene.png"" /></p>\n\n<b>Language-Driven Synthesis of 3D Scenes from Scene Databases (SIGGRAPH Asia 2018)</b> [[Paper]](http://www.sfu.ca/~agadipat/publications/2018/T2S/project_page.html) \n<p align=""center""><img width=""50%"" src=""http://www.sfu.ca/~agadipat/publications/2018/T2S/teaser.png"" /></p>\n\n<b>Deep Generative Modeling for Scene Synthesis via Hybrid Representations (2018)</b> [[Paper]](https://arxiv.org/pdf/1808.02084.pdf) \n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Deep%20Generative%20Modeling%20for%20Scene%20Synthesis%20via%20Hybrid%20Representations%20(2018).jpeg"" /></p>\n\n<b>GRAINS: Generative Recursive Autoencoders for INdoor Scenes (2018)</b> [[Paper]](https://arxiv.org/pdf/1807.09193.pdf) \n<p align=""center""><img width=""50%"" src=""https://www.groundai.com/media/arxiv_projects/373503/new_pics/teaserfig.jpg.750x0_q75_crop.jpg"" /></p>\n\n<b>SEETHROUGH: Finding Objects in Heavily Occluded Indoor Scene Images (2018)</b> [[Paper]](http://www.vovakim.com/papers/18_3DVOral_SeeThrough.pdf) \n<p align=""center""><img width=""50%"" src=""http://geometry.cs.ucl.ac.uk/projects/2018/seethrough/paper_docs/result_plate.png"" /></p>\n\n<b>:space_invader: Scan2CAD: Learning CAD Model Alignment in RGB-D Scans (CVPR 2019)</b> [[Paper]](https://arxiv.org/pdf/1811.11187.pdf) [[Code]](https://github.com/skanti/Scan2CAD)\n<p align=""center""><img width=""50%"" src=""http://www.niessnerlab.org/papers/2019/5scan2cad/teaser.jpg"" /></p>\n\n<b>:gem: Scan2Mesh: From Unstructured Range Scans to 3D Meshes (CVPR 2019)</b> [[Paper]](https://arxiv.org/pdf/1811.10464.pdf)\n<p align=""center""><img width=""50%"" src=""http://www.niessnerlab.org/papers/2019/4scan2mesh/teaser.jpg"" /></p>\n\n<b>:space_invader: 3D-SIC: 3D Semantic Instance Completion for RGB-D Scans (arXiv 2019)</b> [[Paper]](https://arxiv.org/pdf/1904.12012.pdf)\n<p align=""center""><img width=""50%"" src=""http://www.niessnerlab.org/papers/2019/z1sic/teaser.jpg"" /></p>\n\n<b>:space_invader: End-to-End CAD Model Retrieval and 9DoF Alignment in 3D Scans (arXiv 2019)</b> [[Paper]](https://arxiv.org/abs/1906.04201)\n<p align=""center""><img width=""50%"" src=""http://www.niessnerlab.org/papers/2019/z2end2end/teaser.jpg"" /></p>\n\n<a name=""scene_understanding"" />\n\n## Scene Understanding\n<b>Recovering the Spatial Layout of Cluttered Rooms (2009)</b> [[Paper]](http://dhoiem.cs.illinois.edu/publications/iccv2009_hedau_indoor.pdf)\n<p align=""center""><img width=""60%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Recovering%20the%20Spatial%20Layout%20of%20Cluttered%20Rooms.png"" /></p>\n\n<b>Characterizing Structural Relationships in Scenes Using Graph Kernels (2011 SIGGRAPH)</b> [[Paper]](https://graphics.stanford.edu/~mdfisher/graphKernel.html)\n<p align=""center""><img width=""60%"" src=""https://graphics.stanford.edu/~mdfisher/papers/graphKernelTeaser.png"" /></p>\n\n<b>Understanding Indoor Scenes Using 3D Geometric Phrases (2013)</b> [[Paper]](http://cvgl.stanford.edu/projects/3dgp/)\n<p align=""center""><img width=""30%"" src=""http://cvgl.stanford.edu/projects/3dgp/images/title.png"" /></p>\n\n<b>Organizing Heterogeneous Scene Collections through Contextual Focal Points (2014 SIGGRAPH)</b> [[Paper]](http://kevinkaixu.net/projects/focal.html)\n<p align=""center""><img width=""60%"" src=""http://kevinkaixu.net/projects/focal/overlapping_clusters.jpg"" /></p>\n\n<b>SceneGrok: Inferring Action Maps in 3D Environments (2014, SIGGRAPH)</b> [[Paper]](http://graphics.stanford.edu/projects/scenegrok/)\n<p align=""center""><img width=""50%"" src=""http://graphics.stanford.edu/projects/scenegrok/scenegrok.png"" /></p>\n\n<b>PanoContext: A Whole-room 3D Context Model for Panoramic Scene Understanding (2014)</b> [[Paper]](http://panocontext.cs.princeton.edu/)\n<p align=""center""><img width=""50%"" src=""http://panocontext.cs.princeton.edu/teaser.jpg"" /></p>\n\n<b>Learning Informative Edge Maps for Indoor Scene Layout Prediction (2015)</b> [[Paper]](http://slazebni.cs.illinois.edu/publications/iccv15_informative.pdf)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Learning%20Informative%20Edge%20Maps%20for%20Indoor%20Scene%20Layout%20Prediction.png"" /></p>\n\n<b>Rent3D: Floor-Plan Priors for Monocular Layout Estimation (2015)</b> [[Paper]](http://www.cs.toronto.edu/~fidler/projects/rent3D.html)\n<p align=""center""><img width=""50%"" src=""http://www.cs.toronto.edu/~fidler/projects/layout-res.jpg"" /></p>\n\n<b>A Coarse-to-Fine Indoor Layout Estimation (CFILE) Method (2016)</b> [[Paper]](https://pdfs.semanticscholar.org/7024/a92186b81e6133dc779f497d06877b48d82b.pdf?_ga=2.54181869.497995160.1510977308-665742395.1510465328)\n<p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/A%20Coarse-to-Fine%20Indoor%20Layout%20Estimation%20(CFILE)%20Method%20(2016).png"" /></p>\n\n<b>DeLay: Robust Spatial Layout Estimation for Cluttered Indoor Scenes (2016)</b> [[Paper]](http://deeplayout.stanford.edu/)\n<p align=""center""><img width=""30%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/DeLay-Robust%20Spatial%20Layout%20Estimation%20for%20Cluttered%20Indoor%20Scenes.png"" /></p>\n\n<b>3D Semantic Parsing of Large-Scale Indoor Spaces (2016)</b> [[Paper]](http://buildingparser.stanford.edu/method.html) [[Code]](https://github.com/alexsax/2D-3D-Semantics)\n<p align=""center""><img width=""50%"" src=""http://buildingparser.stanford.edu/images/teaser.png"" /></p>\n\n<b>Single Image 3D Interpreter Network (2016)</b> [[Paper]](http://3dinterpreter.csail.mit.edu/) [[Code]](https://github.com/jiajunwu/3dinn)\n<p align=""center""><img width=""50%"" src=""http://3dinterpreter.csail.mit.edu/images/spotlight_3dinn_large.jpg"" /></p>\n\n<b>Deep Multi-Modal Image Correspondence Learning (2016)</b> [[Paper]](http://www.cse.wustl.edu/~chenliu/floorplan-matching.html)\n<p align=""center""><img width=""50%"" src=""http://art-programmer.github.io/floorplan-matching/teaser.png"" /></p>\n\n<b>Physically-Based Rendering for Indoor Scene Understanding Using Convolutional Neural Networks (2017)</b> [[Paper]](http://3dvision.princeton.edu/projects/2016/PBRS/) [[Code]](https://github.com/yindaz/pbrs) [[Code]](https://github.com/yindaz/surface_normal) [[Code]](https://github.com/fyu/dilation) [[Code]](https://github.com/s9xie/hed)\n<p align=""center""><img width=""50%"" src=""https://pbs.twimg.com/media/C0YERJOXEAA69xN.jpg"" /></p>\n\n<b>RoomNet: End-to-End Room Layout Estimation (2017)</b> [[Paper]](https://arxiv.org/pdf/1703.06241.pdf)\n<p align=""center""><img width=""50%"" src=""https://pbs.twimg.com/media/C7Z29GsV0AASEvR.jpg"" /></p>\n\n<b>SUN RGB-D: A RGB-D Scene Understanding Benchmark Suite (2017)</b> [[Paper]](http://rgbd.cs.princeton.edu/)\n<p align=""center""><img width=""50%"" src=""http://rgbd.cs.princeton.edu/teaser.jpg"" /></p>\n\n<b>Semantic Scene Completion from a Single Depth Image (2017)</b> [[Paper]](http://sscnet.cs.princeton.edu/) [[Code]](https://github.com/shurans/sscnet)\n<p align=""center""><img width=""50%"" src=""http://sscnet.cs.princeton.edu/teaser.jpg"" /></p>\n\n<b>Factoring Shape, Pose, and Layout  from the 2D Image of a 3D Scene (2018 CVPR)</b> [[Paper]](https://arxiv.org/pdf/1712.01812.pdf) [[Code]](https://shubhtuls.github.io/factored3d/)\n<p align=""center""><img width=""50%"" src=""https://shubhtuls.github.io/factored3d/resources/images/teaser.png"" /></p>\n\n<b>LayoutNet: Reconstructing the 3D Room Layout from a Single RGB Image (2018 CVPR)</b> [[Paper]](https://arxiv.org/pdf/1803.08999.pdf) [[Code]](https://github.com/zouchuhang/LayoutNet)\n<p align=""center""><img width=""50%"" src=""http://p0.ifengimg.com/pmop/2018/0404/A1D0CAE48130C918FE624FA60495F237C67172F6_size63_w797_h755.jpeg"" /></p>\n\n<b>PlaneNet: Piece-wise Planar Reconstruction from a Single RGB Image (2018 CVPR)</b> [[Paper]](http://art-programmer.github.io/planenet/paper.pdf) [[Code]](http://art-programmer.github.io/planenet.html)\n<p align=""center""><img width=""50%"" src=""http://art-programmer.github.io/images/planenet.png"" /></p>\n\n<b>Cross-Domain Self-supervised Multi-task Feature Learning using Synthetic Imagery (2018 CVPR)</b> [[Paper]](http://web.cs.ucdavis.edu/~yjlee/projects/cvpr2018.pdf) <p align=""center""><img width=""50%"" src=""https://jason718.github.io/project/cvpr18/files/concept_pic.png"" /></p>\n\n<b>Pano2CAD: Room Layout From A Single Panorama Image (2018 CVPR)</b> [[Paper]](http://bjornstenger.github.io/papers/xu_wacv2017.pdf) <p align=""center""><img width=""50%"" src=""https://www.groundai.com/media/arxiv_projects/58924/figures/Compare_2b.png"" /></p>\n\n<b>Automatic 3D Indoor Scene Modeling from Single Panorama (2018 CVPR)</b> [[Paper]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Yang_Automatic_3D_Indoor_CVPR_2018_paper.pdf) <p align=""center""><img width=""50%"" src=""https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Automatic%203D%20Indoor%20Scene%20Modeling%20from%20Single%20Panorama%20(2018%20CVPR).jpeg"" /></p>\n\n<b>Single-Image Piece-wise Planar 3D Reconstruction via Associative Embedding (2019 CVPR)</b> [[Paper]](https://arxiv.org/pdf/1902.09777.pdf) [[Code]](https://github.com/svip-lab/PlanarReconstruction) <p align=""center""><img width=""50%"" src=""https://github.com/svip-lab/PlanarReconstruction/blob/master/misc/pipeline.jpg"" /></p>\n\n<b>3D-Aware Scene Manipulation via Inverse Graphics (NeurIPS 2018)</b> [[Paper]](http://3dsdn.csail.mit.edu/) [[Code]](https://github.com/svip-lab/PlanarReconstruction) <p align=""center""><img width=""50%"" src=""http://3dsdn.csail.mit.edu/images/teaser.png"" /></p>\n\n:gem: <b>3D Scene Reconstruction with Multi-layer Depth and Epipolar Transformers (ICCV 2019)</b> [[Paper]](https://research.dshin.org/iccv19/multi-layer-depth/) <p align=""center""><img width=""50%"" src=""https://research.dshin.org/iccv19/multi-layer-depth/figures/overview_1.png"" /><br><img width=""50%"" src=""https://research.dshin.org/iccv19/multi-layer-depth/figures/voxelization00.jpg"" /></p>\n'"
27,RedstoneWill/HsuanTienLin_MachineLearning,RedstoneWill,,2018-05-05 05:42:53,2020-06-18 04:24:03,,705,1898,b'# NTU-HsuanTienLin-MachineLearning\xef\xbc\x88\xe6\x9e\x97\xe8\xbd\xa9\xe7\x94\xb0\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x89\n\n![](images/1.jpg)\n\n## 1. \xe8\xaf\xbe\xe7\xa8\x8b\xe4\xbb\x8b\xe7\xbb\x8d\n\n\xe5\x8f\xb0\xe6\xb9\xbe\xe5\xa4\xa7\xe5\xad\xa6\xe6\x9e\x97\xe8\xbd\xa9\xe7\x94\xb0\xe8\x80\x81\xe5\xb8\x88\xe6\x9b\xbe\xe5\x9c\xa8coursera\xe4\xb8\x8a\xe5\xbc\x80\xe8\xae\xbe\xe4\xba\x86\xe4\xb8\xa4\xe9\x97\xa8\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xbb\x8f\xe5\x85\xb8\xe8\xaf\xbe\xe7\xa8\x8b\xef\xbc\x9a\xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x9f\xba\xe7\x9f\xb3\xe3\x80\x8b\xe5\x92\x8c\xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x8a\x80\xe6\xb3\x95\xe3\x80\x8b\xe3\x80\x82\xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x9f\xba\xe7\x9f\xb3\xe3\x80\x8b\xe8\xaf\xbe\xe7\xa8\x8b\xe7\x94\xb1\xe6\xb5\x85\xe5\x85\xa5\xe6\xb7\xb1\xe3\x80\x81\xe5\x86\x85\xe5\xae\xb9\xe5\x85\xa8\xe9\x9d\xa2\xef\xbc\x8c\xe5\x9f\xba\xe6\x9c\xac\xe6\xb6\xb5\xe7\x9b\x96\xe4\xba\x86\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe9\xa2\x86\xe5\x9f\x9f\xe7\x9a\x84\xe5\xbe\x88\xe5\xa4\x9a\xe6\x96\xb9\xe9\x9d\xa2\xe3\x80\x82\xe5\x85\xb6\xe4\xbd\x9c\xe4\xb8\xba\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9a\x84\xe5\x85\xa5\xe9\x97\xa8\xe5\x92\x8c\xe8\xbf\x9b\xe9\x98\xb6\xe8\xb5\x84\xe6\x96\x99\xe9\x9d\x9e\xe5\xb8\xb8\xe9\x80\x82\xe5\x90\x88\xe3\x80\x82\xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x8a\x80\xe6\xb3\x95\xe3\x80\x8b\xe8\xaf\xbe\xe7\xa8\x8b\xe4\xb8\xbb\xe8\xa6\x81\xe4\xbb\x8b\xe7\xbb\x8d\xe4\xba\x86\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe9\xa2\x86\xe5\x9f\x9f\xe7\xbb\x8f\xe5\x85\xb8\xe7\x9a\x84\xe4\xb8\x80\xe4\xba\x9b\xe7\xae\x97\xe6\xb3\x95\xef\xbc\x8c\xe5\x8c\x85\xe6\x8b\xac\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba\xe3\x80\x81\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe3\x80\x81\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\xe3\x80\x81\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe7\xad\x89\xe7\xad\x89\xe3\x80\x82\xe6\x9e\x97\xe8\x80\x81\xe5\xb8\x88\xe7\x9a\x84\xe6\x95\x99\xe5\xad\xa6\xe9\xa3\x8e\xe6\xa0\xbc\xe4\xb9\x9f\xe5\xbe\x88\xe5\xb9\xbd\xe9\xbb\x98\xe9\xa3\x8e\xe8\xb6\xa3\xef\xbc\x8c\xe6\x80\xbb\xe8\xae\xa9\xe8\xaf\xbb\xe8\x80\x85\xe5\x9c\xa8\xe8\xbd\xbb\xe6\x9d\xbe\xe6\x84\x89\xe5\xbf\xab\xe7\x9a\x84\xe6\xb0\x9b\xe5\x9b\xb4\xe4\xb8\xad\xe6\x8e\x8c\xe6\x8f\xa1\xe7\x9f\xa5\xe8\xaf\x86\xe3\x80\x82\xe5\x9c\xa8\xe6\xad\xa4\xef\xbc\x8c\xe7\xac\x94\xe8\x80\x85\xe5\xb0\x86\xe6\x8a\x8a\xe8\xbf\x99\xe4\xb8\xa4\xe9\x97\xa8\xe8\xaf\xbe\xe7\x9a\x84\xe6\x89\x80\xe6\x9c\x89\xe8\xa7\x86\xe9\xa2\x91\xe3\x80\x81\xe7\xac\x94\xe8\xae\xb0\xe3\x80\x81\xe4\xb9\xa6\xe7\xb1\x8d\xe7\xad\x89\xe8\xaf\xa6\xe7\xbb\x86\xe8\xb5\x84\xe6\x96\x99\xe5\x88\x86\xe4\xba\xab\xe7\xbb\x99\xe5\xa4\xa7\xe5\xae\xb6\xe3\x80\x82\n\n\xe9\xa6\x96\xe5\x85\x88\xe9\x99\x84\xe4\xb8\x8a\xe8\xbf\x99\xe4\xb8\xa4\xe9\x97\xa8\xe8\xaf\xbe\xe7\x9a\x84\xe4\xb8\xbb\xe9\xa1\xb5\xef\xbc\x9a\n\n[Hsuan-Tien Lin \xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x9f\xba\xe7\x9f\xb3](https://www.csie.ntu.edu.tw/~htlin/)\n\n## 2. \xe8\xaf\xbe\xe7\xa8\x8b\xe5\x86\x85\xe5\xae\xb9\n\n### 2.1 \xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x9f\xba\xe7\x9f\xb3\xe3\x80\x8b\n\n\xe8\xbf\x99\xe9\x97\xa8\xe8\xaf\xbe\xe4\xb8\xbb\xe8\xa6\x81\xe6\xb6\x89\xe5\x8f\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x85\xb3\xe9\x94\xae\xe9\x97\xae\xe9\xa2\x98\xe7\x9a\x84\xe5\x9b\x9b\xe4\xb8\xaa\xe6\x96\xb9\xe9\x9d\xa2\xef\xbc\x9a\n\n- **When Can Machine Learn?**\n\n- **Why Can Machine Learn?**\n\n- **How Can Machine Learn?**\n\n- **How Can Machine Learn Better?**\n\n\xe5\x85\xb6\xe4\xb8\xad\xe6\xaf\x8f\xe4\xb8\xaa\xe6\x96\xb9\xe9\x9d\xa2\xe5\x8c\x85\xe5\x90\xab4\xe8\x8a\x82\xe8\xaf\xbe\xef\xbc\x8c\xe6\x80\xbb\xe5\x85\xb1\xe6\x9c\x8916\xe8\x8a\x82\xe8\xaf\xbe\xe3\x80\x82\xe5\x85\xb7\xe4\xbd\x93\xe6\x89\x80\xe6\x9c\x89\xe8\xaf\xbe\xe7\xa8\x8b\xe5\x86\x85\xe5\xae\xb9\xe5\xa6\x82\xe4\xb8\x8b\xef\xbc\x9a\n\n- **When Can Machine Learn?**\n\t\n - [The Learning Problem](https://redstonewill.com/65/)\n\n - [Learning to Answer Yes/No](https://redstonewill.com/70/)\n\n - [Types of Learning](https://redstonewill.com/73/)\n\n - [Feasibility of Learning](https://redstonewill.com/77/)\n\n- **Why Can Machine Learn?**\n\n - [Training versus Testing](https://redstonewill.com/80/)\n\n - [Theory of Generalization](https://redstonewill.com/217/)\n\n - [The VC Dimension](https://redstonewill.com/222/)\n\n - [Noise and Error](https://redstonewill.com/227/)\n\n- **How Can Machine Learn?**\n\n - [Linear Regression](https://redstonewill.com/232/)\n\n - [Logistic Regression](https://redstonewill.com/236/)\n\n - [Linear Models for Classification](https://redstonewill.com/243/)\n\n - [Nonlinear Transformation](https://redstonewill.com/246/)\n\n- **How Can Machine Learn Better?**\n\n - [Hazard of Overfitting](https://redstonewill.com/249/)\n\n - [Regularization](https://redstonewill.com/252/)\n\n - [Validation](https://redstonewill.com/255/)\n\n - [Three Learning Principles](https://redstonewill.com/311/)\n\t\n### 2.2 \xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x8a\x80\xe6\xb3\x95\xe3\x80\x8b\n\n\xe8\xbf\x99\xe9\x97\xa8\xe8\xaf\xbe\xe4\xb8\xbb\xe8\xa6\x81\xe6\xb6\x89\xe5\x8f\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xbb\x8f\xe5\x85\xb8\xe7\xae\x97\xe6\xb3\x95\xe7\x9a\x84\xe4\xb8\x89\xe4\xb8\xaa\xe6\x96\xb9\xe9\x9d\xa2\xef\xbc\x9a\n\n- **Embedding Numerous Features: Kernel Models**\n\n- **Combining Predictive Features: Aggregation Models**\n\n- **Distilling Implicit Features: Extraction Models**\n\n\xe6\x80\xbb\xe5\x85\xb1\xe6\x9c\x8916\xe8\x8a\x82\xe8\xaf\xbe\xe3\x80\x82\xe5\x85\xb7\xe4\xbd\x93\xe6\x89\x80\xe6\x9c\x89\xe8\xaf\xbe\xe7\xa8\x8b\xe5\x86\x85\xe5\xae\xb9\xe5\xa6\x82\xe4\xb8\x8b\xef\xbc\x9a\n\n- **Embedding Numerous Features: Kernel Models**\n\t\n - [Linear Support Vector Machine](https://redstonewill.com/345/)\n\n - [Dual Support Vector Machine](https://redstonewill.com/369/)\n\n - [Kernel Support Vector Machine](https://redstonewill.com/393/)\n\n - [Soft-Margin Support Vector Machine](https://redstonewill.com/417/)\n\t\n - [Kernel Logistic Regression](https://redstonewill.com/456/)\n\t\n - [Support Vector Regression](https://redstonewill.com/477/)\n\n- **Combining Predictive Features: Aggregation Models**\n\n - [Blending and Bagging](https://redstonewill.com/509/)\n\n - [Adaptive Boosting](https://redstonewill.com/535/)\n\n - [Decision Tree](https://redstonewill.com/569/)\n\n - [Random Forest](https://redstonewill.com/601/)\n\t\n - [Gradient Boosted Decision Tree](https://redstonewill.com/644/)\n\n- **Distilling Implicit Features: Extraction Models**\n\n - [Neural Network](https://redstonewill.com/682/)\n\n - [Deep Learning](https://redstonewill.com/710/)\n\n - [Radial Basis Function Network](https://redstonewill.com/739/)\n\n - [Matrix Factorization](https://redstonewill.com/783/)\n\t\n - [Finale](https://redstonewill.com/810/)\n\n## 3. \xe8\xb5\x84\xe6\xba\x90\xe6\xb1\x87\xe6\x80\xbb\n\n\xe7\xac\x94\xe8\x80\x85\xe5\x9c\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xbf\x99\xe9\x97\xa8\xe8\xaf\xbe\xe7\x9a\x84\xe8\xbf\x87\xe7\xa8\x8b\xe4\xb8\xad\xe6\x95\xb4\xe7\x90\x86\xe4\xba\x86\xe5\x90\x84\xe7\xa7\x8d\xe8\xaf\xbe\xe7\xa8\x8b\xe8\xb5\x84\xe6\xba\x90\xef\xbc\x8c\xe5\x8c\x85\xe6\x8b\xac\xe8\xa7\x86\xe9\xa2\x91\xe3\x80\x81\xe7\xac\x94\xe8\xae\xb0\xe3\x80\x81\xe4\xb9\xa6\xe7\xb1\x8d\xe7\xad\x89\xe3\x80\x82\xe5\x85\xb7\xe4\xbd\x93\xe5\xa6\x82\xe4\xb8\x8b\xef\xbc\x9a\n\n### 3.1 \xe8\xaf\xbe\xe7\xa8\x8b\xe8\xa7\x86\xe9\xa2\x91\n\n\xe8\xaf\xbe\xe7\xa8\x8b\xe8\xa7\x86\xe9\xa2\x91\xe5\x9c\xa8B\xe7\xab\x99\xe4\xb8\x8a\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x9b\xb4\xe6\x8e\xa5\xe8\xa7\x82\xe7\x9c\x8b\xe5\x93\xa6\xef\xbd\x9e\xe8\xbf\x99\xe9\x87\x8c\xe9\x99\x84\xe4\xb8\x8a\xe4\xbc\xa0\xe9\x80\x81\xe9\x97\xa8\xef\xbc\x9a\n\n[\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x9f\xba\xe7\x9f\xb3\xef\xbc\x88\xe6\x9e\x97\xe8\xbd\xa9\xe7\x94\xb0\xef\xbc\x89](https://www.bilibili.com/video/av36731342)\n\n[\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x8a\x80\xe6\xb3\x95\xef\xbc\x88\xe6\x9e\x97\xe8\xbd\xa9\xe7\x94\xb0\xef\xbc\x89](https://www.bilibili.com/video/av36760800)\n\n### 3.2 \xe8\xaf\xbe\xe7\xa8\x8b\xe8\xaf\xbe\xe4\xbb\xb6\n\n\xe6\xad\xa4\xe9\xa1\xb9\xe7\x9b\xae\xe5\x8c\x85\xe5\x90\xab\xe4\xba\x86\xe6\x9e\x97\xe8\xbd\xa9\xe7\x94\xb0\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xaf\xbe\xe7\xa8\x8b\xe5\xae\x8c\xe6\x95\xb4\xe7\x9a\x84\xe8\xaf\xbe\xe4\xbb\xb6\xef\xbc\x9a\n\n![](images/2.png)\n\n### 3.3 \xe8\xaf\xbe\xe7\xa8\x8b\xe7\xac\x94\xe8\xae\xb0\n\n\xe8\xbf\x99\xe6\x98\xaf\xe7\xac\x94\xe8\x80\x85\xe6\x9c\x80\xe7\x94\xa8\xe5\xbf\x83\xe6\x95\xb4\xe7\x90\x86\xe4\xb9\x9f\xe6\x98\xaf\xe8\x8a\xb1\xe7\x9a\x84\xe6\x97\xb6\xe9\x97\xb4\xe6\x9c\x80\xe5\xa4\x9a\xe7\x9a\x84\xef\xbc\x8c\xe8\xaf\xbb\xe8\x80\x85\xe5\x8f\xaf\xe4\xbb\xa5\xe8\xbe\xb9\xe7\x9c\x8b\xe8\xa7\x86\xe9\xa2\x91\xe8\xbe\xb9\xe7\x9c\x8b\xe6\x88\x91\xe7\x9a\x84\xe7\xac\x94\xe8\xae\xb0\xef\xbc\x8c\xe5\xb8\x8c\xe6\x9c\x9b\xe8\x83\xbd\xe7\xbb\x99\xe8\xaf\xbb\xe8\x80\x85\xe6\x8f\x90\xe4\xbe\x9b\xe5\xbe\xae\xe8\x96\x84\xe4\xb9\x8b\xe5\x8a\x9b\xe3\x80\x82\xe6\x89\x80\xe6\x9c\x89\xe7\xb2\xbe\xe7\x82\xbc\xe7\xac\x94\xe8\xae\xb0\xe9\x83\xbd\xe5\xb7\xb2\xe5\x8f\x91\xe5\xb8\x83\xe5\x9c\xa8\xe4\xb8\xaa\xe4\xba\xba\xe4\xb8\xbb\xe9\xa1\xb5\xe4\xb8\x8a\xe3\x80\x82\xe4\xbd\x86\xe6\x98\xaf\xe4\xb8\xba\xe4\xba\x86\xe4\xbe\xbf\xe4\xba\x8e\xe5\xa4\xa7\xe5\xae\xb6\xe7\xba\xbf\xe4\xb8\x8b\xe9\x98\x85\xe8\xaf\xbb\xef\xbc\x8c\xe7\x89\xb9\xe6\xad\xa4\xe5\xb0\x86\xe7\xac\x94\xe8\xae\xb0\xe7\x9a\x84pdf\xe6\x96\x87\xe4\xbb\xb6\xe5\x85\xa8\xe9\x83\xbd\xe5\x8f\x91\xe5\xb8\x83\xe5\x9c\xa8github\xe4\xb8\x8a\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbe\x9b\xe6\x9f\xa5\xe9\x98\x85\xe5\x92\x8c\xe6\x89\x93\xe5\x8d\xb0\xe3\x80\x82\n\n![](images/3.png)\n\n\xe5\x8f\xa6\xe5\xa4\x96\xef\xbc\x8c\xe6\x88\x91\xe5\xb7\xb2\xe7\xbb\x8f\xe6\x8a\x8a\xe5\xae\x8c\xe6\x95\xb4\xe7\x9a\x84\xe6\x9e\x97\xe8\xbd\xa9\xe7\x94\xb0\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xac\x94\xe8\xae\xb0\xe6\x95\xb4\xe7\x90\x86\xe6\x88\x90\xe4\xb8\x80\xe4\xb8\xaapdf\xe6\x96\x87\xe4\xbb\xb6\xef\xbc\x8c\xe5\xb0\xb1\xe6\x94\xbe\xe5\x9c\xa8\xe9\xa1\xb9\xe7\x9b\xae\xe6\xa0\xb9\xe7\x9b\xae\xe5\xbd\x95\xe4\xb8\x8b\xe4\xba\x86\xe3\x80\x82\n\n### 3.4 \xe8\xaf\xbe\xe7\xa8\x8b\xe4\xb9\xa6\xe7\xb1\x8d\n\n\xe6\x9e\x97\xe8\xbd\xa9\xe7\x94\xb0\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x9f\xba\xe7\x9f\xb3\xe8\xbf\x99\xe9\x97\xa8\xe8\xaf\xbe\xe6\x9c\x89\xe4\xb8\x80\xe4\xb8\xaa\xe9\x85\x8d\xe5\xa5\x97\xe6\x95\x99\xe6\x9d\x90\xef\xbc\x9a\xe3\x80\x8aLearning From Data\xe3\x80\x8b\xef\xbc\x8c\xe6\x9e\x97\xe8\xbd\xa9\xe7\x94\xb0\xe4\xb9\x9f\xe6\x98\xaf\xe7\xbc\x96\xe8\x80\x85\xe4\xb9\x8b\xe4\xb8\x80\xe3\x80\x82\xe8\xbf\x99\xe6\x9c\xac\xe4\xb9\xa6\xe7\x9a\x84\xe4\xb8\xbb\xe9\xa1\xb5\xe4\xb8\xba\xef\xbc\x9a\n\n[Learning From Data](http://amlbook.com/)\n\n![](images/4.jpg)\n\n\xe8\xb1\x86\xe7\x93\xa3\xe4\xb8\x8a\xe5\x85\xb3\xe4\xba\x8e\xe8\xbf\x99\xe6\x9c\xac\xe4\xb9\xa6\xe7\x9a\x84\xe8\xaf\x84\xe5\x88\x86\xe9\xab\x98\xe8\xbe\xbe9.4\xef\xbc\x8c\xe8\xbf\x98\xe6\x98\xaf\xe5\xbe\x88\xe4\xb8\x8d\xe9\x94\x99\xe7\x9a\x84\xef\xbc\x8c\xe5\x80\xbc\xe5\xbe\x97\xe6\x8e\xa8\xe8\x8d\x90\xef\xbc\x81\xe5\x8f\xaf\xe4\xbb\xa5\xe9\x85\x8d\xe5\xa5\x97\xe8\xa7\x86\xe9\xa2\x91\xe4\xb8\x80\xe8\xb5\xb7\xe5\xad\xa6\xe4\xb9\xa0\xe3\x80\x82\n\n![](images/5.jpg)\n\n\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x8a\x80\xe6\xb3\x95\xe5\xaf\xb9\xe8\xbf\x99\xe6\x9c\xac\xe4\xb9\xa6\xe6\xb7\xbb\xe5\x8a\xa0\xe4\xba\x86\xe4\xb8\x80\xe4\xba\x9b\xe7\xab\xa0\xe8\x8a\x82\xef\xbc\x8c\xe4\xbd\x9c\xe4\xb8\xba\xe6\x89\xa9\xe5\xb1\x95\xe3\x80\x82\xe5\x8e\x9f\xe4\xb9\xa6\xe5\x92\x8c\xe9\x99\x84\xe5\x8a\xa0\xe7\xab\xa0\xe8\x8a\x82\xe5\x9d\x87\xe6\x94\xbe\xe5\x9c\xa8\xe6\x9c\xac\xe9\xa1\xb9\xe7\x9b\xae\xe4\xb8\xad\xe3\x80\x82\n\n![](images/6.png)\n\n### 4 \xe5\xae\x8c\xe6\x95\xb4\xe4\xb8\x8b\xe8\xbd\xbd\n\n\xe8\xaf\xa5GitHub\xe9\xa1\xb9\xe7\x9b\xae\xe4\xb8\xad\xe5\xae\x8c\xe6\x95\xb4\xe7\x9a\x84\xe8\xb5\x84\xe6\xba\x90\xe5\x9d\x87\xe5\xb7\xb2\xe6\x95\xb4\xe7\x90\x86\xe5\xa5\xbd\xef\xbc\x8c\xe6\x96\xb9\xe4\xbe\xbf\xe5\xa4\xa7\xe5\xae\xb6\xe5\x85\x8d\xe8\xb4\xb9\xe4\xb8\x8b\xe8\xbd\xbd\xe3\x80\x82\xe6\x83\xb3\xe8\xa6\x81\xe8\x8e\xb7\xe5\xbe\x97\xe7\xa6\xbb\xe7\xba\xbf\xe8\xb5\x84\xe6\xba\x90\xe7\x9a\x84\xe5\x8f\xaf\xe4\xbb\xa5\xe5\x9c\xa8\xe5\x85\xac\xe4\xbc\x97\xe5\x8f\xb7\xef\xbc\x9a**AI\xe6\x9c\x89\xe9\x81\x93\xef\xbc\x88ID: redstonewill\xef\xbc\x89**\xef\xbc\x8c\xe5\x90\x8e\xe5\x8f\xb0\xe5\x9b\x9e\xe5\xa4\x8d\xef\xbc\x9a**Lin**\xef\xbc\x8c\xe5\x8d\xb3\xe5\x8f\xaf\xe8\x8e\xb7\xe5\x8f\x96\xe3\x80\x82\n\n![](images/7.jpg)\n\n## 5. \xe6\x9c\x80\xe5\x90\x8e\n\n\xe5\xa6\x82\xe6\x9e\x9c\xe8\xa7\x89\xe5\xbe\x97\xe6\x88\x91\xe7\x9a\x84\xe5\x88\x86\xe4\xba\xab\xe5\xaf\xb9\xe4\xbd\xa0\xe6\x9c\x89\xe7\x94\xa8\xef\xbc\x8c\xe9\x82\xa3\xe4\xb9\x88\xe5\xb0\xb1**Star**\xe4\xb8\x80\xe4\xb8\x8b\xe5\x90\xa7\xef\xbd\x9e\xe5\x90\x8c\xe6\x97\xb6\xef\xbc\x8c\xe4\xb9\x9f\xe6\xac\xa2\xe8\xbf\x8e\xe5\xa4\xa7\xe5\xae\xb6\xe5\x85\xb3\xe6\xb3\xa8\xe6\x88\x91\xe7\x9a\x84\xe5\xbe\xae\xe4\xbf\xa1\xe5\x85\xac\xe4\xbc\x97\xe5\x8f\xb7\xef\xbc\x9a**AI\xe6\x9c\x89\xe9\x81\x93\xef\xbc\x88ID: redstonewill\xef\xbc\x89**\xe3\x80\x82\xe6\x88\x91\xe4\xbc\x9a\xe4\xb8\x80\xe5\xa6\x82\xe6\x97\xa2\xe5\xbe\x80\xe5\x8f\x91\xe5\xb8\x83\xe6\x9b\xb4\xe5\xa4\x9a\xe6\x9b\xb4\xe5\xa5\xbd\xe7\x9a\x84\xe6\x96\x87\xe7\xab\xa0\xe7\xbb\x99\xe5\xa4\xa7\xe5\xae\xb6\xef\xbc\x81\xe4\xb8\x80\xe8\xb5\xb7\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x8c\xe5\x85\xb1\xe5\x90\x8c\xe8\xbf\x9b\xe6\xad\xa5\xef\xbc\x81\n\n![](images/7.jpg)\n\n\xe5\x90\x8c\xe6\x97\xb6\xef\xbc\x8c\xe4\xb9\x9f\xe6\xac\xa2\xe8\xbf\x8e\xe5\x8a\xa0\xe5\x85\xa5AI\xe6\x9c\x89\xe9\x81\x93\xe6\x8a\x80\xe6\x9c\xaf\xe4\xba\xa4\xe6\xb5\x81QQ\xe7\xbe\xa4\xef\xbc\x8c\xe8\xbf\x9b\xe8\xa1\x8c\xe4\xba\xa4\xe6\xb5\x81\xef\xbc\x9a\xef\xbc\x88\xe7\xbe\xa4\xe5\x8f\xb7\xef\xbc\x9a223490966\xef\xbc\x89\n\n![](images/8.jpg)\n\n## \xe4\xb8\xaa\xe4\xba\xba\xe4\xb8\xbb\xe9\xa1\xb5\n\n**\xe5\x85\xac\xe4\xbc\x97\xe5\x8f\xb7**\xef\xbc\x9aAI\xe6\x9c\x89\xe9\x81\x93\xef\xbc\x88ID\xef\xbc\x9aredstonewill\xef\xbc\x89\n\n**\xe5\x8d\x9a\xe5\xae\xa2**\xef\xbc\x9a[http://redstonewill.com/](http://redstonewill.com/)\n\n**\xe7\x9f\xa5\xe4\xb9\x8e**\xef\xbc\x9a[https://www.zhihu.com/people/red_stone_wl](https://www.zhihu.com/people/red_stone_wl)\n\n**\xe5\xbe\xae\xe5\x8d\x9a**\xef\xbc\x9a[AI\xe6\x9c\x89\xe9\x81\x93](https://weibo.com/aiyoudao?from=profile&wvr=6)\n\n\n\n'
28,ddbourgin/numpy-ml,ddbourgin,"Machine learning, in numpy",2019-04-06 22:29:49,2020-06-18 11:39:24,Python,2493,8745,"b'# numpy-ml\nEver wish you had an inefficient but somewhat legible collection of machine\nlearning algorithms implemented exclusively in numpy? No?\n\n## Documentation\nTo see all of the available models, take a look at the [project documentation](https://numpy-ml.readthedocs.io/) or see [here](https://github.com/ddbourgin/numpy-ml/blob/master/numpy_ml/README.md).\n\n## Contributing\n\nAm I missing your favorite model? Is there something that could be cleaner /\nless confusing? Did I mess something up? Submit a PR! The only requirement is\nthat your models are written with just the [Python standard\nlibrary](https://docs.python.org/3/library/) and [NumPy](https://www.numpy.org/). The\n[SciPy library](https://scipy.github.io/devdocs/) is also permitted under special\ncircumstances ;)\n\nSee full contributing guidelines [here](./CONTRIBUTING.md).\n'"
29,roboticcam/machine-learning-notes,roboticcam,"My continuously updated Machine Learning, Probabilistic Models and Deep Learning notes and demos (1500+ slides)  我不间断更新的机器学习，概率模型和深度学习的讲义(1500+页)和视频链接",2018-02-15 15:42:33,2020-06-18 07:29:19,Jupyter Notebook,1125,3935,"b'# Sinovasinovation DeeCamp \xe5\x88\x9b\xe6\x96\xb0\xe5\xb7\xa5\xe5\x9c\xbaDeeCAMP\xe8\xae\xb2\xe4\xb9\x89\n\n* ### [DeeCamp 2019\xef\xbc\x9aStory of Softmax](https://github.com/roboticcam/machine-learning-notes/blob/master/files/deecamp_2019.pdf) ###\n\nproperties of Softmax, Estimating softmax without compute denominator, Probability re-parameterization: Gumbel-Max trick and REBAR algorithm\n(softmax\xe7\x9a\x84\xe6\x95\x85\xe4\xba\x8b) Softmax\xe7\x9a\x84\xe5\xb1\x9e\xe6\x80\xa7, \xe4\xbc\xb0\xe8\xae\xa1softmax\xe6\x97\xb6\xe4\xb8\x8d\xe9\x9c\x80\xe8\xae\xa1\xe7\xae\x97\xe5\x88\x86\xe6\xaf\x8d, \xe6\xa6\x82\xe7\x8e\x87\xe9\x87\x8d\xe6\x96\xb0\xe5\x8f\x82\xe6\x95\xb0\xe5\x8c\x96, Gumbel-Max\xe6\x8a\x80\xe5\xb7\xa7\xe5\x92\x8cREBAR\xe7\xae\x97\xe6\xb3\x95\n\n* ### [DeeCamp 2018\xef\xbc\x9aWhen Probabilities meet Neural Networks](https://github.com/roboticcam/machine-learning-notes/blob/master/files/DeeCamp2018_Xu_final.pptx) ###\n\nExpectation-Maximization & Matrix Capsule Networks; Determinantal Point Process & Neural Networks compression; Kalman Filter & LSTM; Model estimation & Binary classifier\n(\xe5\xbd\x93\xe6\xa6\x82\xe7\x8e\x87\xe9\x81\x87\xe5\x88\xb0\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c) \xe4\xb8\xbb\xe9\xa2\x98\xe5\x8c\x85\xe6\x8b\xac\xef\xbc\x9aEM\xe7\xae\x97\xe6\xb3\x95\xe5\x92\x8c\xe7\x9f\xa9\xe9\x98\xb5\xe8\x83\xb6\xe5\x9b\x8a\xe7\xbd\x91\xe7\xbb\x9c; \xe8\xa1\x8c\xe5\x88\x97\xe5\xbc\x8f\xe7\x82\xb9\xe8\xbf\x87\xe7\xa8\x8b\xe5\x92\x8c\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe5\x8e\x8b\xe7\xbc\xa9; \xe5\x8d\xa1\xe5\xb0\x94\xe6\x9b\xbc\xe6\xbb\xa4\xe6\xb3\xa2\xe5\x99\xa8\xe5\x92\x8cLSTM; \xe6\xa8\xa1\xe5\x9e\x8b\xe4\xbc\xb0\xe8\xae\xa1\xe5\x92\x8c\xe4\xba\x8c\xe5\x88\x86\xe7\xb1\xbb\xe9\x97\xae\xe9\xa2\x98\xe5\x85\xb3\xe7\xb3\xbb\n\n# Video Tutorial to these notes \xe8\xa7\x86\xe9\xa2\x91\xe8\xb5\x84\xe6\x96\x99\n\n* I recorded about 20% of these notes in videos in 2015 in Mandarin (all my notes and writings are in English) You may find them on [Youtube](https://www.youtube.com/channel/UConITmGn5PFr0hxTI2tWD4Q) and [bilibili](https://space.bilibili.com/327617676) and [Youku](http://i.youku.com/i/UMzIzNDgxNTg5Ng)       \n\n\xe6\x88\x91\xe5\x9c\xa82015\xe5\xb9\xb4\xe7\x94\xa8\xe4\xb8\xad\xe6\x96\x87\xe5\xbd\x95\xe5\x88\xb6\xe4\xba\x86\xe8\xbf\x99\xe4\xba\x9b\xe8\xaf\xbe\xe4\xbb\xb6\xe4\xb8\xad\xe7\xba\xa620\xef\xbc\x85\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9 (\xe6\x88\x91\xe7\x9b\xae\xe5\x89\x8d\xe7\x9a\x84\xe8\xaf\xbe\xe4\xbb\xb6\xe9\x83\xbd\xe6\x98\xaf\xe8\x8b\xb1\xe6\x96\x87\xe7\x9a\x84)\xe5\xa4\xa7\xe5\xae\xb6\xe5\x8f\xaf\xe4\xbb\xa5\xe5\x9c\xa8[Youtube](https://www.youtube.com/channel/UConITmGn5PFr0hxTI2tWD4Q) [\xe5\x93\x94\xe5\x93\xa9\xe5\x93\x94\xe5\x93\xa9](https://space.bilibili.com/327617676) and [\xe4\xbc\x98\xe9\x85\xb7](http://i.youku.com/i/UMzIzNDgxNTg5Ng) \xe4\xb8\x8b\xe8\xbd\xbd\n\n# 3D Geometry Computer vision 3D\xe5\x87\xa0\xe4\xbd\x95\xe8\xae\xa1\xe7\xae\x97\xe6\x9c\xba\xe8\xa7\x86\xe8\xa7\x89 \n\n* ### [3D Geometry Fundamentals](https://github.com/roboticcam/machine-learning-notes/blob/master/files/cv_3d_foundation.pdf) ###\nCamera Models, Intrinsic and Extrinsic parameter estimation, Epipolar Geometry, 3D reconstruction, Depth Estimation\n\xe7\x9b\xb8\xe6\x9c\xba\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x8c\xe5\x86\x85\xe9\x83\xa8\xe5\x92\x8c\xe5\xa4\x96\xe9\x83\xa8\xe5\x8f\x82\xe6\x95\xb0\xe4\xbc\xb0\xe8\xae\xa1\xef\xbc\x8c\xe5\xaf\xb9\xe6\x9e\x81\xe5\x87\xa0\xe4\xbd\x95\xef\xbc\x8c\xe4\xb8\x89\xe7\xbb\xb4\xe9\x87\x8d\xe5\xbb\xba\xef\xbc\x8c\xe5\x9b\xbe\xe5\x83\x8f\xe6\xb7\xb1\xe5\xba\xa6\xe4\xbc\xb0\xe8\xae\xa1\n\n* ### [Recent Deep 3D Geometry based Research](https://github.com/roboticcam/machine-learning-notes/blob/master/files/cv_3d_research.pdf) ###\nRecent research of the following topics: Single image to Camera Model estimation, Multi-Person 3D pose estimation from multi-view, GAN-based 3D pose estimation, Deep Structure-from-Motion, Deep Learning based Depth Estimation, \xe4\xbb\xa5\xe4\xb8\x8b\xe4\xb8\xbb\xe9\xa2\x98\xe7\x9a\x84\xe6\x9c\x80\xe6\x96\xb0\xe7\xa0\x94\xe7\xa9\xb6\xef\xbc\x9a\xe5\x8d\x95\xe5\x9b\xbe\xe5\x83\x8f\xe5\x88\xb0\xe7\x9b\xb8\xe6\x9c\xba\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe4\xbc\xb0\xe8\xae\xa1\xef\xbc\x8c\xe5\x9f\xba\xe4\xba\x8e\xe5\xa4\x9a\xe8\xa7\x86\xe5\x9b\xbe\xe7\x9a\x84\xe5\xa4\x9a\xe4\xba\xba3D\xe5\xa7\xbf\xe5\x8a\xbf\xe4\xbc\xb0\xe8\xae\xa1\xef\xbc\x8c\xe5\x9f\xba\xe4\xba\x8eGAN\xe7\x9a\x843D\xe5\xa7\xbf\xe5\x8a\xbf\xe4\xbc\xb0\xe8\xae\xa1\xef\xbc\x8c\xe5\x9f\xba\xe4\xba\x8e\xe8\xbf\x90\xe5\x8a\xa8\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\xe7\xbb\x93\xe6\x9e\x84\xef\xbc\x8c\xe5\x9f\xba\xe4\xba\x8e\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\xe4\xbc\xb0\xe8\xae\xa1\n\nThis section is co-authored with PhD student Yang Li \xe6\x9c\xac\xe9\x83\xa8\xe5\x88\x86\xe4\xb8\x8e\xe5\x8d\x9a\xe5\xa3\xab\xe7\xa0\x94\xe7\xa9\xb6\xe7\x94\x9f\xe6\x9d\x8e\xe6\x9d\xa8\xe5\x90\x88\xe5\x86\x99\n\n# Deep Learning \xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe8\xaf\xbe\xe4\xbb\xb6\n\n* ### [New Research on Softmax function](https://github.com/roboticcam/machine-learning-notes/blob/master/files/softmax.pdf) ###\nOut-of-distribution, Neural Network Calibration, Gumbel-Max trick, Stochastic Beams Search (some of these lectures overlap with DeeCamp2019)\n\n\xe5\x88\x86\xe5\xb8\x83\xe5\xa4\x96\xe3\x80\x81\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe6\xa0\xa1\xe5\x87\x86\xe3\x80\x81Gumbel-Max \xe6\x8a\x80\xe5\xb7\xa7\xe3\x80\x81\xe9\x9a\x8f\xe6\x9c\xba\xe5\x85\x89\xe6\x9d\x9f(BEAM)\xe6\x90\x9c\xe7\xb4\xa2\xef\xbc\x88\xe5\x85\xb6\xe4\xb8\xad\xe4\xb8\x80\xe4\xba\x9b\xe8\xae\xb2\xe5\xba\xa7\xe4\xb8\x8e DeeCamp2019 \xe9\x87\x8d\xe5\x8f\xa0\xef\xbc\x89\n\n* ### [Optimisation methods](https://github.com/roboticcam/machine-learning-notes/blob/master/files/optimization.pdf) ###\nOptimisation methods in general. not limited to just Deep Learning\n\n\xe5\xb8\xb8\xe7\x94\xa8\xe7\x9a\x84\xe4\xbc\x98\xe5\x8c\x96\xe6\x96\xb9\xe6\xb3\x95\xe3\x80\x82\xe4\xb8\x8d\xe4\xbb\x85\xe9\x99\x90\xe4\xba\x8e\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\n\n* ### [Neural Networks](https://github.com/roboticcam/machine-learning-notes/blob/master/files/neural_networks.pdf) ###\nbasic neural networks and multilayer perceptron \n\n\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c: \xe5\x9f\xba\xe6\x9c\xac\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe5\x92\x8c\xe5\xa4\x9a\xe5\xb1\x82\xe6\x84\x9f\xe7\x9f\xa5\xe5\x99\xa8\n\n* ### [Convolution Neural Networks: from basic to recent Research](https://github.com/roboticcam/machine-learning-notes/blob/master/files/cnn_beyond.pdf) ###\ndetailed explanation of CNN, various Loss function, Centre Loss, contrastive Loss, Residual Networks, Capsule Networks, YOLO, SSD\n\n\xe5\x8d\xb7\xe7\xa7\xaf\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xef\xbc\x9a\xe4\xbb\x8e\xe5\x9f\xba\xe7\xa1\x80\xe5\x88\xb0\xe6\x9c\x80\xe8\xbf\x91\xe7\x9a\x84\xe7\xa0\x94\xe7\xa9\xb6\xef\xbc\x9a\xe5\x8c\x85\xe6\x8b\xac\xe5\x8d\xb7\xe7\xa7\xaf\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe7\x9a\x84\xe8\xaf\xa6\xe7\xbb\x86\xe8\xa7\xa3\xe9\x87\x8a\xef\xbc\x8c\xe5\x90\x84\xe7\xa7\x8d\xe6\x8d\x9f\xe5\xa4\xb1\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x8c\xe4\xb8\xad\xe5\xbf\x83\xe6\x8d\x9f\xe5\xa4\xb1\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x8c\xe5\xaf\xb9\xe6\xaf\x94\xe6\x8d\x9f\xe5\xa4\xb1\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x8c\xe6\xae\x8b\xe5\xb7\xae\xe7\xbd\x91\xe7\xbb\x9c\xef\xbc\x8c\xe8\x83\xb6\xe5\x9b\x8a\xe7\xbd\x91\xe7\xbb\x9c, YOLO\xef\xbc\x8cSSD\n\n\n* ### [Word Embeddings](https://github.com/roboticcam/machine-learning-notes/blob/master/files/word_vector.pdf) ###\nWord2Vec, skip-gram, GloVe, Fasttext\n\n\xe7\xb3\xbb\xe7\xbb\x9f\xe7\x9a\x84\xe4\xbb\x8b\xe7\xbb\x8d\xe4\xba\x86\xe8\x87\xaa\xe7\x84\xb6\xe8\xaf\xad\xe8\xa8\x80\xe5\xa4\x84\xe7\x90\x86\xe4\xb8\xad\xe7\x9a\x84\xe2\x80\x9c\xe8\xaf\x8d\xe8\xa1\xa8\xe7\xa4\xba\xe2\x80\x9d\xe4\xb8\xad\xe7\x9a\x84\xe6\x8a\x80\xe5\xb7\xa7\n\n* ### [Deep Natural Language Processing](https://github.com/roboticcam/machine-learning-notes/blob/master/files/deep_nlp.pdf) ###\nRNN, LSTM, Seq2Seq with Attenion, Beam search, Attention is all you need, Convolution Seq2Seq, Pointer Networks\n\n\xe6\xb7\xb1\xe5\xba\xa6\xe8\x87\xaa\xe7\x84\xb6\xe8\xaf\xad\xe8\xa8\x80\xe5\xa4\x84\xe7\x90\x86\xef\xbc\x9a\xe9\x80\x92\xe5\xbd\x92\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c,LSTM,\xe5\x85\xb7\xe6\x9c\x89\xe6\xb3\xa8\xe6\x84\x8f\xe5\x8a\x9b\xe6\x9c\xba\xe5\x88\xb6\xe7\x9a\x84Seq2Seq\xef\xbc\x8c\xe9\x9b\x86\xe6\x9d\x9f\xe6\x90\x9c\xe7\xb4\xa2\xef\xbc\x8c\xe6\x8c\x87\xe9\x92\x88\xe7\xbd\x91\xe7\xbb\x9c\xe5\x92\x8c ""Attention is all you need"", \xe5\x8d\xb7\xe7\xa7\xafSeq2Seq\n\n* ### [Mathematics for Generative Adversarial Networks](https://github.com/roboticcam/machine-learning-notes/blob/master/files/GAN.pdf) ###\nHow GAN works, Traditional GAN, Mathematics on W-GAN, Duality and KKT conditions, Info-GAN, Bayesian GAN\n\nGAN\xe5\xa6\x82\xe4\xbd\x95\xe5\xb7\xa5\xe4\xbd\x9c\xef\xbc\x8c\xe4\xbc\xa0\xe7\xbb\x9fGAN\xef\xbc\x8cW-GAN\xe6\x95\xb0\xe5\xad\xa6\xef\xbc\x8c\xe5\xaf\xb9\xe5\x81\xb6\xe6\x80\xa7\xe5\x92\x8cKKT\xe6\x9d\xa1\xe4\xbb\xb6\xef\xbc\x8cInfo-GAN\xef\xbc\x8c\xe8\xb4\x9d\xe5\x8f\xb6\xe6\x96\xafGAN\n\n* ### [Restricted Boltzmann Machine](https://github.com/roboticcam/machine-learning-notes/blob/master/files/rbm_gan.pdf) ###\nbasic knowledge in Restricted Boltzmann Machine (RBM)\n\n\xe5\x8f\x97\xe9\x99\x90\xe7\x8e\xbb\xe5\xb0\x94\xe5\x85\xb9\xe6\x9b\xbc\xe6\x9c\xba(RBM)\xe4\xb8\xad\xe7\x9a\x84\xe5\x9f\xba\xe7\xa1\x80\xe7\x9f\xa5\xe8\xaf\x86\n\n# Reinforcement Learning \xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0\n\n* ### [Reinforcement Learning Basics](https://github.com/roboticcam/machine-learning-notes/blob/master/files/dqn.pdf) ###\nbasic knowledge in reinforcement learning, Markov Decision Process, Bellman Equation and move onto Deep Q-Learning\n\n\xe6\xb7\xb1\xe5\xba\xa6\xe5\xa2\x9e\xe5\xbc\xba\xe5\xad\xa6\xe4\xb9\xa0: \xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9a\x84\xe5\x9f\xba\xe7\xa1\x80\xe7\x9f\xa5\xe8\xaf\x86\xef\xbc\x8c\xe9\xa9\xac\xe5\xb0\x94\xe5\x8f\xaf\xe5\xa4\xab\xe5\x86\xb3\xe7\xad\x96\xe8\xbf\x87\xe7\xa8\x8b\xef\xbc\x8c\xe8\xb4\x9d\xe5\xb0\x94\xe6\x9b\xbc\xe6\x96\xb9\xe7\xa8\x8b\xef\xbc\x8c\xe6\xb7\xb1\xe5\xba\xa6Q\xe5\xad\xa6\xe4\xb9\xa0\n\n* ### [Monto Carlo Tree Search](https://github.com/roboticcam/machine-learning-notes/blob/master/files/mcts.pdf) ###\nMonto Carlo Tree Search, alphaGo learning algorithm\n\n\xe8\x92\x99\xe6\x89\x98\xe5\x8d\xa1\xe7\xbd\x97\xe6\xa0\x91\xe6\x90\x9c\xe7\xb4\xa2\xef\xbc\x8calphaGo\xe5\xad\xa6\xe4\xb9\xa0\xe7\xae\x97\xe6\xb3\x95\n\n* ### [Policy Gradient](https://github.com/roboticcam/machine-learning-notes/blob/master/files/policy_gradient.pdf) ###\nPolicy Gradient Theorem, Mathematics on Trusted Region Optimization in RL, Natural Gradients on TRPO, Proximal Policy Optimization (PPO), Conjugate Gradient Algorithm\n\n\xe6\x94\xbf\xe7\xad\x96\xe6\xa2\xaf\xe5\xba\xa6\xe5\xae\x9a\xe7\x90\x86, RL\xe4\xb8\xad\xe5\x8f\xaf\xe4\xbf\xa1\xe5\x8c\xba\xe5\x9f\x9f\xe4\xbc\x98\xe5\x8c\x96\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\xa6,TRPO\xe8\x87\xaa\xe7\x84\xb6\xe6\xa2\xaf\xe5\xba\xa6, \xe8\xbf\x91\xe4\xbc\xbc\xe7\xad\x96\xe7\x95\xa5\xe4\xbc\x98\xe5\x8c\x96(PPO), \xe5\x85\xb1\xe8\xbd\xad\xe6\xa2\xaf\xe5\xba\xa6\xe7\xae\x97\xe6\xb3\x95\n\n# Data Science \xe6\x95\xb0\xe6\x8d\xae\xe7\xa7\x91\xe5\xad\xa6\xe8\xaf\xbe\xe4\xbb\xb6\n\n* ### [30 minutes introduction to AI and Machine Learning](https://github.com/roboticcam/machine-learning-notes/blob/master/files/30_min_AI.pptx)\nAn extremely gentle 30 minutes introduction to AI and Machine Learning. Thanks to my PhD student Haodong Chang for assist editing\n\n30\xe5\x88\x86\xe9\x92\x9f\xe4\xbb\x8b\xe7\xbb\x8d\xe4\xba\xba\xe5\xb7\xa5\xe6\x99\xba\xe8\x83\xbd\xe5\x92\x8c\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0, \xe6\x84\x9f\xe8\xb0\xa2\xe6\x88\x91\xe7\x9a\x84\xe5\xad\xa6\xe7\x94\x9f\xe5\xb8\xb8\xe6\xb5\xa9\xe4\xb8\x9c\xe8\xbf\x9b\xe8\xa1\x8c\xe5\x8d\x8f\xe5\x8a\xa9\xe7\xbc\x96\xe8\xbe\x91\n\n* ### [Regression methods](https://github.com/roboticcam/machine-learning-notes/blob/master/files/regression.pdf) ###\nClassification: Logistic and Softmax; Regression: Linear, polynomial; Mix Effect model **[[costFunction.m]](https://github.com/roboticcam/matlab_demos/blob/master/costFunction.m)** and **[[soft_max.m]](https://github.com/roboticcam/matlab_demos/blob/master/soft_max.m)** \n\n\xe5\x88\x86\xe7\xb1\xbb\xe4\xbb\x8b\xe7\xbb\x8d: Logistic\xe5\x9b\x9e\xe5\xbd\x92\xe5\x92\x8cSoftmax\xe5\x88\x86\xe7\xb1\xbb; \xe5\x9b\x9e\xe5\xbd\x92\xe4\xbb\x8b\xe7\xbb\x8d\xef\xbc\x9a\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xef\xbc\x8c\xe5\xa4\x9a\xe9\xa1\xb9\xe5\xbc\x8f\xe5\x9b\x9e\xe5\xbd\x92; \xe6\xb7\xb7\xe5\x90\x88\xe6\x95\x88\xe6\x9e\x9c\xe6\xa8\xa1\xe5\x9e\x8b **[[costFunction.m]](https://github.com/roboticcam/matlab_demos/blob/master/costFunction.m)** \xe5\x92\x8c **[[soft_max.m]](https://github.com/roboticcam/matlab_demos/blob/master/soft_max.m)**\n\n* ### [Recommendation system](https://github.com/roboticcam/machine-learning-notes/blob/master/files/recommendation.pdf) ###\ncollaborative filtering, Factorization Machines, Non-Negative Matrix factorisation, Multiplicative Update Rule\n\n\xe6\x8e\xa8\xe8\x8d\x90\xe7\xb3\xbb\xe7\xbb\x9f: \xe5\x8d\x8f\xe5\x90\x8c\xe8\xbf\x87\xe6\xbb\xa4\xef\xbc\x8c\xe5\x88\x86\xe8\xa7\xa3\xe6\x9c\xba\xef\xbc\x8c\xe9\x9d\x9e\xe8\xb4\x9f\xe7\x9f\xa9\xe9\x98\xb5\xe5\x88\x86\xe8\xa7\xa3\xef\xbc\x8c\xe5\x92\x8c\xe6\x9c\x9f\xe4\xb8\xad\xe2\x80\x9c\xe4\xb9\x98\xe6\xb3\x95\xe6\x9b\xb4\xe6\x96\xb0\xe8\xa7\x84\xe5\x88\x99\xe2\x80\x9d\xe7\x9a\x84\xe4\xbb\x8b\xe7\xbb\x8d\n\n* ### [Dimension Reduction](https://github.com/roboticcam/machine-learning-notes/blob/master/files/dimension_reduction.pdf) ###\nclassic PCA and t-SNE\n\n\xe7\xbb\x8f\xe5\x85\xb8\xe7\x9a\x84PCA\xe9\x99\x8d\xe7\xbb\xb4\xe6\xb3\x95\xe5\x92\x8ct-SNE\xe9\x99\x8d\xe7\xbb\xb4\xe6\xb3\x95\n\n* ### [Introduction to Data Analytics](https://github.com/roboticcam/machine-learning-notes/blob/master/files/AI_and_machine_learning.pdf) and [associate Jupyter notebook](https://github.com/roboticcam/machine-learning-notes/blob/master/files/industry_master_class.ipynb) ###\nSupervised vs Unsupervised Learning, Classification accuracy\n\n\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe6\x9e\x90\xe7\xae\x80\xe4\xbb\x8b\xe5\x92\x8c\xe7\x9b\xb8\xe5\x85\xb3\xe7\x9a\x84jupyter notebook\xef\xbc\x8c\xe5\x8c\x85\xe6\x8b\xac\xe7\x9b\x91\xe7\x9d\xa3\xe4\xb8\x8e\xe6\x97\xa0\xe7\x9b\x91\xe7\x9d\xa3\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x8c\xe5\x88\x86\xe7\xb1\xbb\xe5\x87\x86\xe7\xa1\xae\xe6\x80\xa7\n\n# Probability and Statistics Background \xe6\xa6\x82\xe7\x8e\x87\xe8\xae\xba\xe4\xb8\x8e\xe6\x95\xb0\xe7\x90\x86\xe7\xbb\x9f\xe8\xae\xa1\xe5\x9f\xba\xe7\xa1\x80\xe8\xaf\xbe\xe4\xbb\xb6\n\n* ### [Bayesian model](https://github.com/roboticcam/machine-learning-notes/blob/master/files/bayesian.pdf) ###\nrevision on Bayes model include Bayesian predictive model, conditional expectation\n\n\xe5\xa4\x8d\xe4\xb9\xa0\xe8\xb4\x9d\xe5\x8f\xb6\xe6\x96\xaf\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x8c\xe5\x8c\x85\xe6\x8b\xac\xe8\xb4\x9d\xe5\x8f\xb6\xe6\x96\xaf\xe9\xa2\x84\xe6\xb5\x8b\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x8c\xe6\x9d\xa1\xe4\xbb\xb6\xe6\x9c\x9f\xe6\x9c\x9b\xe7\xad\x89\xe5\x9f\xba\xe7\xa1\x80\xe7\x9f\xa5\xe8\xaf\x86\n\n* ### [Probabilistic Estimation](https://github.com/roboticcam/machine-learning-notes/blob/master/files/probability.pdf) ###\nsome useful distributions, conjugacy, MLE, MAP, Exponential family and natural parameters\n\n \xe4\xb8\x80\xe4\xba\x9b\xe5\xb8\xb8\xe7\x94\xa8\xe7\x9a\x84\xe5\x88\x86\xe5\xb8\x83\xef\xbc\x8c\xe5\x85\xb1\xe8\xbd\xad\xe7\x89\xb9\xe6\x80\xa7\xef\xbc\x8c\xe6\x9c\x80\xe5\xa4\xa7\xe4\xbc\xbc\xe7\x84\xb6\xe4\xbc\xb0\xe8\xae\xa1, \xe6\x9c\x80\xe5\xa4\xa7\xe5\x90\x8e\xe9\xaa\x8c\xe4\xbc\xb0\xe8\xae\xa1, \xe6\x8c\x87\xe6\x95\xb0\xe6\x97\x8f\xe5\x92\x8c\xe8\x87\xaa\xe7\x84\xb6\xe5\x8f\x82\xe6\x95\xb0\n\n* ### [Statistics Properties](https://github.com/roboticcam/machine-learning-notes/blob/master/files/statistics.pdf) ###\nuseful statistical properties to help us prove things, include Chebyshev and Markov inequality\n\n \xe4\xb8\x80\xe4\xba\x9b\xe9\x9d\x9e\xe5\xb8\xb8\xe6\x9c\x89\xe7\x94\xa8\xe7\x9a\x84\xe7\xbb\x9f\xe8\xae\xa1\xe5\xb1\x9e\xe6\x80\xa7\xe5\x8f\xaf\xe4\xbb\xa5\xe5\xb8\xae\xe5\x8a\xa9\xe6\x88\x91\xe4\xbb\xac\xe5\x9c\xa8\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe4\xb8\xad\xe7\x9a\x84\xe8\xaf\x81\xe6\x98\x8e\xef\xbc\x8c\xe5\x8c\x85\xe6\x8b\xac\xe5\x88\x87\xe6\xaf\x94\xe9\x9b\xaa\xe5\xa4\xab\xe5\x92\x8c\xe9\xa9\xac\xe5\xb0\x94\xe7\xa7\x91\xe5\xa4\xab\xe4\xb8\x8d\xe7\xad\x89\xe5\xbc\x8f\n\n# Probabilistic Model \xe6\xa6\x82\xe7\x8e\x87\xe6\xa8\xa1\xe5\x9e\x8b\xe8\xaf\xbe\xe4\xbb\xb6\n\n* ### [Expectation Maximisation](https://github.com/roboticcam/machine-learning-notes/blob/master/files/em.pdf) ###\nProof of convergence for E-M, examples of E-M through Gaussian Mixture Model, **[[gmm_demo.m]](https://github.com/roboticcam/matlab_demos/blob/master/gmm_demo.m)** and **[[kmeans_demo.m]](https://github.com/roboticcam/matlab_demos/blob/master/kmeans_demo.m)** and **[[bilibili video]](https://www.bilibili.com/video/av23901379)**\n\n \xe6\x9c\x80\xe5\xa4\xa7\xe6\x9c\x9f\xe6\x9c\x9bE-M\xe7\x9a\x84\xe6\x94\xb6\xe6\x95\x9b\xe8\xaf\x81\xe6\x98\x8e, E-M\xe5\x88\xb0\xe9\xab\x98\xe6\x96\xaf\xe6\xb7\xb7\xe5\x90\x88\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe4\xbe\x8b\xe5\xad\x90, **[[gmm_demo.m]](https://github.com/roboticcam/matlab_demos/blob/master/gmm_demo.m)** \xe5\x92\x8c **[[kmeans_demo.m]](https://github.com/roboticcam/matlab_demos/blob/master/kmeans_demo.m)** \xe5\x92\x8c **[[B\xe7\xab\x99\xe8\xa7\x86\xe9\xa2\x91\xe9\x93\xbe\xe6\x8e\xa5]](https://www.bilibili.com/video/av23901379)**\n\n* ### [State Space Model (Dynamic model)](https://github.com/roboticcam/machine-learning-notes/blob/master/files/dynamic_model.pdf) ###\nexplain in detail of Kalman Filter  **[[bilibili video]](https://www.bilibili.com/video/av24225243)**, **[[kalman_demo.m]](https://github.com/roboticcam/matlab_demos/blob/master/kalman_demo.m)** and Hidden Markov Model **[[bilibili video]](https://www.bilibili.com/video/av24132174)** \n\n\xe7\x8a\xb6\xe6\x80\x81\xe7\xa9\xba\xe9\x97\xb4\xe6\xa8\xa1\xe5\x9e\x8b(\xe5\x8a\xa8\xe6\x80\x81\xe6\xa8\xa1\xe5\x9e\x8b) \xe8\xaf\xa6\xe7\xbb\x86\xe8\xa7\xa3\xe9\x87\x8a\xe4\xba\x86\xe5\x8d\xa1\xe5\xb0\x94\xe6\x9b\xbc\xe6\xbb\xa4\xe6\xb3\xa2\xe5\x99\xa8\n**[[B\xe7\xab\x99\xe8\xa7\x86\xe9\xa2\x91\xe9\x93\xbe\xe6\x8e\xa5]](https://www.bilibili.com/video/av24225243)**, **[[kalman_demo.m]](https://github.com/roboticcam/matlab_demos/blob/master/kalman_demo.m)**\n\xe5\x92\x8c\xe9\x9a\x90\xe9\xa9\xac\xe5\xb0\x94\xe5\x8f\xaf\xe5\xa4\xab\xe6\xa8\xa1\xe5\x9e\x8b **[[B\xe7\xab\x99\xe8\xa7\x86\xe9\xa2\x91\xe9\x93\xbe\xe6\x8e\xa5]](https://www.bilibili.com/video/av24132174)** \n\n# Inference \xe6\x8e\xa8\xe6\x96\xad\xe8\xaf\xbe\xe4\xbb\xb6\n\n* ### [Variational Inference](https://github.com/roboticcam/machine-learning-notes/blob/master/files/variational.pdf) ###\nexplain Variational Bayes both the non-exponential and exponential family distribution plus stochastic variational inference. **[[vb_normal_gamma.m]](https://github.com/roboticcam/matlab_demos/blob/master/vb_normal_gamma.m)** and **[[bilibili video]](https://www.bilibili.com/video/av24062247)**\n\n\xe5\x8f\x98\xe5\x88\x86\xe6\x8e\xa8\xe5\xaf\xbc\xe7\x9a\x84\xe4\xbb\x8b\xe7\xbb\x8d: \xe8\xa7\xa3\xe9\x87\x8a\xe5\x8f\x98\xe5\x88\x86\xe8\xb4\x9d\xe5\x8f\xb6\xe6\x96\xaf\xe9\x9d\x9e\xe6\x8c\x87\xe6\x95\xb0\xe5\x92\x8c\xe6\x8c\x87\xe6\x95\xb0\xe6\x97\x8f\xe5\x88\x86\xe5\xb8\x83\xe5\x8a\xa0\xe4\xb8\x8a\xe9\x9a\x8f\xe6\x9c\xba\xe5\x8f\x98\xe5\x88\x86\xe6\x8e\xa8\xe6\x96\xad\xe3\x80\x82**[[vb_normal_gamma.m]](https://github.com/roboticcam/matlab_demos/blob/master/vb_normal_gamma.m)** \xe5\x92\x8c **[[B\xe7\xab\x99\xe8\xa7\x86\xe9\xa2\x91\xe9\x93\xbe\xe6\x8e\xa5]](https://www.bilibili.com/video/av24062247)** \n\n* ### [Stochastic Matrices](https://github.com/roboticcam/machine-learning-notes/blob/master/files/stochastic_matrices.pdf) ###\nstochastic matrix, Power Method Convergence Theorem, detailed balance and PageRank algorithm\n\n\xe9\x9a\x8f\xe6\x9c\xba\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x8c\xe5\xb9\x82\xe6\x96\xb9\xe6\xb3\x95\xe6\x94\xb6\xe6\x95\x9b\xe5\xae\x9a\xe7\x90\x86\xef\xbc\x8c\xe8\xaf\xa6\xe7\xbb\x86\xe5\xb9\xb3\xe8\xa1\xa1\xe5\x92\x8c\xe8\xb0\xb7\xe6\xad\x8cPageRank\xe7\xae\x97\xe6\xb3\x95\n\n* ### [Introduction to Monte Carlo](https://github.com/roboticcam/machine-learning-notes/blob/master/files/introduction_monte_carlo.pdf) ###\ninverse CDF, rejection, adaptive rejection, importance sampling **[[adaptive_rejection_sampling.m]](https://github.com/roboticcam/matlab_demos/blob/master/adaptive_rejection_sampling.m)** and **[[hybrid_gmm.m]](https://github.com/roboticcam/matlab_demos/blob/master/hybrid_gmm.m)**\n\n\xe7\xb4\xaf\xe7\xa7\xaf\xe5\x88\x86\xe5\xb8\x83\xe5\x87\xbd\xe6\x95\xb0\xe9\x80\x86\xe9\x87\x87\xe6\xa0\xb7, \xe6\x8b\x92\xe7\xbb\x9d\xe5\xbc\x8f\xe9\x87\x87\xe6\xa0\xb7, \xe8\x87\xaa\xe9\x80\x82\xe5\xba\x94\xe6\x8b\x92\xe7\xbb\x9d\xe5\xbc\x8f\xe9\x87\x87\xe6\xa0\xb7, \xe9\x87\x8d\xe8\xa6\x81\xe6\x80\xa7\xe9\x87\x87\xe6\xa0\xb7 **[[adaptive_rejection_sampling.m]](https://github.com/roboticcam/matlab_demos/blob/master/adaptive_rejection_sampling.m)** \xe5\x92\x8c **[[hybrid_gmm.m]](https://github.com/roboticcam/matlab_demos/blob/master/hybrid_gmm.m)**\n\n* ### [Markov Chain Monte Carlo](https://github.com/roboticcam/machine-learning-notes/blob/master/files/markov_chain_monte_carlo.pdf) ###\nM-H, Gibbs, Slice Sampling, Elliptical Slice sampling, Swendesen-Wang, demonstrate collapsed Gibbs using LDA **[[lda_gibbs_example.m]](https://github.com/roboticcam/matlab_demos/blob/master/lda_gibbs_example.m)** and **[[test_autocorrelation.m]](https://github.com/roboticcam/matlab_demos/blob/master/test_autocorrelation.m)** and **[[gibbs.m]](https://github.com/roboticcam/matlab_demos/blob/master/gibbs.m)** and **[[bilibili video]](https://www.bilibili.com/video/av23980130)**\n\n\xe9\xa9\xac\xe5\xb0\x94\xe5\x8f\xaf\xe5\xa4\xab\xe9\x93\xbe\xe8\x92\x99\xe7\x89\xb9\xe5\x8d\xa1\xe6\xb4\x9b\xe7\x9a\x84\xe5\x90\x84\xe7\xa7\x8d\xe6\x96\xb9\xe6\xb3\x95 **[[lda_gibbs_example.m]](https://github.com/roboticcam/matlab_demos/blob/master/lda_gibbs_example.m)** \xe5\x92\x8c **[[test_autocorrelation.m]](https://github.com/roboticcam/matlab_demos/blob/master/test_autocorrelation.m)** \xe5\x92\x8c **[[gibbs.m]](https://github.com/roboticcam/matlab_demos/blob/master/gibbs.m)** \xe5\x92\x8c **[[B\xe7\xab\x99\xe8\xa7\x86\xe9\xa2\x91\xe9\x93\xbe\xe6\x8e\xa5]](https://www.bilibili.com/video/av23980130)**\n\n\n* ### [Particle Filter (Sequential Monte-Carlo)](https://github.com/roboticcam/machine-learning-notes/blob/master/files/particle_filter.pdf) ###\nSequential Monte-Carlo, Condensational Filter algorithm, Auxiliary Particle Filter **[[bilibili video]](https://www.bilibili.com/video/av24285449)**\n\n\xe7\xb2\x92\xe5\xad\x90\xe6\xbb\xa4\xe6\xb3\xa2\xe5\x99\xa8\xef\xbc\x88\xe5\xba\x8f\xe5\x88\x97\xe8\x92\x99\xe7\x89\xb9\xe5\x8d\xa1\xe6\xb4\x9b\xef\xbc\x89**[[B\xe7\xab\x99\xe8\xa7\x86\xe9\xa2\x91\xe9\x93\xbe\xe6\x8e\xa5]](https://www.bilibili.com/video/av24285449)**\n\n# Advanced Probabilistic Model \xe9\xab\x98\xe7\xba\xa7\xe6\xa6\x82\xe7\x8e\x87\xe6\xa8\xa1\xe5\x9e\x8b\xe8\xaf\xbe\xe4\xbb\xb6\n\n* ### [Bayesian Non Parametrics (BNP) and its inference basics](https://github.com/roboticcam/machine-learning-notes/blob/master/files/non_parametrics.pdf) ###\nDircihlet Process (DP), Chinese Restaurant Process insights, Slice sampling for DP **[[dirichlet_process.m]](https://github.com/roboticcam/matlab_demos/blob/master/dirichlet_process.m)** and **[[bilibili video]](https://www.bilibili.com/video/av23881062)** and **[[Jupyter Notebook]](https://github.com/roboticcam/python_machine_learning/blob/master/chinese_restaurant_process.ipynb)**\n\n\xe9\x9d\x9e\xe5\x8f\x82\xe8\xb4\x9d\xe5\x8f\xb6\xe6\x96\xaf\xe5\x8f\x8a\xe5\x85\xb6\xe6\x8e\xa8\xe5\xaf\xbc\xe5\x9f\xba\xe7\xa1\x80: \xe7\x8b\x84\xe5\x88\xa9\xe5\x85\x8b\xe9\x9b\xb7\xe8\xbf\x87\xe7\xa8\x8b,\xe4\xb8\xad\xe5\x9b\xbd\xe9\xa4\x90\xe9\xa6\x86\xe8\xbf\x87\xe7\xa8\x8b,\xe7\x8b\x84\xe5\x88\xa9\xe5\x85\x8b\xe9\x9b\xb7\xe8\xbf\x87\xe7\xa8\x8bSlice\xe9\x87\x87\xe6\xa0\xb7 **[[dirichlet_process.m]](https://github.com/roboticcam/matlab_demos/blob/master/dirichlet_process.m)** \xe5\x92\x8c **[[B\xe7\xab\x99\xe8\xa7\x86\xe9\xa2\x91\xe9\x93\xbe\xe6\x8e\xa5]](https://www.bilibili.com/video/av23881062)** \xe5\x92\x8c **[[Jupyter Notebook]](https://github.com/roboticcam/python_machine_learning/blob/master/chinese_restaurant_process.ipynb)**\n\n* ### [Bayesian Non Parametrics (BNP) extensions](https://github.com/roboticcam/machine-learning-notes/blob/master/files/non_parametrics_extensions.pdf) ###\nHierarchical DP, HDP-HMM, Indian Buffet Process (IBP)\n\n\xe9\x9d\x9e\xe5\x8f\x82\xe8\xb4\x9d\xe5\x8f\xb6\xe6\x96\xaf\xe6\x89\xa9\xe5\xb1\x95: \xe5\xb1\x82\xe6\xac\xa1\xe7\x8b\x84\xe5\x88\xa9\xe5\x85\x8b\xe9\x9b\xb7\xe8\xbf\x87\xe7\xa8\x8b\xef\xbc\x8c\xe5\x88\x86\xe5\xb1\x82\xe7\x8b\x84\xe5\x88\xa9\xe5\x85\x8b\xe9\x9b\xb7\xe8\xbf\x87\xe7\xa8\x8b-\xe9\x9a\x90\xe9\xa9\xac\xe5\xb0\x94\xe5\x8f\xaf\xe5\xa4\xab\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x8c\xe5\x8d\xb0\xe5\xba\xa6\xe8\x87\xaa\xe5\x8a\xa9\xe9\xa4\x90\xe8\xbf\x87\xe7\xa8\x8b(IBP)\n\n* ### [Completely Random Measure (early draft - written in 2015)](https://github.com/roboticcam/machine-learning-notes/blob/master/files/random_measure.pdf) ###\nLevy-Khintchine representation, Compound Poisson Process, Gamma Process, Negative Binomial Process\n\nLevy-Khintchine\xe8\xa1\xa8\xe7\xa4\xba\xef\xbc\x8c\xe5\xa4\x8d\xe5\x90\x88Poisson\xe8\xbf\x87\xe7\xa8\x8b\xef\xbc\x8cGamma\xe8\xbf\x87\xe7\xa8\x8b\xef\xbc\x8c\xe8\xb4\x9f\xe4\xba\x8c\xe9\xa1\xb9\xe8\xbf\x87\xe7\xa8\x8b\n\n* ### [Determinantal Point Process](https://github.com/roboticcam/machine-learning-notes/blob/master/files/dpp.pdf) ###\nexplain the details of DPP\xe2\x80\x99s marginal distribution, L-ensemble, its sampling strategy, our work in time-varying DPP\n\n\xe8\xa1\x8c\xe5\x88\x97\xe5\xbc\x8f\xe7\x82\xb9\xe8\xbf\x87\xe7\xa8\x8b\xe8\xa7\xa3\xe9\x87\x8a:\xe8\xa1\x8c\xe5\x88\x97\xe5\xbc\x8f\xe7\x82\xb9\xe8\xbf\x87\xe7\xa8\x8b\xe7\x9a\x84\xe8\xbe\xb9\xe7\xbc\x98\xe5\x88\x86\xe5\xb8\x83\xef\xbc\x8cL-ensemble\xef\xbc\x8c\xe5\x85\xb6\xe6\x8a\xbd\xe6\xa0\xb7\xe7\xad\x96\xe7\x95\xa5\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\x9c\xa8\xe2\x80\x9c\xe6\x97\xb6\xe5\x8f\x98\xe8\xa1\x8c\xe5\x88\x97\xe5\xbc\x8f\xe7\x82\xb9\xe8\xbf\x87\xe7\xa8\x8b\xe2\x80\x9d\xe4\xb8\xad\xe7\x9a\x84\xe5\xb7\xa5\xe4\xbd\x9c\xe7\xbb\x86\xe8\x8a\x82\n\n# Special Thanks\n* I would like to thank my following PhD students for help me proofreading, and provide great discussions and suggestions to various topics in these notes, including (but not limited to) Hayden Chang, Shawn Jiang, Erica Huang, Deng Chen, Ember Liang; \xe7\x89\xb9\xe5\x88\xab\xe6\x84\x9f\xe8\xb0\xa2\xe6\x88\x91\xe7\x9a\x84\xe5\x8d\x9a\xe5\xa3\xab\xe7\x94\x9f\xe5\x9b\xa2\xe9\x98\x9f\xe5\x8d\x8f\xe5\x8a\xa9\xe6\x88\x91\xe4\xb8\x80\xe8\xb5\xb7\xe6\xa0\xa1\xe5\xaf\xb9\xe8\xaf\xbe\xe4\xbb\xb6\xef\xbc\x8c\xe4\xbb\xa5\xe5\x8f\x8a\xe5\xb0\xb1\xe8\xaf\xbe\xe4\xbb\xb6\xe5\x86\x85\xe5\xae\xb9\xe6\x89\x80\xe6\x8f\x90\xe5\x87\xba\xe7\x9a\x84\xe6\x83\xb3\xe6\xb3\x95\xe5\x92\x8c\xe5\xbb\xba\xe8\xae\xae\xef\xbc\x8c\xe5\x9b\xa2\xe9\x98\x9f\xe6\x88\x90\xe5\x91\x98\xe5\x8c\x85\xe6\x8b\xac\xef\xbc\x88\xe4\xbd\x86\xe4\xb8\x8d\xe9\x99\x90\xe4\xba\x8e\xef\xbc\x89\xe5\xb8\xb8\xe6\xb5\xa9\xe4\xb8\x9c\xef\xbc\x8c\xe5\xa7\x9c\xe5\xb8\x85\xef\xbc\x8c\xe9\xbb\x84\xe7\x9a\x96\xe9\xb8\xa3\xef\xbc\x8c\xe9\x82\x93\xe8\xbe\xb0\xef\xbc\x8c\xe6\xa2\x81\xe8\xbd\xa9\xe3\x80\x82\n\n* I always look for high quality PhD students in Machine Learning, both in terms of probabilistic model and Deep Learning models. Contact me on YiDa.Xu@uts.edu.au\n\n\xe5\xa6\x82\xe6\x9e\x9c\xe4\xbd\xa0\xe6\x83\xb3\xe5\x8a\xa0\xe5\x85\xa5\xe6\x88\x91\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x8d\x9a\xe5\xa3\xab\xe7\x94\x9f\xe5\x9b\xa2\xe9\x98\x9f\xe6\x88\x96\xe6\x9c\x89\xe5\x85\xb4\xe8\xb6\xa3\xe5\xae\x9e\xe4\xb9\xa0, \xe8\xaf\xb7\xe9\x80\x9a\xe8\xbf\x87YiDa.Xu@uts.edu.au\xe4\xb8\x8e\xe6\x88\x91\xe8\x81\x94\xe7\xb3\xbb\xe3\x80\x82\n'"
30,jobbole/awesome-machine-learning-cn,jobbole,机器学习资源大全中文版，包括机器学习领域的框架、库以及软件,2015-11-03 11:22:38,2020-06-18 02:46:04,,1162,3341,"b'# \xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xb5\x84\xe6\xba\x90\xe5\xa4\xa7\xe5\x85\xa8\xe4\xb8\xad\xe6\x96\x87\xe7\x89\x88\n\n\xe6\x88\x91\xe6\x83\xb3\xe5\xbe\x88\xe5\xa4\x9a\xe7\xa8\x8b\xe5\xba\x8f\xe5\x91\x98\xe5\xba\x94\xe8\xaf\xa5\xe8\xae\xb0\xe5\xbe\x97 GitHub \xe4\xb8\x8a\xe6\x9c\x89\xe4\xb8\x80\xe4\xb8\xaa Awesome - XXX \xe7\xb3\xbb\xe5\x88\x97\xe7\x9a\x84\xe8\xb5\x84\xe6\xba\x90\xe6\x95\xb4\xe7\x90\x86\xe3\x80\x82[awesome-machine-learning](https://github.com/josephmisiti/awesome-machine-learning) \xe5\xb0\xb1\xe6\x98\xaf josephmisiti \xe5\x8f\x91\xe8\xb5\xb7\xe7\xbb\xb4\xe6\x8a\xa4\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xb5\x84\xe6\xba\x90\xe5\x88\x97\xe8\xa1\xa8\xef\xbc\x8c\xe5\x86\x85\xe5\xae\xb9\xe5\x8c\x85\xe6\x8b\xac\xe4\xba\x86\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe9\xa2\x86\xe5\x9f\x9f\xe7\x9a\x84\xe6\xa1\x86\xe6\x9e\xb6\xe3\x80\x81\xe5\xba\x93\xe4\xbb\xa5\xe5\x8f\x8a\xe8\xbd\xaf\xe4\xbb\xb6\xef\xbc\x88\xe6\x8c\x89\xe7\xbc\x96\xe7\xa8\x8b\xe8\xaf\xad\xe8\xa8\x80\xe6\x8e\x92\xe5\xba\x8f\xef\xbc\x89\xe3\x80\x82\n\nAwesome \xe7\xb3\xbb\xe5\x88\x97\xe8\x99\xbd\xe7\x84\xb6\xe6\x8c\xba\xe5\x85\xa8\xef\xbc\x8c\xe4\xbd\x86\xe5\x9f\xba\xe6\x9c\xac\xe5\x8f\xaa\xe5\xaf\xb9\xe6\x94\xb6\xe5\xbd\x95\xe7\x9a\x84\xe8\xb5\x84\xe6\xba\x90\xe5\x81\x9a\xe4\xba\x86\xe6\x9e\x81\xe4\xb8\xba\xe7\xae\x80\xe8\xa6\x81\xe7\x9a\x84\xe4\xbb\x8b\xe7\xbb\x8d\xef\xbc\x8c\xe5\xa6\x82\xe6\x9e\x9c\xe6\x9c\x89\xe6\x9b\xb4\xe8\xaf\xa6\xe7\xbb\x86\xe7\x9a\x84\xe4\xb8\xad\xe6\x96\x87\xe4\xbb\x8b\xe7\xbb\x8d\xef\xbc\x8c\xe5\xaf\xb9\xe7\x9b\xb8\xe5\xba\x94\xe5\xbc\x80\xe5\x8f\x91\xe8\x80\x85\xe7\x9a\x84\xe5\xb8\xae\xe5\x8a\xa9\xe4\xbc\x9a\xe6\x9b\xb4\xe5\xa4\xa7\xe3\x80\x82\xe8\xbf\x99\xe4\xb9\x9f\xe6\x98\xaf\xe6\x88\x91\xe4\xbb\xac\xe5\x8f\x91\xe8\xb5\xb7\xe8\xbf\x99\xe4\xb8\xaa\xe5\xbc\x80\xe6\xba\x90\xe9\xa1\xb9\xe7\x9b\xae\xe7\x9a\x84\xe5\x88\x9d\xe8\xa1\xb7\xe3\x80\x82\n\n* * *\n\n### \xe6\x88\x91\xe4\xbb\xac\xe8\xa6\x81\xe5\x81\x9a\xe4\xbb\x80\xe4\xb9\x88\xef\xbc\x9f\n\n- \xe5\x9f\xba\xe4\xba\x8e awesome-machine-learning \xe8\xb5\x84\xe6\xba\x90\xe5\x88\x97\xe8\xa1\xa8\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\xb0\x86\xe5\xaf\xb9\xe5\x90\x84\xe4\xb8\xaa\xe8\xb5\x84\xe6\xba\x90\xe9\xa1\xb9\xe8\xbf\x9b\xe8\xa1\x8c\xe7\xbc\x96\xe8\xaf\x91\xe6\x95\xb4\xe7\x90\x86\xe3\x80\x82\n- \xe6\x95\xb4\xe7\x90\x86\xe5\x90\x8e\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9\xef\xbc\x8c\xe5\xb0\x86\xe6\x94\xb6\xe5\xbd\x95\xe5\x9c\xa8[\xe4\xbc\xaf\xe4\xb9\x90\xe5\x9c\xa8\xe7\xba\xbf\xe8\xb5\x84\xe6\xba\x90\xe9\xa2\x91\xe9\x81\x93](http://hao.importnew.com/)\xe3\x80\x82\xe5\x8f\xaf\xe5\x8f\x82\xe8\x80\x83\xe5\xb7\xb2\xe6\x95\xb4\xe7\x90\x86\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9\xef\xbc\x9a\n  - \xe3\x80\x8a[Apache OpenNLP\xef\xbc\x9a\xe5\xa4\x84\xe7\x90\x86\xe7\xb1\xbb\xe4\xbc\xbc\xe5\x88\x86\xe8\xaf\x8d\xe7\xad\x89\xe5\xb8\xb8\xe8\xa7\x81\xe4\xbb\xbb\xe5\x8a\xa1\xe7\x9a\x84\xe5\xb7\xa5\xe5\x85\xb7](http://hao.importnew.com/apache-opennlp/)\xe3\x80\x8b\n  - \xe3\x80\x8a[Mallet\xef\xbc\x9aNLP\xe5\xb7\xa5\xe5\x85\xb7\xef\xbc\x8c\xe6\x94\xaf\xe6\x8c\x81\xe6\x96\x87\xe6\xa1\xa3\xe5\x88\x86\xe7\xb1\xbb\xe3\x80\x81\xe8\x81\x9a\xe7\xb1\xbb\xe3\x80\x81\xe4\xb8\xbb\xe9\xa2\x98\xe5\xbb\xba\xe6\xa8\xa1](http://hao.importnew.com/mallet/ )\xe3\x80\x8b\n\n* * *\n\n### \xe5\xa6\x82\xe4\xbd\x95\xe5\x8f\x82\xe4\xb8\x8e\xe6\x9c\xac\xe9\xa1\xb9\xe7\x9b\xae\xef\xbc\x9f\n\n<!-- \xe4\xbb\x8e\xe4\xb8\x8b\xe9\x9d\xa2\xe7\x9a\x84\xe7\x9b\xae\xe5\xbd\x95\xe6\x9d\xa5\xe7\x9c\x8b\xef\xbc\x8c\xe6\x9c\xac\xe9\xa1\xb9\xe7\x9b\xae\xe7\x9a\x84\xe5\xb7\xa5\xe4\xbd\x9c\xe9\x87\x8f\xe5\xb0\x8f\xe4\xb8\x8d\xe4\xba\x86\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xe9\x9d\x9e\xe5\xb8\xb8\xe6\x9c\x9f\xe5\xbe\x85\xe8\x83\xbd\xe6\x9c\x89\xe6\x9b\xb4\xe5\xa4\x9a\xe7\xa8\x8b\xe5\xba\x8f\xe5\x91\x98\xe4\xb8\x80\xe8\xb5\xb7\xe6\x9d\xa5\xe5\x8f\x82\xe4\xb8\x8e\xe3\x80\x82\n\n\xe4\xb8\x8d\xe8\xbf\x87\xe5\x8a\xa0\xe5\x85\xa5\xe5\x89\x8d\xef\xbc\x8c\xe6\x9c\x89\xe5\x87\xa0\xe4\xb8\xaa\xe5\xb0\x8f\xe8\xa6\x81\xe6\xb1\x82\xef\xbc\x9a\n\n* \xe8\x8b\xb1\xe6\x96\x87\xe8\xbf\x98\xe4\xb8\x8d\xe9\x94\x99\xef\xbc\x8c\xe8\x83\xbd\xe8\xaf\xbb\xe6\x87\x82\xe8\x8b\xb1\xe6\x96\x87\xe5\xb9\xb6\xe7\x94\xa8\xe8\x87\xaa\xe5\xb7\xb1\xe7\x9a\x84\xe8\xaf\x9d\xe5\xa4\x8d\xe8\xbf\xb0\xef\xbc\x9b\n* \xe6\x9c\x89 \xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0 \xe7\x9b\xb8\xe5\x85\xb3\xe7\x9a\x84\xe5\xbc\x80\xe5\x8f\x91\xe7\xbb\x8f\xe9\xaa\x8c\xef\xbc\x9b\n\n\xe5\xa6\x82\xe6\x9c\x89\xe5\x85\xb4\xe8\xb6\xa3\xef\xbc\x8c\xe8\xaf\xb7\xe5\x8a\xa0 QQ\xef\xbc\x9a50872495\xe3\x80\x82\xe5\x8a\xa0 Q \xe6\x97\xb6\xe8\xaf\xb7\xe6\xb3\xa8\xe6\x98\x8e\xe3\x80\x8c\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xa4\xa7\xe5\x85\xa8\xe3\x80\x8d -->\n\n* * *\n\n### \xe6\x9c\xac\xe9\xa1\xb9\xe7\x9b\xae\xe7\x9a\x84\xe5\x8f\x82\xe4\xb8\x8e\xe8\x80\x85\n\n- \xe7\xbb\xb4\xe6\x8a\xa4\xe8\x80\x85\xef\xbc\x9a[tangyouhua](https://github.com/tangyouhua)\n\n- \xe8\xb4\xa1\xe7\x8c\xae\xe8\x80\x85\xef\xbc\x9a[toolate](http://www.importnew.com/members/toolate)\xe3\x80\x81[\xe5\x86\xb0\xe6\x96\x8c](http://hao.importnew.com/author/libing1209/)\xe3\x80\x81[\xe4\xba\x91\xe4\xb8\xad\xe6\xb8\xb8](http://hao.importnew.com/author/tonyaaron/)\xe3\x80\x81[Daetalus](http://hao.importnew.com/author/daetalus/)\xe3\x80\x81[\xe8\xb5\xb5\xe5\x8f\xb6\xe5\xae\x87](http://www.importnew.com/members/nelsonzhao/)\xe3\x80\x81You\n\n\xe6\xb3\xa8\xef\xbc\x9a\xe5\x90\x8d\xe5\x8d\x95\xe4\xb8\x8d\xe5\x88\x86\xe6\x8e\x92\xe5\x90\x8d\xef\xbc\x8c\xe4\xb8\x8d\xe5\xae\x9a\xe6\x9c\x9f\xe8\xa1\xa5\xe5\x85\x85\xe6\x9b\xb4\xe6\x96\xb0\n\n* * *\n\n<!-- ### \xe5\xa5\x96\xe5\x8a\xb1\xe8\xae\xa1\xe5\x88\x92\n\n\xe8\x99\xbd\xe7\x84\xb6\xe5\xa5\x96\xe5\x8a\xb1\xe5\x8f\xaf\xe8\x83\xbd\xe5\xb9\xb6\xe4\xb8\x8d\xe6\x98\xaf\xe4\xbd\xa0\xe5\x8a\xa0\xe5\x85\xa5\xe7\x9a\x84\xe4\xb8\xbb\xe8\xa6\x81\xe5\x8e\x9f\xe5\x9b\xa0\xef\xbc\x8c\xe4\xbd\x86\xe8\xbf\x98\xe6\x98\xaf\xe6\x9c\x89\xe5\xbf\x85\xe8\xa6\x81\xe6\x8f\x90\xe4\xb8\x80\xe4\xb8\x8b\xef\xbc\x9a\n\n* \xe6\x95\xb4\xe7\x90\x86\xe8\xb6\x85\xe8\xbf\x87 20 \xe4\xb8\xaa\xe8\xb5\x84\xe6\xba\x90\xe5\x90\x8e\xef\xbc\x8c\xe5\x8f\xaf\xe5\x9c\xa8\xe4\xbc\xaf\xe4\xb9\x90\xe5\x9c\xa8\xe7\xba\xbf\xe4\xb8\x8a\xe5\xbc\x80\xe9\x80\x9a\xe6\x89\x93\xe8\xb5\x8f\xef\xbc\x9b\n* \xe6\xaf\x8f\xe6\x95\xb4\xe7\x90\x86 20 \xe4\xb8\xaa\xe8\xb5\x84\xe6\xba\x90\xef\xbc\x8c\xe6\x9c\x89\xe6\x9c\xba\xe4\xbc\x9a\xe8\x8e\xb7\xe5\xbe\x97\xe6\x8a\x80\xe6\x9c\xaf\xe4\xb9\xa6\xe7\xb1\x8d\xe6\x88\x96\xe5\x90\x84\xe7\xa7\x8d\xe6\x9c\x89\xe6\x84\x8f\xe6\x80\x9d\xe7\x9a\x84\xe5\x88\x9b\xe6\x84\x8f\xe3\x80\x81\xe6\x9e\x81\xe5\xae\xa2\xe4\xba\xa7\xe5\x93\x81\xef\xbc\x9b\n* [\xe5\xa5\x96\xe5\x8a\xb1\xe8\xaf\xa6\xe6\x83\x85](http://hao.importnew.com/rewards/)\n\n* * * -->\n\n## [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#c)C++\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#compute-vision)\xe8\xae\xa1\xe7\xae\x97\xe6\x9c\xba\xe8\xa7\x86\xe8\xa7\x89\n\n*   [CCV](http://hao.importnew.com/ccv/)\xef\xbc\x9a\xe5\x9f\xba\xe4\xba\x8eC\xe8\xaf\xad\xe8\xa8\x80/\xe6\x8f\x90\xe4\xbe\x9b\xe7\xbc\x93\xe5\xad\x98/\xe6\xa0\xb8\xe5\xbf\x83\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe8\xa7\x86\xe8\xa7\x89\xe5\xba\x93\xef\xbc\x8c\xe6\x96\xb0\xe9\xa2\x96\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe8\xa7\x86\xe8\xa7\x89\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/liuliu/ccv)\n*   [OpenCV](http://hao.importnew.com/opencv/)\xef\xbc\x9a\xe5\xae\x83\xe6\x8f\x90\xe4\xbe\x9bC++\xe3\x80\x81C\xe3\x80\x81Python\xe3\x80\x81Java \xe4\xbb\xa5\xe5\x8f\x8a MATLAB\xe6\x8e\xa5\xe5\x8f\xa3\xe3\x80\x82\xe5\xb9\xb6\xe6\x94\xaf\xe6\x8c\x81Windows\xe3\x80\x81Linux\xe3\x80\x81Android \xe5\x92\x8c Mac OS\xe6\x93\x8d\xe4\xbd\x9c\xe7\xb3\xbb\xe7\xbb\x9f\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://opencv.org/)\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#general-purpose-machine-learning)\xe9\x80\x9a\xe7\x94\xa8\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\n\n*   MLPack\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](http://www.mlpack.org/)\xe3\x80\x82\n*   DLib\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](http://dlib.net/ml.html)\xe3\x80\x82\n*   ecogg\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](https://code.google.com/p/encog-cpp/)\xe3\x80\x82\n*   shark\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](http://image.diku.dk/shark/sphinx_pages/build/html/index.html)\xe3\x80\x82\n\n## [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#clojure)Clojure\n\n#### \xe9\x80\x9a\xe7\x94\xa8\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\n\n*   Clojure Toolbox\xef\xbc\x9aClojure\xe8\xaf\xad\xe8\xa8\x80\xe5\xba\x93\xe4\xb8\x8e\xe5\xb7\xa5\xe5\x85\xb7\xe7\x9a\x84\xe5\x88\x86\xe7\xb1\xbb\xe7\x9b\xae\xe5\xbd\x95\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://www.clojure-toolbox.com/)\n\n## [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#go)Go\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#natural-language-processing)\xe8\x87\xaa\xe7\x84\xb6\xe8\xaf\xad\xe8\xa8\x80\xe5\xa4\x84\xe7\x90\x86\n\n*   go-porterstemmer\xef\xbc\x9a\xe4\xb8\x80\xe4\xb8\xaaPorter\xe8\xaf\x8d\xe5\xb9\xb2\xe6\x8f\x90\xe5\x8f\x96\xe7\xae\x97\xe6\xb3\x95\xe7\x9a\x84\xe5\x8e\x9f\xe7\x94\x9fGo\xe8\xaf\xad\xe8\xa8\x80\xe5\x87\x80\xe5\xae\xa4\xe5\xae\x9e\xe7\x8e\xb0\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/reiver/go-porterstemmer)\n*   paicehusk\xef\xbc\x9aPaice/Husk\xe8\xaf\x8d\xe5\xb9\xb2\xe6\x8f\x90\xe5\x8f\x96\xe7\xae\x97\xe6\xb3\x95\xe7\x9a\x84Go\xe8\xaf\xad\xe8\xa8\x80\xe5\xae\x9e\xe7\x8e\xb0\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/Rookii/paicehusk)\n*   snowball\xef\xbc\x9aGo\xe8\xaf\xad\xe8\xa8\x80\xe7\x89\x88\xe7\x9a\x84Snowball\xe8\xaf\x8d\xe5\xb9\xb2\xe6\x8f\x90\xe5\x8f\x96\xe5\x99\xa8\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://bitbucket.org/tebeka/snowball)\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#general-purpose-machine-learning-2)\xe9\x80\x9a\xe7\x94\xa8\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\n\n*   Go Learn\xef\xbc\x9aGo\xe8\xaf\xad\xe8\xa8\x80\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/sjwhitworth/golearn)\n*   go-pr\xef\xbc\x9aGo\xe8\xaf\xad\xe8\xa8\x80\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x8c\x85\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/daviddengcn/go-pr)\n*   bayesian\xef\xbc\x9aGo\xe8\xaf\xad\xe8\xa8\x80\xe6\x9c\xb4\xe7\xb4\xa0\xe8\xb4\x9d\xe5\x8f\xb6\xe6\x96\xaf\xe5\x88\x86\xe7\xb1\xbb\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/jbrukh/bayesian)\n*   go-galib\xef\xbc\x9aGo\xe8\xaf\xad\xe8\xa8\x80\xe9\x81\x97\xe4\xbc\xa0\xe7\xae\x97\xe6\xb3\x95\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/thoj/go-galib)\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#data-analysis--data-visualization)\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe6\x9e\x90/\xe6\x95\xb0\xe6\x8d\xae\xe5\x8f\xaf\xe8\xa7\x86\xe5\x8c\x96\n\n*   go-graph\xef\xbc\x9aGo\xe8\xaf\xad\xe8\xa8\x80\xe5\x9b\xbe\xe5\xbd\xa2\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/StepLg/go-graph)\n*   SVGo\xef\xbc\x9aGo\xe8\xaf\xad\xe8\xa8\x80\xe7\x9a\x84SVG\xe7\x94\x9f\xe6\x88\x90\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://www.svgopen.org/2011/papers/34-SVGo_a_Go_Library_for_SVG_generation/)\n\n## [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#java)Java\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#natural-language-processing-1)\xe8\x87\xaa\xe7\x84\xb6\xe8\xaf\xad\xe8\xa8\x80\xe5\xa4\x84\xe7\x90\x86\n\n*   CoreNLP\xef\xbc\x9a\xe6\x96\xaf\xe5\x9d\xa6\xe7\xa6\x8f\xe5\xa4\xa7\xe5\xad\xa6\xe7\x9a\x84CoreNLP\xe6\x8f\x90\xe4\xbe\x9b\xe4\xb8\x80\xe7\xb3\xbb\xe5\x88\x97\xe7\x9a\x84\xe8\x87\xaa\xe7\x84\xb6\xe8\xaf\xad\xe8\xa8\x80\xe5\xa4\x84\xe7\x90\x86\xe5\xb7\xa5\xe5\x85\xb7\xef\xbc\x8c\xe8\xbe\x93\xe5\x85\xa5\xe5\x8e\x9f\xe5\xa7\x8b\xe8\x8b\xb1\xe8\xaf\xad\xe6\x96\x87\xe6\x9c\xac\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe7\xbb\x99\xe5\x87\xba\xe5\x8d\x95\xe8\xaf\x8d\xe7\x9a\x84\xe5\x9f\xba\xe6\x9c\xac\xe5\xbd\xa2\xe5\xbc\x8f\xef\xbc\x88\xe4\xb8\x8b\xe9\x9d\xa2Stanford\xe5\xbc\x80\xe5\xa4\xb4\xe7\x9a\x84\xe5\x87\xa0\xe4\xb8\xaa\xe5\xb7\xa5\xe5\x85\xb7\xe9\x83\xbd\xe5\x8c\x85\xe5\x90\xab\xe5\x85\xb6\xe4\xb8\xad)\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://nlp.stanford.edu/software/corenlp.shtml)\n*   Stanford Parser\xef\xbc\x9a\xe4\xb8\x80\xe4\xb8\xaa\xe8\x87\xaa\xe7\x84\xb6\xe8\xaf\xad\xe8\xa8\x80\xe8\xa7\xa3\xe6\x9e\x90\xe5\x99\xa8\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://nlp.stanford.edu/software/lex-parser.shtml)\n*   Stanford POS Tagger\xef\xbc\x9a\xe4\xb8\x80\xe4\xb8\xaa\xe8\xaf\x8d\xe6\x80\xa7\xe5\x88\x86\xe7\xb1\xbb\xe5\x99\xa8\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://nlp.stanford.edu/software/tagger.shtml)\n*   Stanford Name Entity Recognizer\xef\xbc\x9aJava\xe5\xae\x9e\xe7\x8e\xb0\xe7\x9a\x84\xe5\x90\x8d\xe7\xa7\xb0\xe8\xaf\x86\xe5\x88\xab\xe5\x99\xa8\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://nlp.stanford.edu/software/CRF-NER.shtml)\n*   Stanford Word Segmenter\xef\xbc\x9a\xe5\x88\x86\xe8\xaf\x8d\xe5\x99\xa8\xef\xbc\x8c\xe5\xbe\x88\xe5\xa4\x9aNLP\xe5\xb7\xa5\xe4\xbd\x9c\xe4\xb8\xad\xe9\x83\xbd\xe8\xa6\x81\xe7\x94\xa8\xe5\x88\xb0\xe7\x9a\x84\xe6\xa0\x87\xe5\x87\x86\xe9\xa2\x84\xe5\xa4\x84\xe7\x90\x86\xe6\xad\xa5\xe9\xaa\xa4\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://nlp.stanford.edu/software/segmenter.shtml)\xe3\x80\x82\n*   Tregex\xe3\x80\x81Tsurgeon\xe4\xb8\x8eSemgrex\xef\xbc\x9a\xe7\x94\xa8\xe6\x9d\xa5\xe5\x9c\xa8\xe6\xa0\x91\xe7\x8a\xb6\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\xe4\xb8\xad\xe8\xbf\x9b\xe8\xa1\x8c\xe6\xa8\xa1\xe5\xbc\x8f\xe5\x8c\xb9\xe9\x85\x8d\xef\xbc\x8c\xe5\x9f\xba\xe4\xba\x8e\xe6\xa0\x91\xe5\x85\xb3\xe7\xb3\xbb\xe4\xbb\xa5\xe5\x8f\x8a\xe8\x8a\x82\xe7\x82\xb9\xe5\x8c\xb9\xe9\x85\x8d\xe7\x9a\x84\xe6\xad\xa3\xe5\x88\x99\xe8\xa1\xa8\xe8\xbe\xbe\xe5\xbc\x8f\xef\xbc\x88\xe5\x90\x8d\xe5\xad\x97\xe6\x98\xaf\xe2\x80\x9ctree regular expressions""\xe7\x9a\x84\xe7\xbc\xa9\xe5\x86\x99\xef\xbc\x89[\xe5\xae\x98\xe7\xbd\x91](http://nlp.stanford.edu/software/tregex.shtml) \n*   Stanford Phrasal\xef\xbc\x9a\xe6\x9c\x80\xe6\x96\xb0\xe7\x9a\x84\xe5\x9f\xba\xe4\xba\x8e\xe7\xbb\x9f\xe8\xae\xa1\xe7\x9f\xad\xe8\xaf\xad\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe7\xbf\xbb\xe8\xaf\x91\xe7\xb3\xbb\xe7\xbb\x9f\xef\xbc\x8cjava\xe7\xbc\x96\xe5\x86\x99\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://nlp.stanford.edu/software/phrasal/)\n*   Stanford Tokens Regex\xef\xbc\x9a\xe7\x94\xa8\xe4\xbb\xa5\xe5\xae\x9a\xe4\xb9\x89\xe6\x96\x87\xe6\x9c\xac\xe6\xa8\xa1\xe5\xbc\x8f\xe7\x9a\x84\xe6\xa1\x86\xe6\x9e\xb6\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://nlp.stanford.edu/software/tokensregex.shtml)\n*   Stanford Temporal Tagger\xef\xbc\x9aSUTime\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe8\xaf\x86\xe5\x88\xab\xe5\xb9\xb6\xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\xe6\x97\xb6\xe9\x97\xb4\xe8\xa1\xa8\xe8\xbe\xbe\xe5\xbc\x8f\xe7\x9a\x84\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://nlp.stanford.edu/software/sutime.shtml)\n*   Stanford SPIED\xef\xbc\x9a\xe5\x9c\xa8\xe7\xa7\x8d\xe5\xad\x90\xe9\x9b\x86\xe4\xb8\x8a\xe4\xbd\xbf\xe7\x94\xa8\xe6\xa8\xa1\xe5\xbc\x8f\xef\xbc\x8c\xe4\xbb\xa5\xe8\xbf\xad\xe4\xbb\xa3\xe6\x96\xb9\xe5\xbc\x8f\xe4\xbb\x8e\xe6\x97\xa0\xe6\xa0\x87\xe7\xad\xbe\xe6\x96\x87\xe6\x9c\xac\xe4\xb8\xad\xe5\xad\xa6\xe4\xb9\xa0\xe5\xad\x97\xe7\xac\xa6\xe5\xae\x9e\xe4\xbd\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://nlp.stanford.edu/software/patternslearning.shtml)\xe3\x80\x82\n*   Stanford Topic Modeling Toolbox\xef\xbc\x9a\xe4\xb8\xba\xe7\xa4\xbe\xe4\xbc\x9a\xe7\xa7\x91\xe5\xad\xa6\xe5\xae\xb6\xe5\x8f\x8a\xe5\x85\xb6\xe4\xbb\x96\xe5\xb8\x8c\xe6\x9c\x9b\xe5\x88\x86\xe6\x9e\x90\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe4\xba\xba\xe5\x91\x98\xe6\x8f\x90\xe4\xbe\x9b\xe7\x9a\x84\xe4\xb8\xbb\xe9\xa2\x98\xe5\xbb\xba\xe6\xa8\xa1\xe5\xb7\xa5\xe5\x85\xb7\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://nlp.stanford.edu/software/tmt/tmt-0.4/)\n*   Twitter Text Java\xef\xbc\x9aJava\xe5\xae\x9e\xe7\x8e\xb0\xe7\x9a\x84\xe6\x8e\xa8\xe7\x89\xb9\xe6\x96\x87\xe6\x9c\xac\xe5\xa4\x84\xe7\x90\x86\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/twitter/twitter-text-java)\n*   MALLET\xef\xbc\x9a\xe5\x9f\xba\xe4\xba\x8eJava\xe7\x9a\x84\xe7\xbb\x9f\xe8\xae\xa1\xe8\x87\xaa\xe7\x84\xb6\xe8\xaf\xad\xe8\xa8\x80\xe5\xa4\x84\xe7\x90\x86\xe3\x80\x81\xe6\x96\x87\xe6\xa1\xa3\xe5\x88\x86\xe7\xb1\xbb\xe3\x80\x81\xe8\x81\x9a\xe7\xb1\xbb\xe3\x80\x81\xe4\xb8\xbb\xe9\xa2\x98\xe5\xbb\xba\xe6\xa8\xa1\xe3\x80\x81\xe4\xbf\xa1\xe6\x81\xaf\xe6\x8f\x90\xe5\x8f\x96\xe4\xbb\xa5\xe5\x8f\x8a\xe5\x85\xb6\xe4\xbb\x96\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x96\x87\xe6\x9c\xac\xe5\xba\x94\xe7\x94\xa8\xe5\x8c\x85\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://mallet.cs.umass.edu/) \n*   OpenNLP\xef\xbc\x9a\xe5\xa4\x84\xe7\x90\x86\xe8\x87\xaa\xe7\x84\xb6\xe8\xaf\xad\xe8\xa8\x80\xe6\x96\x87\xe6\x9c\xac\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xb7\xa5\xe5\x85\xb7\xe5\x8c\x85\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://hao.importnew.com/apache-opennlp/)\n*   LingPipe\xef\xbc\x9a\xe4\xbd\xbf\xe7\x94\xa8\xe8\xae\xa1\xe7\xae\x97\xe6\x9c\xba\xe8\xaf\xad\xe8\xa8\x80\xe5\xad\xa6\xe5\xa4\x84\xe7\x90\x86\xe6\x96\x87\xe6\x9c\xac\xe7\x9a\x84\xe5\xb7\xa5\xe5\x85\xb7\xe5\x8c\x85\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://alias-i.com/lingpipe/index.html)\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#general-purpose-machine-learning-3)\xe9\x80\x9a\xe7\x94\xa8\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\n\n*   MLlib in Apache Spark\xef\xbc\x9aSpark\xe4\xb8\xad\xe7\x9a\x84\xe5\x88\x86\xe5\xb8\x83\xe5\xbc\x8f\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xa8\x8b\xe5\xba\x8f\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://spark.apache.org/docs/latest/mllib-guide.html)\n*   Mahout\xef\xbc\x9a\xe5\x88\x86\xe5\xb8\x83\xe5\xbc\x8f\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/apache/mahout)\n*   Stanford Classifier\xef\xbc\x9a\xe6\x96\xaf\xe5\x9d\xa6\xe7\xa6\x8f\xe5\xa4\xa7\xe5\xad\xa6\xe7\x9a\x84\xe5\x88\x86\xe7\xb1\xbb\xe5\x99\xa8\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://nlp.stanford.edu/software/classifier.shtml)\n*   Weka\xef\xbc\x9aWeka\xe6\x98\xaf\xe6\x95\xb0\xe6\x8d\xae\xe6\x8c\x96\xe6\x8e\x98\xe6\x96\xb9\xe9\x9d\xa2\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xae\x97\xe6\xb3\x95\xe9\x9b\x86\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://www.cs.waikato.ac.nz/ml/weka/)\n*   ORYX\xef\xbc\x9a\xe6\x8f\x90\xe4\xbe\x9b\xe4\xb8\x80\xe4\xb8\xaa\xe7\xae\x80\xe5\x8d\x95\xe7\x9a\x84\xe5\xa4\xa7\xe8\xa7\x84\xe6\xa8\xa1\xe5\xae\x9e\xe6\x97\xb6\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0/\xe9\xa2\x84\xe6\xb5\x8b\xe5\x88\x86\xe6\x9e\x90\xe5\x9f\xba\xe7\xa1\x80\xe6\x9e\xb6\xe6\x9e\x84\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/cloudera/oryx)\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#data-analysis--data-visualization-1)\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe6\x9e\x90/\xe6\x95\xb0\xe6\x8d\xae\xe5\x8f\xaf\xe8\xa7\x86\xe5\x8c\x96\n\n*   Hadoop\xef\xbc\x9a\xe5\xa4\xa7\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe6\x9e\x90\xe5\xb9\xb3\xe5\x8f\xb0\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/apache/hadoop-mapreduce)\n*   Spark\xef\xbc\x9a\xe5\xbf\xab\xe9\x80\x9f\xe9\x80\x9a\xe7\x94\xa8\xe7\x9a\x84\xe5\xa4\xa7\xe8\xa7\x84\xe6\xa8\xa1\xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\xe5\xbc\x95\xe6\x93\x8e\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/apache/spark)\n*   Impala\xef\xbc\x9a\xe4\xb8\xbaHadoop\xe5\xae\x9e\xe7\x8e\xb0\xe5\xae\x9e\xe6\x97\xb6\xe6\x9f\xa5\xe8\xaf\xa2\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/cloudera/impala)\n\n## [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#javascript)Javascript\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#natural-language-processing-2)\xe8\x87\xaa\xe7\x84\xb6\xe8\xaf\xad\xe8\xa8\x80\xe5\xa4\x84\xe7\x90\x86\n\n*   Twitter-text-js\xef\xbc\x9aJavaScript\xe5\xae\x9e\xe7\x8e\xb0\xe7\x9a\x84\xe6\x8e\xa8\xe7\x89\xb9\xe6\x96\x87\xe6\x9c\xac\xe5\xa4\x84\xe7\x90\x86\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/twitter/twitter-text-js)\n*   NLP.js\xef\xbc\x9ajavascript\xe5\x8f\x8acoffeescript\xe7\xbc\x96\xe5\x86\x99\xe7\x9a\x84NLP\xe5\xb7\xa5\xe5\x85\xb7\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/nicktesla/nlpjs)\n*   natural\xef\xbc\x9aNode\xe4\xb8\x8b\xe7\x9a\x84\xe9\x80\x9a\xe7\x94\xa8NLP\xe5\xb7\xa5\xe5\x85\xb7\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/NaturalNode/natural)\n*   Knwl.js\xef\xbc\x9aJS\xe7\xbc\x96\xe5\x86\x99\xe7\x9a\x84\xe8\x87\xaa\xe7\x84\xb6\xe8\xaf\xad\xe8\xa8\x80\xe5\xa4\x84\xe7\x90\x86\xe5\x99\xa8\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/loadfive/Knwl.js)\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#data-analysis--data-visualization-2)\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe6\x9e\x90/\xe6\x95\xb0\xe6\x8d\xae\xe5\x8f\xaf\xe8\xa7\x86\xe5\x8c\x96\n\n*   D3.js\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](http://d3js.org/)\xe3\x80\x82\n*   High Charts\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](http://www.highcharts.com/)\xe3\x80\x82\n*   NVD3.js\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](http://nvd3.org/)\xe3\x80\x82\n*   dc.js\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](http://dc-js.github.io/dc.js/)\xe3\x80\x82\n*   chartjs\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](http://www.chartjs.org/)\xe3\x80\x82\n*   dimple\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](http://dimplejs.org/)\xe3\x80\x82\n*   amCharts\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](http://www.amcharts.com/)\xe3\x80\x82\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#general-purpose-machine-learning-4)\xe9\x80\x9a\xe7\x94\xa8\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\n\n*   Convnet.js\xef\xbc\x9a\xe8\xae\xad\xe7\xbb\x83\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84JavaScript\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://cs.stanford.edu/people/karpathy/convnetjs/)\n*   Clustering.js\xef\xbc\x9a\xe7\x94\xa8JavaScript\xe5\xae\x9e\xe7\x8e\xb0\xe7\x9a\x84\xe8\x81\x9a\xe7\xb1\xbb\xe7\xae\x97\xe6\xb3\x95\xef\xbc\x8c\xe4\xbe\x9bNode.js\xe5\x8f\x8a\xe6\xb5\x8f\xe8\xa7\x88\xe5\x99\xa8\xe4\xbd\xbf\xe7\x94\xa8\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/tixz/clustering.js)\n*   Decision Trees\xef\xbc\x9aNode.js\xe5\xae\x9e\xe7\x8e\xb0\xe7\x9a\x84\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xef\xbc\x8c\xe4\xbd\xbf\xe7\x94\xa8ID3\xe7\xae\x97\xe6\xb3\x95\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/serendipious/nodejs-decision-tree-id3)\n*   Node-fann\xef\xbc\x9aNode.js\xe4\xb8\x8b\xe7\x9a\x84\xe5\xbf\xab\xe9\x80\x9f\xe4\xba\xba\xe5\xb7\xa5\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/rlidwka/node-fann)\n*   Kmeans.js\xef\xbc\x9ak-means\xe7\xae\x97\xe6\xb3\x95\xe7\x9a\x84\xe7\xae\x80\xe5\x8d\x95Javascript\xe5\xae\x9e\xe7\x8e\xb0\xef\xbc\x8c\xe4\xbe\x9bNode.js\xe5\x8f\x8a\xe6\xb5\x8f\xe8\xa7\x88\xe5\x99\xa8\xe4\xbd\xbf\xe7\x94\xa8\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/tixz/kmeans.js)\n*   LDA.js\xef\xbc\x9a\xe4\xbe\x9bNode.js\xe7\x94\xa8\xe7\x9a\x84LDA\xe4\xb8\xbb\xe9\xa2\x98\xe5\xbb\xba\xe6\xa8\xa1\xe5\xb7\xa5\xe5\x85\xb7\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/primaryobjects/lda)\n*   Learning.js\xef\xbc\x9a\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92/c4.5\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe7\x9a\x84JavaScript\xe5\xae\x9e\xe7\x8e\xb0\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/yandongliu/learningjs)\n*   Machine Learning\xef\xbc\x9aNode.js\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://joonku.com/project/machine_learning)\n*   Node-SVM\xef\xbc\x9aNode.js\xe7\x9a\x84\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/nicolaspanel/node-svm)\n*   Brain\xef\xbc\x9aJavaScript\xe5\xae\x9e\xe7\x8e\xb0\xe7\x9a\x84\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/harthur/brain)\n*   Bayesian-Bandit\xef\xbc\x9a\xe8\xb4\x9d\xe5\x8f\xb6\xe6\x96\xaf\xe5\xbc\xba\xe7\x9b\x97\xe7\xae\x97\xe6\xb3\x95\xe7\x9a\x84\xe5\xae\x9e\xe7\x8e\xb0\xef\xbc\x8c\xe4\xbe\x9bNode.js\xe5\x8f\x8a\xe6\xb5\x8f\xe8\xa7\x88\xe5\x99\xa8\xe4\xbd\xbf\xe7\x94\xa8\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/omphalos/bayesian-bandit.js)\n\n## [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#julia)Julia\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#general-purpose-machine-learning-5)\xe9\x80\x9a\xe7\x94\xa8\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\n\n*   PGM\xef\xbc\x9aJulia\xe5\xae\x9e\xe7\x8e\xb0\xe7\x9a\x84\xe6\xa6\x82\xe7\x8e\x87\xe5\x9b\xbe\xe6\xa8\xa1\xe5\x9e\x8b\xe6\xa1\x86\xe6\x9e\xb6\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/JuliaStats/PGM.jl)\n*   DA\xef\xbc\x9aJulia\xe5\xae\x9e\xe7\x8e\xb0\xe7\x9a\x84\xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96\xe5\x88\xa4\xe5\x88\xab\xe5\x88\x86\xe6\x9e\x90\xe5\x8c\x85\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/trthatcher/DA.jl)\n*   Regression\xef\xbc\x9a\xe5\x9b\x9e\xe5\xbd\x92\xe5\x88\x86\xe6\x9e\x90\xe7\xae\x97\xe6\xb3\x95\xe5\x8c\x85\xef\xbc\x88\xe5\xa6\x82\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe5\x92\x8c\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92\xef\xbc\x89\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/lindahua/Regression.jl)\n*   Local Regression\xef\xbc\x9a\xe5\xb1\x80\xe9\x83\xa8\xe5\x9b\x9e\xe5\xbd\x92\xef\xbc\x8c\xe9\x9d\x9e\xe5\xb8\xb8\xe5\xb9\xb3\xe6\xbb\x91\xef\xbc\x81\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/dcjones/Loess.jl)\n*   Naive Bayes\xef\xbc\x9a\xe6\x9c\xb4\xe7\xb4\xa0\xe8\xb4\x9d\xe5\x8f\xb6\xe6\x96\xaf\xe7\x9a\x84\xe7\xae\x80\xe5\x8d\x95Julia\xe5\xae\x9e\xe7\x8e\xb0\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/nutsiepully/NaiveBayes.jl)\n*   Mixed Models\xef\xbc\x9a\xef\xbc\x88\xe7\xbb\x9f\xe8\xae\xa1\xef\xbc\x89\xe6\xb7\xb7\xe5\x90\x88\xe6\x95\x88\xe5\xba\x94\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84Julia\xe5\x8c\x85\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/dmbates/MixedModels.jl)\n*   Simple MCMC\xef\xbc\x9aJulia\xe5\xae\x9e\xe7\x8e\xb0\xe7\x9a\x84\xe5\x9f\xba\xe6\x9c\xacmcmc\xe9\x87\x87\xe6\xa0\xb7\xe5\x99\xa8\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/fredo-dedup/SimpleMCMC.jl)\xe3\x80\x82\n*   Distance\xef\xbc\x9aJulia\xe5\xae\x9e\xe7\x8e\xb0\xe7\x9a\x84\xe8\xb7\x9d\xe7\xa6\xbb\xe8\xaf\x84\xe4\xbc\xb0\xe6\xa8\xa1\xe5\x9d\x97\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/JuliaStats/Distance.jl)\n*   Decision Tree\xef\xbc\x9a\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe5\x88\x86\xe7\xb1\xbb\xe5\x99\xa8\xe5\x8f\x8a\xe5\x9b\x9e\xe5\xbd\x92\xe5\x88\x86\xe6\x9e\x90\xe5\x99\xa8\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/bensadeghi/DecisionTree.jl)\n*   Neural\xef\xbc\x9aJulia\xe5\xae\x9e\xe7\x8e\xb0\xe7\x9a\x84\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/compressed/neural.jl)\n*   MCMC\xef\xbc\x9aJulia\xe4\xb8\x8b\xe7\x9a\x84MCMC\xe5\xb7\xa5\xe5\x85\xb7\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/doobwa/MCMC.jl)\n*   GLM\xef\xbc\x9aJulia\xe5\x86\x99\xe7\x9a\x84\xe5\xb9\xbf\xe4\xb9\x89\xe7\xba\xbf\xe6\x80\xa7\xe6\xa8\xa1\xe5\x9e\x8b\xe5\x8c\x85\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/JuliaStats/GLM.jl)\n*   Online Learning\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](https://github.com/lendle/OnlineLearning.jl)\n*   GLMNet\xef\xbc\x9aGMLNet\xe7\x9a\x84Julia\xe5\x8c\x85\xe8\xa3\x85\xe7\x89\x88\xef\xbc\x8c\xe9\x80\x82\xe5\x90\x88\xe5\xa5\x97\xe7\xb4\xa2/\xe5\xbc\xb9\xe6\x80\xa7\xe7\xbd\x91\xe6\xa8\xa1\xe5\x9e\x8b\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/simonster/GLMNet.jl)\n*   Clustering\xef\xbc\x9ak-means, dp-means\xe7\xad\x89\xe6\x95\xb0\xe6\x8d\xae\xe8\x81\x9a\xe7\xb1\xbb\xe7\x9a\x84\xe5\x9f\xba\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/JuliaStats/Clustering.jl)\n*   SVM\xef\xbc\x9aJulia\xe4\xb8\x8b\xe7\x9a\x84\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/JuliaStats/SVM.jl)\n*   Kernal Density\xef\xbc\x9aJulia\xe4\xb8\x8b\xe7\x9a\x84\xe6\xa0\xb8\xe5\xaf\x86\xe5\xba\xa6\xe4\xbc\xb0\xe8\xae\xa1\xe5\x99\xa8\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/JuliaStats/KernelDensity.jl)\n*   Dimensionality Reduction\xef\xbc\x9a\xe9\x99\x8d\xe7\xbb\xb4\xe7\xae\x97\xe6\xb3\x95\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/JuliaStats/DimensionalityReduction.jl)\n*   NMF\xef\xbc\x9aJulia\xe4\xb8\x8b\xe7\x9a\x84\xe9\x9d\x9e\xe8\xb4\x9f\xe7\x9f\xa9\xe9\x98\xb5\xe5\x88\x86\xe8\xa7\xa3\xe5\x8c\x85\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/JuliaStats/NMF.jl)\n*   ANN\xef\xbc\x9aJulia\xe5\xae\x9e\xe7\x8e\xb0\xe7\x9a\x84\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/EricChiang/ANN.jl)\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#natural-language-processing-3)\xe8\x87\xaa\xe7\x84\xb6\xe8\xaf\xad\xe8\xa8\x80\xe5\xa4\x84\xe7\x90\x86\n\n*   Topic Models\xef\xbc\x9aJulia\xe4\xb8\x8b\xe7\x9a\x84\xe4\xb8\xbb\xe9\xa2\x98\xe5\xbb\xba\xe6\xa8\xa1\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/slycoder/TopicModels.jl)\n*   Text Analysis\xef\xbc\x9aJulia\xe4\xb8\x8b\xe7\x9a\x84\xe6\x96\x87\xe6\x9c\xac\xe5\x88\x86\xe6\x9e\x90\xe5\x8c\x85\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/johnmyleswhite/TextAnalysis.jl)\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#data-analysis--data-visualization-3)\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe6\x9e\x90/\xe6\x95\xb0\xe6\x8d\xae\xe5\x8f\xaf\xe8\xa7\x86\xe5\x8c\x96\n\n*   Graph Layout\xef\xbc\x9a\xe7\xba\xafJulia\xe5\xae\x9e\xe7\x8e\xb0\xe7\x9a\x84\xe5\x9b\xbe\xe5\xb8\x83\xe5\xb1\x80\xe7\xae\x97\xe6\xb3\x95\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/IainNZ/GraphLayout.jl)\n*   Data Frames Meta\xef\xbc\x9aDataFrames\xe7\x9a\x84\xe5\x85\x83\xe7\xbc\x96\xe7\xa8\x8b\xe5\xb7\xa5\xe5\x85\xb7\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/JuliaStats/DataFramesMeta.jl)\n*   Julia Data\xef\xbc\x9a\xe5\xa4\x84\xe7\x90\x86\xe8\xa1\xa8\xe6\xa0\xbc\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84Julia\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/nfoti/JuliaData)\n*   Data Read\xef\xbc\x9a\xe4\xbb\x8eStata\xe3\x80\x81SAS\xe3\x80\x81SPSS\xe8\xaf\xbb\xe5\x8f\x96\xe6\x96\x87\xe4\xbb\xb6\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/WizardMac/DataRead.jl)\n*   Hypothesis Tests\xef\xbc\x9aJulia\xe4\xb8\xad\xe7\x9a\x84\xe5\x81\x87\xe8\xae\xbe\xe6\xa3\x80\xe9\xaa\x8c\xe5\x8c\x85\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/JuliaStats/HypothesisTests.jl)\n*   Gladfly\xef\xbc\x9aJulia\xe7\xbc\x96\xe5\x86\x99\xe7\x9a\x84\xe7\x81\xb5\xe5\xb7\xa7\xe7\x9a\x84\xe7\xbb\x9f\xe8\xae\xa1\xe7\xbb\x98\xe5\x9b\xbe\xe7\xb3\xbb\xe7\xbb\x9f\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/dcjones/Gadfly.jl)\n*   Stats\xef\xbc\x9aJulia\xe7\xbc\x96\xe5\x86\x99\xe7\x9a\x84\xe7\xbb\x9f\xe8\xae\xa1\xe6\xb5\x8b\xe8\xaf\x95\xe5\x87\xbd\xe6\x95\xb0\xe5\x8c\x85\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/johnmyleswhite/stats.jl)\n*   RDataSets\xef\xbc\x9a\xe8\xaf\xbb\xe5\x8f\x96R\xe8\xaf\xad\xe8\xa8\x80\xe4\xb8\xad\xe4\xbc\x97\xe5\xa4\x9a\xe5\x8f\xaf\xe7\x94\xa8\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84Julia\xe5\x87\xbd\xe6\x95\xb0\xe5\x8c\x85\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/johnmyleswhite/RDatasets.jl)\n*   DataFrames\xef\xbc\x9a\xe5\xa4\x84\xe7\x90\x86\xe8\xa1\xa8\xe6\xa0\xbc\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84Julia\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/JuliaStats/DataFrames.jl)\n*   Distributions\xef\xbc\x9a\xe6\xa6\x82\xe7\x8e\x87\xe5\x88\x86\xe5\xb8\x83\xe5\x8f\x8a\xe7\x9b\xb8\xe5\x85\xb3\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84Julia\xe5\x8c\x85\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/JuliaStats/Distributions.jl)\n*   Data Arrays\xef\xbc\x9a\xe5\x85\x83\xe7\xb4\xa0\xe5\x80\xbc\xe5\x8f\xaf\xe4\xbb\xa5\xe4\xb8\xba\xe7\xa9\xba\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/JuliaStats/DataArrays.jl)\n*   Time Series\xef\xbc\x9aJulia\xe7\x9a\x84\xe6\x97\xb6\xe9\x97\xb4\xe5\xba\x8f\xe5\x88\x97\xe6\x95\xb0\xe6\x8d\xae\xe5\xb7\xa5\xe5\x85\xb7\xe5\x8c\x85\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/JuliaStats/TimeSeries.jl)\n*   Sampling\xef\xbc\x9aJulia\xe7\x9a\x84\xe5\x9f\xba\xe6\x9c\xac\xe9\x87\x87\xe6\xa0\xb7\xe7\xae\x97\xe6\xb3\x95\xe5\x8c\x85\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/JuliaStats/Sampling.jl)\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#misc-stuff--presentations)\xe6\x9d\x82\xe9\xa1\xb9/\xe6\xbc\x94\xe7\xa4\xba\xe6\x96\x87\xe7\xa8\xbf\n\n*   DSP\xef\xbc\x9a\xe6\x95\xb0\xe5\xad\x97\xe4\xbf\xa1\xe5\x8f\xb7\xe5\xa4\x84\xe7\x90\x86\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/JuliaDSP/DSP)\n*   JuliaCon Presentations\xef\xbc\x9aJulia\xe5\xa4\xa7\xe4\xbc\x9a\xe4\xb8\x8a\xe7\x9a\x84\xe6\xbc\x94\xe7\xa4\xba\xe6\x96\x87\xe7\xa8\xbf\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/JuliaCon/presentations)\n*   SignalProcessing\xef\xbc\x9aJulia\xe7\x9a\x84\xe4\xbf\xa1\xe5\x8f\xb7\xe5\xa4\x84\xe7\x90\x86\xe5\xb7\xa5\xe5\x85\xb7\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/davidavdav/SignalProcessing)\n*   Images\xef\xbc\x9aJulia\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/timholy/Images.jl)\n\n## [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#matlab)\n\n## Lua\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning#general-purpose-machine-learning-7)\xe9\x80\x9a\xe7\x94\xa8\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\n\n*   [Torch7](http://torch.ch/)\xe3\x80\x82\n    *   cephes\xef\xbc\x9a\xe2\x80\x94Cephes\xe6\x95\xb0\xe5\xad\xa6\xe5\x87\xbd\xe6\x95\xb0\xe5\xba\x93\xef\xbc\x8c\xe5\x8c\x85\xe8\xa3\x85\xe6\x88\x90Torch\xe5\x8f\xaf\xe7\x94\xa8\xe5\xbd\xa2\xe5\xbc\x8f\xe6\x8f\x90\xe4\xbe\x9b\xe5\xb9\xb6\xe5\x8c\x85\xe8\xa3\x85\xe4\xba\x86\xe8\xb6\x85\xe8\xbf\x87180\xe4\xb8\xaa\xe7\x89\xb9\xe6\xae\x8a\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\xa6\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x8c\xe7\x94\xb1Stephen L. Moshier\xe5\xbc\x80\xe5\x8f\x91\xef\xbc\x8c\xe6\x98\xafSciPy\xe7\x9a\x84\xe6\xa0\xb8\xe5\xbf\x83\xef\xbc\x8c\xe5\xba\x94\xe7\x94\xa8\xe4\xba\x8e\xe5\xbe\x88\xe5\xa4\x9a\xe5\x9c\xba\xe5\x90\x88\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://jucor.github.io/torch-cephes)\n    *   graph\xef\xbc\x9a\xe4\xbe\x9bTorch\xe4\xbd\xbf\xe7\x94\xa8\xe7\x9a\x84\xe5\x9b\xbe\xe5\xbd\xa2\xe5\x8c\x85\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/torch/graph)\n    *   randomkit\xef\xbc\x9a\xe4\xbb\x8eNumpy\xe6\x8f\x90\xe5\x8f\x96\xe7\x9a\x84\xe9\x9a\x8f\xe6\x9c\xba\xe6\x95\xb0\xe7\x94\x9f\xe6\x88\x90\xe5\x8c\x85\xef\xbc\x8c\xe5\x8c\x85\xe8\xa3\x85\xe6\x88\x90Torch\xe5\x8f\xaf\xe7\x94\xa8\xe5\xbd\xa2\xe5\xbc\x8f\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://jucor.github.io/torch-randomkit/)\n    *   signal\xef\xbc\x9aTorch-7\xe5\x8f\xaf\xe7\x94\xa8\xe7\x9a\x84\xe4\xbf\xa1\xe5\x8f\xb7\xe5\xa4\x84\xe7\x90\x86\xe5\xb7\xa5\xe5\x85\xb7\xe5\x8c\x85\xef\xbc\x8c\xe5\x8f\xaf\xe8\xbf\x9b\xe8\xa1\x8cFFT, DCT, Hilbert, cepstrums, stft\xe7\xad\x89\xe5\x8f\x98\xe6\x8d\xa2\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://soumith.ch/torch-signal/signal/)\n    *   nn\xef\xbc\x9aTorch\xe5\x8f\xaf\xe7\x94\xa8\xe7\x9a\x84\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe5\x8c\x85\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/torch/nn)\n    *   nngraph\xef\xbc\x9a\xe4\xb8\xbann\xe5\xba\x93\xe6\x8f\x90\xe4\xbe\x9b\xe5\x9b\xbe\xe5\xbd\xa2\xe8\xae\xa1\xe7\xae\x97\xe8\x83\xbd\xe5\x8a\x9b\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/torch/nngraph)\n    *   nnx\xef\xbc\x9a\xe4\xb8\x80\xe4\xb8\xaa\xe4\xb8\x8d\xe7\xa8\xb3\xe5\xae\x9a\xe5\xae\x9e\xe9\xaa\x8c\xe6\x80\xa7\xe7\x9a\x84\xe5\x8c\x85\xef\xbc\x8c\xe6\x89\xa9\xe5\xb1\x95Torch\xe5\x86\x85\xe7\xbd\xae\xe7\x9a\x84nn\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/clementfarabet/lua---nnx)\n    *   optim\xef\xbc\x9aTorch\xe5\x8f\xaf\xe7\x94\xa8\xe7\x9a\x84\xe4\xbc\x98\xe5\x8c\x96\xe7\xae\x97\xe6\xb3\x95\xe5\xba\x93\xef\xbc\x8c\xe5\x8c\x85\xe6\x8b\xac SGD, Adagrad, \xe5\x85\xb1\xe8\xbd\xad\xe6\xa2\xaf\xe5\xba\xa6\xe7\xae\x97\xe6\xb3\x95, LBFGS, RProp\xe7\xad\x89\xe7\xae\x97\xe6\xb3\x95\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/torch/optim)\n    *   unsup\xef\xbc\x9aTorch\xe4\xb8\x8b\xe7\x9a\x84\xe9\x9d\x9e\xe7\x9b\x91\xe7\x9d\xa3\xe5\xad\xa6\xe4\xb9\xa0\xe5\x8c\x85\xe6\x8f\x90\xe4\xbe\x9b\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9d\x97\xe4\xb8\x8enn\xef\xbc\x88LinearPsd\xe3\x80\x81ConvPsd\xe3\x80\x81AutoEncoder\xe3\x80\x81...\xef\xbc\x89\xe5\x8f\x8a\xe7\x8b\xac\xe7\xab\x8b\xe7\xae\x97\xe6\xb3\x95\xef\xbc\x88k-means\xe3\x80\x81PCA\xef\xbc\x89\xe7\xad\x89\xe5\x85\xbc\xe5\xae\xb9\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/koraykv/unsup)\n    *   manifold\xef\xbc\x9a\xe6\x93\x8d\xe4\xbd\x9c\xe6\xb5\x81\xe5\xbd\xa2\xe7\x9a\x84\xe5\x8c\x85\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/clementfarabet/manifold)\n    *   svm\xef\xbc\x9aTorch\xe7\x9a\x84\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/koraykv/torch-svm)\n    *   lbfgs\xef\xbc\x9a\xe5\xb0\x86liblbfgs\xe5\x8c\x85\xe8\xa3\x85\xe4\xb8\xbaFFI\xe6\x8e\xa5\xe5\x8f\xa3\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/clementfarabet/lbfgs)\n    *   vowpalwabbit\xef\xbc\x9a\xe8\x80\x81\xe7\x89\x88\xe7\x9a\x84vowpalwabbit\xe5\xaf\xb9torch\xe7\x9a\x84\xe6\x8e\xa5\xe5\x8f\xa3\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/clementfarabet/vowpal_wabbit)\n    *   OpenGM\xef\xbc\x9aOpenGM\xe6\x98\xafC++\xe7\xbc\x96\xe5\x86\x99\xe7\x9a\x84\xe5\x9b\xbe\xe5\xbd\xa2\xe5\xbb\xba\xe6\xa8\xa1\xe5\x8f\x8a\xe6\x8e\xa8\xe6\x96\xad\xe5\xba\x93\xef\xbc\x8c\xe8\xaf\xa5binding\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x94\xa8Lua\xe4\xbb\xa5\xe7\xae\x80\xe5\x8d\x95\xe7\x9a\x84\xe6\x96\xb9\xe5\xbc\x8f\xe6\x8f\x8f\xe8\xbf\xb0\xe5\x9b\xbe\xe5\xbd\xa2\xef\xbc\x8c\xe7\x84\xb6\xe5\x90\x8e\xe7\x94\xa8OpenGM\xe4\xbc\x98\xe5\x8c\x96\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/clementfarabet/lua---opengm)\xe3\x80\x82\n    *   sphagetti\xef\xbc\x9aMichaelMathieu\xe4\xb8\xbatorch7\xe7\xbc\x96\xe5\x86\x99\xe7\x9a\x84\xe7\xa8\x80\xe7\x96\x8f\xe7\xba\xbf\xe6\x80\xa7\xe6\xa8\xa1\xe5\x9d\x97\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/MichaelMathieu/lua---spaghetti)\n    *   LuaSHKit\xef\xbc\x9a\xe5\xb0\x86\xe5\xb1\x80\xe9\x83\xa8\xe6\x95\x8f\xe6\x84\x9f\xe5\x93\x88\xe5\xb8\x8c\xe5\xba\x93SHKit\xe5\x8c\x85\xe8\xa3\x85\xe6\x88\x90lua\xe5\x8f\xaf\xe7\x94\xa8\xe5\xbd\xa2\xe5\xbc\x8f\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/ocallaco/LuaSHkit)\n    *   kernel smoothing\xef\xbc\x9aKNN\xe3\x80\x81\xe6\xa0\xb8\xe6\x9d\x83\xe5\xb9\xb3\xe5\x9d\x87\xe4\xbb\xa5\xe5\x8f\x8a\xe5\xb1\x80\xe9\x83\xa8\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe5\xb9\xb3\xe6\xbb\x91\xe5\x99\xa8\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/rlowrance/kernel-smoothers)\n    *   cutorch\xef\xbc\x9atorch\xe7\x9a\x84CUDA\xe5\x90\x8e\xe7\xab\xaf\xe5\xae\x9e\xe7\x8e\xb0\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/torch/cutorch)\n    *   cunn\xef\xbc\x9atorch\xe7\x9a\x84CUDA\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe5\xae\x9e\xe7\x8e\xb0\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/torch/cunn)\n    *   imgraph\xef\xbc\x9atorch\xe7\x9a\x84\xe5\x9b\xbe\xe5\x83\x8f/\xe5\x9b\xbe\xe5\xbd\xa2\xe5\xba\x93\xef\xbc\x8c\xe6\x8f\x90\xe4\xbe\x9b\xe4\xbb\x8e\xe5\x9b\xbe\xe5\x83\x8f\xe5\x88\x9b\xe5\xbb\xba\xe5\x9b\xbe\xe5\xbd\xa2\xe3\x80\x81\xe5\x88\x86\xe5\x89\xb2\xe3\x80\x81\xe5\xbb\xba\xe7\xab\x8b\xe6\xa0\x91\xe3\x80\x81\xe5\x8f\x88\xe8\xbd\xac\xe5\x8c\x96\xe5\x9b\x9e\xe5\x9b\xbe\xe5\x83\x8f\xe7\x9a\x84\xe4\xbe\x8b\xe7\xa8\x8b\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/clementfarabet/lua---imgraph)\n    *   videograph\xef\xbc\x9atorch\xe7\x9a\x84\xe8\xa7\x86\xe9\xa2\x91/\xe5\x9b\xbe\xe5\xbd\xa2\xe5\xba\x93\xef\xbc\x8c\xe6\x8f\x90\xe4\xbe\x9b\xe4\xbb\x8e\xe8\xa7\x86\xe9\xa2\x91\xe5\x88\x9b\xe5\xbb\xba\xe5\x9b\xbe\xe5\xbd\xa2\xe3\x80\x81\xe5\x88\x86\xe5\x89\xb2\xe3\x80\x81\xe5\xbb\xba\xe7\xab\x8b\xe6\xa0\x91\xe3\x80\x81\xe5\x8f\x88\xe8\xbd\xac\xe5\x8c\x96\xe5\x9b\x9e\xe8\xa7\x86\xe9\xa2\x91\xe7\x9a\x84\xe4\xbe\x8b\xe7\xa8\x8b\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/clementfarabet/videograph)\n    *   saliency\xef\xbc\x9a\xe7\xa7\xaf\xe5\x88\x86\xe5\x9b\xbe\xe5\x83\x8f\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81\xe5\x92\x8c\xe5\xb7\xa5\xe5\x85\xb7\xef\xbc\x8c\xe7\x94\xa8\xe6\x9d\xa5\xe4\xbb\x8e\xe5\xbf\xab\xe9\x80\x9f\xe7\xa7\xaf\xe5\x88\x86\xe7\x9b\xb4\xe6\x96\xb9\xe5\x9b\xbe\xe4\xb8\xad\xe5\xaf\xbb\xe6\x89\xbe\xe5\x85\xb4\xe8\xb6\xa3\xe7\x82\xb9\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/marcoscoffier/torch-saliency) \n    *   stitch\xef\xbc\x9a\xe4\xbd\xbf\xe7\x94\xa8hugin\xe6\x8b\xbc\xe5\x90\x88\xe5\x9b\xbe\xe5\x83\x8f\xe5\xb9\xb6\xe5\xb0\x86\xe5\x85\xb6\xe7\x94\x9f\xe6\x88\x90\xe8\xa7\x86\xe9\xa2\x91\xe5\xba\x8f\xe5\x88\x97\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/marcoscoffier/lua---stitch)\n    *   sfm\xef\xbc\x9a\xe8\xbf\x90\xe5\x8a\xa8\xe5\x9c\xba\xe6\x99\xaf\xe6\x9d\x9f\xe8\xb0\x83\xe6\x95\xb4/\xe7\xbb\x93\xe6\x9e\x84\xe5\x8c\x85\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/marcoscoffier/lua---sfm)\n    *   fex\xef\xbc\x9atorch\xe7\x9a\x84\xe7\x89\xb9\xe5\xbe\x81\xe6\x8f\x90\xe5\x8f\x96\xe5\x8c\x85\xef\xbc\x8c\xe6\x8f\x90\xe4\xbe\x9bSIFT\xe5\x92\x8cdSIFT\xe6\xa8\xa1\xe5\x9d\x97\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/koraykv/fex)\n    *   OverFeat\xef\xbc\x9a\xe5\xbd\x93\xe5\x89\x8d\xe6\x9c\x80\xe9\xab\x98\xe6\xb0\xb4\xe5\x87\x86\xe7\x9a\x84\xe9\x80\x9a\xe7\x94\xa8\xe5\xaf\x86\xe5\xba\xa6\xe7\x89\xb9\xe5\xbe\x81\xe6\x8f\x90\xe5\x8f\x96\xe5\x99\xa8\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/sermanet/OverFeat)\n*   Numeric Lua\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](http://numlua.luaforge.net/)\xe3\x80\x82\n*   Lunatic Python\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](http://labix.org/lunatic-python)\xe3\x80\x82\n*   SciLua\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](http://www.scilua.org/)\xe3\x80\x82\n*   Lua - Numerical Algorithms\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](https://bitbucket.org/lucashnegri/lna)\xe3\x80\x82\n*   Lunum\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](http://zrake.webfactional.com/projects/lunum)\xe3\x80\x82\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning#demos-and-scripts)\xe6\xbc\x94\xe7\xa4\xba\xe5\x8f\x8a\xe8\x84\x9a\xe6\x9c\xac\n\n*   Core torch7 demos repository\xef\xbc\x9a\xe6\xa0\xb8\xe5\xbf\x83torch7\xe6\xbc\x94\xe7\xa4\xba\xe7\xa8\x8b\xe5\xba\x8f\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/e-lab/torch7-demos)\n    *   \xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe3\x80\x81\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92\n    *   \xe4\xba\xba\xe8\x84\xb8\xe6\xa3\x80\xe6\xb5\x8b\xef\xbc\x88\xe8\xae\xad\xe7\xbb\x83\xe5\x92\x8c\xe6\xa3\x80\xe6\xb5\x8b\xe6\x98\xaf\xe7\x8b\xac\xe7\xab\x8b\xe7\x9a\x84\xe6\xbc\x94\xe7\xa4\xba\xef\xbc\x89\n    *   \xe5\x9f\xba\xe4\xba\x8emst\xe7\x9a\x84\xe6\x96\xad\xe8\xaf\x8d\xe5\x99\xa8\n    *   train-a-digit-classifier\n    *   train-autoencoder\n    *   optical flow demo\n    *   train-on-housenumbers\n    *   train-on-cifar\n    *   tracking with deep nets\n    *   kinect demo\n    *   \xe6\xbb\xa4\xe6\xb3\xa2\xe5\x8f\xaf\xe8\xa7\x86\xe5\x8c\x96\n    *   saliency-networks\n*   Training a Convnet for the Galaxy-Zoo Kaggle challenge(CUDA demo)\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](https://github.com/soumith/galaxyzoo)\n*   Music Tagging\xef\xbc\x9atorch7\xe4\xb8\x8b\xe7\x9a\x84\xe9\x9f\xb3\xe4\xb9\x90\xe6\xa0\x87\xe7\xad\xbe\xe8\x84\x9a\xe6\x9c\xac\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/mbhenaff/MusicTagging)\n*   torch-datasets\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](https://github.com/rosejn/torch-datasets) \xe8\xaf\xbb\xe5\x8f\x96\xe5\x87\xa0\xe4\xb8\xaa\xe6\xb5\x81\xe8\xa1\x8c\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe8\x84\x9a\xe6\x9c\xac\xef\xbc\x8c\xe5\x8c\x85\xe6\x8b\xac\n    *   BSR 500\n    *   CIFAR-10\n    *   COIL\n    *   Street View House Numbers\n    *   MNIST\n    *   NORB\n*   Atari2600\xef\xbc\x9a\xe5\x9c\xa8Arcade Learning Environment\xe6\xa8\xa1\xe6\x8b\x9f\xe5\x99\xa8\xe4\xb8\xad\xe7\x94\xa8\xe9\x9d\x99\xe6\x80\x81\xe5\xb8\xa7\xe7\x94\x9f\xe6\x88\x90\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe8\x84\x9a\xe6\x9c\xac\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/fidlej/aledataset)\n\n## Matlab\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#computer-vision)\xe8\xae\xa1\xe7\xae\x97\xe6\x9c\xba\xe8\xa7\x86\xe8\xa7\x89\n\n*   Contourlets\xef\xbc\x9a\xe5\xae\x9e\xe7\x8e\xb0\xe8\xbd\xae\xe5\xbb\x93\xe6\xb3\xa2\xe5\x8f\x98\xe6\x8d\xa2\xe5\x8f\x8a\xe5\x85\xb6\xe4\xbd\xbf\xe7\x94\xa8\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84MATLAB\xe6\xba\x90\xe4\xbb\xa3\xe7\xa0\x81\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://www.ifp.illinois.edu/~minhdo/software/contourlet_toolbox.tar) \xe3\x80\x82\n*   Shearlets\xef\xbc\x9a\xe5\x89\xaa\xe5\x88\x87\xe6\xb3\xa2\xe5\x8f\x98\xe6\x8d\xa2\xe7\x9a\x84MATLAB\xe6\xba\x90\xe7\xa0\x81\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://www.shearlab.org/index_software.html)\n*   Curvelets\xef\xbc\x9aCurvelet\xe5\x8f\x98\xe6\x8d\xa2\xe7\x9a\x84MATLAB\xe6\xba\x90\xe7\xa0\x81\xef\xbc\x88Curvelet\xe5\x8f\x98\xe6\x8d\xa2\xe6\x98\xaf\xe5\xaf\xb9\xe5\xb0\x8f\xe6\xb3\xa2\xe5\x8f\x98\xe6\x8d\xa2\xe5\x90\x91\xe6\x9b\xb4\xe9\xab\x98\xe7\xbb\xb4\xe7\x9a\x84\xe6\x8e\xa8\xe5\xb9\xbf\xef\xbc\x8c\xe7\x94\xa8\xe6\x9d\xa5\xe5\x9c\xa8\xe4\xb8\x8d\xe5\x90\x8c\xe5\xb0\xba\xe5\xba\xa6\xe8\xa7\x92\xe5\xba\xa6\xe8\xa1\xa8\xe7\xa4\xba\xe5\x9b\xbe\xe5\x83\x8f\xef\xbc\x89\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://www.curvelet.org/software.html)\n*   Bandlets\xef\xbc\x9aBandlets\xe5\x8f\x98\xe6\x8d\xa2\xe7\x9a\x84MATLAB\xe6\xba\x90\xe7\xa0\x81\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://www.cmap.polytechnique.fr/~peyre/download/)\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#natural-language-processing-4)\xe8\x87\xaa\xe7\x84\xb6\xe8\xaf\xad\xe8\xa8\x80\xe5\xa4\x84\xe7\x90\x86\n\n*   NLP\xef\xbc\x9a\xe4\xb8\x80\xe4\xb8\xaaMatlab\xe7\x9a\x84NLP\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://amplab.cs.berkeley.edu/2012/05/05/an-nlp-library-for-matlab/)\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#general-purpose-machine-learning-6)\xe9\x80\x9a\xe7\x94\xa8\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\n\n*   Training a deep autoencoder or a classifier on MNIST digits\xef\xbc\x9a\xe5\x9c\xa8MNIST\xe5\xad\x97\xe7\xac\xa6\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe4\xb8\x8a\xe8\xae\xad\xe7\xbb\x83\xe4\xb8\x80\xe4\xb8\xaa\xe6\xb7\xb1\xe5\xba\xa6\xe7\x9a\x84autoencoder\xe6\x88\x96\xe5\x88\x86\xe7\xb1\xbb\xe5\x99\xa8\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://www.cs.toronto.edu/~hinton/MatlabForSciencePaper.html)\n*   t-Distributed Stochastic Neighbor Embedding\xef\xbc\x9a\xe8\x8e\xb7\xe5\xa5\x96\xe7\x9a\x84\xe9\x99\x8d\xe7\xbb\xb4\xe6\x8a\x80\xe6\x9c\xaf\xef\xbc\x8c\xe7\x89\xb9\xe5\x88\xab\xe9\x80\x82\xe5\x90\x88\xe4\xba\x8e\xe9\xab\x98\xe7\xbb\xb4\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe5\x8f\xaf\xe8\xa7\x86\xe5\x8c\x96\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://homepage.tudelft.nl/19j49/t-SNE.html)\n*   Spider\xef\xbc\x9aMatlab\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9a\x84\xe5\xae\x8c\xe6\x95\xb4\xe9\x9d\xa2\xe5\x90\x91\xe5\xaf\xb9\xe8\xb1\xa1\xe7\x8e\xaf\xe5\xa2\x83\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://people.kyb.tuebingen.mpg.de/spider/)\n*   LibSVM\xef\xbc\x9a\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba\xe7\xa8\x8b\xe5\xba\x8f\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://www.csie.ntu.edu.tw/~cjlin/libsvm/#matlab)\n*   LibLinear\xef\xbc\x9a\xe5\xa4\xa7\xe5\x9e\x8b\xe7\xba\xbf\xe6\x80\xa7\xe5\x88\x86\xe7\xb1\xbb\xe7\xa8\x8b\xe5\xba\x8f\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://www.csie.ntu.edu.tw/~cjlin/liblinear/#download)\n*   Machine Learning Module\xef\xbc\x9aM. A .Girolami\xe6\x95\x99\xe6\x8e\x88\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xaf\xbe\xe7\xa8\x8b\xef\xbc\x8c\xe5\x8c\x85\xe6\x8b\xacPDF\xe3\x80\x81\xe8\xae\xb2\xe4\xb9\x89\xe5\x8f\x8a\xe4\xbb\xa3\xe7\xa0\x81\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/josephmisiti/machine-learning-module) \n*   Caffe\xef\xbc\x9a\xe8\x80\x83\xe8\x99\x91\xe4\xba\x86\xe4\xbb\xa3\xe7\xa0\x81\xe6\xb8\x85\xe6\xb4\x81\xe3\x80\x81\xe5\x8f\xaf\xe8\xaf\xbb\xe6\x80\xa7\xe5\x8f\x8a\xe9\x80\x9f\xe5\xba\xa6\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe6\xa1\x86\xe6\x9e\xb6\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://caffe.berkeleyvision.org/)\n*   Pattern Recognition Toolbox\xef\xbc\x9aMatlab\xe4\xb8\xad\xe7\x9a\x84\xe6\xa8\xa1\xe5\xbc\x8f\xe8\xaf\x86\xe5\x88\xab\xe5\xb7\xa5\xe5\x85\xb7\xe5\x8c\x85\xe3\x80\x81\xe5\xae\x8c\xe5\x85\xa8\xe9\x9d\xa2\xe5\x90\x91\xe5\xaf\xb9\xe8\xb1\xa1\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/newfolder/PRT)\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#data-analysis--data-visualization-4)\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe6\x9e\x90/\xe6\x95\xb0\xe6\x8d\xae\xe5\x8f\xaf\xe8\xa7\x86\xe5\x8c\x96\n\n*   matlab_gbl\xef\xbc\x9a\xe5\xa4\x84\xe7\x90\x86\xe5\x9b\xbe\xe5\x83\x8f\xe7\x9a\x84Matlab\xe5\x8c\x85\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://www.cs.purdue.edu/homes/dgleich/packages/matlab_bgl/)\n*   gamic\xef\xbc\x9a\xe5\x9b\xbe\xe5\x83\x8f\xe7\xae\x97\xe6\xb3\x95\xe7\xba\xafMatlab\xe9\xab\x98\xe6\x95\x88\xe5\xae\x9e\xe7\x8e\xb0\xef\xbc\x8c\xe5\xaf\xb9MatlabBGL\xe7\x9a\x84mex\xe5\x87\xbd\xe6\x95\xb0\xe6\x98\xaf\xe4\xb8\xaa\xe8\xa1\xa5\xe5\x85\x85\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://www.mathworks.com/matlabcentral/fileexchange/24134-gaimc---graph-algorithms-in-matlab-code)\n\n## [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#python)\n\n## .NET\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning#computer-vision-3)\xe8\xae\xa1\xe7\xae\x97\xe6\x9c\xba\xe8\xa7\x86\xe8\xa7\x89\n\n*   OpenCVDotNet\xef\xbc\x9a\xe5\x8c\x85\xe8\xa3\x85\xe5\x99\xa8\xef\xbc\x8c\xe4\xbd\xbf.NET\xe7\xa8\x8b\xe5\xba\x8f\xe8\x83\xbd\xe4\xbd\xbf\xe7\x94\xa8OpenCV\xe4\xbb\xa3\xe7\xa0\x81\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://code.google.com/p/opencvdotnet/)\n*   Emgu CV\xef\xbc\x9a\xe8\xb7\xa8\xe5\xb9\xb3\xe5\x8f\xb0\xe7\x9a\x84\xe5\x8c\x85\xe8\xa3\x85\xe5\x99\xa8\xef\xbc\x8c\xe8\x83\xbd\xe5\x9c\xa8Windows\xe3\x80\x81Linux\xe3\x80\x81Mac OS X\xe3\x80\x81iOS\xe5\x92\x8cAndroid\xe4\xb8\x8a\xe7\xbc\x96\xe8\xaf\x91\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://www.emgu.com/wiki/index.php/Main_Page)\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning#natural-language-processing-6)\xe8\x87\xaa\xe7\x84\xb6\xe8\xaf\xad\xe8\xa8\x80\xe5\xa4\x84\xe7\x90\x86\n\n*   Stanford.NLP for .NET\xef\xbc\x9a\xe6\x96\xaf\xe5\x9d\xa6\xe7\xa6\x8f\xe5\xa4\xa7\xe5\xad\xa6NLP\xe5\x8c\x85\xe5\x9c\xa8.NET\xe4\xb8\x8a\xe7\x9a\x84\xe5\xae\x8c\xe5\x85\xa8\xe7\xa7\xbb\xe6\xa4\x8d\xef\xbc\x8c\xe8\xbf\x98\xe5\x8f\xaf\xe4\xbd\x9c\xe4\xb8\xbaNuGet\xe5\x8c\x85\xe8\xbf\x9b\xe8\xa1\x8c\xe9\xa2\x84\xe7\xbc\x96\xe8\xaf\x91\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/sergey-tihon/Stanford.NLP.NET/) \xe3\x80\x82\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning#general-purpose-machine-learning-9)\xe9\x80\x9a\xe7\x94\xa8\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\n\n*   Accord.MachineLearning\xef\xbc\x9a\xe9\x9a\x8f\xe6\x9c\xba\xe6\x8a\xbd\xe6\xa0\xb7\xe4\xb8\x80\xe8\x87\xb4\xe6\x80\xa7\xe7\xae\x97\xe6\xb3\x95\xe3\x80\x81\xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe7\xbd\x91\xe6\xa0\xbc\xe6\x90\x9c\xe7\xb4\xa2\xe8\xbf\x99\xe4\xb8\xaa\xe5\x8c\x85\xe6\x98\xafAccord.NET\xe6\xa1\x86\xe6\x9e\xb6\xe7\x9a\x84\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba\xe3\x80\x81\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe3\x80\x81\xe6\x9c\xb4\xe7\xb4\xa0\xe8\xb4\x9d\xe5\x8f\xb6\xe6\x96\xaf\xe6\xa8\xa1\xe3\x80\x82\xe5\x9e\x8b\xe3\x80\x81K-means\xe3\x80\x81\xe9\xab\x98\xe6\x96\xaf\xe6\xb7\xb7\xe5\x90\x88\xe6\xa8\xa1\xe5\x9e\x8b\xe5\x92\x8c\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xba\x94\xe7\x94\xa8\xe7\x9a\x84\xe9\x80\x9a\xe7\x94\xa8\xe7\xae\x97\xe6\xb3\x95\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://www.nuget.org/packages/Accord.MachineLearning/)\xef\xbc\x9a\n*   Vulpes\xef\xbc\x9aF#\xe8\xaf\xad\xe8\xa8\x80\xe5\xae\x9e\xe7\x8e\xb0\xe7\x9a\x84Deep belief\xe5\x92\x8c\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe5\x8c\x85\xef\xbc\x8c\xe5\xae\x83\xe5\x9c\xa8Alea.cuBase\xe4\xb8\x8b\xe5\x88\xa9\xe7\x94\xa8CUDA GPU\xe6\x9d\xa5\xe6\x89\xa7\xe8\xa1\x8c\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/fsprojects/Vulpes)\n*   Encog\xef\xbc\x9a\xe5\x85\x88\xe8\xbf\x9b\xe7\x9a\x84\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe5\x92\x8c\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\xa1\x86\xe6\x9e\xb6\xef\xbc\x8c\xe5\x8c\x85\xe6\x8b\xac\xe7\x94\xa8\xe6\x9d\xa5\xe5\x88\x9b\xe5\xbb\xba\xe5\xa4\x9a\xe7\xa7\x8d\xe7\xbd\x91\xe7\xbb\x9c\xe7\x9a\x84\xe7\xb1\xbb\xef\xbc\x8c\xe4\xb9\x9f\xe6\x94\xaf\xe3\x80\x82\xe6\x8c\x81\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe9\x9c\x80\xe8\xa6\x81\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe8\xa7\x84\xe5\x88\x99\xe5\x8c\x96\xe5\x8f\x8a\xe5\xa4\x84\xe7\x90\x86\xe7\x9a\x84\xe7\xb1\xbb\xe5\xae\x83\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\xe9\x87\x87\xe7\x94\xa8\xe5\xa4\x9a\xe7\xba\xbf\xe7\xa8\x8b\xe5\xbc\xb9\xe6\x80\xa7\xe4\xbc\xa0\xe6\x92\xad\xe3\x80\x82\xe5\xae\x83\xe4\xb9\x9f\xe8\x83\xbd\xe4\xbd\xbf\xe7\x94\xa8GPU\xe5\x8a\xa0\xe5\xbf\xab\xe5\xa4\x84\xe7\x90\x86\xe6\x97\xb6\xe9\x97\xb4\xe6\x8f\x90\xe4\xbe\x9b\xe4\xba\x86\xe5\x9b\xbe\xe5\xbd\xa2\xe5\x8c\x96\xe7\x95\x8c\xe9\x9d\xa2\xe6\x9d\xa5\xe5\xb8\xae\xe5\x8a\xa9\xe5\xbb\xba\xe6\xa8\xa1\xe5\x92\x8c\xe8\xae\xad\xe7\xbb\x83\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://www.nuget.org/packages/encog-dotnet-core/)\n*   Neural Network Designer\xef\xbc\x9a\xe8\xbf\x99\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe6\x95\xb0\xe6\x8d\xae\xe5\xba\x93\xe7\xae\xa1\xe7\x90\x86\xe7\xb3\xbb\xe7\xbb\x9f\xe5\x92\x8c\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe8\xae\xbe\xe8\xae\xa1\xe5\x99\xa8\xe8\xae\xbe\xe8\xae\xa1\xe5\x99\xa8\xe7\x94\xa8WPF\xe5\xbc\x80\xe5\x8f\x91\xef\xbc\x8c\xe4\xb9\x9f\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaaUI\xef\xbc\x8c\xe4\xbd\xa0\xe5\x8f\xaf\xe4\xbb\xa5\xe8\xae\xbe\xe8\xae\xa1\xe4\xbd\xa0\xe7\x9a\x84\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe3\x80\x81\xe6\x9f\xa5\xe8\xaf\xa2\xe7\xbd\x91\xe7\xbb\x9c\xe3\x80\x81\xe5\x88\x9b\xe5\xbb\xba\xe5\xb9\xb6\xe9\x85\x8d\xe7\xbd\xae\xe8\x81\x8a\xe5\xa4\xa9\xe6\x9c\xba\xe5\x99\xa8\xe4\xba\xba\xef\xbc\x8c\xe5\xae\x83\xe8\x83\xbd\xe9\x97\xae\xe9\x97\xae\xe9\xa2\x98\xef\xbc\x8c\xe5\xb9\xb6\xe4\xbb\x8e\xe4\xbd\xa0\xe7\x9a\x84\xe5\x8f\x8d\xe9\xa6\x88\xe4\xb8\xad\xe5\xad\xa6\xe4\xb9\xa0\xe8\xbf\x99\xe4\xba\x9b\xe6\x9c\xba\xe5\x99\xa8\xe4\xba\xba\xe7\x94\x9a\xe8\x87\xb3\xe5\x8f\xaf\xe4\xbb\xa5\xe4\xbb\x8e\xe7\xbd\x91\xe7\xbb\x9c\xe6\x90\x9c\xe9\x9b\x86\xe4\xbf\xa1\xe6\x81\xaf\xe7\x94\xa8\xe6\x9d\xa5\xe8\xbe\x93\xe5\x87\xba\xef\xbc\x8c\xe6\x88\x96\xe6\x98\xaf\xe7\x94\xa8\xe6\x9d\xa5\xe5\xad\xa6\xe4\xb9\xa0\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://bragisoft.com/)\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning#data-analysis--data-visualization-6)\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe6\x9e\x90/\xe6\x95\xb0\xe6\x8d\xae\xe5\x8f\xaf\xe8\xa7\x86\xe5\x8c\x96\n\n*   numl\xef\xbc\x9anuml\xe8\xbf\x99\xe4\xb8\xaa\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xba\x93\xef\xbc\x8c\xe7\x9b\xae\xe6\xa0\x87\xe5\xb0\xb1\xe6\x98\xaf\xe7\xae\x80\xe5\x8c\x96\xe9\xa2\x84\xe6\xb5\x8b\xe5\x92\x8c\xe8\x81\x9a\xe7\xb1\xbb\xe7\x9a\x84\xe6\xa0\x87\xe5\x87\x86\xe5\xbb\xba\xe6\xa8\xa1\xe6\x8a\x80\xe6\x9c\xaf\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://www.nuget.org/packages/numl/)\n*   Math.NET Numerics\xef\xbc\x9aMath.NET\xe9\xa1\xb9\xe7\x9b\xae\xe7\x9a\x84\xe6\x95\xb0\xe5\x80\xbc\xe8\xae\xa1\xe7\xae\x97\xe5\x9f\xba\xe7\xa1\x80\xef\xbc\x8c\xe7\x9d\x80\xe7\x9c\xbc\xe6\x8f\x90\xe4\xbe\x9b\xe7\xa7\x91\xe5\xad\xa6\xe3\x80\x81\xe5\xb7\xa5\xe7\xa8\x8b\xe4\xbb\xa5\xe5\x8f\x8a\xe6\x97\xa5\xe5\xb8\xb8\xe6\x95\xb0\xe5\x80\xbc\xe8\xae\xa1\xe7\xae\x97\xe7\x9a\x84\xe6\x96\xb9\xe6\xb3\x95\xe5\x92\x8c\xe7\xae\x97\xe6\xb3\x95\xe6\x94\xaf\xe6\x8c\x81 Windows\xe3\x80\x81Linux \xe5\x92\x8c \xe3\x80\x82Mac\xe4\xb8\x8a\xe7\x9a\x84 .Net 4.0\xe3\x80\x81.Net 3.5 \xe5\x92\x8c Mono \xef\xbc\x8cSilverlight 5\xe3\x80\x81WindowsPhone/SL 8\xe3\x80\x81WindowsPhone 8.1 \xe4\xbb\xa5\xe5\x8f\x8a\xe8\xa3\x85\xe6\x9c\x89 PCL Portable Profiles 47 \xe5\x8f\x8a 344\xe7\x9a\x84Windows 8\xef\xbc\x8c \xe8\xa3\x85\xe6\x9c\x89 Xamarin\xe7\x9a\x84Android/iOS\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://www.nuget.org/packages/MathNet.Numerics/)\n*   Sho\xef\xbc\x9aSho\xe6\x98\xaf\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe6\x9e\x90\xe5\x92\x8c\xe7\xa7\x91\xe5\xad\xa6\xe8\xae\xa1\xe7\xae\x97\xe7\x9a\x84\xe4\xba\xa4\xe4\xba\x92\xe5\xbc\x8f\xe7\x8e\xaf\xe5\xa2\x83\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe8\xae\xa9\xe4\xbd\xa0\xe5\xb0\x86\xe8\x84\x9a\xe6\x9c\xac\xef\xbc\x88IronPython\xe8\xaf\xad\xe8\xa8\x80\xef\xbc\x89\xe5\x92\x8c\xe7\xbc\x96\xe8\xaf\x91\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x88.NET\xef\xbc\x89\xe6\x97\xa0\xe7\xbc\x9d\xe8\xbf\x9e\xe6\x8e\xa5\xef\xbc\x8c\xe4\xbb\xa5\xe5\xbf\xab\xe9\x80\x9f\xe7\x81\xb5\xe6\xb4\xbb\xe7\x9a\x84\xe5\xbb\xba\xe7\xab\x8b\xe5\x8e\x9f\xe5\x9e\x8b\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://research.microsoft.com/en-us/projects/sho/)\xe8\xbf\x99\xe4\xb8\xaa\xe7\x8e\xaf\xe5\xa2\x83\xe5\x8c\x85\xe6\x8b\xac\xe5\xbc\xba\xe5\xa4\xa7\xe9\xab\x98\xe6\x95\x88\xe7\x9a\x84\xe5\xba\x93\xef\xbc\x8c\xe5\xa6\x82\xe7\xba\xbf\xe6\x80\xa7\xe4\xbb\xa3\xe6\x95\xb0\xe3\x80\x81\xe6\x95\xb0\xe6\x8d\xae\xe5\x8f\xaf\xe8\xa7\x86\xe5\x8c\x96\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbe\x9b\xe4\xbb\xbb\xe4\xbd\x95.NET\xe8\xaf\xad\xe8\xa8\x80\xe4\xbd\xbf\xe7\x94\xa8\xef\xbc\x8c\xe8\xbf\x98\xe4\xb8\xba\xe5\xbf\xab\xe9\x80\x9f\xe5\xbc\x80\xe5\x8f\x91\xe6\x8f\x90\xe4\xbe\x9b\xe4\xba\x86\xe5\x8a\x9f\xe8\x83\xbd\xe4\xb8\xb0\xe5\xaf\x8c\xe7\x9a\x84\xe4\xba\xa4\xe4\xba\x92\xe5\xbc\x8fshell\n\n## Python\n\n#### \xe8\xae\xa1\xe7\xae\x97\xe6\x9c\xba\xe8\xa7\x86\xe8\xa7\x89\n\n*   [SimpleCV](http://hao.importnew.com/simplecv/)\xef\xbc\x9a\xe5\xbc\x80\xe6\xba\x90\xe8\xae\xa1\xe7\xae\x97\xe6\x9c\xba\xe8\xa7\x86\xe8\xa7\x89\xe6\xa1\x86\xe6\x9e\xb6\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe8\xae\xbf\xe9\x97\xae\xe5\xa6\x82OpenCV\xe7\xad\x89\xe9\xab\x98\xe6\x80\xa7\xe8\x83\xbd\xe8\xae\xa1\xe7\xae\x97\xe6\x9c\xba\xe8\xa7\x86\xe8\xa7\x89\xe5\xba\x93\xe4\xbd\xbf\xe7\x94\xa8Python\xe7\xbc\x96\xe5\x86\x99\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe5\x9c\xa8Mac\xe3\x80\x81Windows\xe4\xbb\xa5\xe5\x8f\x8aUbuntu\xe4\xb8\x8a\xe8\xbf\x90\xe8\xa1\x8c\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://simplecv.org/)\xe3\x80\x82\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#natural-language-processing-5)\xe8\x87\xaa\xe7\x84\xb6\xe8\xaf\xad\xe8\xa8\x80\xe5\xa4\x84\xe7\x90\x86\n\n*   NLTK\xef\xbc\x9a\xe4\xb8\x80\xe4\xb8\xaa\xe9\xa2\x86\xe5\x85\x88\xe7\x9a\x84\xe5\xb9\xb3\xe5\x8f\xb0\xef\xbc\x8c\xe7\x94\xa8\xe6\x9d\xa5\xe7\xbc\x96\xe5\x86\x99\xe5\xa4\x84\xe7\x90\x86\xe4\xba\xba\xe7\xb1\xbb\xe8\xaf\xad\xe8\xa8\x80\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84Python\xe7\xa8\x8b\xe5\xba\x8f\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://www.nltk.org/)\n*   Pattern\xef\xbc\x9aPython\xe5\x8f\xaf\xe7\x94\xa8\xe7\x9a\x84web\xe6\x8c\x96\xe6\x8e\x98\xe6\xa8\xa1\xe5\x9d\x97\xef\xbc\x8c\xe5\x8c\x85\xe6\x8b\xac\xe8\x87\xaa\xe7\x84\xb6\xe8\xaf\xad\xe8\xa8\x80\xe5\xa4\x84\xe7\x90\x86\xe3\x80\x81\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xad\x89\xe5\xb7\xa5\xe5\x85\xb7\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://www.clips.ua.ac.be/pattern)\n*   TextBlob\xef\xbc\x9a\xe4\xb8\xba\xe6\x99\xae\xe9\x80\x9a\xe8\x87\xaa\xe7\x84\xb6\xe8\xaf\xad\xe8\xa8\x80\xe5\xa4\x84\xe7\x90\x86\xe4\xbb\xbb\xe5\x8a\xa1\xe6\x8f\x90\xe4\xbe\x9b\xe4\xb8\x80\xe8\x87\xb4\xe7\x9a\x84API\xef\xbc\x8c\xe4\xbb\xa5NLTK\xe5\x92\x8cPattern\xe4\xb8\xba\xe5\x9f\xba\xe7\xa1\x80\xef\xbc\x8c\xe5\xb9\xb6\xe5\x92\x8c\xe4\xb8\xa4\xe8\x80\x85\xe9\x83\xbd\xe8\x83\xbd\xe5\xbe\x88\xe5\xa5\xbd\xe5\x85\xbc\xe5\xae\xb9\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://textblob.readthedocs.org/)\xe3\x80\x82\n*   jieba\xef\xbc\x9a\xe4\xb8\xad\xe6\x96\x87\xe6\x96\xad\xe8\xaf\x8d\xe5\xb7\xa5\xe5\x85\xb7\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/fxsjy/jieba#jieba-1)\n*   SnowNLP\xef\xbc\x9a\xe4\xb8\xad\xe6\x96\x87\xe6\x96\x87\xe6\x9c\xac\xe5\xa4\x84\xe7\x90\x86\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/isnowfy/snownlp)\n*   loso\xef\xbc\x9a\xe5\x8f\xa6\xe4\xb8\x80\xe4\xb8\xaa\xe4\xb8\xad\xe6\x96\x87\xe6\x96\xad\xe8\xaf\x8d\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/victorlin/loso)\n*   genius\xef\xbc\x9a\xe5\x9f\xba\xe4\xba\x8e\xe6\x9d\xa1\xe4\xbb\xb6\xe9\x9a\x8f\xe6\x9c\xba\xe5\x9f\x9f\xe7\x9a\x84\xe4\xb8\xad\xe6\x96\x87\xe6\x96\xad\xe8\xaf\x8d\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/duanhongyi/genius)\n*   nut\xef\xbc\x9a\xe8\x87\xaa\xe7\x84\xb6\xe8\xaf\xad\xe8\xa8\x80\xe7\x90\x86\xe8\xa7\xa3\xe5\xb7\xa5\xe5\x85\xb7\xe5\x8c\x85\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/pprett/nut)\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#general-purpose-machine-learning-7)\xe9\x80\x9a\xe7\x94\xa8\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\n\n*   Bayesian Methods for Hackers\xef\xbc\x9aPython\xe8\xaf\xad\xe8\xa8\x80\xe6\xa6\x82\xe7\x8e\x87\xe8\xa7\x84\xe5\x88\x92\xe7\x9a\x84\xe7\x94\xb5\xe5\xad\x90\xe4\xb9\xa6\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/CamDavidsonPilon/\xe3\x80\x82Probabilistic-Programming-and-Bayesian-Methods-for-Hackers)\n*   MLlib in Apache Spark\xef\xbc\x9aSpark\xe4\xb8\x8b\xe7\x9a\x84\xe5\x88\x86\xe5\xb8\x83\xe5\xbc\x8f\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://spark.apache.org/docs/latest/mllib-guide.html)\n*   scikit-learn\xef\xbc\x9a\xe5\x9f\xba\xe4\xba\x8eSciPy\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\xa8\xa1\xe5\x9d\x97\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://scikit-learn.org/)\n*   graphlab-create\xef\xbc\x9a\xe5\x8c\x85\xe5\x90\xab\xe5\xa4\x9a\xe7\xa7\x8d\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\xa8\xa1\xe5\x9d\x97\xe7\x9a\x84\xe5\xba\x93\xef\xbc\x88\xe5\x9b\x9e\xe5\xbd\x92\xe3\x80\x81\xe8\x81\x9a\xe7\xb1\xbb\xe3\x80\x81\xe6\x8e\xa8\xe8\x8d\x90\xe7\xb3\xbb\xe7\xbb\x9f\xe3\x80\x81\xe5\x9b\xbe\xe5\x88\x86\xe6\x9e\x90\xe7\xad\x89\xef\xbc\x89\xef\xbc\x8c\xe5\x9f\xba\xe4\xba\x8e\xe5\x8f\xaf\xe4\xbb\xa5\xe7\xa3\x81\xe7\x9b\x98\xe5\xad\x98\xe5\x82\xa8\xe7\x9a\x84DataFrame\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://graphlab.com/products/create/docs/)\n*   BigML\xef\xbc\x9a\xe8\xbf\x9e\xe6\x8e\xa5\xe5\xa4\x96\xe9\x83\xa8\xe6\x9c\x8d\xe5\x8a\xa1\xe5\x99\xa8\xe7\x9a\x84\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://bigml.com/)\n*   pattern\xef\xbc\x9aPython\xe7\x9a\x84web\xe6\x8c\x96\xe6\x8e\x98\xe6\xa8\xa1\xe5\x9d\x97\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/clips/pattern)\n*   NuPIC\xef\xbc\x9aNumenta\xe5\x85\xac\xe5\x8f\xb8\xe7\x9a\x84\xe6\x99\xba\xe8\x83\xbd\xe8\xae\xa1\xe7\xae\x97\xe5\xb9\xb3\xe5\x8f\xb0\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/numenta/nupic)\n*   Pylearn2\xef\xbc\x9a\xe5\x9f\xba\xe4\xba\x8eTheano\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/lisa-lab/pylearn2)\n*   hebel\xef\xbc\x9aPython\xe7\xbc\x96\xe5\x86\x99\xe7\x9a\x84\xe4\xbd\xbf\xe7\x94\xa8GPU\xe5\x8a\xa0\xe9\x80\x9f\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/hannes-brt/hebel)\n*   gensim\xef\xbc\x9a\xe4\xb8\xbb\xe9\xa2\x98\xe5\xbb\xba\xe6\xa8\xa1\xe5\xb7\xa5\xe5\x85\xb7\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/piskvorky/gensim)\n*   PyBrain\xef\xbc\x9a\xe5\x8f\xa6\xe4\xb8\x80\xe4\xb8\xaa\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/pybrain/pybrain)\n*   Crab\xef\xbc\x9a\xe5\x8f\xaf\xe6\x89\xa9\xe5\xb1\x95\xe7\x9a\x84\xe3\x80\x81\xe5\xbf\xab\xe9\x80\x9f\xe6\x8e\xa8\xe8\x8d\x90\xe5\xbc\x95\xe6\x93\x8e\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/muricoca/crab)\n*   python-recsys\xef\xbc\x9aPython\xe5\xae\x9e\xe7\x8e\xb0\xe7\x9a\x84\xe6\x8e\xa8\xe8\x8d\x90\xe7\xb3\xbb\xe7\xbb\x9f\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/ocelma/python-recsys)\n*   thinking bayes\xef\xbc\x9a\xe5\x85\xb3\xe4\xba\x8e\xe8\xb4\x9d\xe5\x8f\xb6\xe6\x96\xaf\xe5\x88\x86\xe6\x9e\x90\xe7\x9a\x84\xe4\xb9\xa6\xe7\xb1\x8d\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/AllenDowney/ThinkBayes)\n*   Restricted Boltzmann Machines\xef\xbc\x9aPython\xe5\xae\x9e\xe7\x8e\xb0\xe7\x9a\x84\xe5\x8f\x97\xe9\x99\x90\xe6\xb3\xa2\xe5\xb0\x94\xe5\x85\xb9\xe6\x9b\xbc\xe6\x9c\xba\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/echen/restricted-boltzmann-machines)\n*   Bolt\xef\xbc\x9a\xe5\x9c\xa8\xe7\xba\xbf\xe5\xad\xa6\xe4\xb9\xa0\xe5\xb7\xa5\xe5\x85\xb7\xe7\xae\xb1\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/pprett/bolt)\n*   CoverTree\xef\xbc\x9acover tree\xe7\x9a\x84Python\xe5\xae\x9e\xe7\x8e\xb0\xef\xbc\x8cscipy.spatial.kdtree\xe4\xbe\xbf\xe6\x8d\xb7\xe7\x9a\x84\xe6\x9b\xbf\xe4\xbb\xa3\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/patvarilly/CoverTree)\n*   nilearn\xef\xbc\x9aPython\xe5\xae\x9e\xe7\x8e\xb0\xe7\x9a\x84\xe7\xa5\x9e\xe7\xbb\x8f\xe5\xbd\xb1\xe5\x83\x8f\xe5\xad\xa6\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/nilearn/nilearn)\n*   Shogun\xef\xbc\x9a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xb7\xa5\xe5\x85\xb7\xe7\xae\xb1\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/shogun-toolbox/shogun)\n*   Pyevolve\xef\xbc\x9a\xe9\x81\x97\xe4\xbc\xa0\xe7\xae\x97\xe6\xb3\x95\xe6\xa1\x86\xe6\x9e\xb6\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/perone/Pyevolve)\n*   Caffe\xef\xbc\x9a\xe8\x80\x83\xe8\x99\x91\xe4\xba\x86\xe4\xbb\xa3\xe7\xa0\x81\xe6\xb8\x85\xe6\xb4\x81\xe3\x80\x81\xe5\x8f\xaf\xe8\xaf\xbb\xe6\x80\xa7\xe5\x8f\x8a\xe9\x80\x9f\xe5\xba\xa6\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe6\xa1\x86\xe6\x9e\xb6\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://caffe.berkeleyvision.org/)\n*   breze\xef\xbc\x9a\xe6\xb7\xb1\xe5\xba\xa6\xe5\x8f\x8a\xe9\x80\x92\xe5\xbd\x92\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe7\x9a\x84\xe7\xa8\x8b\xe5\xba\x8f\xe5\xba\x93\xef\xbc\x8c\xe5\x9f\xba\xe4\xba\x8eTheano\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/breze-no-salt/breze)\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#data-analysis--data-visualization-5)\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe6\x9e\x90/\xe6\x95\xb0\xe6\x8d\xae\xe5\x8f\xaf\xe8\xa7\x86\xe5\x8c\x96\n\n*   SciPy\xef\xbc\x9a\xe5\x9f\xba\xe4\xba\x8ePython\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\xa6\xe3\x80\x81\xe7\xa7\x91\xe5\xad\xa6\xe3\x80\x81\xe5\xb7\xa5\xe7\xa8\x8b\xe5\xbc\x80\xe6\xba\x90\xe8\xbd\xaf\xe4\xbb\xb6\xe7\x94\x9f\xe6\x80\x81\xe7\xb3\xbb\xe7\xbb\x9f\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://www.scipy.org/)\n*   NumPy\xef\xbc\x9aPython\xe7\xa7\x91\xe5\xad\xa6\xe8\xae\xa1\xe7\xae\x97\xe5\x9f\xba\xe7\xa1\x80\xe5\x8c\x85\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://www.numpy.org/)\n*   Numba\xef\xbc\x9aPython\xe7\x9a\x84\xe4\xbd\x8e\xe7\xba\xa7\xe8\x99\x9a\xe6\x8b\x9f\xe6\x9c\xbaJIT\xe7\xbc\x96\xe8\xaf\x91\xe5\x99\xa8\xef\xbc\x8cCython and NumPy\xe7\x9a\x84\xe5\xbc\x80\xe5\x8f\x91\xe8\x80\x85\xe7\xbc\x96\xe5\x86\x99\xef\xbc\x8c\xe4\xbe\x9b\xe7\xa7\x91\xe5\xad\xa6\xe8\xae\xa1\xe7\xae\x97\xe4\xbd\xbf\xe7\x94\xa8\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://numba.pydata.org/)\n*   NetworkX\xef\xbc\x9a\xe4\xb8\xba\xe5\xa4\x8d\xe6\x9d\x82\xe7\xbd\x91\xe7\xbb\x9c\xe4\xbd\xbf\xe7\x94\xa8\xe7\x9a\x84\xe9\xab\x98\xe6\x95\x88\xe8\xbd\xaf\xe4\xbb\xb6\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://networkx.github.io/)\n*   Pandas\xef\xbc\x9a\xe8\xbf\x99\xe4\xb8\xaa\xe5\xba\x93\xe6\x8f\x90\xe4\xbe\x9b\xe4\xba\x86\xe9\xab\x98\xe6\x80\xa7\xe8\x83\xbd\xe3\x80\x81\xe6\x98\x93\xe7\x94\xa8\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\xe5\x8f\x8a\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe6\x9e\x90\xe5\xb7\xa5\xe5\x85\xb7\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://pandas.pydata.org/)\n*   [Open Mining](http://hao.importnew.com/open-mining/)\xef\xbc\x9aPython\xe4\xb8\xad\xe7\x9a\x84\xe5\x95\x86\xe4\xb8\x9a\xe6\x99\xba\xe8\x83\xbd\xe5\xb7\xa5\xe5\x85\xb7\xef\xbc\x88Pandas web\xe6\x8e\xa5\xe5\x8f\xa3\xef\xbc\x89\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/avelino/mining)\n*   [PyMC](http://hao.importnew.com/pymc/)\xef\xbc\x9aMCMC\xe9\x87\x87\xe6\xa0\xb7\xe5\xb7\xa5\xe5\x85\xb7\xe5\x8c\x85\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/pymc-devs/pymc)\n*   zipline\xef\xbc\x9aPython\xe7\x9a\x84\xe7\xae\x97\xe6\xb3\x95\xe4\xba\xa4\xe6\x98\x93\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/quantopian/zipline)\n*   PyDy\xef\xbc\x9a\xe5\x85\xa8\xe5\x90\x8dPython Dynamics\xef\xbc\x8c\xe5\x8d\x8f\xe5\x8a\xa9\xe5\x9f\xba\xe4\xba\x8eNumPy\xe3\x80\x81SciPy\xe3\x80\x81IPython\xe4\xbb\xa5\xe5\x8f\x8a matplotlib\xe7\x9a\x84\xe5\x8a\xa8\xe6\x80\x81\xe5\xbb\xba\xe6\xa8\xa1\xe5\xb7\xa5\xe4\xbd\x9c\xe6\xb5\x81\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://pydy.org/)\n*   SymPy\xef\xbc\x9a\xe7\xac\xa6\xe5\x8f\xb7\xe6\x95\xb0\xe5\xad\xa6Python\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/sympy/sympy)\n*   statsmodels\xef\xbc\x9aPython\xe7\x9a\x84\xe7\xbb\x9f\xe8\xae\xa1\xe5\xbb\xba\xe6\xa8\xa1\xe5\x8f\x8a\xe8\xae\xa1\xe9\x87\x8f\xe7\xbb\x8f\xe6\xb5\x8e\xe5\xad\xa6\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/statsmodels/statsmodels)\n*   astropy\xef\xbc\x9aPython\xe5\xa4\xa9\xe6\x96\x87\xe5\xad\xa6\xe7\xa8\x8b\xe5\xba\x8f\xe5\xba\x93\xef\xbc\x8c\xe7\xa4\xbe\xe5\x8c\xba\xe5\x8d\x8f\xe4\xbd\x9c\xe7\xbc\x96\xe5\x86\x99\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://www.astropy.org/)\n*   matplotlib\xef\xbc\x9aPython\xe7\x9a\x842D\xe7\xbb\x98\xe5\x9b\xbe\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://matplotlib.org/)\n*   bokeh\xef\xbc\x9aPython\xe7\x9a\x84\xe4\xba\xa4\xe4\xba\x92\xe5\xbc\x8fWeb\xe7\xbb\x98\xe5\x9b\xbe\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/ContinuumIO/bokeh)\n*   plotly\xef\xbc\x9aPython and matplotlib\xe7\x9a\x84\xe5\x8d\x8f\xe4\xbd\x9cweb\xe7\xbb\x98\xe5\x9b\xbe\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://plot.ly/python)\n*   vincent\xef\xbc\x9a\xe5\xb0\x86Python\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\xe8\xbd\xac\xe6\x8d\xa2\xe4\xb8\xbaVega\xe5\x8f\xaf\xe8\xa7\x86\xe5\x8c\x96\xe8\xaf\xad\xe6\xb3\x95\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/wrobstory/vincent)\n*   d3py\xef\xbc\x9aPython\xe7\x9a\x84\xe7\xbb\x98\xe5\x9b\xbe\xe5\xba\x93\xef\xbc\x8c\xe5\x9f\xba\xe4\xba\x8eD3.js\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/mikedewar/d3py)\n*   ggplot\xef\xbc\x9a\xe5\x92\x8cR\xe8\xaf\xad\xe8\xa8\x80\xe9\x87\x8c\xe7\x9a\x84ggplot2\xe6\x8f\x90\xe4\xbe\x9b\xe5\x90\x8c\xe6\xa0\xb7\xe7\x9a\x84API\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/yhat/ggplot)\n*   Kartograph.py\xef\xbc\x9aPython\xe4\xb8\xad\xe6\xb8\xb2\xe6\x9f\x93SVG\xe5\x9b\xbe\xe7\x9a\x84\xe5\xba\x93\xef\xbc\x8c\xe6\x95\x88\xe6\x9e\x9c\xe6\xbc\x82\xe4\xba\xae\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/kartograph/kartograph.py)\n*   pygal\xef\xbc\x9aPython\xe4\xb8\x8b\xe7\x9a\x84SVG\xe5\x9b\xbe\xe8\xa1\xa8\xe7\x94\x9f\xe6\x88\x90\xe5\x99\xa8\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://pygal.org/)\n*   pycascading\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](https://github.com/twitter/pycascading)\n\n#### \xe6\x9d\x82\xe9\xa1\xb9\xe8\x84\x9a\xe6\x9c\xac/iPython\xe7\xac\x94\xe8\xae\xb0/\xe4\xbb\xa3\xe7\xa0\x81\xe5\xba\x93[](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#misc-scripts--ipython-notebooks--codebases)\n\n*   pattern_classification\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](https://github.com/rasbt/pattern_classification)\n*   thinking stats 2\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](https://github.com/Wavelets/ThinkStats2)\n*   hyperopt\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](https://github.com/hyperopt/hyperopt-sklearn)\n*   numpic\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](https://github.com/numenta/nupic)\n*   2012-paper-diginorm\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](https://github.com/ged-lab/2012-paper-diginorm)\n*   ipython-notebooks\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](https://github.com/ogrisel/notebooks)\n*   decision-weights\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](https://github.com/CamDavidsonPilon/decision-weights)\n*   Sarah Palin LDA\xef\xbc\x9aSarah Palin\xe5\x85\xb3\xe4\xba\x8e\xe4\xb8\xbb\xe9\xa2\x98\xe5\xbb\xba\xe6\xa8\xa1\xe7\x9a\x84\xe7\x94\xb5\xe9\x82\xae\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/Wavelets/sarah-palin-lda)\n*   Diffusion Segmentation\xef\xbc\x9a\xe5\x9f\xba\xe4\xba\x8e\xe6\x89\xa9\xe6\x95\xa3\xe6\x96\xb9\xe6\xb3\x95\xe7\x9a\x84\xe5\x9b\xbe\xe5\x83\x8f\xe5\x88\x86\xe5\x89\xb2\xe7\xae\x97\xe6\xb3\x95\xe9\x9b\x86\xe5\x90\x88\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/Wavelets/diffusion-segmentation)\n*   Scipy Tutorials\xef\xbc\x9aSciPy\xe6\x95\x99\xe7\xa8\x8b\xef\xbc\x8c\xe5\xb7\xb2\xe8\xbf\x87\xe6\x97\xb6\xef\xbc\x8c\xe8\xaf\xb7\xe6\x9f\xa5\xe7\x9c\x8bscipy-lecture-notes\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/Wavelets/scipy-tutorials)\n*   Crab\xef\xbc\x9aPython\xe7\x9a\x84\xe6\x8e\xa8\xe8\x8d\x90\xe5\xbc\x95\xe6\x93\x8e\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/marcelcaraciolo/crab)\n*   BayesPy\xef\xbc\x9aPython\xe4\xb8\xad\xe7\x9a\x84\xe8\xb4\x9d\xe5\x8f\xb6\xe6\x96\xaf\xe6\x8e\xa8\xe6\x96\xad\xe5\xb7\xa5\xe5\x85\xb7\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/maxsklar/BayesPy)\n*   scikit-learn tutorials\xef\xbc\x9ascikit-learn\xe5\xad\xa6\xe4\xb9\xa0\xe7\xac\x94\xe8\xae\xb0\xe7\xb3\xbb\xe5\x88\x97\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/GaelVaroquaux/scikit-learn-tutorial)\n*   sentiment-analyzer\xef\xbc\x9a\xe6\x8e\xa8\xe7\x89\xb9\xe6\x83\x85\xe7\xbb\xaa\xe5\x88\x86\xe6\x9e\x90\xe5\x99\xa8\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/madhusudancs/sentiment-analyzer)\n*   group-lasso\xef\xbc\x9a\xe5\x9d\x90\xe6\xa0\x87\xe4\xb8\x8b\xe9\x99\x8d\xe7\xae\x97\xe6\xb3\x95\xe5\xae\x9e\xe9\xaa\x8c\xef\xbc\x8c\xe5\xba\x94\xe7\x94\xa8\xe4\xba\x8e\xef\xbc\x88\xe7\xa8\x80\xe7\x96\x8f\xef\xbc\x89\xe7\xbe\xa4\xe5\xa5\x97\xe7\xb4\xa2\xe6\xa8\xa1\xe5\x9e\x8b\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/fabianp/group_lasso)\n*   mne-python-notebooks\xef\xbc\x9a\xe4\xbd\xbf\xe7\x94\xa8 mne-python\xe8\xbf\x9b\xe8\xa1\x8cEEG/MEG\xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\xe7\x9a\x84IPython\xe7\xac\x94\xe8\xae\xb0\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/mne-tools/mne-python-notebooks)\n*   pandas cookbook\xef\xbc\x9a\xe4\xbd\xbf\xe7\x94\xa8Python pandas\xe5\xba\x93\xe7\x9a\x84\xe6\x96\xb9\xe6\xb3\x95\xe4\xb9\xa6\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/jvns/pandas-cookbook)\n*   climin\xef\xbc\x9a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9a\x84\xe4\xbc\x98\xe5\x8c\x96\xe7\xa8\x8b\xe5\xba\x8f\xe5\xba\x93\xef\xbc\x8c\xe7\x94\xa8Python\xe5\xae\x9e\xe7\x8e\xb0\xe4\xba\x86\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xe3\x80\x81LBFGS\xe3\x80\x81rmsprop\xe3\x80\x81adadelta \xe7\xad\x89\xe7\xae\x97\xe6\xb3\x95\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/BRML/climin)\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#kaggle-competition-source-code)Kaggle\xe7\xab\x9e\xe8\xb5\x9b\xe6\xba\x90\xe4\xbb\xa3\xe7\xa0\x81\n\n*   wiki challange\xef\xbc\x9aKaggle\xe4\xb8\x8a\xe4\xb8\x80\xe4\xb8\xaa\xe7\xbb\xb4\xe5\x9f\xba\xe9\xa2\x84\xe6\xb5\x8b\xe6\x8c\x91\xe6\x88\x98\xe8\xb5\x9b Dell Zhang\xe8\xa7\xa3\xe6\xb3\x95\xe7\x9a\x84\xe5\xae\x9e\xe7\x8e\xb0\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/hammer/wikichallenge)\n*   kaggle insults\xef\xbc\x9aKaggle\xe4\xb8\x8a\xe2\x80\x9d\xe4\xbb\x8e\xe7\xa4\xbe\xe4\xba\xa4\xe5\xaa\x92\xe4\xbd\x93\xe8\xaf\x84\xe8\xae\xba\xe4\xb8\xad\xe6\xa3\x80\xe6\xb5\x8b\xe8\xbe\xb1\xe9\xaa\x82\xe2\x80\x9c\xe7\xab\x9e\xe8\xb5\x9b\xe6\x8f\x90\xe4\xba\xa4\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/amueller/kaggle_insults)\n*   kaggle_acquire-valued-shoppers-challenge\xef\xbc\x9aKaggle\xe9\xa2\x84\xe6\xb5\x8b\xe5\x9b\x9e\xe5\xa4\xb4\xe5\xae\xa2\xe6\x8c\x91\xe6\x88\x98\xe8\xb5\x9b\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/MLWave/\xe3\x80\x82kaggle_acquire-valued-shoppers-challenge)\n*   kaggle-cifar\xef\xbc\x9aKaggle\xe4\xb8\x8aCIFAR-10 \xe7\xab\x9e\xe8\xb5\x9b\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x8c\xe4\xbd\xbf\xe7\x94\xa8cuda-convnet\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/zygmuntz/kaggle-cifar)\n*   kaggle-blackbox\xef\xbc\x9aKaggle\xe4\xb8\x8ablackbox\xe8\xb5\x9b\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x8c\xe5\x85\xb3\xe4\xba\x8e\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/zygmuntz/kaggle-blackbox)\n*   kaggle-accelerometer\xef\xbc\x9aKaggle\xe4\xb8\x8a\xe5\x8a\xa0\xe9\x80\x9f\xe5\xba\xa6\xe8\xae\xa1\xe6\x95\xb0\xe6\x8d\xae\xe8\xaf\x86\xe5\x88\xab\xe7\x94\xa8\xe6\x88\xb7\xe7\xab\x9e\xe8\xb5\x9b\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/zygmuntz/kaggle-accelerometer)\n*   kaggle-advertised-salaries\xef\xbc\x9aKaggle\xe4\xb8\x8a\xe7\x94\xa8\xe5\xb9\xbf\xe5\x91\x8a\xe9\xa2\x84\xe6\xb5\x8b\xe5\xb7\xa5\xe8\xb5\x84\xe7\xab\x9e\xe8\xb5\x9b\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/zygmuntz/kaggle-advertised-salaries) \n*   kaggle amazon\xef\xbc\x9aKaggle\xe4\xb8\x8a\xe7\xbb\x99\xe5\xae\x9a\xe5\x91\x98\xe5\xb7\xa5\xe8\xa7\x92\xe8\x89\xb2\xe9\xa2\x84\xe6\xb5\x8b\xe5\x85\xb6\xe8\xae\xbf\xe9\x97\xae\xe9\x9c\x80\xe6\xb1\x82\xe7\xab\x9e\xe8\xb5\x9b\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/zygmuntz/kaggle-amazon)\n*   kaggle-bestbuy_big\xef\xbc\x9aKaggle\xe4\xb8\x8a\xe6\xa0\xb9\xe6\x8d\xaebestbuy\xe7\x94\xa8\xe6\x88\xb7\xe6\x9f\xa5\xe8\xaf\xa2\xe9\xa2\x84\xe6\xb5\x8b\xe7\x82\xb9\xe5\x87\xbb\xe5\x95\x86\xe5\x93\x81\xe7\xab\x9e\xe8\xb5\x9b\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x88\xe5\xa4\xa7\xe6\x95\xb0\xe6\x8d\xae\xe7\x89\x88\xef\xbc\x89\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/zygmuntz/kaggle-bestbuy_big)\n*   kaggle-bestbuy_small\xef\xbc\x9aKaggle\xe4\xb8\x8a\xe6\xa0\xb9\xe6\x8d\xaebestbuy\xe7\x94\xa8\xe6\x88\xb7\xe6\x9f\xa5\xe8\xaf\xa2\xe9\xa2\x84\xe6\xb5\x8b\xe7\x82\xb9\xe5\x87\xbb\xe5\x95\x86\xe5\x93\x81\xe7\xab\x9e\xe8\xb5\x9b\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x88\xe5\xb0\x8f\xe6\x95\xb0\xe6\x8d\xae\xe7\x89\x88\xef\xbc\x89\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/zygmuntz/kaggle-bestbuy_small)\n*   Kaggle Dogs vs. Cats\xef\xbc\x9aKaggle\xe4\xb8\x8a\xe4\xbb\x8e\xe5\x9b\xbe\xe7\x89\x87\xe4\xb8\xad\xe8\xaf\x86\xe5\x88\xab\xe7\x8c\xab\xe5\x92\x8c\xe7\x8b\x97\xe7\xab\x9e\xe8\xb5\x9b\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/kastnerkyle/kaggle-dogs-vs-cats)\n*   Kaggle Galaxy Challenge\xef\xbc\x9aKaggle\xe4\xb8\x8a\xe9\x81\xa5\xe8\xbf\x9c\xe6\x98\x9f\xe7\xb3\xbb\xe5\xbd\xa2\xe6\x80\x81\xe5\x88\x86\xe7\xb1\xbb\xe7\xab\x9e\xe8\xb5\x9b\xe7\x9a\x84\xe4\xbc\x98\xe8\x83\x9c\xe4\xbb\xa3\xe7\xa0\x81\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/benanne/kaggle-galaxies)\n*   Kaggle Gender\xef\xbc\x9aKaggle\xe7\xab\x9e\xe8\xb5\x9b\xef\xbc\x8c\xe4\xbb\x8e\xe7\xac\x94\xe8\xbf\xb9\xe5\x8c\xba\xe5\x88\x86\xe6\x80\xa7\xe5\x88\xab\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/zygmuntz/kaggle-gender)\n*   Kaggle Merck\xef\xbc\x9aKaggle\xe4\xb8\x8a\xe9\xa2\x84\xe6\xb5\x8b\xe8\x8d\xaf\xe7\x89\xa9\xe5\x88\x86\xe5\xad\x90\xe6\xb4\xbb\xe6\x80\xa7\xe7\xab\x9e\xe8\xb5\x9b\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x88\xe9\xbb\x98\xe5\x85\x8b\xe5\x88\xb6\xe8\x8d\xaf\xe8\xb5\x9e\xe5\x8a\xa9\xef\xbc\x89\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/zygmuntz/kaggle-merck)\n*   Kaggle Stackoverflow\xef\xbc\x9aKaggle\xe4\xb8\x8a \xe9\xa2\x84\xe6\xb5\x8bStackOverflow\xe7\xbd\x91\xe7\xab\x99\xe9\x97\xae\xe9\xa2\x98\xe6\x98\xaf\xe5\x90\xa6\xe4\xbc\x9a\xe8\xa2\xab\xe5\x85\xb3\xe9\x97\xad\xe7\xab\x9e\xe8\xb5\x9b\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/zygmuntz/kaggle-stackoverflow)\n*   wine-quality\xef\xbc\x9a\xe9\xa2\x84\xe6\xb5\x8b\xe7\xba\xa2\xe9\x85\x92\xe8\xb4\xa8\xe9\x87\x8f\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/zygmuntz/wine-quality)\n\n## [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#ruby)Ruby\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#natural-language-processing-6)\xe8\x87\xaa\xe7\x84\xb6\xe8\xaf\xad\xe8\xa8\x80\xe5\xa4\x84\xe7\x90\x86\n\n*   Treat\xef\xbc\x9a\xe6\x96\x87\xe6\x9c\xac\xe6\xa3\x80\xe7\xb4\xa2\xe4\xb8\x8e\xe6\xb3\xa8\xe9\x87\x8a\xe5\xb7\xa5\xe5\x85\xb7\xe5\x8c\x85\xef\xbc\x8cRuby\xe4\xb8\x8a\xe6\x88\x91\xe8\xa7\x81\xe8\xbf\x87\xe7\x9a\x84\xe6\x9c\x80\xe5\x85\xa8\xe9\x9d\xa2\xe7\x9a\x84\xe5\xb7\xa5\xe5\x85\xb7\xe5\x8c\x85\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/louismullie/treat)\n*   Ruby Linguistics\xef\xbc\x9a\xe8\xbf\x99\xe4\xb8\xaa\xe6\xa1\x86\xe6\x9e\xb6\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x94\xa8\xe4\xbb\xbb\xe4\xbd\x95\xe8\xaf\xad\xe8\xa8\x80\xe4\xb8\xbaRuby\xe5\xaf\xb9\xe8\xb1\xa1\xe6\x9e\x84\xe5\xbb\xba\xe8\xaf\xad\xe8\xa8\x80\xe5\xad\xa6\xe5\xb7\xa5\xe5\x85\xb7\xe5\x8c\x85\xe3\x80\x82\xe6\x8b\xac\xe4\xb8\x80\xe4\xb8\xaa\xe8\xaf\xad\xe8\xa8\x80\xe6\x97\xa0\xe5\x85\xb3\xe7\x9a\x84\xe9\x80\x9a\xe7\x94\xa8\xe5\x89\x8d\xe7\xab\xaf\xef\xbc\x8c\xe4\xb8\x80\xe4\xb8\xaa\xe5\xb0\x86\xe8\xaf\xad\xe8\xa8\x80\xe4\xbb\xa3\xe7\xa0\x81\xe6\x98\xa0\xe5\xb0\x84\xe5\x88\xb0\xe8\xaf\xad\xe8\xa8\x80\xe5\x90\x8d\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9d\x97\xef\xbc\x8c\xe5\x92\x8c\xe4\xb8\x80\xe4\xb8\xaa\xe5\x90\xab\xe6\x9c\x89\xe5\xbe\x88\xe6\x9c\x89\xe8\x8b\xb1\xe6\x96\x87\xe8\xaf\xad\xe8\xa8\x80\xe5\xb7\xa5\xe5\x85\xb7\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9d\x97\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://www.deveiate.org/projects/Linguistics/)\n*   Stemmer\xef\xbc\x9a\xe4\xbd\xbf\xe5\xbe\x97Ruby\xe5\x8f\xaf\xe7\x94\xa8 libstemmer_c\xe4\xb8\xad\xe7\x9a\x84\xe6\x8e\xa5\xe5\x8f\xa3\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/aurelian/ruby-stemmer)\n*   Ruby Wordnet\xef\xbc\x9aWordNet\xe7\x9a\x84Ruby\xe6\x8e\xa5\xe5\x8f\xa3\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://www.deveiate.org/projects/Ruby-WordNet/)\n*   Raspel\xef\xbc\x9aaspell\xe7\xbb\x91\xe5\xae\x9a\xe5\x88\xb0Ruby\xe7\x9a\x84\xe6\x8e\xa5\xe5\x8f\xa3\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://sourceforge.net/projects/raspell/)\n*   UEA Stemmer\xef\xbc\x9aUEALite Stemmer\xe7\x9a\x84Ruby\xe7\xa7\xbb\xe6\xa4\x8d\xe7\x89\x88\xef\xbc\x8c\xe4\xbe\x9b\xe6\x90\x9c\xe7\xb4\xa2\xe5\x92\x8c\xe6\xa3\x80\xe7\xb4\xa2\xe7\x94\xa8\xe7\x9a\x84\xe4\xbf\x9d\xe5\xae\x88\xe7\x9a\x84\xe8\xaf\x8d\xe5\xb9\xb2\xe5\x88\x86\xe6\x9e\x90\xe5\x99\xa8\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/ealdent/uea-stemmer)\n*   Twitter-text-rb\xef\xbc\x9a\xe8\xaf\xa5\xe7\xa8\x8b\xe5\xba\x8f\xe5\xba\x93\xe5\x8f\xaf\xe4\xbb\xa5\xe5\xb0\x86\xe6\x8e\xa8\xe7\x89\xb9\xe4\xb8\xad\xe7\x9a\x84\xe7\x94\xa8\xe6\x88\xb7\xe5\x90\x8d\xe3\x80\x81\xe5\x88\x97\xe8\xa1\xa8\xe5\x92\x8c\xe8\xaf\x9d\xe9\xa2\x98\xe6\xa0\x87\xe7\xad\xbe\xe8\x87\xaa\xe5\x8a\xa8\xe8\xbf\x9e\xe6\x8e\xa5\xe5\xb9\xb6\xe6\x8f\x90\xe5\x8f\x96\xe5\x87\xba\xe6\x9d\xa5\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/twitter/twitter-text-rb)\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#general-purpose-machine-learning-8)\xe9\x80\x9a\xe7\x94\xa8\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\n\n*   Ruby Machine Learning\xef\xbc\x9aRuby\xe5\xae\x9e\xe7\x8e\xb0\xe7\x9a\x84\xe4\xb8\x80\xe4\xba\x9b\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xae\x97\xe6\xb3\x95\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/tsycho/ruby-machine-learning)\n*   Machine Learning Ruby\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](https://github.com/mizoR/machine-learning-ruby)\n*   jRuby Mahout\xef\xbc\x9a\xe7\xb2\xbe\xe5\x8d\x8e\xef\xbc\x81\xe5\x9c\xa8JRuby\xe4\xb8\x96\xe7\x95\x8c\xe4\xb8\xad\xe9\x87\x8a\xe6\x94\xbe\xe4\xba\x86Apache Mahout\xe7\x9a\x84\xe5\xa8\x81\xe5\x8a\x9b\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/vasinov/jruby_mahout)\n*   CardMagic-Classifier\xef\xbc\x9a\xe5\x8f\xaf\xe7\x94\xa8\xe8\xb4\x9d\xe5\x8f\xb6\xe6\x96\xaf\xe5\x8f\x8a\xe5\x85\xb6\xe4\xbb\x96\xe5\x88\x86\xe7\xb1\xbb\xe6\xb3\x95\xe7\x9a\x84\xe9\x80\x9a\xe7\x94\xa8\xe5\x88\x86\xe7\xb1\xbb\xe5\x99\xa8\xe6\xa8\xa1\xe5\x9d\x97\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/cardmagic/classifier)\n*   Neural Networks and Deep Learning\xef\xbc\x9a\xe3\x80\x8a\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe5\x92\x8c\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe3\x80\x8b\xe4\xb8\x80\xe4\xb9\xa6\xe7\x9a\x84\xe7\xa4\xba\xe4\xbe\x8b\xe4\xbb\xa3\xe7\xa0\x81\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/mnielsen/neural-networks-and-deep-learning)\n\n#### \xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe6\x9e\x90/\xe6\x95\xb0\xe6\x8d\xae\xe5\x8f\xaf\xe8\xa7\x86\xe5\x8c\x96[](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#data-analysis--data-visualization-6)\n\n*   rsruby\xef\xbc\x9aRuby - R bridge\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/alexgutteridge/rsruby)\n*   data-visualization-ruby\xef\xbc\x9a\xe5\x85\xb3\xe4\xba\x8e\xe6\x95\xb0\xe6\x8d\xae\xe5\x8f\xaf\xe8\xa7\x86\xe5\x8c\x96\xe7\x9a\x84Ruby Manor\xe6\xbc\x94\xe7\xa4\xba\xe7\x9a\x84\xe6\xba\x90\xe4\xbb\xa3\xe7\xa0\x81\xe5\x92\x8c\xe6\x94\xaf\xe6\x8c\x81\xe5\x86\x85\xe5\xae\xb9\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/chrislo/data_visualisation_ruby)\n*   ruby-plot\xef\xbc\x9a\xe5\xb0\x86gnuplot\xe5\x8c\x85\xe8\xa3\x85\xe4\xb8\xbaRuby\xe5\xbd\xa2\xe5\xbc\x8f\xef\xbc\x8c\xe7\x89\xb9\xe5\x88\xab\xe9\x80\x82\xe5\x90\x88\xe5\xb0\x86ROC\xe6\x9b\xb2\xe7\xba\xbf\xe8\xbd\xac\xe5\x8c\x96\xe4\xb8\xbasvg\xe6\x96\x87\xe4\xbb\xb6\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://www.ruby-toolbox.com/projects/ruby-plot)\n*   plot-rb\xef\xbc\x9a\xe5\x9f\xba\xe4\xba\x8eVega\xe5\x92\x8cD3\xe7\x9a\x84ruby\xe7\xbb\x98\xe5\x9b\xbe\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/zuhao/plotrb)\n*   scruffy\xef\xbc\x9aRuby\xe4\xb8\x8b\xe5\x87\xba\xe8\x89\xb2\xe7\x9a\x84\xe5\x9b\xbe\xe5\xbd\xa2\xe5\xb7\xa5\xe5\x85\xb7\xe5\x8c\x85\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://www.rubyinside.com/scruffy-a-beautiful-graphing-toolkit-for-ruby-194.html) \n*   SciRuby\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](http://sciruby.com/)\n*   Glean\xef\xbc\x9a\xe6\x95\xb0\xe6\x8d\xae\xe7\xae\xa1\xe7\x90\x86\xe5\xb7\xa5\xe5\x85\xb7\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/glean/glean)\n*   Bioruby\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](https://github.com/bioruby/bioruby)\n*   Arel\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](https://github.com/nkallen/arel)\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#misc)Misc \xe6\x9d\x82\xe9\xa1\xb9\n\n*   Big Data For Chimps\xef\xbc\x9a\xe5\xa4\xa7\xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\xe4\xb8\xa5\xe8\x82\x83\xe8\x80\x8c\xe6\x9c\x89\xe8\xb6\xa3\xe7\x9a\x84\xe6\x8c\x87\xe5\x8d\x97\xe4\xb9\xa6\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/infochimps-labs/big_data_for_chimps)\n\n## [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#r)R\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#general-purpose-machine-learning-9)\xe9\x80\x9a\xe7\x94\xa8\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\n\n*   Clever Algorithms For Machine Learning\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](https://github.com/jbrownlee/CleverAlgorithmsMachineLearning)\xe3\x80\x82\n*   Machine Learning For Hackers\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](https://github.com/johnmyleswhite/ML_for_Hackers)\xe3\x80\x82\n*   Machine Learning Task View on CRAN\xef\xbc\x9aR\xe8\xaf\xad\xe8\xa8\x80\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x8c\x85\xe5\x88\x97\xe8\xa1\xa8\xef\xbc\x8c\xe6\x8c\x89\xe7\xae\x97\xe6\xb3\x95\xe7\xb1\xbb\xe5\x9e\x8b\xe5\x88\x86\xe7\xbb\x84\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://cran.r-project.org/web/views/MachineLearning.html)\xe3\x80\x82\n*   caret\xef\xbc\x9aR\xe8\xaf\xad\xe8\xa8\x80150\xe4\xb8\xaa\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xae\x97\xe6\xb3\x95\xe7\x9a\x84\xe7\xbb\x9f\xe4\xb8\x80\xe6\x8e\xa5\xe5\x8f\xa3\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://caret.r-forge.r-project.org/)\n*   [SuperLearner\xef\xbc\x9a\xe8\xaf\xa5\xe5\x8c\x85\xe9\x9b\x86\xe5\x90\x88\xe4\xba\x86\xe5\xa4\x9a\xe7\xa7\x8d\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xae\x97\xe6\xb3\x95](https://github.com/ecpolley/SuperLearner)\xe4\xb8\x8e[subsemble](http://cran.r-project.org/web/\xe3\x80\x82packages/subsemble/index.html)\n*   Introduction to Statistical Learning\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](http://www-bcf.usc.edu/~gareth/ISL/)\xe3\x80\x82\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#data-analysis--data-visualization-7)\n\n#### \xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe6\x9e\x90/\xe6\x95\xb0\xe6\x8d\xae\xe5\x8f\xaf\xe8\xa7\x86\xe5\x8c\x96\n\n*   Learning Statistics Using R\xef\xbc\x9a[\xe5\xae\x98\xe7\xbd\x91](http://health.adelaide.edu.au/psychology/ccs/teaching/lsr/)\n*   ggplot2\xef\xbc\x9a\xe5\x9f\xba\xe4\xba\x8e\xe5\x9b\xbe\xe5\xbd\xa2\xe8\xaf\xad\xe6\xb3\x95\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\x8f\xaf\xe8\xa7\x86\xe5\x8c\x96\xe5\x8c\x85\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://ggplot2.org/)\n\n## [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#scala)Scala\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#natural-language-processing-7)\xe8\x87\xaa\xe7\x84\xb6\xe8\xaf\xad\xe8\xa8\x80\xe5\xa4\x84\xe7\x90\x86\n\n*   ScalaNLP\xef\xbc\x9a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x92\x8c\xe6\x95\xb0\xe5\x80\xbc\xe8\xae\xa1\xe7\xae\x97\xe5\xba\x93\xe7\x9a\x84\xe5\xa5\x97\xe8\xa3\x85\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://www.scalanlp.org/)\n*   Breeze\xef\xbc\x9aScala\xe7\x94\xa8\xe7\x9a\x84\xe6\x95\xb0\xe5\x80\xbc\xe5\xa4\x84\xe7\x90\x86\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/scalanlp/breeze)\n*   Chalk\xef\xbc\x9a\xe8\x87\xaa\xe7\x84\xb6\xe8\xaf\xad\xe8\xa8\x80\xe5\xa4\x84\xe7\x90\x86\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/scalanlp/chalk)\n*   FACTORIE\xef\xbc\x9a\xe5\x8f\xaf\xe9\x83\xa8\xe7\xbd\xb2\xe7\x9a\x84\xe6\xa6\x82\xe7\x8e\x87\xe5\xbb\xba\xe6\xa8\xa1\xe5\xb7\xa5\xe5\x85\xb7\xe5\x8c\x85\xef\xbc\x8c\xe7\x94\xa8Scala\xe5\xae\x9e\xe7\x8e\xb0\xe7\x9a\x84\xe8\xbd\xaf\xe4\xbb\xb6\xe5\xba\x93\xe4\xb8\xba\xe7\x94\xa8\xe6\x88\xb7\xe6\x8f\x90\xe4\xbe\x9b\xe7\xae\x80\xe6\xb4\x81\xe7\x9a\x84\xe8\xaf\xad\xe8\xa8\x80\xe6\x9d\xa5\xe5\x88\x9b\xe5\xbb\xba\xe5\x85\xb3\xe7\xb3\xbb\xe5\x9b\xa0\xe7\xb4\xa0\xe5\x9b\xbe\xef\xbc\x8c\xe8\xaf\x84\xe4\xbc\xb0\xe5\x8f\x82\xe6\x95\xb0\xe5\xb9\xb6\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x8e\xa8\xe6\x96\xad\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/factorie/factorie)\xe3\x80\x82\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#data-analysis--data-visualization-8)\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe6\x9e\x90/\xe6\x95\xb0\xe6\x8d\xae\xe5\x8f\xaf\xe8\xa7\x86\xe5\x8c\x96\n\n*   MLlib in Apache Spark\xef\xbc\x9aSpark\xe4\xb8\x8b\xe7\x9a\x84\xe5\x88\x86\xe5\xb8\x83\xe5\xbc\x8f\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](http://spark.apache.org/docs/latest/mllib-guide.html)\n*   Scalding\xef\xbc\x9aCAscading\xe7\x9a\x84Scala\xe6\x8e\xa5\xe5\x8f\xa3\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/twitter/scalding)\n*   Summing Bird\xef\xbc\x9a\xe7\x94\xa8Scalding \xe5\x92\x8c Storm\xe8\xbf\x9b\xe8\xa1\x8cStreaming MapReduce\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/twitter/summingbird)\n*   Algebird\xef\xbc\x9aScala\xe7\x9a\x84\xe6\x8a\xbd\xe8\xb1\xa1\xe4\xbb\xa3\xe6\x95\xb0\xe5\xb7\xa5\xe5\x85\xb7\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/twitter/algebird)\n*   xerial\xef\xbc\x9aScala\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe7\xae\xa1\xe7\x90\x86\xe5\xb7\xa5\xe5\x85\xb7\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/xerial/xerial)\n*   simmer\xef\xbc\x9a\xe5\x8c\x96\xe7\xae\x80\xe4\xbd\xa0\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe8\xbf\x9b\xe8\xa1\x8c\xe4\xbb\xa3\xe6\x95\xb0\xe8\x81\x9a\xe5\x90\x88\xe7\x9a\x84unix\xe8\xbf\x87\xe6\xbb\xa4\xe5\x99\xa8\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/avibryant/simmer)\n*   PredictionIO\xef\xbc\x9a\xe4\xbe\x9b\xe8\xbd\xaf\xe4\xbb\xb6\xe5\xbc\x80\xe5\x8f\x91\xe8\x80\x85\xe5\x92\x8c\xe6\x95\xb0\xe6\x8d\xae\xe5\xb7\xa5\xe7\xa8\x8b\xe5\xb8\x88\xe7\x94\xa8\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x9c\x8d\xe5\x8a\xa1\xe5\x99\xa8\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/PredictionIO/PredictionIO)\n*   BIDMat\xef\xbc\x9a\xe6\x94\xaf\xe6\x8c\x81\xe5\xa4\xa7\xe8\xa7\x84\xe6\xa8\xa1\xe6\x8e\xa2\xe7\xb4\xa2\xe6\x80\xa7\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe6\x9e\x90\xe7\x9a\x84CPU\xe5\x92\x8cGPU\xe5\x8a\xa0\xe9\x80\x9f\xe7\x9f\xa9\xe9\x98\xb5\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/BIDData/BIDMat)\n\n#### [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#general-purpose-machine-learning-10)\xe9\x80\x9a\xe7\x94\xa8\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\n\n*   Conjecture\xef\xbc\x9aScalding\xe4\xb8\x8b\xe5\x8f\xaf\xe6\x89\xa9\xe5\xb1\x95\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\xa1\x86\xe6\x9e\xb6\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/etsy/Conjecture)\n*   brushfire\xef\xbc\x9ascalding\xe4\xb8\x8b\xe7\x9a\x84\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe5\xb7\xa5\xe5\x85\xb7\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/avibryant/brushfire)\n*   ganitha\xef\xbc\x9a\xe5\x9f\xba\xe4\xba\x8escalding\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xa8\x8b\xe5\xba\x8f\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/tresata/ganitha)\n*   adam\xef\xbc\x9a\xe4\xbd\xbf\xe7\x94\xa8Apache Avro, Apache Spark \xe5\x92\x8c Parquet\xe7\x9a\x84\xe5\x9f\xba\xe5\x9b\xa0\xe7\xbb\x84\xe5\xa4\x84\xe7\x90\x86\xe5\xbc\x95\xe6\x93\x8e\xef\xbc\x8c\xe6\x9c\x89\xe4\xb8\x93\xe7\x94\xa8\xe7\x9a\x84\xe6\x96\x87\xe4\xbb\xb6\xe6\xa0\xbc\xe5\xbc\x8f\xef\xbc\x8cApache 2\xe8\xbd\xaf\xe4\xbb\xb6\xe8\xae\xb8\xe5\x8f\xaf\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/bigdatagenomics/adam)\n*   bioscala\xef\xbc\x9aScala\xe8\xaf\xad\xe8\xa8\x80\xe5\x8f\xaf\xe7\x94\xa8\xe7\x9a\x84\xe7\x94\x9f\xe7\x89\xa9\xe4\xbf\xa1\xe6\x81\xaf\xe5\xad\xa6\xe7\xa8\x8b\xe5\xba\x8f\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/bioscala/bioscala)\n*   BIDMach\xef\xbc\x9a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0CPU\xe5\x92\x8cGPU\xe5\x8a\xa0\xe9\x80\x9f\xe5\xba\x93\xe3\x80\x82[\xe5\xae\x98\xe7\xbd\x91](https://github.com/BIDData/BIDMach)\n\n## [](https://github.com/josephmisiti/awesome-machine-learning/blob/master/README.md#credits)\n'"
31,TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials,TarrySingh,"A comprehensive list of Deep Learning / Artificial Intelligence and Machine Learning tutorials - rapidly expanding into areas of AI/Deep Learning / Machine Vision / NLP and industry specific areas such as Automotives, Retail, Pharma, Medicine, Healthcare by Tarry Singh until at-least 2020 until he finishes his Ph.D. (which might end up being inter-stellar cosmic networks! Who knows! 😀)",2017-07-13 19:46:01,2020-06-16 05:03:47,Python,1232,2365,"b'# NEW LIST 2017 - 2020: Machine-Learning / Deep-Learning / AI -Tutorials\n\nHi - Thanks for dropping by!<br>\n<br>\nI will be updating this tutorials site on a <b>daily basis</b> adding all relevant topcis, including latest researches papers from internet such as [arxiv.org](https://arxiv.org), [BIORXIV - Specifically Neuroscience](https://www.biorxiv.org/collection/neuroscience) to name a few. <br>\n<br>\nMore importantly the applications of ML/DL/AI into industry areas such as Transportation, Medicine/Healthcare etc. will be something I\'ll watch with keen interest and would love to share the same with you.\n<br>\nFinally, it is **YOUR** help I will seek to make it more useful and less boring, so please do suggest/comment/contribute!\n<p align=""center"">\n  <img src=""https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/blob/master/images/AI.png"">\n</p>\n\n## Index\n\n* [deep-learning](#deep-learning)\n   * [UBER | Pyro](#uber-pyro-probabalistic-tutorials)\n   * [Netflix | VectorFlow](#netflix-vectorflow-tutorials)\n   * [PyTorch](#pytorch-tutorials)\n   * [tensorflow](#tensor-flow-tutorials)\n   * [theano](#theano-tutorials)\n   * [keras](#keras-tutorials)\n   * [caffe](#deep-learning-misc)\n   * [Torch/Lua]()\n   * [MXNET]()\n   \n* [scikit-learn](#scikit-learn)\n* [statistical-inference-scipy](#statistical-inference-scipy)\n* [pandas](#pandas)\n* [matplotlib](#matplotlib)\n* [numpy](#numpy)\n* [python-data](#python-data)\n* [kaggle-and-business-analyses](#kaggle-and-business-analyses)\n* [spark](#spark)\n* [mapreduce-python](#mapreduce-python)\n* [amazon web services](#aws)\n* [command lines](#commands)\n* [misc](#misc)\n* [notebook-installation](#notebook-installation)\n* [Curated list of Deep Learning / AI blogs](#curated-list-of-deeplearning-blogs)\n* [credits](#credits)\n* [contributing](#contributing)\n* [contact-info](#contact-info)\n* [license](#license)\n\n## deep-learning\n\nIPython Notebook(s) and other programming tools such as Torch/Lua/D lang in demonstrating deep learning functionality.\n\n### uber-pyro-probabalistic-tutorials\n<p align=""center"">\n  <img src=""https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/blob/master/images/pyro.png"">\n</p>\n\nAdditional PyRo tutorials:\n\n* [pyro-examples/full examples](http://pyro.ai/examples/)\n* [pyro-examples/Variational Autoencoders](http://pyro.ai/examples/vae.html)\n* [pyro-examples/Bayesian Regression](http://pyro.ai/examples/bayesian_regression.html)\n* [pyro-examples/Deep Markov Model](http://pyro.ai/examples/dmm.html)\n* [pyro-examples/AIR(Attend Infer Repeat)](http://pyro.ai/examples/air.html)\n* [pyro-examples/Semi-Supervised VE](http://pyro.ai/examples/ss-vae.html)\n* [pyro-examples/GMM](http://pyro.ai/examples/gmm.html)\n* [pyro-examples/Gaussian Process](http://pyro.ai/examples/gp.html)\n* [pyro-examples/Bayesian Optimization](http://pyro.ai/examples/bo.html)\n* [Full Pyro Code](https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/tree/master/deep-learning/UBER-pyro)\n\n\n\n### netflix-vectorflow-tutorials\n<p align=""center"">\n  <img src=""https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/blob/master/images/VectorFlow.png"">\n</p>\n\n* [MNIST Example, running with Dlang](https://github.com/Netflix/vectorflow/tree/master/examples)\n\n### pytorch-tutorials\n<p align=""center"">\n  <img src=""https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/blob/master/images/PyTorch.png"">\n</p>\n\n| Level | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [Beginners/Zakizhou](https://github.com/pytorch/tutorials/tree/master/beginner_source) | Learning the basics of PyTorch from Facebook. |\n| [Intermedia/Quanvuong](https://github.com/pytorch/tutorials/tree/master/intermediate_source) | Learning the intermediate stuff about PyTorch of from Facebook. |\n| [Advanced/Chsasank](https://github.com/pytorch/tutorials/tree/master/advanced_source) | Learning the advanced stuff about PyTorch of from Facebook. |\n| [Learning PyTorch by Examples - Numpy, Tensors and Autograd](https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/tree/master/pytorch) | At its core, PyTorch provides two main features an n-dimensional Tensor, similar to numpy but can run on GPUs AND automatic differentiation for building and training neural networks. |\n| [PyTorch - Getting to know autograd.Variable, Gradient, Neural Network](https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/blob/master/pytorch/PyTorch%20NN%20Basics%20-%20Autograd%20Gradient%20Neural%20Network%20Loss%20Backprop.ipynb) | Here we start with ultimate basics of Tensors, wrap a Tensor with Variable module, play with nn.Module and implement forward and backward function. |\n\n\n### tensor-flow-tutorials\n<br/>\n<p align=""center"">\n  <img src=""https://avatars0.githubusercontent.com/u/15658638?v=3&s=100"">\n</p>\nAdditional TensorFlow tutorials:\n\n* [pkmital/tensorflow_tutorials](https://github.com/pkmital/tensorflow_tutorials)\n* [nlintz/TensorFlow-Tutorials](https://github.com/nlintz/TensorFlow-Tutorials)\n* [alrojo/tensorflow-tutorial](https://github.com/alrojo/tensorflow-tutorial)\n* [BinRoot/TensorFlow-Book](https://github.com/BinRoot/TensorFlow-Book)\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [tsf-basics](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/1_intro/basic_operations.ipynb) | Learn basic operations in TensorFlow, a library for various kinds of perceptual and language understanding tasks from Google. |\n| [tsf-linear](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/linear_regression.ipynb) | Implement linear regression in TensorFlow. |\n| [tsf-logistic](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/logistic_regression.ipynb) | Implement logistic regression in TensorFlow. |\n| [tsf-nn](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/nearest_neighbor.ipynb) | Implement nearest neighboars in TensorFlow. |\n| [tsf-alex](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/alexnet.ipynb) | Implement AlexNet in TensorFlow. |\n| [tsf-cnn](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/convolutional_network.ipynb) | Implement convolutional neural networks in TensorFlow. |\n| [tsf-mlp](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/multilayer_perceptron.ipynb) | Implement multilayer perceptrons in TensorFlow. |\n| [tsf-rnn](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/recurrent_network.ipynb) | Implement recurrent neural networks in TensorFlow. |\n| [tsf-gpu](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/4_multi_gpu/multigpu_basics.ipynb) | Learn about basic multi-GPU computation in TensorFlow. |\n| [tsf-gviz](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/5_ui/graph_visualization.ipynb) | Learn about graph visualization in TensorFlow. |\n| [tsf-lviz](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/5_ui/loss_visualization.ipynb) | Learn about loss visualization in TensorFlow. |\n\n### tensor-flow-exercises\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [tsf-not-mnist](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-exercises/1_notmnist.ipynb) | Learn simple data curation by creating a pickle with formatted datasets for training, development and testing in TensorFlow. |\n| [tsf-fully-connected](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-exercises/2_fullyconnected.ipynb) | Progressively train deeper and more accurate models using logistic regression and neural networks in TensorFlow. |\n| [tsf-regularization](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-exercises/3_regularization.ipynb) | Explore regularization techniques by training fully connected networks to classify notMNIST characters in TensorFlow. |\n| [tsf-convolutions](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-exercises/4_convolutions.ipynb) | Create convolutional neural networks in TensorFlow. |\n| [tsf-word2vec](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-exercises/5_word2vec.ipynb) | Train a skip-gram model over Text8 data in TensorFlow. |\n| [tsf-lstm](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-exercises/6_lstm.ipynb) | Train a LSTM character model over Text8 data in TensorFlow. |\n\n<br/>\n<p align=""center"">\n  <img src=""http://www.deeplearning.net/software/theano/_static/theano_logo_allblue_200x46.png"">\n</p>\n\n### theano-tutorials\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [theano-intro](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/theano-tutorial/intro_theano/intro_theano.ipynb) | Intro to Theano, which allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. It can use GPUs and perform efficient symbolic differentiation. |\n| [theano-scan](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/theano-tutorial/scan_tutorial/scan_tutorial.ipynb) | Learn scans, a mechanism to perform loops in a Theano graph. |\n| [theano-logistic](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/theano-tutorial/intro_theano/logistic_regression.ipynb) | Implement logistic regression in Theano. |\n| [theano-rnn](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/theano-tutorial/rnn_tutorial/simple_rnn.ipynb) | Implement recurrent neural networks in Theano. |\n| [theano-mlp](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/theano-tutorial/theano_mlp/theano_mlp.ipynb) | Implement multilayer perceptrons in Theano. |\n\n<br/>\n<p align=""center"">\n  <img src=""http://i.imgur.com/L45Q8c2.jpg"">\n</p>\n\n### keras-tutorials\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| keras | Keras is an open source neural network library written in Python. It is capable of running on top of either Tensorflow or Theano. |\n| [setup](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/README.md) | Learn about the tutorial goals and how to set up your Keras environment. |\n| [intro-deep-learning-ann](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.%20ANN/1.1%20Introduction%20-%20Deep%20Learning%20and%20ANN.ipynb) | Get an intro to deep learning with Keras and Artificial Neural Networks (ANN). |\n| [Perceptrons and Adaline](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.%20ANN/1.1.1%20Perceptron%20and%20Adaline.ipynb) | Implement Peceptron and adaptive linear neurons. |\n| [MLP and MNIST Data](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.%20ANN/1.1.2%20MLP%20and%20MNIST.ipynb) | Classifying handwritten digits,implement MLP, train and debug ANN |\n| [theano](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.2%20Introduction%20-%20Theano.ipynb) | Learn about Theano by working with weights matrices and gradients. |\n| [keras-otto](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.3%20Introduction%20-%20Keras.ipynb) | Learn about Keras by looking at the Kaggle Otto challenge. |\n| [ann-mnist](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.4%20(Extra)%20A%20Simple%20Implementation%20of%20ANN%20for%20MNIST.ipynb) | Review a simple implementation of ANN for MNIST using Keras. |\n| [conv-nets](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/2.1%20Supervised%20Learning%20-%20ConvNets.ipynb) | Learn about Convolutional Neural Networks (CNNs) with Keras. |\n| [conv-net-1](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/2.2.1%20Supervised%20Learning%20-%20ConvNet%20HandsOn%20Part%20I.ipynb) | Recognize handwritten digits from MNIST using Keras - Part 1. |\n| [conv-net-2](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/2.2.2%20Supervised%20Learning%20-%20ConvNet%20HandsOn%20Part%20II.ipynb) | Recognize handwritten digits from MNIST using Keras - Part 2. |\n| [keras-models](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/2.3%20Supervised%20Learning%20-%20Famous%20Models%20with%20Keras.ipynb) | Use pre-trained models such as VGG16, VGG19, ResNet50, and Inception v3 with Keras. |\n| [auto-encoders](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/6.%20AutoEncoders%20and%20Embeddings/6.1.%20AutoEncoders%20and%20Embeddings.ipynb) | Learn about Autoencoders with Keras. |\n| [rnn-lstm](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/7.%20Recurrent%20Neural%20Networks/7.1%20RNN%20and%20LSTM.ipynb) | Learn about Recurrent Neural Networks (RNNs) with Keras. |\n| [lstm-sentence-gen](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/7.%20Recurrent%20Neural%20Networks/7.2%20LSTM%20for%20Sentence%20Generation.ipynb) |  Learn about RNNs using Long Short Term Memory (LSTM) networks with Keras. |\n| [nlp-deep-learning](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/6.%20AutoEncoders%20and%20Embeddings/6.2%20NLP%20and%20Deep%20Learning.ipynb) | Learn about NLP using ANN (Artificial Neural Networks. |\n| [hyperparamter-tuning](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/5.%20HyperParameter%20Tuning%20and%20Transfer%20Learning/5.1%20HyperParameter%20Tuning.ipynb) | Hyperparamters tuning using keras-wrapper.scikit-learn |\n\n### deep-learning-misc\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [deep-dream](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/deep-dream/dream.ipynb) | Caffe-based computer vision program which uses a convolutional neural network to find and enhance patterns in images. |\n\n<br/>\n<p align=""center"">\n  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/scikitlearn.png"">\n</p>\n\n## scikit-learn\n\nIPython Notebook(s) demonstrating scikit-learn functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [intro](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-intro.ipynb) | Intro notebook to scikit-learn.  Scikit-learn adds Python support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays. |\n| [knn](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-intro.ipynb#K-Nearest-Neighbors-Classifier) | Implement k-nearest neighbors in scikit-learn. |\n| [linear-reg](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-linear-reg.ipynb) | Implement linear regression in scikit-learn. |\n| [svm](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-svm.ipynb) | Implement support vector machine classifiers with and without kernels in scikit-learn. |\n| [random-forest](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-random-forest.ipynb) | Implement random forest classifiers and regressors in scikit-learn. |\n| [k-means](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-k-means.ipynb) | Implement k-means clustering in scikit-learn. |\n| [pca](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-pca.ipynb) | Implement principal component analysis in scikit-learn. |\n| [gmm](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-gmm.ipynb) | Implement Gaussian mixture models in scikit-learn. |\n| [validation](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-validation.ipynb) | Implement validation and model selection in scikit-learn. |\n\n<br/>\n<p align=""center"">\n  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/scipy.png"">\n</p>\n\n## statistical-inference-scipy\n\nIPython Notebook(s) demonstrating statistical inference with SciPy functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| scipy | SciPy is a collection of mathematical algorithms and convenience functions built on the Numpy extension of Python. It adds significant power to the interactive Python session by providing the user with high-level commands and classes for manipulating and visualizing data. |\n| [effect-size](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scipy/effect_size.ipynb) | Explore statistics that quantify effect size by analyzing the difference in height between men and women.  Uses data from the Behavioral Risk Factor Surveillance System (BRFSS) to estimate the mean and standard deviation of height for adult women and men in the United States. |\n| [sampling](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scipy/sampling.ipynb) | Explore random sampling by analyzing the average weight of men and women in the United States using BRFSS data. |\n| [hypothesis](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scipy/hypothesis.ipynb) | Explore hypothesis testing by analyzing the difference of first-born babies compared with others. |\n\n<br/>\n<p align=""center"">\n  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/pandas.png"">\n</p>\n\n## pandas\n\nIPython Notebook(s) demonstrating pandas functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [pandas](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/pandas.ipynb) | Software library written for data manipulation and analysis in Python. Offers data structures and operations for manipulating numerical tables and time series. |\n| [github-data-wrangling](https://github.com/donnemartin/viz/blob/master/githubstats/data_wrangling.ipynb) | Learn how to load, clean, merge, and feature engineer by analyzing GitHub data from the [`Viz`](https://github.com/donnemartin/viz) repo. |\n| [Introduction-to-Pandas](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.00-Introduction-to-Pandas.ipynb) | Introduction to Pandas. |\n| [Introducing-Pandas-Objects](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.01-Introducing-Pandas-Objects.ipynb) | Learn about Pandas objects. |\n| [Data Indexing and Selection](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.02-Data-Indexing-and-Selection.ipynb) | Learn about data indexing and selection in Pandas. |\n| [Operations-in-Pandas](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.03-Operations-in-Pandas.ipynb) | Learn about operating on data in Pandas. |\n| [Missing-Values](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.04-Missing-Values.ipynb) | Learn about handling missing data in Pandas. |\n| [Hierarchical-Indexing](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.05-Hierarchical-Indexing.ipynb) | Learn about hierarchical indexing in Pandas. |\n| [Concat-And-Append](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.06-Concat-And-Append.ipynb) | Learn about combining datasets: concat and append in Pandas. |\n| [Merge-and-Join](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.07-Merge-and-Join.ipynb) | Learn about combining datasets: merge and join in Pandas. |\n| [Aggregation-and-Grouping](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.08-Aggregation-and-Grouping.ipynb) | Learn about aggregation and grouping in Pandas. |\n| [Pivot-Tables](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.09-Pivot-Tables.ipynb) | Learn about pivot tables in Pandas. |\n| [Working-With-Strings](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.10-Working-With-Strings.ipynb) | Learn about vectorized string operations in Pandas. |\n| [Working-with-Time-Series](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.11-Working-with-Time-Series.ipynb) | Learn about working with time series in pandas. |\n| [Performance-Eval-and-Query](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.12-Performance-Eval-and-Query.ipynb) | Learn about high-performance Pandas: eval() and query() in Pandas. |\n\n<br/>\n<p align=""center"">\n  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/matplotlib.png"">\n</p>\n\n## matplotlib\n\nIPython Notebook(s) demonstrating matplotlib functionality.\n\n| Notebook | Description |\n|-----------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [matplotlib](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/matplotlib.ipynb) | Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms. |\n| [matplotlib-applied](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/matplotlib-applied.ipynb) | Apply matplotlib visualizations to Kaggle competitions for exploratory data analysis.  Learn how to create bar plots, histograms, subplot2grid, normalized plots, scatter plots, subplots, and kernel density estimation plots. |\n| [Introduction-To-Matplotlib](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.00-Introduction-To-Matplotlib.ipynb) | Introduction to Matplotlib. |\n| [Simple-Line-Plots](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.01-Simple-Line-Plots.ipynb) | Learn about simple line plots in Matplotlib. |\n| [Simple-Scatter-Plots](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.02-Simple-Scatter-Plots.ipynb) | Learn about simple scatter plots in Matplotlib. |\n| [Errorbars.ipynb](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.03-Errorbars.ipynb) | Learn about visualizing errors in Matplotlib. |\n| [Density-and-Contour-Plots](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.04-Density-and-Contour-Plots.ipynb) | Learn about density and contour plots in Matplotlib. |\n| [Histograms-and-Binnings](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.05-Histograms-and-Binnings.ipynb) | Learn about histograms, binnings, and density in Matplotlib. |\n| [Customizing-Legends](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.06-Customizing-Legends.ipynb) | Learn about customizing plot legends in Matplotlib. |\n| [Customizing-Colorbars](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.07-Customizing-Colorbars.ipynb) | Learn about customizing colorbars in Matplotlib. |\n| [Multiple-Subplots](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.08-Multiple-Subplots.ipynb) | Learn about multiple subplots in Matplotlib. |\n| [Text-and-Annotation](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.09-Text-and-Annotation.ipynb) | Learn about text and annotation in Matplotlib. |\n| [Customizing-Ticks](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.10-Customizing-Ticks.ipynb) | Learn about customizing ticks in Matplotlib. |\n| [Settings-and-Stylesheets](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.11-Settings-and-Stylesheets.ipynb) | Learn about customizing Matplotlib: configurations and stylesheets. |\n| [Three-Dimensional-Plotting](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.12-Three-Dimensional-Plotting.ipynb) | Learn about three-dimensional plotting in Matplotlib. |\n| [Geographic-Data-With-Basemap](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.13-Geographic-Data-With-Basemap.ipynb) | Learn about geographic data with basemap in Matplotlib. |\n| [Visualization-With-Seaborn](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.14-Visualization-With-Seaborn.ipynb) | Learn about visualization with Seaborn. |\n\n<br/>\n<p align=""center"">\n  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/numpy.png"">\n</p>\n\n## numpy\n\nIPython Notebook(s) demonstrating NumPy functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [numpy](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/numpy.ipynb) | Adds Python support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays. |\n| [Introduction-to-NumPy](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.00-Introduction-to-NumPy.ipynb) | Introduction to NumPy. |\n| [Understanding-Data-Types](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.01-Understanding-Data-Types.ipynb) | Learn about data types in Python. |\n| [The-Basics-Of-NumPy-Arrays](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.02-The-Basics-Of-NumPy-Arrays.ipynb) | Learn about the basics of NumPy arrays. |\n| [Computation-on-arrays-ufuncs](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.03-Computation-on-arrays-ufuncs.ipynb) | Learn about computations on NumPy arrays: universal functions. |\n| [Computation-on-arrays-aggregates](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.04-Computation-on-arrays-aggregates.ipynb) | Learn about aggregations: min, max, and everything in between in NumPy. |\n| [Computation-on-arrays-broadcasting](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.05-Computation-on-arrays-broadcasting.ipynb) | Learn about computation on arrays: broadcasting in NumPy. |\n| [Boolean-Arrays-and-Masks](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.06-Boolean-Arrays-and-Masks.ipynb) | Learn about comparisons, masks, and boolean logic in NumPy. |\n| [Fancy-Indexing](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.07-Fancy-Indexing.ipynb) | Learn about fancy indexing in NumPy. |\n| [Sorting](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.08-Sorting.ipynb) | Learn about sorting arrays in NumPy. |\n| [Structured-Data-NumPy](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.09-Structured-Data-NumPy.ipynb) | Learn about structured data: NumPy\'s structured arrays. |\n\n<br/>\n<p align=""center"">\n  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/python.png"">\n</p>\n\n## python-data\n\nIPython Notebook(s) demonstrating Python functionality geared towards data analysis.\n\n| Notebook | Description |\n|-----------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------|\n| [data structures](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/structs.ipynb) | Learn Python basics with tuples, lists, dicts, sets. |\n| [data structure utilities](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/structs_utils.ipynb) | Learn Python operations such as slice, range, xrange, bisect, sort, sorted, reversed, enumerate, zip, list comprehensions. |\n| [functions](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/functions.ipynb) | Learn about more advanced Python features: Functions as objects, lambda functions, closures, *args, **kwargs currying, generators, generator expressions, itertools. |\n| [datetime](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/datetime.ipynb) | Learn how to work with Python dates and times: datetime, strftime, strptime, timedelta. |\n| [logging](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/logs.ipynb) | Learn about Python logging with RotatingFileHandler and TimedRotatingFileHandler. |\n| [pdb](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/pdb.ipynb) | Learn how to debug in Python with the interactive source code debugger. |\n| [unit tests](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/unit_tests.ipynb) | Learn how to test in Python with Nose unit tests. |\n\n<br/>\n<p align=""center"">\n  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/kaggle.png"">\n</p>\n\n## kaggle-and-business-analyses\n\nIPython Notebook(s) used in [kaggle](https://www.kaggle.com/) competitions and business analyses.\n\n| Notebook | Description |\n|-------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------|\n| [titanic](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/kaggle/titanic.ipynb) | Predict survival on the Titanic.  Learn data cleaning, exploratory data analysis, and machine learning. |\n| [churn-analysis](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/analyses/churn.ipynb) | Predict customer churn.  Exercise logistic regression, gradient boosting classifers, support vector machines, random forests, and k-nearest-neighbors.  Includes discussions of confusion matrices, ROC plots, feature importances, prediction probabilities, and calibration/descrimination.|\n\n<br/>\n<p align=""center"">\n  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/spark.png"">\n</p>\n\n## spark\n\nIPython Notebook(s) demonstrating spark and HDFS functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|\n| [spark](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/spark/spark.ipynb) | In-memory cluster computing framework, up to 100 times faster for certain applications and is well suited for machine learning algorithms. |\n| [hdfs](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/spark/hdfs.ipynb) | Reliably stores very large files across machines in a large cluster. |\n\n<br/>\n<p align=""center"">\n  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/mrjob.png"">\n</p>\n\n## mapreduce-python\n\nIPython Notebook(s) demonstrating Hadoop MapReduce with mrjob functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|\n| [mapreduce-python](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/mapreduce/mapreduce-python.ipynb) | Runs MapReduce jobs in Python, executing jobs locally or on Hadoop clusters. Demonstrates Hadoop Streaming in Python code with unit test and [mrjob](https://github.com/Yelp/mrjob) config file to analyze Amazon S3 bucket logs on Elastic MapReduce.  [Disco](https://github.com/discoproject/disco/) is another python-based alternative.|\n\n<br/>\n\n<p align=""center"">\n  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/aws.png"">\n</p>\n\n## aws\n\nIPython Notebook(s) demonstrating Amazon Web Services (AWS) and AWS tools functionality.\n\n\nAlso check out:\n\n* [SAWS](https://github.com/donnemartin/saws): A Supercharged AWS command line interface (CLI).\n* [Awesome AWS](https://github.com/donnemartin/awesome-aws): A curated list of libraries, open source repos, guides, blogs, and other resources.\n\n| Notebook | Description |\n|------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [boto](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#Boto) | Official AWS SDK for Python. |\n| [s3cmd](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#s3cmd) | Interacts with S3 through the command line. |\n| [s3distcp](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#s3distcp) | Combines smaller files and aggregates them together by taking in a pattern and target file.  S3DistCp can also be used to transfer large volumes of data from S3 to your Hadoop cluster. |\n| [s3-parallel-put](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#s3-parallel-put) | Uploads multiple files to S3 in parallel. |\n| [redshift](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#redshift) | Acts as a fast data warehouse built on top of technology from massive parallel processing (MPP). |\n| [kinesis](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#kinesis) | Streams data in real time with the ability to process thousands of data streams per second. |\n| [lambda](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#lambda) | Runs code in response to events, automatically managing compute resources. |\n\n<br/>\n<p align=""center"">\n  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/commands.png"">\n</p>\n\n## commands\n\nIPython Notebook(s) demonstrating various command lines for Linux, Git, etc.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [linux](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/linux.ipynb) | Unix-like and mostly POSIX-compliant computer operating system.  Disk usage, splitting files, grep, sed, curl, viewing running processes, terminal syntax highlighting, and Vim.|\n| [anaconda](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#anaconda) | Distribution of the Python programming language for large-scale data processing, predictive analytics, and scientific computing, that aims to simplify package management and deployment. |\n| [ipython notebook](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#ipython-notebook) | Web-based interactive computational environment where you can combine code execution, text, mathematics, plots and rich media into a single document. |\n| [git](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#git) | Distributed revision control system with an emphasis on speed, data integrity, and support for distributed, non-linear workflows. |\n| [ruby](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#ruby) | Used to interact with the AWS command line and for Jekyll, a blog framework that can be hosted on GitHub Pages. |\n| [jekyll](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#jekyll) | Simple, blog-aware, static site generator for personal, project, or organization sites.  Renders Markdown or Textile and Liquid templates, and produces a complete, static website ready to be served by Apache HTTP Server, Nginx or another web server. |\n| [pelican](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#pelican) | Python-based alternative to Jekyll. |\n| [django](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#django) | High-level Python Web framework that encourages rapid development and clean, pragmatic design. It can be useful to share reports/analyses and for blogging. Lighter-weight alternatives include [Pyramid](https://github.com/Pylons/pyramid), [Flask](https://github.com/pallets/flask), [Tornado](https://github.com/tornadoweb/tornado), and [Bottle](https://github.com/bottlepy/bottle).\n\n## misc\n\nIPython Notebook(s) demonstrating miscellaneous functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [regex](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/misc/regex.ipynb) | Regular expression cheat sheet useful in data wrangling.|\n[algorithmia](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/misc/Algorithmia.ipynb) | Algorithmia is a marketplace for algorithms. This notebook showcases 4 different algorithms: Face Detection, Content Summarizer, Latent Dirichlet Allocation and Optical Character Recognition.|\n\n## notebook-installation\n\n### anaconda\n\nAnaconda is a free distribution of the Python programming language for large-scale data processing, predictive analytics, and scientific computing that aims to simplify package management and deployment.\n\nFollow instructions to install [Anaconda](https://docs.continuum.io/anaconda/install) or the more lightweight [miniconda](http://conda.pydata.org/miniconda.html).\n\n### dev-setup\n\nFor detailed instructions, scripts, and tools to set up your development environment for data analysis, check out the [dev-setup](https://github.com/donnemartin/dev-setup) repo.\n\n### running-notebooks\n\nNote: If you intend to learn the hard way (preferred method)then I\'d strongly advice to write as much code as you can yourself and not just run pre-written code. If you still want to test it, then do the following: \n\nTo view interactive content or to modify elements within the IPython notebooks, you must first clone or download the repository then run the notebook.  More information on IPython Notebooks can be found [here.](http://ipython.org/notebook.html)\n\n    $ git clone https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials.git\n    $ cd Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials\n    $ jupyter notebook\n    \n\nNotebooks tested with Python 2.7.x.(will soon be updated to Python 3.5+)\n\n## curated-list-of-deeplearning-blogs\n\n* A Blog From a Human-engineer-being http://www.erogol.com/ [(RSS)](http://www.erogol.com/feed/)\n* Aakash Japi http://aakashjapi.com/ [(RSS)](http://logicx24.github.io/feed.xml)\n* Adit Deshpande https://adeshpande3.github.io/ [(RSS)](https://adeshpande3.github.io/adeshpande3.github.io/feed.xml)\n* Advanced Analytics & R http://advanceddataanalytics.net/ [(RSS)](http://advanceddataanalytics.net/feed/)\n* Adventures in Data Land http://blog.smola.org [(RSS)](http://blog.smola.org/rss)\n* Agile Data Science http://blog.sense.io/ [(RSS)](http://blog.sense.io/rss/)\n* Ahmed El Deeb https://medium.com/@D33B [(RSS)](https://medium.com/feed/@D33B)\n* Airbnb Data blog http://nerds.airbnb.com/data/ [(RSS)](http://nerds.airbnb.com/feed/)\n* Alex Castrounis | InnoArchiTech http://www.innoarchitech.com/ [(RSS)](http://www.innoarchitech.com/feed.xml)\n* Alex Perrier http://alexperrier.github.io/ [(RSS)](http://alexperrier.github.io/feed.xml)\n* Algobeans | Data Analytics Tutorials & Experiments for the Layman https://algobeans.com [(RSS)](https://algobeans.com/feed/)\n* Amazon AWS AI Blog https://aws.amazon.com/blogs/ai/ [(RSS)](https://aws.amazon.com/blogs/amazon-ai/feed/)\n* Analytics Vidhya http://www.analyticsvidhya.com/blog/ [(RSS)](http://feeds.feedburner.com/AnalyticsVidhya)\n* Analytics and Visualization in Big Data @ Sicara https://blog.sicara.com [(RSS)](https://blog.sicara.com/feed)\n* Andreas M\xc3\xbcller http://peekaboo-vision.blogspot.com/ [(RSS)](http://peekaboo-vision.blogspot.com/atom.xml)\n* Andrej Karpathy blog http://karpathy.github.io/ [(RSS)](http://karpathy.github.io/feed.xml)\n* Andrew Brooks http://brooksandrew.github.io/simpleblog/ [(RSS)](http://brooksandrew.github.io/simpleblog/feed.xml)\n* Andrey Kurenkov http://www.andreykurenkov.com/writing/ [(RSS)](http://www.andreykurenkov.com/writing/feed.xml/)\n* Anton Lebedevich\'s Blog http://mabrek.github.io/ [(RSS)](http://mabrek.github.io/feed.xml)\n* Arthur Juliani https://medium.com/@awjuliani [(RSS)](https://medium.com/feed/@awjuliani)\n* Audun M. \xc3\x98ygard http://www.auduno.com/ [(RSS)](http://auduno.tumblr.com/rss)\n* Avi Singh https://avisingh599.github.io/ [(RSS)](http://avisingh599.github.io/feed.xml)\n* Beautiful Data http://beautifuldata.net/ [(RSS)](http://beautifuldata.net/feed/)\n* Beckerfuffle http://mdbecker.github.io/ [(RSS)](http://mdbecker.github.io/atom.xml)\n* Becoming A Data Scientist http://www.becomingadatascientist.com/ [(RSS)](http://www.becomingadatascientist.com/feed/)\n* Ben Bolte\'s Blog http://benjaminbolte.com/ml/ [(RSS)](http://benjaminbolte.com/ml/)\n* Ben Frederickson http://www.benfrederickson.com/blog/ [(RSS)](http://www.benfrederickson.com/atom.xml)\n* Berkeley AI Research http://bair.berkeley.edu/blog/ [(RSS)](http://bair.berkeley.edu/blog/feed.xml)\n* Big-Ish Data http://bigishdata.com/ [(RSS)](http://bigishdata.com/feed/)\n* Blog on neural networks http://yerevann.github.io/ [(RSS)](http://yerevann.github.io/atom.xml)\n* Blogistic RegressionAbout Projects http://d10genes.github.io/blog/ [(RSS)](http://d10genes.github.io/blog/feed.xml)\n* blogR | R tips and tricks from a scientist https://drsimonj.svbtle.com/ [(RSS)](https://drsimonj.svbtle.com/)\n* Brain of mat kelcey http://matpalm.com/blog/ [(RSS)](http://matpalm.com/blog/feed)\n* Brilliantly wrong thoughts on science and programming https://arogozhnikov.github.io/ [(RSS)](http://arogozhnikov.github.io/feed.xml)\n* Bugra Akyildiz http://bugra.github.io/ [(RSS)](http://bugra.github.io/feeds/all.atom.xml)\n* Building Babylon https://building-babylon.net/ [(RSS)](http://building-babylon.net/feed/)\n* Carl Shan http://carlshan.com/ [(RSS)](http://feeds.feedburner.com/carlshan)\n* Chris Stucchio https://www.chrisstucchio.com/blog/index.html [(RSS)](http://www.chrisstucchio.com/blog/atom.xml)\n* Christophe Bourguignat https://medium.com/@chris_bour [(RSS)](https://medium.com/feed/@chris_bour)\n* Christopher Nguyen https://medium.com/@ctn [(RSS)](https://medium.com/feed/@ctn)\n* Cloudera Data Science Posts http://blog.cloudera.com/blog/category/data-science/ [(RSS)](http://blog.cloudera.com/blog/category/data-science/feed/)\n* colah\'s blog http://colah.github.io/archive.html [(RSS)](http://colah.github.io/rss.xml)\n* Cortana Intelligence and Machine Learning Blog https://blogs.technet.microsoft.com/machinelearning/ [(RSS)](http://blogs.technet.com/b/machinelearning/rss.aspx)\n* Daniel Forsyth http://www.danielforsyth.me/ [(RSS)](http://www.danielforsyth.me/rss/)\n* Daniel Homola http://danielhomola.com/category/blog/ [(RSS)](http://danielhomola.com/feed/)\n* Daniel Nee http://danielnee.com [(RSS)](http://danielnee.com/?feed=rss2)\n* Data Based Inventions http://datalab.lu/ [(RSS)](http://datalab.lu/atom.xml)\n* Data Blogger https://www.data-blogger.com/ [(RSS)](https://www.data-blogger.com/feed/)\n* Data Labs http://blog.insightdatalabs.com/ [(RSS)](http://blog.insightdatalabs.com/rss/)\n* Data Meets Media http://datameetsmedia.com/ [(RSS)](http://datameetsmedia.com/feed/)\n* Data Miners Blog http://blog.data-miners.com/ [(RSS)](http://blog.data-miners.com/feeds/posts/default?alt=rss)\n* Data Mining Research http://www.dataminingblog.com/ [(RSS)](http://feeds.feedburner.com/dataminingblog)\n* Data Mining: Text Mining, Visualization and Social Media http://datamining.typepad.com/data_mining/ [(RSS)](http://datamining.typepad.com/data_mining/atom.xml)\n* Data Piques http://blog.ethanrosenthal.com/ [(RSS)](http://blog.ethanrosenthal.com/feeds/all.atom.xml)\n* Data School http://www.dataschool.io/ [(RSS)](http://www.dataschool.io/rss/)\n* Data Science 101 http://101.datascience.community/ [(RSS)](http://101.datascience.community/feed/)\n* Data Science @ Facebook https://research.facebook.com/blog/datascience/ [(RSS)](https://research.facebook.com/blog/datascience/)\n* Data Science Insights http://www.datasciencebowl.com/data-science-insights/ [(RSS)](http://www.datasciencebowl.com/feed/)\n* Data Science Tutorials https://codementor.io/data-science/tutorial [(RSS)](https://www.codementor.io/data-science/tutorial/feed)\n* Data Science Vademecum http://datasciencevademecum.wordpress.com/ [(RSS)](http://datasciencevademecum.wordpress.com/feed/)\n* Dataaspirant http://dataaspirant.com/ [(RSS)](http://dataaspirant.wordpress.com/feed/)\n* Dataclysm http://blog.okcupid.com/ [(RSS)](http://blog.okcupid.com/index.php/feed/)\n* DataGenetics http://datagenetics.com/blog.html [(RSS)](http://datagenetics.com/feed/rss.xml)\n* Dataiku https://www.dataiku.com/blog/ [(RSS)](http://www.dataiku.com/feed.xml)\n* DataKind http://www.datakind.org/blog [(RSS)](http://feeds.feedburner.com/DataKin)\n* DataLook http://blog.datalook.io/ [(RSS)](http://blog.datalook.io/feed/)\n* Datanice https://datanice.wordpress.com/ [(RSS)](https://datanice.wordpress.com/feed/)\n* Dataquest Blog https://www.dataquest.io/blog/ [(RSS)](https://www.dataquest.io/blog/atom.xml)\n* DataRobot http://www.datarobot.com/blog/ [(RSS)](http://www.datarobot.com/feed/)\n* Datascope http://datascopeanalytics.com/blog [(RSS)](http://datascopeanalytics.com/rss)\n* DatasFrame http://tomaugspurger.github.io/ [(RSS)](http://tomaugspurger.github.io/feeds/all.rss.xml)\n* David Mimno http://www.mimno.org/ [(RSS)](http://mimno.infosci.cornell.edu/b/feed.xml)\n* Dayne Batten http://daynebatten.com [(RSS)](http://daynebatten.com/feed/)\n* Deep Learning http://deeplearning.net/blog/ [(RSS)](http://deeplearning.net/feed/)\n* Deepdish http://deepdish.io/ [(RSS)](http://deepdish.io/atom.xml)\n* Delip Rao http://deliprao.com/ [(RSS)](http://deliprao.com/feed)\n* DENNY\'S BLOG http://blog.dennybritz.com/ [(RSS)](http://blog.dennybritz.com/feed/)\n* Dimensionless https://dimensionless.in/blog/ [(RSS)](https://dimensionless.in/feed)\n* Distill http://distill.pub/ [(RSS)](http://distill.pub/rss.xml)\n* District Data Labs http://districtdatalabs.silvrback.com/ [(RSS)](https://districtdatalabs.silvrback.com/feed)\n* Diving into data https://blog.datadive.net/ [(RSS)](http://blog.datadive.net/feed/)\n* Domino Data Lab\'s blog http://blog.dominodatalab.com/ [(RSS)](http://blog.dominodatalab.com/rss/)\n* Dr. Randal S. Olson http://www.randalolson.com/blog/ [(RSS)](http://www.randalolson.com/feed/)\n* Drew Conway https://medium.com/@drewconway [(RSS)](https://medium.com/feed/@drewconway)\n* Dustin Tran http://dustintran.com/blog/ [(RSS)](http://dustintran.com/blog/rss/)\n* Eder Santana https://edersantana.github.io/blog.html [(RSS)](http://edersantana.github.io/feed.xml)\n* Edwin Chen http://blog.echen.me [(RSS)](http://blog.echen.me/feeds/all.rss.xml)\n* EFavDB http://efavdb.com/ [(RSS)](http://efavdb.com/feed/)\n* Emilio Ferrara, Ph.D.  http://www.emilio.ferrara.name/ [(RSS)](http://www.emilio.ferrara.name/feed/)\n* Entrepreneurial Geekiness http://ianozsvald.com/ [(RSS)](http://ianozsvald.com/feed/)\n* Eric Jonas http://ericjonas.com/archives.html [(RSS)](http://ericjonas.com/archives.html)\n* Eric Siegel http://www.predictiveanalyticsworld.com/blog [(RSS)](http://feeds.feedburner.com/predictiveanalyticsworld/GXRy)\n* Erik Bern http://erikbern.com [(RSS)](http://erikbern.com/feed/)\n* ERIN SHELLMAN http://www.erinshellman.com/ [(RSS)](http://www.erinshellman.com/feed/)\n* Eugenio Culurciello http://culurciello.github.io/ [(RSS)](http://culurciello.github.io/feed.xml)\n* Fabian Pedregosa http://fa.bianp.net/ [(RSS)](http://fa.bianp.net/blog/feed/)\n* Fast Forward Labs http://blog.fastforwardlabs.com/ [(RSS)](http://blog.fastforwardlabs.com/rss)\n* FastML http://fastml.com/ [(RSS)](http://fastml.com/atom.xml)\n* Florian Hartl http://florianhartl.com/ [(RSS)](http://florianhartl.com/feed/)\n* FlowingData http://flowingdata.com/ [(RSS)](http://flowingdata.com/feed/)\n* Full Stack ML http://fullstackml.com/ [(RSS)](http://fullstackml.com/feed/)\n* GAB41 http://www.lab41.org/gab41/ [(RSS)](http://www.lab41.org/feed/)\n* Garbled Notes http://www.chioka.in/ [(RSS)](http://www.chioka.in/feed.xml)\n* Greg Reda http://www.gregreda.com/blog/ [(RSS)](http://www.gregreda.com/feeds/all.atom.xml)\n* Hyon S Chu https://medium.com/@adailyventure [(RSS)](https://medium.com/feed/@adailyventure)\n* i am trask http://iamtrask.github.io/ [(RSS)](http://iamtrask.github.io/feed.xml)\n* I Quant NY http://iquantny.tumblr.com/ [(RSS)](http://iquantny.tumblr.com/rss)\n* inFERENCe http://www.inference.vc/ [(RSS)](http://www.inference.vc/rss/)\n* Insight Data Science https://blog.insightdatascience.com/ [(RSS)](https://blog.insightdatascience.com/feed)\n* INSPIRATION INFORMATION http://myinspirationinformation.com/ [(RSS)](http://myinspirationinformation.com/feed/)\n* Ira Korshunova http://irakorshunova.github.io/ [(RSS)](http://irakorshunova.github.io/feed.xml)\n* I\xe2\x80\x99m a bandit https://blogs.princeton.edu/imabandit/ [(RSS)](https://blogs.princeton.edu/imabandit/feed/)\n* Jason Toy http://www.jtoy.net/ [(RSS)](http://jtoy.net/atom.xml)\n* Jeremy D. Jackson, PhD http://www.jeremydjacksonphd.com/ [(RSS)](http://www.jeremydjacksonphd.com/?feed=rss2)\n* Jesse Steinweg-Woods https://jessesw.com/ [(RSS)](https://jessesw.com/feed.xml)\n* Joe Cauteruccio http://www.joecjr.com/ [(RSS)](http://www.joecjr.com/feed/)\n* John Myles White http://www.johnmyleswhite.com/ [(RSS)](http://www.johnmyleswhite.com/feed/)\n* John\'s Soapbox http://joschu.github.io/ [(RSS)](http://joschu.github.io/feed.xml)\n* Jonas Degrave http://317070.github.io/ [(RSS)](http://317070.github.io/feed.xml)\n* Joy Of Data http://www.joyofdata.de/blog/ [(RSS)](http://www.joyofdata.de/blog/feed/)\n* Julia Evans http://jvns.ca/ [(RSS)](http://jvns.ca/atom.xml)\n* KDnuggets http://www.kdnuggets.com/ [(RSS)](http://feeds.feedburner.com/kdnuggets-data-mining-analytics)\n* Keeping Up With The Latest Techniques http://colinpriest.com/ [(RSS)](http://colinpriest.com/feed/)\n* Kenny Bastani http://www.kennybastani.com/ [(RSS)](http://www.kennybastani.com/feeds/posts/default?alt=rss)\n* Kevin Davenport http://kldavenport.com/ [(RSS)](http://kldavenport.com/feed/)\n* kevin frans http://kvfrans.com/ [(RSS)](http://kvfrans.com/rss/)\n* korbonits | Math \xe2\x88\xa9 Data http://korbonits.github.io/ [(RSS)](http://korbonits.github.io/feed.xml)\n* Large Scale Machine Learning  http://bickson.blogspot.com/ [(RSS)](http://bickson.blogspot.com/feeds/posts/default)\n* LATERAL BLOG https://blog.lateral.io/ [(RSS)](https://blog.lateral.io/feed/)\n* Lazy Programmer http://lazyprogrammer.me/ [(RSS)](http://lazyprogrammer.me/feed/)\n* Learn Analytics Here https://learnanalyticshere.wordpress.com/ [(RSS)](https://learnanalyticshere.wordpress.com/feed/)\n* LearnDataSci http://www.learndatasci.com/ [(RSS)](http://www.learndatasci.com/feed/)\n* Learning With Data http://learningwithdata.com/ [(RSS)](http://learningwithdata.com/rss_feed.xml)\n* Life, Language, Learning http://daoudclarke.github.io/ [(RSS)](http://daoudclarke.github.io/atom.xml)\n* Locke Data https://itsalocke.com/blog/ [(RSS)](https://itsalocke.com/feed)\n* Louis Dorard http://www.louisdorard.com/blog/ [(RSS)](http://www.louisdorard.com/blog?format=rss)\n* M.E.Driscoll http://medriscoll.com/ [(RSS)](http://medriscoll.com/rss)\n* Machinalis http://www.machinalis.com/blog [(RSS)](http://www.machinalis.com/blog/feeds/rss/)\n* Machine Learning (Theory) http://hunch.net/ [(RSS)](http://hunch.net/?feed=rss2)\n* Machine Learning and Data Science http://alexhwoods.com/blog/ [(RSS)](http://alexhwoods.com/feed/)\n* Machine Learning https://charlesmartin14.wordpress.com/ [(RSS)](http://charlesmartin14.wordpress.com/feed/)\n* Machine Learning Mastery http://machinelearningmastery.com/blog/ [(RSS)](http://machinelearningmastery.com/feed/)\n* Machine Learning Blogs https://machinelearningblogs.com/ [(RSS)](https://machinelearningblogs.com/feed/)\n* Machine Learning, etc http://yaroslavvb.blogspot.com [(RSS)](http://yaroslavvb.blogspot.com/feeds/posts/default)\n* Machine Learning, Maths and Physics https://mlopezm.wordpress.com/ [(RSS)](https://mlopezm.wordpress.com/feed/)\n* Machine Learning Flashcards https://machinelearningflashcards.com/ $10, but a nicely illustrated set of 300 flash cards\n* Machined Learnings http://www.machinedlearnings.com/ [(RSS)](http://www.machinedlearnings.com/feeds/posts/default)\n* MAPPING BABEL https://jack-clark.net/ [(RSS)](https://jack-clark.net/feed/)\n* MAPR Blog https://www.mapr.com/blog [(RSS)](https://www.mapr.com/bigdata.xml)\n* MAREK REI http://www.marekrei.com/blog/ [(RSS)](http://www.marekrei.com/blog/feed/)\n* MARGINALLY INTERESTING http://blog.mikiobraun.de/ [(RSS)](http://feeds.feedburner.com/MarginallyInteresting)\n* Math \xe2\x88\xa9 Programming http://jeremykun.com/ [(RSS)](http://jeremykun.wordpress.com/feed/)\n* Matthew Rocklin http://matthewrocklin.com/blog/ [(RSS)](http://matthewrocklin.com/blog/atom.xml)\n* Melody Wolk http://melodywolk.com/projects/ [(RSS)](http://melodywolk.com/feed/)\n* Mic Farris http://www.micfarris.com/ [(RSS)](http://www.micfarris.com/feed/)\n* Mike Tyka http://mtyka.github.io/ [(RSS)](http://mtyka.github.io//feed.xml)\n* minimaxir | Max Woolf\'s Blog http://minimaxir.com/ [(RSS)](http://minimaxir.com/rss.xml)\n* Mirror Image https://mirror2image.wordpress.com/ [(RSS)](http://mirror2image.wordpress.com/feed/)\n* Mitch Crowe http://www.dataphoric.com/ [(RSS)](http://www.dataphoric.com/feed.xml)\n* MLWave http://mlwave.com/ [(RSS)](http://mlwave.com/feed/)\n* MLWhiz http://mlwhiz.com/ [(RSS)](http://mlwhiz.com/atom.xml)\n* Models are illuminating and wrong https://peadarcoyle.wordpress.com/ [(RSS)](http://peadarcoyle.wordpress.com/feed/)\n* Moody Rd http://blog.mrtz.org/ [(RSS)](http://blog.mrtz.org/feed.xml)\n* Moonshots http://jxieeducation.com/ [(RSS)](http://jxieeducation.com/feed.xml)\n* Mourad Mourafiq http://mourafiq.com/ [(RSS)](http://mourafiq.com/atom.xml)\n* My thoughts on Data science, predictive analytics, Python http://shahramabyari.com/ [(RSS)](http://shahramabyari.com/feed/)\n* Natural language processing blog http://nlpers.blogspot.fr/ [(RSS)](http://nlpers.blogspot.com/feeds/posts/default)\n* Neil Lawrence http://inverseprobability.com/blog.html [(RSS)](http://inverseprobability.com/rss.xml)\n* NLP and Deep Learning enthusiast http://camron.xyz/ [(RSS)](http://camron.xyz/index.php/feed/)\n* no free hunch http://blog.kaggle.com/ [(RSS)](http://blog.kaggle.com/feed/)\n* Nuit Blanche http://nuit-blanche.blogspot.com/ [(RSS)](http://nuit-blanche.blogspot.com/feeds/posts/default)\n* Number 2147483647 https://no2147483647.wordpress.com/ [(RSS)](http://no2147483647.wordpress.com/feed/)\n* On Machine Intelligence https://aimatters.wordpress.com/ [(RSS)](https://aimatters.wordpress.com/feed/)\n* Opiate for the masses Data is our religion. http://opiateforthemass.es/ [(RSS)](http://opiateforthemass.es/feed.xml)\n* p-value.info http://www.p-value.info/ [(RSS)](http://www.p-value.info/feeds/posts/default)\n* Pete Warden\'s blog http://petewarden.com/ [(RSS)](http://feeds.feedburner.com/typepad/petewarden)\n* Plotly Blog http://blog.plot.ly/ [(RSS)](http://blog.plot.ly/rss)\n* Probably Overthinking It http://allendowney.blogspot.ca/ [(RSS)](http://allendowney.blogspot.com/feeds/posts/default)\n* Prooffreader.com http://www.prooffreader.com [(RSS)](http://www.prooffreader.com/feeds/posts/default)\n* ProoffreaderPlus http://prooffreaderplus.blogspot.ca/ [(RSS)](http://prooffreaderplus.blogspot.ca/feeds/posts/default)\n* Publishable Stuff http://www.sumsar.net/ [(RSS)](http://www.sumsar.net/atom.xml)\n* PyImageSearch http://www.pyimagesearch.com/ [(RSS)](http://feeds.feedburner.com/Pyimagesearch)\n* Pythonic Perambulations https://jakevdp.github.io/ [(RSS)](http://jakevdp.github.com/atom.xml)\n* quintuitive http://quintuitive.com/ [(RSS)](http://quintuitive.com/feed/)\n* R and Data Mining https://rdatamining.wordpress.com/ [(RSS)](http://rdatamining.wordpress.com/feed/)\n* R-bloggers http://www.r-bloggers.com/ [(RSS)](http://feeds.feedburner.com/RBloggers)\n* R2RT http://r2rt.com/ [(RSS)](http://r2rt.com/feeds/all.atom.xml)\n* Ramiro G\xc3\xb3mez http://ramiro.org/notebooks/ [(RSS)](http://ramiro.org/notebook/rss.xml)\n* Random notes on Computer Science, Mathematics and Software Engineering http://barmaley-exe.github.io/ [(RSS)](http://feeds.feedburner.com/barmaley-exe-blog-feed)\n* Randy Zwitch http://randyzwitch.com/ [(RSS)](http://randyzwitch.com/feed.xml)\n* RaRe Technologies http://rare-technologies.com/blog/ [(RSS)](http://rare-technologies.com/feed/)\n* Rayli.Net http://rayli.net/blog/ [(RSS)](http://rayli.net/blog/feed/)\n* Revolutions http://blog.revolutionanalytics.com/ [(RSS)](http://blog.revolutionanalytics.com/atom.xml)\n* Rinu Boney http://rinuboney.github.io/ [(RSS)](http://rinuboney.github.io/feed.xml)\n* RNDuja Blog http://rnduja.github.io/ [(RSS)](http://rnduja.github.io/feed.xml)\n* Robert Chang https://medium.com/@rchang [(RSS)](https://medium.com/feed/@rchang)\n* Rocket-Powered Data Science http://rocketdatascience.org [(RSS)](http://rocketdatascience.org/?feed=rss2)\n* Sachin Joglekar\'s blog https://codesachin.wordpress.com/ [(RSS)](https://codesachin.wordpress.com/feed/)\n* samim https://medium.com/@samim [(RSS)](https://medium.com/feed/@samim)\n* Sean J. Taylor http://seanjtaylor.com/ [(RSS)](http://seanjtaylor.com/rss)\n* Sebastian Raschka http://sebastianraschka.com/blog/index.html [(RSS)](http://sebastianraschka.com/rss_feed.xml)\n* Sebastian Ruder http://sebastianruder.com/ [(RSS)](http://sebastianruder.com/rss/)\n* Sebastian\'s slow blog http://www.nowozin.net/sebastian/blog/ [(RSS)](http://www.nowozin.net/sebastian/blog/feeds/all.atom.xml)\n* SFL Scientific Blog https://sflscientific.com/blog/ [(RSS)](http://sflscientific.com/blog/?format=rss)\n* Shakir\'s Machine Learning Blog http://blog.shakirm.com/ [(RSS)](http://blog.shakirm.com/feed/)\n* Simply Statistics http://simplystatistics.org [(RSS)](http://simplystatistics.org/feed/)\n* Springboard Blog http://springboard.com/blog\n* Startup.ML Blog http://startup.ml/blog [(RSS)](http://www.startup.ml/blog?format=RSS)\n* Statistical Modeling, Causal Inference, and Social Science http://andrewgelman.com/ [(RSS)](http://andrewgelman.com/feed/)\n* Stigler Diet http://stiglerdiet.com/ [(RSS)](http://stiglerdiet.com/feeds/all.atom.xml)\n* Stitch Fix Tech Blog http://multithreaded.stitchfix.com/blog/ [(RSS)](http://multithreaded.stitchfix.com/feed.xml)\n* Stochastic R&D Notes http://arseny.info/ [(RSS)](http://arseny.info/feeds/all.rss.xml)\n* Storytelling with Statistics on Quora http://datastories.quora.com/ [(RSS)](http://datastories.quora.com/rss)\n* StreamHacker http://streamhacker.com/ [(RSS)](http://feeds.feedburner.com/StreamHacker)\n* Subconscious Musings http://blogs.sas.com/content/subconsciousmusings/ [(RSS)](http://feeds.feedburner.com/advanalytics)\n* Swan Intelligence http://swanintelligence.com/ [(RSS)](http://swanintelligence.com/feeds/all.rss.xml)\n* TechnoCalifornia http://technocalifornia.blogspot.se/ [(RSS)](http://technocalifornia.blogspot.com/feeds/posts/default)\n* TEXT ANALYSIS BLOG | AYLIEN http://blog.aylien.com/ [(RSS)](http://blog.aylien.com/rss)\n* The Angry Statistician http://angrystatistician.blogspot.com/ [(RSS)](http://angrystatistician.blogspot.com/feeds/posts/default)\n* The Clever Machine https://theclevermachine.wordpress.com/ [(RSS)](http://theclevermachine.wordpress.com/feed/)\n* The Data Camp Blog https://www.datacamp.com/community/blog [(RSS)](http://blog.datacamp.com/feed/)\n* The Data Incubator http://blog.thedataincubator.com/ [(RSS)](http://blog.thedataincubator.com/feed/)\n* The Data Science Lab https://datasciencelab.wordpress.com/ [(RSS)](http://datasciencelab.wordpress.com/feed/)\n* THE ETZ-FILES http://alexanderetz.com/ [(RSS)](http://nicebrain.wordpress.com/feed/)\n* The Science of Data http://www.martingoodson.com [(RSS)](http://www.martingoodson.com/rss/)\n* The Shape of Data https://shapeofdata.wordpress.com [(RSS)](https://shapeofdata.wordpress.com/feed/)\n* The unofficial Google data science Blog http://www.unofficialgoogledatascience.com/ [(RSS)](http://www.unofficialgoogledatascience.com/feeds/posts/default)\n* Tim Dettmers http://timdettmers.com/ [(RSS)](http://timdettmers.com/feed/)\n* Tombone\'s Computer Vision Blog http://www.computervisionblog.com/ [(RSS)](http://www.computervisionblog.com/feeds/posts/default)\n* Tommy Blanchard http://tommyblanchard.com/category/projects [(RSS)](http://tommyblanchard.com/feeds/all.atom.xml)\n* Trevor Stephens http://trevorstephens.com/ [(RSS)](http://trevorstephens.com/feed.xml)\n* Trey Causey http://treycausey.com/ [(RSS)](http://treycausey.com/feeds/all.atom.xml)\n* UW Data Science Blog http://datasciencedegree.wisconsin.edu/blog/ [(RSS)](http://datasciencedegree.wisconsin.edu/feed/)\n* Wellecks http://wellecks.wordpress.com/ [(RSS)](http://wellecks.wordpress.com/feed/)\n* Wes McKinney http://wesmckinney.com/archives.html [(RSS)](http://wesmckinney.com/feeds/all.atom.xml)\n* While My MCMC Gently Samples http://twiecki.github.io/ [(RSS)](http://twiecki.github.io/atom.xml)\n* WildML http://www.wildml.com/ [(RSS)](http://www.wildml.com/feed/)\n* Will do stuff for stuff http://rinzewind.org/blog-en [(RSS)](http://rinzewind.org/feed-en)\n* Will wolf http://willwolf.io/ [(RSS)](http://willwolf.io/feed/)\n* WILL\'S NOISE http://www.willmcginnis.com/ [(RSS)](http://www.willmcginnis.com/feed/)\n* William Lyon http://www.lyonwj.com/ [(RSS)](http://www.lyonwj.com/atom.xml)\n* Win-Vector Blog http://www.win-vector.com/blog/ [(RSS)](http://www.win-vector.com/blog/feed/)\n* Yanir Seroussi http://yanirseroussi.com/ [(RSS)](http://yanirseroussi.com/feed/)\n* Zac Stewart http://zacstewart.com/ [(RSS)](http://zacstewart.com/feed.xml)\n* \xc5\xb7hat http://blog.yhat.com/ [(RSS)](http://blog.yhat.com/rss.xml)\n* \xe2\x84\x9auantitative \xe2\x88\x9aourney http://outlace.com/ [(RSS)](http://outlace.com/feed.xml)\n* \xe5\xa4\xa7\xe3\x83\x88\xe3\x83\xad http://blog.otoro.net/ [(RSS)](http://blog.otoro.net/feed.xml)\n\n\n## credits\n\n* [Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython](http://www.amazon.com/Python-Data-Analysis-Wrangling-IPython/dp/1449319793) by Wes McKinney\n* [PyCon 2015 Scikit-learn Tutorial](https://github.com/jakevdp/sklearn_pycon2015) by Jake VanderPlas\n* [Python Data Science Handbook](https://github.com/jakevdp/PythonDataScienceHandbook) by Jake VanderPlas\n* [Parallel Machine Learning with scikit-learn and IPython](https://github.com/ogrisel/parallel_ml_tutorial) by Olivier Grisel\n* [Statistical Interference Using Computational Methods in Python](https://github.com/AllenDowney/CompStats) by Allen Downey\n* [TensorFlow Examples](https://github.com/aymericdamien/TensorFlow-Examples) by Aymeric Damien\n* [TensorFlow Tutorials](https://github.com/pkmital/tensorflow_tutorials) by Parag K Mital\n* [TensorFlow Tutorials](https://github.com/nlintz/TensorFlow-Tutorials) by Nathan Lintz\n* [TensorFlow Tutorials](https://github.com/alrojo/tensorflow-tutorial) by Alexander R Johansen\n* [TensorFlow Book](https://github.com/BinRoot/TensorFlow-Book) by Nishant Shukla\n* [Summer School 2015](https://github.com/mila-udem/summerschool2015) by mila-udem\n* [Keras tutorials](https://github.com/leriomaggio/deep-learning-keras-tensorflow) by Valerio Maggio\n* [Kaggle](https://www.kaggle.com/)\n* [Yhat Blog](http://blog.yhat.com/)\n\n## contributing\n\nContributions are welcome!  For bug reports or requests please [submit an issue](https://github.com/tarrysingh/Machine-Learning-Tutorials//issues).\n\n## contact-info\n\nFeel free to contact me to discuss any issues, questions, or comments.\n\n* Email: [tarry.singh@gmail.com](mailto:tarry.singh@gmail.com)\n* Twitter: [@tarrysingh](https://twitter.com/tarrysingh)\n* GitHub: [tarrysingh](https://github.com/tarrysingh.com)\n* LinkedIn: [Tarry Singh](https://www.linkedin.com/in/tarrysingh)\n* Website: [tarrysingh.com](https://tarrysingh.com)\n* Medium: [tarry@Medium](https://medium.com/@tarrysingh)\n* Quora : [Answers from Tarry on Quora](https://www.quora.com/profile/Tarry-Singh)\n\n## license\n\nThis repository contains a variety of content; some developed by Tarry Singh and some from third-parties and a lot will be maintained by me. The third-party content is distributed under the license provided by those parties.\n\nThe content was originally developed by Donne Martin is distributed under the following license. I will be maintaining and revamping it by adding PyTorch, Torch/Lua, MXNET and much more:\n\n*I am providing code and resources in this repository to you under an open source license.*\n\n    Copyright 2017 Tarry Singh\n\n    Licensed under the Apache License, Version 2.0 (the ""License"");\n    you may not use this file except in compliance with the License.\n    You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n    Unless required by applicable law or agreed to in writing, software\n    distributed under the License is distributed on an ""AS IS"" BASIS,\n    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    See the License for the specific language governing permissions and\n    limitations under the License.\n'"
32,firmai/industry-machine-learning,firmai,A curated list of applied machine learning and data science notebooks and libraries across different industries (by @firmai),2019-05-03 05:08:15,2020-06-18 14:41:53,Jupyter Notebook,779,5206,"b'# Machine Learning and Data Science Applications in Industry\n\n### Admin\n\nHave a look at the newly started [FirmAI Medium](https://medium.com/firmai) publication where we have experts of AI in business, write about their topics of interest. \n\nOther FirmAI projects include **[DataGene](https://github.com/firmai/datagene)** for data similarity and comparison statistics, **[AtsPy](https://github.com/firmai/atspy)** automating Python\'s best time series models, **[MTSS-GAN](https://github.com/firmai/mtss-gan)**: multivariate time series simulation using generative adversarial learning, **[PandaPy](https://github.com/firmai/pandapy)** a data structure solutions that has the speed of NumPy and the usability of Pandas (10x to 50x faster), **[FairPut](https://github.com/firmai/fairput)** a holistic approach to implement fair machine learning outputs at the individual and group level, and **[PandasVault](https://github.com/firmai/pandasvault)** a package for advanced pandas functions and code snippets.\n\nIf you enjoy this repository, you would also like [google-colab-notebooks](https://github.com/firmai/google-colab-notebooks): Google Colaboratory End-to-End Notebooks and Repositories https://google-colab.com/. \n\n##### Also instead of ""watching""  you can **join** the link-letter, there is already about 8000 sign-ups, first email will be sent out Feb 2020. Monthly link-sharing list: https://mailchi.mp/ec4942d52cc5/firmai. \n\n---\n\nPlease add your tools and notebooks to this [Google Sheet](https://docs.google.com/spreadsheets/d/1pVdV3r4X3k5D1UtKbhMTmjU8mJTZSLAhJzycurgh_o4/edit?usp=sharing). Or simply add it to this subreddit, [r/datascienceproject](https://www.reddit.com/r/datascienceproject/) \n\nHighlight in **YELLOW** to get your package added, you can also just add it yourself with a **pull request**. \n\n<p align=""center"">\n  <img src=""https://github.com/firmai/industry-machine-learning/raw/master/assets/industry.png"">\n</p>\n\n\nA curated list of applied machine learning and data science notebooks and libraries accross different industries. The code in this repository is in Python (primarily using jupyter notebooks) unless otherwise stated. The catalogue is inspired by `awesome-machine-learning`. [r/datascienceproject](https://www.reddit.com/r/datascienceproject/) is a subreddit where you can share all your data science projects. \n\n***Caution:*** This is a work in progress, please contribute, especially if you are a subject expert in any of the industries listed below. If you are a **[**analytical, computational, statistical, quantitive**]** researcher/analyst in field **X** or a field **X** **[**machine learning engineer, data scientist, modeler, programmer**]** then your contribution will be greatly appreciated.   \n\n\nIf you want to contribute to this list (please do), send me a pull request or contact me [@dereknow](https://twitter.com/dereknow) or on [linkedin](https://www.linkedin.com/in/snowderek/) or get in contact on the website [FirmAI](https://www.firmai.org).\nAlso, a listed repository should be deprecated if:\n\n* Repository\'s owner explicitly say that ""this library is not maintained"".\n* Not committed for long time (2~3 years).\n\n</br>\n\n**Help Needed:** If there is any contributors out there willing to help first populate and then maintain a Python analytics section **in any one of the following sub/industries,** please get in contact with me. Also contact me to add **additional industries**. \n\n</br>\n\n| <!-- -->                         | <!-- -->                         | <!-- -->                          |\n| -------------------------------- | -------------------------------- | --------------------------------- |\n| [Accommodation & Food](#accommodation)             | [Agriculture](#agriculture)           | [Banking & Insurance](#bankfin)               |\n| [Biotechnological & Life Sciences](#biotech) | [Construction & Engineering](#construction)       | [Education & Research](#education)              |\n| [Emergency & Relief](#emergency)               | [Finance](#finance) | [Manufacturing](#manufacturing)             |\n| [Government and Public Works](#public)      | [Healthcare](#healthcare)  | [Media & Publishing](#media)                |\n| [Justice, Law and Regulations](#legal)      | [Miscellaneous](#miscellaneous)                    | [Accounting](#accounting) |\n| [Real Estate, Rental & Leasing](#realestate)    | [Utilities](#utilities)              | [Wholesale & Retail](#wholesale)                  |\n\n\n\n## Table of Contents\n\n### Industry Applications\n<!-- MarkdownTOC depth=4 -->\n\n- [Accommodation & Food](#accommodation)\n    - [Food](#accommodation-food)\n    - [Restaurant](#accommodation-rest)\n    - [Accommodation](#accommodation-acc)\n- [Accounting](#accounting)\n    - [Machine Learning](#accounting-ml)\n    - [Analytics](#accounting-analytics)\n    - [Textual Analysis](#accounting-text)\n    - [Data](#accounting-data)\n    - [Research and Articles](#accounting-ra)\n    - [Websites](#accounting-web)\n    - [Courses](#accounting-course)\n- [Agriculture](#agriculture)\n    - [Economics](#agriculture-econ)\n    - [Development](#agriculture-dev)\n- [Banking & Insurance](#bankfin)\n    - [Consumer Financial](#bankfin-cf)\n    - [Management and Operations](#bankfin-mo)\n    - [Valuation](#bankfin-value)\n    - [Fraud](#bankfin-fraud)\n    - [Insurance and Risk](#bankfin-ir)\n    - [Physical](#bankfin-ph)\n    - [Data](#bankfin-data)\n- [Biotechnological & Life Sciences](#biotech)\n    - [General](#biotech-general)\n    - [Sequencing](#biotech-seq)\n    - [Chemoinformatics and drug discovery](#biotech-chem)\n    - [Genomics](#biotech-gene)\n    - [Life-sciences](#biotech-life)  \n- [Construction & Engineering](#construction)\n    - [Construction](#construction-const)\n    - [Engineering](#construction-eng)\n    - [Material Science](#construction-mat)\n- [Economics](#economics)\n    - [General](#economics-general)\n    - [Machine Learning](#economics-ml)   \n    - [Computational](#economics-computational)   \n- [Education & Research](#education)\n    - [Student](#education-student)\n    - [School](#education-school)\n- [Emergency & Relief](#emergency)\n    - [Preventative and Reactive](#emergency-prevent)\n    - [Crime](#emergency-crime)\n    - [Ambulance](#emergency-ambulance)\n    - [Disaster Management](#emergency-disaster)\n- [Finance](#finance)\n    - [Trading & Investment](#finance-trade)\n    - [Data](#finance-data)\n- [Healthcare](#healthcare)\n    - [General](#healthcare-general)\n- [Justice, Law and Regulations](#legal)\n    - [Tools](#legal-tools)\n    - [Policy and Regulatory](#legal-pr)\n    - [Judicial](#legal-judicial)\n- [Manufacturing](#manufacturing)\n    - [General](#manufacturing-general)\n    - [Maintenance](#manufacturing-maintenance)\n    - [Failure](#manufacturing-fail)\n    - [Quality](#manufacturing-quality)\n- [Media & Publishing](#media)\n    - [Marketing](#media-marketing)\n- [Miscellaneous](#miscellaneous)\n    - [Art](#miscellaneous-art)\n    - [Tourism](#miscellaneous-tour)\n- [Physics](#physics)\n    - [General](#physics-general)\n    - [Machine Learning](#physics-ml)\n- [Government and Public Works](#public)\n    - [Social Policies](#public-social)\n    - [Election Analysis](#public-elect)\n    - [Disaster Management](#public-dis)\n    - [Politics](#public-poli)\n    - [Charities](#public-charity)\n- [Real Estate, Rental & Leasing](#realestate)\n    - [Real Estate](#realestate-real)\n    - [Rental & Leasing](#realestate-rental)\n- [Utilities](#utilities)\n    - [Electricity](#utilities-elect)\n    - [Coal, Oil & Gas](#utilities-coal)\n    - [Water & Pollution](#utilities-water)\n    - [Transportation](#utilities-transport)\n- [Wholesale & Retail](#wholesale)\n    - [Wholesale](#wholesale-whole)\n    - [Retail](#wholesale-retail)\n    \n\n<!-- /MarkdownTOC -->\n\n## ML/DS Career Section for Industry Machine Learning\nSee [data-science-career repo](https://github.com/firmai/data-science-career) for more. \n\n### Platforms:\n1. [Triplebyte](https://triplebyte.com/a/Nosq7GM/d) - Take a quiz. Get offers from multiple top tech companies at once (now have a machine learning track).\n1. [Toptal](https://www.toptal.com/) - Developers seeking to gain entry into the Toptal community are put through a battery of personality and technical tests.\n1. [Hired](https://hired.com/) - Hired matches employers with qualified candidates through a combination of in-house algorithms and online support.\n1. [Kaggle](https://www.kaggle.com/jobs) - Scalable Path is a premium talent matching service.\n\n### Reviews:\n\n- [Glassdoor](https://www.glassdoor.com/index.htm) - Best employee narratives.\n- [Indeed](https://www.indeed.com/) - Best coverage.\n- [Kununu](https://www.kununu.com/us) - Best well-rounded infromation.\n- [Comparably](https://www.comparably.com/) - Best comparison functionality. \n- [InHerSight](https://www.inhersight.com/) - Best female-friendly perspective.\n\n<a name=""accommodation""></a>\n## Accommodation & Food\n\n<a name=""accommodation-food""></a>\n**Food**\n\n- [RobotChef](https://github.com/bschreck/robo-chef) - Refining recipes based on user reviews.\n- [Food Amenities](https://github.com/Ankushr785/Food-amenities-demand-prediction) - Predicting the demand for food amenities using neural networks \n- [Recipe Cuisine and Rating](https://github.com/catherhuang/FP3-recipe) - Predict the rating and type of cuisine from a list of ingredients. \n- [Food Classification](https://github.com/stratospark/food-101-keras) - Classification using Keras. \n- [Image to Recipe](https://github.com/Murgio/Food-Recipe-CNN) - Translate an image to a recipe using deep learning. \n- [Calorie Estimation](https://github.com/jubins/DeepLearning-Food-Image-Recognition-And-Calorie-Estimation) - Estimate calories from photos of food. \n- [Fine Food Reviews](https://github.com/Architectshwet/Amazon-Fine-Food-Reviews) - Sentiment analysis on Amazon Fine Food Reviews. \n\n<a name=""accommodation-rest""></a>\n**Restaurant** \n\n- [Restaurant Violation](https://github.com/nd1/DC_RestaurantViolationForecasting) - Food inspection violation forecasting. \n- [Restaurant Success](https://github.com/alifier/Restaurant_success_model) - Predict whether a restaurant is going to fail. \n- [Predict Michelin](https://github.com/josephofiowa/dc-michelin-challenge/tree/master/submissions) - Predict the likelihood that restaurant is a Michelin restaurant. \n- [Restaurant Inspection](https://github.com/gzsuyu/Data-Analysis-NYC-Restaurant-Inspection-Data) - An inspection analysis to see if cleanliness is related to rating.\n- [Sales](https://github.com/ayeright/sales-forecast-lstm) - Restaurant sales forecasting with LSTM.\n- [Visitor Forecasting](https://github.com/anki1909/Recruit-Restaurant-Visitor-Forecasting) - Reservation and visitation number prediction. \n- [Restaurant Profit](https://github.com/everAspiring/RegressionAnalysis) - Restaurant regression analysis. \n- [Competition](https://github.com/klin90/missinglink) - Restaurant competitiveness analysis.\n- [Business Analysis](https://github.com/nvodoor/RBA) - Restaurant business analysis project.  \n- [Location Recommendation](https://github.com/sanatasy/Restaurant_Risk) - Restaurant location recommendation tool and analysis. \n- [Closure, Rating and Recommendation](https://github.com/Lolonon/Restaurant-Analytical-Solution)  -  Three prediction tasks using Yelp data. \n- [Anti-recommender](https://github.com/Myau5x/anti-recommender) - Find restaurants you don\xe2\x80\x99t want to attend. \n- [Menu Analysis](https://github.com/bzjin/menus) - Deeper analysis of restaurants through their menus. \n- [Menu Recommendation](https://github.com/rphaneendra/Menu-Similarity) - NLP to recommend restaurants with similar menus. \n- [Food Price](https://gist.github.com/analyticsindiamagazine/f9b2ba171a0eef9ad396ce6f1b83bbbc) - Predict food cost. \n- [Automated Restaurant Report](https://github.com/firmai/interactive-corporate-report) - Automated machine learning company report.\n\n<a name=""accommodation-acc""></a>\n**Accommodation** \n\n- [Peer-to-Peer Housing](https://github.com/rochiecuevas/shared_accommodations) - The effect of peer to peer  rentals on housing. \n- [Roommate Recommendation](https://github.com/SiddheshAcharekar/Liveright) - A system for students seeking roommates. \n- [Room Allocation](https://github.com/nus-usp/room-allocation) - Room allocation process. \n- [Dynamic Pricing](https://github.com/marcotav/hotels) - Hotel dynamic pricing calculations. \n- [Hotel Similarity](https://github.com/Montclair-State-University-Info368/Assignment-6) - Compare brands that directly compete\n- [Hotel Reviews](https://github.com/EliadProject/Hotels-Data-Science) - Cluster hotel reviews. \n- [Predict Prices](https://github.com/morenobcn/capstone_hotels_arcpy) - Predict hotel room rates. \n- [Hotels vs Airbnb](https://github.com/morenobcn/hotels_vs_airbnb_proof_of_concept) - Comparing the two approaches. \n- [Hotel Improvement](https://github.com/argha48/smarthotels) - Analyse reviews to suggest hotel improvements. \n- [Orders](https://github.com/Hasan330/Order-Cancellation-Prediction-Model) - Order  cancellation prediction for hotels. \n- [Fake Reviews](https://github.com/danielmachinelearning/HotelSpamDetection) - Identify whether reviews are fake/spam. \n- [Reverse Image Lodging](https://github.com/starfoe/Eye-bnb) - Find your preferred lodging by uploading an image. \n\n\n\n<a name=""accounting""></a>\n## Accounting\n\n<a name=""accounting-ml""></a>\n#### Machine Learning\n* [Chart of Account Prediction](https://github.com/agdgovsg/ml-coa-charging ) - Using labeled data to suggest the account name for every transaction.\n* [Accounting Anomalies](https://github.com/GitiHubi/deepAI/blob/master/GTC_2018_CoLab.ipynb) -  Using deep-learning frameworks to identify accounting anomalies.\n* [Financial Statement Anomalies](https://github.com/rameshcalamur/fin-stmt-anom) - Detecting anomalies before filing, using R.\n* [Useful Life Prediction (FirmAI)](http://www.firmai.org/documents/Aged%20Debtors/) - Predict the useful life of assets using sensor observations and feature engineering.\n* [AI Applied to XBRL](https://github.com/Niels-Peter/XBRL-AI) - Standardized representation of XBRL into AI and Machine learning.\n \n<a name=""accounting-analytics""></a>\n#### Analytics\n\n* [Forensic Accounting](https://github.com/mschermann/forensic_accounting) - Collection of case studies on forensic accounting using data analysis.  On the lookout for more data to practise forensic accounting, *please get in [touch](https://github.com/mschermann/)* \n* [General Ledger (FirmAI)](http://www.firmai.org/documents/General%20Ledger/) - Data processing over a general ledger as exported through an accounting system.\n* [Bullet Graph (FirmAI)](http://www.firmai.org/documents/Bullet-Graph-Article/) - Bullet graph visualisation helpful for tracking sales, commission and other performance.\n* [Aged Debtors (FirmAI)](http://www.firmai.org/documents/Aged%20Debtors/) - Example analysis to invetigate aged debtors.\n* [Automated FS XBRL](https://github.com/CharlesHoffmanCPA/charleshoffmanCPA.github.io) - XML Language, however, possibly port analysis into Python.\n\n<a name=""accounting-text""></a>\n#### Textual Analysis\n\n* [Financial Sentiment Analysis](https://github.com/EricHe98/Financial-Statements-Text-Analysis) - Sentiment, distance and proportion analysis for trading signals.\n* [Extensive NLP](https://github.com/TiesdeKok/Python_NLP_Tutorial/blob/master/NLP_Notebook.ipynb) - Comprehensive NLP techniques for accounting research.\n\n<a name=""accounting-data""></a>\n#### Data, Parsing and APIs\n\n* [EDGAR](https://github.com/TiesdeKok/UW_Python_Camp/blob/master/Materials/Session_5/EDGAR_walkthrough.ipynb) - A walk-through in how to obtain EDGAR data. \n* [PyEDGAR](https://github.com/gaulinmp/pyedgar) - A library for downloading, caching, and accessing EDGAR filings.\n* [IRS](http://social-metrics.org/sox/) - Acessing and parsing IRS filings.\n* [Financial Corporate](http://raw.rutgers.edu/Corporate%20Financial%20Data.html) - Rutgers corporate financial datasets.\n* [Non-financial Corporate](http://raw.rutgers.edu/Non-Financial%20Corporate%20Data.html) - Rutgers non-financial corporate dataset.\n* [PDF Parsing](https://github.com/danshorstein/python4cpas/blob/master/03_parsing_pdf_files/AR%20Aging%20-%20working.ipynb) - Extracting useful data from PDF documents. \n* [PDF Tabel to Excel](https://github.com/danshorstein/ficpa_article) - How to output an excel file from a PDF.\n\n<a name=""accounting-ra""></a>\n#### Research And Articles\n\n* [Understanding Accounting Analytics](http://social-metrics.org/accountinganalytics/) - An article that tackles the importance of accounting analytics.\n* [VLFeat](http://www.vlfeat.org/) - VLFeat is an open and portable library of computer vision algorithms, which has Matlab toolbox.\n\n<a name=""accounting-web""></a>\n#### Websites\n\n* [Rutgers Raw](http://raw.rutgers.edu/) - Good digital accounting research from Rutgers.\n\n<a name=""accounting-course""></a>\n#### Courses\n\n* [Computer Augmented Accounting](https://www.youtube.com/playlist?list=PLauepKFT6DK8TaNaq_SqZW4LIDJhCkZe2) - A video series from Rutgers University looking at the use of computation to improve accounting.\n* [Accounting in a Digital Era](https://www.youtube.com/playlist?list=PLauepKFT6DK8_Xun584UQPPsg1grYkWw0) - Another series by Rutgers investigating the effects the digital age will have on accounting.\n\n\n<a name=""agriculture""></a>\n## Agriculture\n\n<a name=""agriculture-econ""></a>\n**Economics**\n\n- [Prices](https://github.com/deadskull7/Agricultural-Price-Prediction-and-Visualization-on-Android-App) - Agricultural price prediction. \n- [Prices 2](https://github.com/Vipul115/Statistical-Time-Series-Analysis-on-Agricultural-Commodity-Prices)  - Agricultural price prediction.  \n- [Yield](https://github.com/DFS-UCU/UkrainianAgriculture) - Agricultural analysis looking at crop yields in Ukraine. \n- [Recovery](https://github.com/vicelab/slaer) - Strategic land use for agriculture and ecosystem recovery\n- [MPR](https://github.com/gumballhead/mpr) - Mandatory Price Reporting data from the USDA\'s Agricultural Marketing Service.\n\n<a name=""agriculture-dev""></a>\n**Development**\n\n- [Segmentation](https://github.com/chrieke/InstanceSegmentation_Sentinel2) - Agricultural field parcel segmentation using satellite images. \n- [Water Table](https://github.com/jfzhang95/LSTM-water-table-depth-prediction) - Predicting water table depth in agricultural areas. \n- [Assistant](https://github.com/surajmall/Agriculture-Assistant/tree/master/models) - Notebooks from agricultural assistant. \n- [Eco-evolutionary](https://github.com/tecoevo/agriculture) - Eco-evolutionary dynamics. \n- [Diseases](https://github.com/gauravmunjal13/Agriculture) - Identification of crop diseases and pests using Deep Learning framework from the images.\n- [Irrigation and Pest Prediction](https://github.com/divyam3897/agriculture) - Analyse irrigation and predict pest likelihood. \n\n\n\n<a name=""bankfin""></a>\n## Banking & Insurance\n\n<a name=""bankfin-cv""></a>\n#### Consumer Finance\n\n- [Loan Acceptance](https://github.com/Paresh3189/Bankruptcy-Prediction-Growth-Modelling) - Classification and time-series analysis for loan acceptance.\n- [Predict Loan Repayment](https://github.com/Featuretools/predict-loan-repayment) - Predict whether a loan will be repaid using automated feature engineering.\n- [Loan Eligibility Ranking](https://github.com/RealRadOne/Gyani-The-Loan-Eligibility-Predictor) - System to help the banks check if a customer is eligible for a given loan.\n- [Home Credit Default (FirmAI)](http://www.firmai.org/documents/Aggregator/#each-time-step-takes-30-seconds) - Predict home credit default.\n- [Mortgage Analytics](https://github.com/abuchowdhury/Mortgage_Bank_Loan_Analtsics/blob/master/Mortgage%20Bank%20Loan%20Analytics.ipynb) - Extensive mortgage loan analytics.\n- [Credit Approval](https://github.com/IBM-Cloud-DevFest-2018/Data-Science-for-Banking/blob/master/02-CreditCardApprovalModel/CreditCardApprovalModel.ipynb) - A system for credit card approval.\n- [Loan Risk](https://github.com/Brett777/Predict-Risk) - Predictive model to help to reduce charge-offs and losses of loans.\n- [Amortisation Schedule (FirmAI)](http://www.firmai.org/documents/Amortization%20Schedule/) - Simple amortisation schedule in python for personal use.\n\n\n<a name=""bankfin-mo""></a>\n#### Management and Operation\n\n- [Credit Card](https://github.com/am-aditya/Artificial-Intelligence-for-Banking/blob/master/03_ipy_notebooks/clv_prediction.ipynb) - Estimate the CLV of credit card customers.\n- [Survival Analysis](https://github.com/am-aditya/Artificial-Intelligence-for-Banking/blob/master/01_code/01_02_clv_survival/Survival_Analysis.py) - Perform a survival analysis of customers.\n- [Next Transaction](https://github.com/am-aditya/Artificial-Intelligence-for-Banking/blob/master/01_code/01_02_clv_survival/Customer_NextTransaction_Prediction.py) - Deep learning model to predict the transaction amount and days to next transaction.\n- [Credit Card Churn](https://github.com/am-aditya/Artificial-Intelligence-for-Banking/blob/master/01_code/01_02_clv_survival/Customer_NextTransaction_Prediction.py) - Predicting credit card customer churn.\n- [Bank of England Minutes](https://github.com/sekhansen/mpc_minutes_demo/blob/master/information_retrieval.ipynb) - Textual analysis over bank minutes.\n- [CEO](https://github.com/kaumaron/Data_Science/tree/master/CEO_Compensation) - Analysis of CEO compensation. \n\n<a name=""bankfin-value""></a>\n#### Valuation\n\n- [Zillow Prediction](https://github.com/eswar3/Zillow-prediction-models) - Zillow valuation prediction as performed on Kaggle.\n- [Real Estate](https://github.com/denadai2/real-estate-neighborhood-prediction) - Predicting real estate prices from the urban environment.\n- [Used Car](https://nbviewer.jupyter.org/github/albahnsen/PracticalMachineLearningClass/blob/master/exercises/P1-UsedVehiclePricePrediction.ipynb) - Used vehicle price prediction.\n\n\n<a name=""bankfin-fraud""></a>\n#### Fraud\n\n- [XGBoost](https://github.com/KSpiliop/Fraud_Detection) - Fraud Detection by tuning XGBoost hyper-parameters with Simulated Annealing\n- [Fraud Detection Loan in R](https://github.com/longtng/frauddetectionproject/blob/master/A%20Consideration%20Point%20of%20%20Fraud%20Detection%20in%20Bank%20Loans%20Project%20Code.ipynb) - Fraud detection in bank loans.\n- [AML Finance Due Diligence](https://github.com/Michaels72/AML-Due-Diligence/blob/master/AML_Finance_DD.ipynb) - Search news articles to do finance AML DD.\n- [Credit Card Fraud](https://github.com/am-aditya/Artificial-Intelligence-for-Banking/blob/master/03_ipy_notebooks/fraud_detection.ipynb) - Detecting credit card fraud.\n\n<a name=""bankfin-ir""></a>\n#### Insurance and Risk\n\n\n- [Car Damage Detective](https://github.com/neokt/car-damage-detective) - Assessing car damage with convolution neural networks for a personal auto *claims.*\n- [Medical Insurance Claims](https://github.com/roshank1605A04/Insurance-Claim-Prediction/blob/master/InsuranceClaim.ipynb) - Predicting medical insurance claims. \n- [Claim Denial](https://github.com/slegroux/claimdenial/blob/master/Claim%20Denial.ipynb) - Predicting insurance claim denial\n- [Claim Fraud](https://github.com/rshea3/alpha-insurance) -  Predictive models to determine which automobile claims are fraudulent. \n- [Claims Anomalies](https://github.com/dchannah/fraudhacker) - Anomaly detection system for medical insurance claims data.\n- [Actuarial Sciences (R)](https://github.com/JSchelldorfer/ActuarialDataScience) - A range of actuarial tools in R.\n- [Bank Failure](https://github.com/Shomona/Bank-Failure-Prediction/blob/master/Bank.ipynb) - Predicting bank failure.\n- [Risk Management](https://github.com/andrey-lukyanov/Risk-Management) - Finance risk engagement course resources.\n- [VaR GaN](https://github.com/hamaadshah/market_risk_gan_keras) - Estimate Value-at-Risk for market risk management using Keras and TensorFlow.\n- [Compliance](https://github.com/SaiBiswas/Bank-Grievance-Compliance-Management/blob/master/The%20Main%20File.ipynb) - Bank Grievance Compliance Management.  \n- [Stress Testing](https://github.com/apbecker/Systemic_Risk/blob/master/Generalized.ipynb) - ECB stress testing.\n- [Stress Testing Techniques](https://github.com/kaitai/stress-testing-with-jupyter/blob/master/Playing%20with%20financial%20data%20and%20Python%203.ipynb) - A notebook with various stress testing exercises. \n- [Reverse Stress Test](https://github.com/arcadynovosyolov/reverse_stress_testing/blob/master/reverse_stress_testing.ipynb) - Given a portfolio and a predefined loss size, determine which factors stress (scenarios) would lead to that loss\n- [BoE stress test](https://github.com/VankatPetr/BoE_stress_test/blob/master/BoE_stress_test_5Y_cummulative_imparment_charge.ipynb)- Stress test results and plotting. \n- [Recovery](https://github.com/hkacmaz/Bankin_Recovery/blob/master/Banking_Recovery.ipynb) - Recovery of money owed. \n- [Quality Control](https://github.com/mick-zhang/Quality-Control-for-Banking-using-LDA-and-LDA-Mallet) - Quality control for banking using LDA\n\n\n<a name=""bankfin-ph""></a>\n#### Physical\n\n* [Bank Note Fraud Detection](https://github.com/apoorv-goel/Bank-Note-Authentication-Using-DNN-Tensorflow-Classifier-and-RandomForest) - Bank Note Authentication Using DNN Tensorflow Classifier and RandomForest.\n* [ATM Surveillance](https://github.com/ShreyaGupta08/InfosysHack) - ATM Surveillance in banks use case.\n\n\n<a name=""biotech""></a>\n## Biotechnological & Life Sciences\n\n<a name=""biotech-general""></a>\n**General**\n\n- [Programming](https://github.com/burkesquires/python_biologist) - Python Programming for Biologists\n- [Introduction DL](https://colab.research.google.com/drive/17E4h5aAOioh5DiTo7MZg4hpL6Z_0FyWr) - A Primer on Deep Learning in Genomics\n- [Pose](https://github.com/talmo/leap) - Estimating animal poses using DL.\n- [Privacy](https://github.com/greenelab/SPRINT_gan) - Privacy preserving NNs for clinical data sharing. \n- [Population Genetics](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004845) - DL for population genetic inference. \n- [Bioinformatics Course](https://github.com/ricket-sjtu/bioinformatics) - Course materials for Computational *Biology*and Bioinformatics\n- [Applied Stats](https://github.com/waldronlab/AppStatBio) - Applied Statistics for High-Throughput *Biology*\n- [Scripts](https://github.com/mingzhangyang/Mybiotools) - Python scripts for biologists. \n- [Molecular NN](https://github.com/mitmedialab/Evolutron) - A mini-framework to build and train neural networks for molecular *biology*.\n- [Systems Biology Simulations](https://github.com/hallba/WritingSimulators) - Systems *biology* practical on writing simulators with F# and Z3\n- [Cell Movement](https://github.com/jrieke/lstm-biology) - LSTM to predict biological cell movement.\n- [Deepchem](https://github.com/deepchem/deepchem) - Democratizing Deep-Learning for Drug Discovery, Quantum Chemistry, Materials Science and Biology\n\n<a name=""biotech-seq""></a>\n**Sequencing** \n\n- [DNA, RNA and Protein Sequencing](https://github.com/ehsanasgari/Deep-Proteomics) - Anew representation for biological sequences using DL.\n- [CNN Sequencing](https://github.com/budach/pysster) - A toolbox for learning motifs from DNA/RNA sequence data using convolutional neural networks\n- [NLP Sequencing](https://github.com/hussius/deeplearning-biology) - Language transfer learning model for genomics\n\n<a name=""biotech-chem""></a>\n**Chemoinformatics and drug discovery**\n\n- [Novel Molecules](https://github.com/HIPS/neural-fingerprint) - A convolutional net that can learn features.\n- [Automating Chemical Design](https://github.com/aspuru-guzik-group/chemical_vae) - Generate new molecules for efficient exploration.\n- [GAN drug Discovery](https://github.com/gablg1/ORGAN) - A method that combines generative models with reinforcement learning.\n- [RL](https://github.com/MarcusOlivecrona/REINVENT) - generating compounds predicted to be active against a biological target.\n- [One-shot learning](https://github.com/deepchem/deepchem) - Python library that aims to make the use of machine-learning in drug discovery straightforward and convenient.\n\n<a name=""biotech-gene""></a>\n**Genomics**\n\n- [Jupyter Genomics](https://github.com/ucsd-ccbb/jupyter-genomics) -  Collection of computation biology and bioinformatics notebooks. \n- [Variant calling](https://github.com/google/deepvariant) - Correctly identify variations from the reference genome in an individual\'s DNA.\n- [Gene Expression Graphs](https://github.com/mila-iqia/gene-graph-conv) - Using convolutions on an image. \n- [Autoencoding Expression](https://github.com/greenelab/adage) - Extracting relevant patterns from large sets of gene expression data\n- [Gene Expression Inference](https://github.com/uci-cbcl/D-GEX) - Predict the expression of specified target genes from a panel of about 1,000 pre-selected \xe2\x80\x9clandmark genes\xe2\x80\x9d. \n- [Plant Genomics](https://github.com/widdowquinn/Teaching-EMBL-Plant-Path-Genomics) - Presentation and example material for *Plant* and Pathogen Genomics\n\n<a name=""biotech-life""></a>\n**Life-sciences**\n\n- [Plants Disease](https://github.com/viritaromero/Plant-diseases-classifier) - App that detects diseases in *plants* using a deep learning model.\n- [Leaf Identification](https://github.com/AayushG159/Plant-Leaf-Identification) - Identification of *plants* through *plant* leaves on the basis of their shape, color and texture.\n- [Crop Analysis](https://github.com/openalea/eartrack) - An imaging library to detect and track future position of ears on maize *plants*\n- [Seedlings](https://github.com/mfsatya/PlantSeedlings-Classification) - *Plant* Seedlings Classification from kaggle competition\n- [Plant Stress](https://github.com/Planteome/ontology-of-plant-stress) - An ontology containing plant stresses; biotic and abiotic.\n- [Animal Hierarchy](https://github.com/sacul-git/hierarpy) - Package for calculating *animal* dominance hierarchies.\n- [Animal Identification](https://github.com/A7med01/Deep-learning-for-Animal-Identification) - Deep learning for animal identification. \n- [Species](https://github.com/NomaanAhmed/BigData_AnimalSpeciesAnalysis) - Big Data analysis of different species of *animals*\n- [Animal Vocalisations](https://github.com/timsainb/AVGN) - A generative network for animal vocalizations\n- [Evolutionary](https://github.com/hardmaru/estool) - Evolution Strategies Tool\n- [Glaciers](https://github.com/OGGM/oggm-edu) - Educational material about glaciers.\n\n\n<a name=""construction""></a>\n## Construction & Engineering\n\n<a name=""construction-con""></a>\n**Construction**\n\n- [DL Architecture](https://github.com/carolineh101/deep-learning-architecture) - Deep learning classifier and image generator for building architecture.\n- [Construction Materials](https://github.com/damontallen/Construction-materials) - A course on construction materials. \n- [Bad Actor Risk Model](https://github.com/dariusmehri/Social-Network-Bad-Actor-Risk-Tool) - Risk model to improve construction related building safety\n- [Inspectors](https://github.com/dariusmehri/Tracking-Inspectors-with-Euclidean-Distance-Algorithm) - Determine the assigned inspections. \n- [Corrupt Social Interactions](https://github.com/dariusmehri/Social-Network-Analysis-to-Expose-Corruption) - Uncover potential corrupt social interactions between an industry member and the staff at the DOB\n- [Risk Construction](https://github.com/dariusmehri/Risk-Screening-Tool-to-Predict-Accidents-at-Construction-Sites) - Identify high risk construction. \n- [Facade Risk](https://github.com/dariusmehri/Algorithm-for-Finding-Buildings-with-Facade-Risk) - A risk model to predict unsafe facades.\n- [Staff Levels](https://github.com/dariusmehri/Predicting-Staff-Levels-for-Front-line-Workers) - Predicting staff levels for front line workers.  \n- [Injuries](https://github.com/dariusmehri/Topic-Modeling-and-Analysis-of-Building-Related-Injuries) - Building related injuries topic modelling. \n- [Building Violations](https://github.com/dariusmehri/Predictive-Analysis-of-Building-Violations) - Predictive analysis of building violations. \n- [Productivity](https://github.com/dariusmehri/Inspection-Productivity-Analysis-and-Visualization-with-Tableau) - Productivity analysis and inspection with Tableau. \n\n<a name=""construction-eng""></a>\n**Engineering:**\n\n- [Structural Analysis](https://github.com/ritchie46/anaStruct) - 2D Structural Analysis in Python. \n- [Structural Engineering](https://github.com/buddyd16/Structural-Engineering) - Structural engineering modules.\n- [Nusa](https://github.com/JorgeDeLosSantos/nusa) - Structural analysis using the finite element method.\n- [StructPy](https://github.com/BrianChevalier/StructPy) - Structural Analysis Library for Python based on the direct stiffness method\n- [Aileron](https://github.com/albiboni/AileronSimulation) - Structural analysis of the aileron of a Boeing 737\n- [Vibration](https://github.com/vibrationtoolbox/vibration_toolbox) - Educational vibration programs. \n- [Civil](https://github.com/ebrahimraeyat/Civil) - Collection of civil engineering tools in FreeCAD\n- [GEstimator](https://github.com/manuvarkey/GEstimator) - Simple civil estimation software\n- [Fatpack](https://github.com/Gunnstein/fatpack) - Functions and classes for fatigue analysis of data series.\n- [Pysteel](https://github.com/yajnab/pySteel) - Automated design of different steel structure \n- [Structural Uncertainty](https://github.com/davidsteinar/structural-uncertainty) - Quantifying structural uncertainty with deep learning.\n- [Pymech](https://github.com/jellespijker/pymech) - A Python module for mechanical engineers\n- [Aerospace Engineering](https://github.com/AlvaroMenduina/Jupyter_Notebooks/tree/master/Introduction_Aerospace_Engineering) - Astrodynamics and Statistics\n- [Interactive Quantum Chemistry](https://github.com/psi4/psi4numpy) - Combining Psi4 and Numpy for education and development.\n- [Chemical and Process Engineering](https://github.com/CAChemE/learn) - Various resources.\n- [PyTherm](https://github.com/iurisegtovich/PyTherm-applied-thermodynamics) - Applied Thermodynamics \n- [Aerogami](https://github.com/kshitizkhanal7/Aerogami) - Aerodynamics using planes.\n- [Electro geophysics](https://github.com/geoscixyz/em-apps) - Interactive applications for electromagnetics in geophysics\n- [Graph Signal](https://github.com/mdeff/pygsp_tutorial_graphsip) - Graph signal processing tutorial.\n- [Mechanical Vibrations](https://github.com/DocVaughan/MCHE485---Mechanical-Vibrations) -  Mechanical Vibrations at the Univsersity of Louisiana.\n- [Process Dynamics](https://github.com/OpenChemE/CHBE356) - Process Dynamics and Control\n- [Battery Life Cycle](https://github.com/rdbraatz/data-driven-prediction-of-battery-cycle-life-before-capacity-degradation) - Data driven prediction of batter life cycle. \n- [Wind Energy](https://github.com/DTUWindEnergy/Python4WindEnergy) - Python for wind energy\n- [Energy Use](https://github.com/openeemeter/eemeter/blob/master/scripts/tutorial.ipynb) - Standard methods for calculating normalized metered energy consumption\n- [Nuclear Radiation](https://github.com/HitarthiShah/Radiation-Data-Analysis) - How people are affected by radiations emitted by nuclear power plants\n\n\n<a name=""construction-mat""></a>\n**Material Science**\n\n\n- [Python Materials Genomics](https://github.com/materialsproject/pymatgen/) - Robust material analysis code used in a well-established project.\n- [Materials Mining](https://github.com/dchannah/materials_mining) - Scripts for simulations and analysis of materials.\n- [Emmet](https://github.com/materialsproject/emmet) - Build databases of material properties. \n- [Megnet](https://github.com/materialsvirtuallab/megnet) - Graph networks as a ML framework for Molecules and Crystals\n- [Atomate](https://github.com/hackingmaterials/atomate) - Pre-built workflows for computational material science.\n- [Bylaws Compliance](https://github.com/Mehranov/UnderstandingAndPredictingPropertyMaintenanceFines/blob/master/Assignment4_complete.ipynb) - Predicting property fines. \n- [Asphalt Binder](https://github.com/sierraporta/asphalt_binder) - Construction materials, free energy and chemical composition of asphalt binder.\n- [Steel](https://github.com/hbutsuak95/Quality-Optimization-of-Steel) - Optimisation of steel.\n- [Awesome Materials Informatics](https://github.com/tilde-lab/awesome-materials-informatics) - Curated list of known efforts in materials informatics.\n\n\n<a name=""economics""></a>\n## Economics\n\n<a name=""economics-general""></a>\n**General**\n\n- [Trading Economics API](https://github.com/tradingeconomics/tradingeconomics) -  Information for 196 countries.\n- [Development Economics](https://github.com/jhconning/Dev-II/tree/master/notebooks) - Development microeconomics are written mostly as interactive jupyter notebooks\n- [Applied Econ & Fin](https://github.com/lnsongxf/Applied_Computational_Economics_and_Finance/blob/master/Chapter05.ipynb) - Applied Computational Economics and Finance\n- [Macroeconomics](https://github.com/jlperla/ECON407_2018) - Topics in macroeconomics with notebook examples. \n\n<a name=""economics-ml""></a>\n**Machine Learning**\n\n- [EconML](https://github.com/microsoft/EconML) - Automated Learning and Intelligence for Causation and *Economics.*\n- [Auctions](https://github.com/saisrivatsan/deep-opt-auctions) - Optimal auctions using deep learning. \n\n<a name=""economics-comp""></a>\n**Computational**\n\n- [Quant Econ](https://github.com/jstac/quantecon_nyu_2016) - Quantitative economics course by NYU\n- [Computational](https://github.com/zhentaoshi/econ5170) - Computational methods in economics. \n- [Computational 2](https://github.com/QuantEcon/columbia_mini_course) - Small course in computational economics. \n- [Econometric Theory](https://github.com/jstac/econometrics/tree/master/notebooks) - Notebooks of A Primer on Econometric theory. \n\n<a name=""education""></a>\n## Education & Research\n\n<a name=""education-student""></a>\n**Student**\n\n- [Student Performance](https://github.com/roshank1605A04/Education-Process-Mining) - Mining student performance using machine learning. \n- [Student Performance 2](https://github.com/janzaib-masood/Educational-Data-Mining) - Student exam performance.\n- [Student Performance 3](https://github.com/RohithYogi/Student-Performance-Prediction) - Student achievement in secondary education.\n- [Student Performance 4](https://github.com/roshank1605A04/Students-Performance-Analytics) - Students Performance Evaluation using Feature Engineering\n- [Student Intervention](https://github.com/eloyekunle/student_intervention/blob/master/student_intervention.ipynb) - Building a student intervention system. \n- [Student Enrolment](https://github.com/arrahman17/Learning-Analytics-Project-) - Student enrolment and performance analysis. \n- [Academic Performance](https://github.com/janzaib-masood/Educational-Data-Mining) - Explore the demographic and family features that have an impact a student\'s academic performance. \n- [Grade Analysis](https://github.com/kaumaron/Data_Science/tree/master/Grade_Analysis) - Student achievement analysis. \n\n<a name=""education-school""></a>\n**School**\n\n- [School Choice](https://github.com/nprapps/school-choice) - Data analysis for education\'s school choice.\n- [School Budgets and Priorities](https://github.com/tullyvelte/SchoolPerformanceDataAnalysis) - Helping the school board and mayor make strategic decisions regarding future school budgets and priorities\n- [School Performance](https://github.com/bradleyrobinson/School-Performance) - Data analysis practice using data from data.utah.gov on school performance.\n- [School Performance 2](https://github.com/vtyeh/pandas-challenge) - Using pandas to analyze school and student performance within a district\n- [School Performance 3](https://github.com/benattix/philly-schools) - Philadelphia School Performance\n- [School Performance 4](https://github.com/adrianakopf/NJPublicSchools) - NJ School Performance\n- [School Closure](https://github.com/whugue/school-closure) - Identify schools at risk for closure by performance and other characteristics.\n- [School Budgets](https://github.com/datacamp/course-resources-ml-with-experts-budgets/blob/master/notebooks/1.0-full-model.ipynb) - Tools and techniques for school budgeting. \n- [School Budgets](https://github.com/nymarya/school-budgets-for-education/tree/master/notebooks) - Same as a above, datacamp. \n- [PyCity](https://github.com/JonathanREB/Budget_SchoolsAnalysis/blob/master/PyCitySchools_starter.ipynb) - School analysis. \n- [PyCity 2](https://github.com/1davegalloway/SchoolDistrictAnalysis)  - School budget vs school results. \n- [Budget NLP](https://github.com/jinsonfernandez/NLP_School-Budget-Project) - NLP classification for budget resources. \n- [Budget NLP 2](https://github.com/DivyaMadhu/School-Budget-Prediction) - Further classification exercise. \n- [Budget NLP 3](https://github.com/sushant2811/SchoolBudgetData/blob/master/SchoolBudgetData.ipynb) - Budget classification. \n- [Survey Analysis](https://github.com/kaumaron/Data_Science/tree/master/Education) - Education survey analysis. \n\n<a name=""emergency""></a>\n## Emergency & Police\n\n<a name=""emergency-prevent""></a>\n**Preventative and Reactive**\n\n- [Emergency Mapping](https://github.com/aeronetlab/emergency-mapping) -  Detection of destroyed houses in California \n- [Emergency Room](https://github.com/roshetty/Supporting-Emergency-Room-Decision-Making-with-Relevant-Scientific-Literature) -  Supporting em*ergency r*oom decision making\n- [Emergency Readmission](https://github.com/mesgarpour/T-CARER) - Adjusted Risk of *Emergency* Readmission. \n- [Forest Fire](https://github.com/LeadingIndiaAI/Forest-Fire-Detection-through-UAV-imagery-using-CNNs) - Forest fire detection through UAV imagery using CNNs\n- [Emergency Response](https://github.com/sky-t/hack-or-emergency-response) - Emergency response analysis. \n- [Emergency Transportation](https://github.com/bayesimpact/bayeshack-transportation-ems) - Transportation prompt on *emergency* services\n- [Emergency Dispatch](https://github.com/jamesypeng/Smarter-Emergency-Dispatch) - Reducing response times with predictive modeling, optimization, and automation\n- [Emergency Calls](https://github.com/analystiu/LICT-Project-Emergency-911-Calls) - Emergency calls analysis project. \n- [Calls Data Analysis](https://github.com/tanoybhattacharya/911-Data-Analysis) - 911 data analysis. \n- [Emergency Response](https://github.com/amunategui/Leak-At-Chemical-Factory-RL) - Chemical factory RL. \n\n<a name=""emergency-crime""></a>\n**Crime**\n\n- [Crime Classification](https://github.com/datadesk/lapd-crime-classification-analysis) -  Times analysis of serious assaults misclassified by LAPD.\n- [Article Tagging](https://github.com/chicago-justice-project/article-tagging) - Natural Language Processing of Chicago news article\n- [Crime Analysis](https://github.com/chrisPiemonte/crime-analysis) - Association Rule Mining from Spatial Data for *Crime* Analysis\n- [Chicago Crimes](https://github.com/search?o=desc&q=crime+language%3A%22Jupyter+Notebook%22+NOT+%22taxi%22+NOT+%22baseline%22&s=stars&type=Repositories) - Exploring public Chicago *crimes* data set in Python\n- [Graph Analytics](https://github.com/pedrohserrano/graph-analytics-nederlands) - The Hague Crimes.\n- [Crime Prediction](https://github.com/vikram-bhati/PAASBAAN-crime-prediction) - *Crime* classification, analysis & prediction in Indore city.\n- [Crime Prediction](https://github.com/tina31726/Crime-Prediction) - Developed predictive models for *crime* rate.\n- [Crime Review](https://github.com/felzek/Crime-Review-Data-Analysis) - Crime review data analysis. \n- [Crime Trends](https://github.com/benjaminsingleton/crime-trends) -  The *Crime* Trends Analysis Tool analyses *crime* trends and surfaces problematic *crime* conditions\n- [Crime Analytics](https://github.com/cmenguy/crime-analytics) - Analysis of *crime* data in Seattle and San Francisco.\n\n<a name=""emergency-ambulance""></a>\n**Ambulance:**\n\n- [Ambulance Analysis](https://github.com/kaiareyes/ambulance) - An investigation of Local Government Area ambulance time variation in Victoria.\n- [Site Location](https://github.com/ankitkariryaa/ambulanceSiteLocation) - Ambulance site locations. \n- [Dispatching](https://github.com/DimaStoyanov/Ambulance-Dispatching) - Applying game theory and discrete event simulation to find optimal solution for ambulance dispatching\n- [Ambulance Allocation](https://github.com/scngo/SD-ambulance-allocation) - Time series analysis of ambulance dispatches in the City of San Diego.\n- [Response Time](https://github.com/nonsignificantp/ambulance-response-time) - An analysis on the improvements of ambulance response time.\n- [Optimal Routing](https://github.com/aditink/EMSRouting) - Project to find optimal routing of ambulances in Ithaca.\n- [Crash Analysis](https://github.com/ArpitVora/Maryland_Crash) - Predicting the probability of accidents on a given segment on a given time.\n\n\n<a name=""emergency-disaster""></a>\n**Disaster Management**\n\n- [Conflict Prediction](https://github.com/Polichinel/Master_Thesis) - Notebooks on conflict prediction.\n- [Burglary Prediction](https://github.com/Polichinel/Master_Thesis) - Spatio-Temporal Modelling for burglary prediction.\n- [Predicting Disease Outbreak](https://github.com/ab-bh/Disease-Outbreak-Prediction/blob/master/Disease%20Outbreak%20Prediction.ipynb) - Machine Learning implementation based on multiple classifier algorithm implementations.\n- [Road accident prediction](https://github.com/leportella/federal-road-accidents) - Prediction on type of victims on federal road accidents in Brazil.\n- [Text Mining](https://github.com/rajaswa/Disaster-Management-) - Disaster Management using Text mining.\n- [Twitter and disasters](https://github.com/paultopia/concrete_NLP_tutorial/blob/master/NLP_notebook.ipynb) - Try to correctly predict whether tweets that are about disasters.\n- [Flood Risk](https://github.com/arijitsaha/FloodRisk) -  Impact of catastrophic flood events.\n- [Fire Prediction](https://github.com/Senkichi/The_Catastrophe_Coefficient) - We used 4 different algorithms to predict the likelihood of future fires.\n\n\n<a name=""finance""></a>\n## Finance\n\n<a name=""finance-trading""></a>\n**Trading and Investment** \n- For **more** see [financial-machine-learning](https://github.com/firmai/financial-machine-learning)\n- For **asset management** see [financial-machine-learning](https://github.com/firmai/machine-learning-asset-management)\n- [Deep Portfolio](https://github.com/DLColumbia/DL_forFinance) - Deep learning for finance Predict volume of bonds.\n- [AI Trading](https://github.com/borisbanushev/stockpredictionai/blob/master/readme2.md) - Modern AI trading techniques.\n- [Corporate Bonds](https://github.com/ishank011/gs-quantify-bond-prediction) - Predicting the buying and selling volume of the corporate bonds.\n- [Simulation](https://github.com/chenbowen184/Computational_Finance) - Investigating simulations as part of computational finance.\n- [Industry Clustering](https://github.com/SeanMcOwen/FinanceAndPython.com-ClusteringIndustries) - Project to cluster industries according to financial attributes.\n- [Financial Modeling](https://github.com/MiyainNYC/Financial-Modeling/tree/master/codes) - HFT trading and implied volatility modeling.\n- [Trend Following](http://inseaddataanalytics.github.io/INSEADAnalytics/ExerciseSet2.html) - A futures trend following portfolio investment strategy.\n- [Financial Statement Sentiment](https://github.com/MAydogdu/TextualAnalysis) - Extracting sentiment from financial statements using neural networks.\n- [Applied Corporate Finance](https://github.com/chenbowen184/Data_Science_in_Applied_Corporate_Finance) - Studies the empirical behaviors in stock market.\n- [Market Crash Prediction](https://github.com/sarachmax/MarketCrashes_Prediction/blob/master/LPPL_Comparasion.ipynb) - Predicting market crashes using an LPPL model.\n- [NLP Finance Papers](https://github.com/chenbowen184/Research_Documents_Curation_with_NLP) - Curating quantitative finance papers using machine learning.\n- [ARIMA-LTSM Hybrid](https://github.com/imhgchoi/Corr_Prediction_ARIMA_LSTM_Hybrid) - Hybrid model to predict future price correlation coefficients of two assets\n- [Basic Investments](https://github.com/SeanMcOwen/FinanceAndPython.com-Investments) - Basic investment tools in python.\n- [Basic Derivatives](https://github.com/SeanMcOwen/FinanceAndPython.com-Derivatives) - Basic forward contracts and hedging.\n- [Basic Finance](https://github.com/SeanMcOwen/FinanceAndPython.com-BasicFinance) - Source code notebooks basic finance applications.\n- [Advanced Pricing ML](https://github.com/jjakimoto/finance_ml) - Additional implementation of Advances in Financial Machine Learning (Book)\n- [Options and Regression](https://github.com/aluo417/Financial-Engineering-Projects) - Financial engineering project for option pricing techniques. \n- [Quant Notebooks](https://github.com/LongOnly/Quantitative-Notebooks) - Educational notebooks on quant finance, algorithmic trading and investment strategy. \n- [Forecasting Challenge](https://github.com/bukosabino/financial-forecasting-challenge-gresearch) - Financial forecasting challenge by G-Research (Hedge Fund)\n- [XGboost](https://github.com/firmai?after=Y3Vyc29yOnYyOpK5MjAxOS0wNS0wMlQwNToyMzoyMSswMTowMM4KBjIV&tab=stars) - A trading algorithm using XgBoost\n- [Research Paper Trading](https://github.com/rawillis98/alpaca) - A strategy implementation based on a paper using Alpaca Markets. \n- [Various](https://github.com/arcadynovosyolov/finance) - Options, Allocation, Simulation \n- [ML & RL NYU](https://github.com/joelowj/Machine-Learning-and-Reinforcement-Learning-in-Finance) - Machine Learning and Reinforcement Learning in Finance. \n\n\n<a name=""finance-data""></a>\n**Data**\n\n- [Datastream](https://github.com/mbravidor/PyDSout) - Datastrem from Thomson Reuters accessible through Python. \n- [AlphaVantage](http://twopirllc) - API wrapper to simplify the process of acquiring free financial data.\n- [FSA](https://github.com/duncangh/FSA)- A project to transfer SEC Edgar Filings\xe2\x80\x99 financial data to custom financial statement analysis models. \n- [TradeConnector](https://github.com/tradeasystems/tradeasystems_connector) - A layer to connect with market data providers. \n- [Employee Count SEC Filings](https://github.com/healthgradient/sec_employee_information_extraction) - Extraction to get the exact employee count values for companies from SEC filings.\n- [SEC Parsing](https://github.com/healthgradient/sec-doc-info-extraction/blob/master/classify_sections_containing_relevant_information.ipynb) -  NLP to find and extract specific information from long, unstructured documents\n- [Open Edgar](https://github.com/LexPredict/openedgar) - OpenEDGAR (openedgar.io)\n- [Rating Industries](http://www.ratingshistory.info/) - Histories from multiple agencies converted to CSV format\n\n**Personal Papers**\n\n- [Financial Machine Learning Regulation](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3371902)\n- [Predicting Restaurant Facility Closures](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3420490)\n- [Predicting Corporate Bankruptcies](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3420889)\n- [Predicting Earnings Surprises](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3420722) \n- [Machine Learning in Asset Management](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3420952) \n\n\n<a name=""healtcare""></a>\n## Healthcare\n\n<a name=""healtcare-general""></a>\n**General**\n\n- [zEpid](https://github.com/pzivich/zEpid)  - Epidemiology analysis package.\n- [Python For Epidemiologists](https://github.com/pzivich/Python-for-Epidemiologists) - Tutorial to introduce epidemiology analysis in Python. \n- [Prescription Compliance](https://github.com/rjhere/Prescription-compliance-prediction) - An analysis of prescription and medical compliance \n- [Respiratory Disease](https://github.com/alistairwallace97/olympian-biotech) -  Tracking respiratory diseases in Olympic athletes\n- [Bubonic Plague](https://github.com/callysto/curriculum-notebooks/blob/master/Humanities/BubonicPlague/bubonic-plague-and-SIR-model.ipynb) - Bubonic plague and SIR model. \n\n\n\n<a name=""legal""></a>\n## Justics, Law & Regulations\n\n\n<a name=""legal-tools""></a>\n#### Tools\n- [LexPredict](https://github.com/LexPredict/lexpredict-contraxsuite) - Software package and library.\n- [AI Para-legal](https://github.com/davidawad/lobe) - Lobe is the world\'s first AI paralegal.\n- [Legal Entity Detection](https://github.com/hockeyjudson/Legal-Entity-Detection/blob/master/Dataset_conv.ipynb) - NER For Legal Documents.\n- [Legal Case Summarisation](https://github.com/Law-AI/summarization) - Implementation of different summarisation algorithms applied to legal case judgements.\n- [Legal Documents Google Scholar](https://github.com/GirrajMaheshwari/Web-scrapping-/blob/master/Google_scholar%2BExtract%2Bcase%2Bdocument.ipynb) - Using Google scholar to extract cases programatically.\n- [Chat Bot](https://github.com/akarazeev/LegalTech) - Chat-bot and email notifications.\n- [Congress API](https://github.com/propublica/congress-api-docs) - ProPublica congress API access. \n- [Data Generator GDPR](https://github.com/toningega/Data_Generator) - Dummy data generator for GDPR compliance\n- [Blackstone](https://github.com/ICLRandD/Blackstone) - spaCy pipeline and model for NLP on unstructured legal text.\n\n\n<a name=""legal-pr""></a>\n#### Policy and Regulatory\n- [GDPR scores](https://github.com/erickjtorres/AI_LegalDoc_Hackathon) - Predicting GDPR Scores for Legal Documents.\n- [Driving Factors FINRA](https://github.com/siddhantmaharana/text-analysis-on-FINRA-docs) - Identify the driving factors that influence the FINRA arbitration decisions.\n- [Securities Bias Correction](https://github.com/davidsontheath/bias_corrected_estimators/blob/master/bias_corrected_estimators.ipynb) - Bias-Corrected Estimation of Price Impact in Securities Litigation.\n- [Public Firm to Legal Decision](https://github.com/anshu3769/FirmEmbeddings) - Embed public firms based on their reaction to legal decisions.\n- [Night Life Regulation](https://github.com/Kevin-McIsaac/Nightlife) - Australian nightlife and its regulation and policing\n- [Comments](https://github.com/ProximaDas/nlp-govt-regulations) - Public comments on government regulations. \n- [Clustering](https://github.com/philxchen/Clustering-Canadian-regulations) - Clustering Canadian regulations. \n- [Environment](https://github.com/ds-modules/EEP-147) - Regulation of Energy and the Environment\n- [Risk](https://github.com/vsub21/systemic-risk-dashboard) - Systematic risk of various financial regulations.\n- [FINRA Compliance](https://github.com/raymond180/FINRA_TRACE) - Topic modelling on compliance. \n\n\n<a name=""legal-judicial""></a>\n#### Judicial Applied\n- [Supreme Court Prediction](https://github.com/davidmasse/US-supreme-court-prediction) - Predicting the ideological direction of Supreme Court decisions: ensemble vs. unified case-based model.\n- [Supreme Court Topic Modeling](https://github.com/AccelAI/AI-Law-Minicourse/tree/master/Supreme_Court_Topic_Modeling) - Multiple steps necessary to implement topic modeling on supreme court decisions.\n- [Judge Opinion](https://github.com/GirrajMaheshwari/Legal-Analytics-project---Court-misclassification) - Using text mining and machine learning to analyze judges\xe2\x80\x99 opinions for a particular concern.\n- [ML Law Matching](https://github.com/whs2k/GPO-AI) - A machine learning law match maker.\n- [Bert Multi-label Classification](https://github.com/brightmart/sentiment_analysis_fine_grain) - Fine Grained Sentiment Analysis from AI.\n- [Some Computational AI Course](https://www.youtube.com/channel/UC5UHm2J9pbEZmWl97z_0hZw) - Video series Law MIT.\n- [Financial Machine Learning Regulation (Paper)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3371902)\n\n\n<a name=""manufacturing""></a>\n## Manufacturing\n\n<a name=""manufacturing-general""></a>\n**General**\n\n- [Green Manufacturing](https://github.com/Danila89/kaggle_mercedes) - Mercedes-Benz Greener *Manufacturing* competition on Kaggle. \n- [Semiconductor Manufacturing](https://github.com/Meena-Mani/SECOM_class_imbalance) - Semicondutor *manufacturing* process line data analysis. \n- [Smart Manufacturing](https://github.com/usnistgov/modelmeth) - Shared work of a modelling Methodology.\n- [Bosch Manufacturing](https://github.com/han-yan-ds/Kaggle-Bosch) - Bosch manufacturing project, Kaggle. \n\n<a name=""manufacturing-maintenance""></a>\n**Maintenance**\n\n- [Predictive Maintenance](https://github.com/Azure/lstms_for_predictive_maintenance) 1 - Predict remaining useful life of aircraft engines\n- [Predictive Maintenance 2](https://github.com/Samimust/predictive-maintenance) - Time-To-Failure (TTF) or Remaining Useful Life (RUL) \n- [Manufacturing Maintenance](https://github.com/m-hoff/maintsim) - Simulation of maintenance in *manufacturing* systems. \n\n<a name=""manufacturing-fail""></a>\n**Failure**\n\n- [Predictive Analytics](https://github.com/IBM/iot-predictive-analytics) - Method for Predicting failures in Equipment using Sensor data.\n- [Detecting Defects](https://github.com/roshank1605A04/SECOM-Detecting-Defected-Items)  - Anomaly detection for defective semiconductors\n- [Defect Detection](https://github.com/jorgehas/smart-defect-inspection) - Smart defect detection for pill manufacturing. \n- [Manufacturing Failures](https://github.com/aayushmudgal/Reducing-Manufacturing-Failures) - Reducing manufacturing failures. \n- [Manufacturing Anomalies](https://github.com/mohan-mj/Manufacturing-Line-I4.0) - Intelligent anomaly detection for *manufacturing* line. \n\n<a name=""manufacturing-quality""></a>\n**Quality**\n\n- [Quality Control](https://github.com/buzz11/productionFailures) - Bosh failure of quality control. \n- [Manufacturing Quality](https://github.com/limberc/tianchi-IMQF) - Intelligent *Manufacturing* Quality Forecast \n- [Auto Manufacturing](https://github.com/trentwoodbury/ManufacturingAuctionRegression) -  Regression Case Study Project on *Manufacturing* Auction Sale Data.\n\n\n<a name=""media""></a>\n## Media & Publishing\n\n<a name=""media-marketing""></a>\n**Marketing**\n\n- [Video Popularity](https://github.com/andrei-rizoiu/hip-popularity) - HIP model for predicting the popularity of videos.\n- [YouTube transcriber](https://github.com/hathix/youtube-transcriber) - Automatically transcribe YouTube videos. \n- [Marketing Analytics](https://github.com/byukan/Marketing-Data-Science) - Marketing analytics case studies. \n- [Algorithmic Marketing](https://github.com/ikatsov/algorithmic-examples) - Models from Introduction to Algorithmic Marketing book\n- [Marketing Scripts](https://github.com/HowardNTUST/Marketing-Data-Science-Application) - Marketing data science applications. \n- [Social Mining](https://github.com/mikhailklassen/Mining-the-Social-Web-3rd-Edition/tree/master/notebooks) - Mining the social web. \n\n\n<a name=""miscellaneous""></a>\n## Miscellaneous\n\n<a name=""miscellaneous-art""></a>\n**Art**\n\n- [Painting Forensics](https://github.com/ivan-bilan/Painting_Forensics) - Analysing paintings to find out their year of creation. \n\n\n<a name=""miscellaneous-tour""></a>\n**Tourism**\n- [Flickr](https://github.com/xiaofei6677/TourismFlickrMiner) - Metadata mining tool for tourism research. \n- [Fashion](https://github.com/khanhnamle1994/fashion-recommendation) **-** A clothing retrieval and visual recommendation model for fashion images\n\n\n\n<a name=""physics""></a>\n## Physics\n\n\n<a name=""physics-general""></a>\n**General**\n\n- [Gamma-hadron Reconstruction](https://github.com/fvisconti/gammas_machine_learning) - Tools used in Gamma-ray ground based astronomy. \n- [Curriculum](https://github.com/callysto/curriculum-notebooks/tree/master/Physics) - Newtonian notebooks. \n- [Interaction Networks](https://github.com/higgsfield/interaction_network_pytorch) - Interaction Networks for Learning about Objects, Relations and *Physics.* \n- [Particle Physics](https://github.com/hep-lbdl/adversarial-jets) - Training, generation, and analysis code for learning Particle *Physics*\n- [Computational Physics](https://github.com/ernestyalumni/CompPhys) - A computational physics repository. \n- [Medical Physics](https://github.com/robmarkcole/Useful-python-for-medical-physics) - Useful python for medical physics. \n- [Medical Physics 2](https://github.com/pymedphys/pymedphys) - A common, core Python package for Medical *Physics*\n- [Flow Physics](https://github.com/FPAL-Stanford-University/FloATPy) - Flow *Physics* and Aeroacoustics Toolbox with Python\n\n\n<a name=""physics-ml""></a>\n**Machine Learning**\n\n- [Physics ML and Stats](https://github.com/dkirkby/MachineLearningStatistics) - Machine learning and statistics for physicists\n- [High Energy](https://github.com/arogozhnikov/hep_ml) - Machine Learning for High Energy *Physics*.\n- [High Energy GAN](https://github.com/hep-lbdl/CaloGAN) - Generative Adversarial Networks for High Energy *Physics.* \n- [Neural Networks](https://github.com/GiggleLiu/marburg) - P*hysics* meets neural networks\n\n\n\n<a name=""public""></a>\n## Government and Public Works\n\n<a name=""public-social""></a>\n#### Social Policies\n- [Triage](https://github.com/dssg/triage) - General Purpose Risk Modeling and Prediction Toolkit for Policy and Social Good Problems.\n- [World Bank Poverty I](https://github.com/worldbank/ML-classification-algorithms-poverty/tree/master/notebooks) - A comparative assessment of machine learning classification algorithms applied to poverty prediction.\n- [World Bank Poverty II](https://github.com/avsolatorio/world-bank-pover-t-tests-solution) - Repository for the World Bank Pover-t Test Competition Solution Overseas Company Land Ownership .\n- [Overseas Company Land Ownership](https://github.com/Global-Witness/overseas-companies-land-ownership/blob/master/overseas_companies_land_ownership_analysis.ipynb) - Identifying foreign ownership in the UK.\n- [CFPB](https://github.com/MAydogdu/ConsumerFinancialProtectionBureau/blob/master/CFPB_Complaints_2017September.ipynb) - Consumer Finances Protection Bureau complaints analysis.\n- [Cannabis Legalisation Effect](https://github.com/tslindner/Effects-of-Cannabis-Legalization) - Effects of cannabis legalization on crime.\n- [Public Credit Card](https://github.com/dmodjeska/barnet_transactions/blob/master/Barnet_Transactions_Analysis.ipynb) - Identification of potential fraud for council credit cards. [Data](https://open.barnet.gov.uk/dataset/corporate-credit-card-transaction-2016-17)\n- [Recidivism Prediction](https://github.com/shayanray/GlassBox/tree/master/mlPredictor) - Transparency and audibility to recidivism risk assessment  \n- [Household Poverty](https://github.com/Featuretools/predict-household-poverty) - Predict poverty in households in Costa Rica. \n- [NLP Public Policy](https://github.com/ancilcrayton/nlp_public_policy) - An example of an NLP use-case in public policy. \n- [World Food Production](https://github.com/roshank1605A04/World-Food-Production) - Comparing Top food and feed Producers around the globe.\n- [Tax Inequality](https://github.com/DataScienceForGood/TaxationInequality) - Data project around taxation and inequality in Basel Stadt.\n- [Sheriff Compliance](https://github.com/austinbrian/sheriffs)  - Compliance to ICE requests.\n- [Apps Detection](https://github.com/MengchuanFu/Suspecious-Apps-Detection) - Suspicious app detection for kids. \n- [Social Assistance](https://github.com/farkhondehm/Social-Assistance) - Trending information on social assistance\n- [Computational Social Science](https://github.com/abjer/sds/tree/master/material) - Social data science summer school course. \n- [Liquor and Crime](https://github.com/bhaveshgoyal/safeLiquor) - Effect of liquor licenses issued on the crime rate.\n- [Animal Placement Kennels](https://github.com/austinpetsalive/distemper-outbreak) - Optimising animal placement in shelters.\n- [Staffing Wall](https://github.com/ryanschaub/The-U.S.-Mexican-Border-Wall-and-Staffing-A-Statistical-Approach-) - Independent exploration project on U.S. Mexican Border wall\n- [Worker Fatalities](https://github.com/zischwartz/workerfatalities) - Worker Fatalities and Catastrophes Map from OSHA data\n\n<a name=""public-charity""></a>\n**Charities**\n\n- [Census Data API](https://github.com/johnfwhitesell/CensusPull/blob/master/Census_ACS5_Pull.ipynb) - Pull variables from the 5-year American Community Survey.\n- [Philantropic Giving](https://github.com/datakind/datadive-gates92y-proj3-form990) - Work done by numerous DataKind volunteers on harnessing Form 990 data\n- [Charity Recommender](https://github.com/Chris-Manna/charity_recommender) - NYC *Charity* Collaborative Recommender System on an Implicit DataSet.\n- [Donor Identification](https://github.com/gouravaich/finding-donors-for-charity) - A machine learning project in which we need to find donors for *charity.*\n- [US Charities](https://github.com/staceb/charities_in_the_united_states) -  Charity exploration and machine learning. \n- [Charity Effectiveness](https://github.com/LauraChen/02-Metis-Web-Scraping) -  Scraping online data about *charities* to understand effectiveness\n\n<a name=""public-election""></a>\n#### Election Analysis\n- [Election Analysis](https://github.com/1jinwoo/DeepWave/blob/master/DR_Random_Forest.ipynb) - Election Analysis and Prediction Models\n- [American Election Causal](https://github.com/Akesari12/LS123_Data_Prediction_Law_Spring-2019/blob/master/labs/OLS%20for%20Causal%20Inference/OLS_Causal_Inference_solution.ipynb) - Using ANES data with causal inference models.\n- [Campaign Finance and Election Results](https://github.com/sfbrigade/datasci-campaign-finance/blob/master/notebooks/ML%20Campaign%20Finance%20and%20Election%20Results%20Example.ipynb) - Investigating the relation between campaign finance and subsequent election results.\n- [Voting System](https://github.com/nealmcb/pr_voting_methods) - Proportional representation voting methods. \n- [President Vote](https://github.com/austinbrian/portfolio/blob/master/tax_votes/president_counties.ipynb) - Vote by income level analysis.. \n\n<a name=""public-politics""></a>\n**Politics**\n\n- [Congressional politics](https://github.com/kaumaron/Data_Science/tree/master/Congressional_Partisanship) - House and senate congressional partisanship. \n- [Politico](https://github.com/okfn-brasil/perfil-politico) - A platform for profiling public figures in Brazilian *politics.*\n- [Bots](https://github.com/ParticipaPY/politic-bots) - Tools and algorithms to analyze Paraguayan Tweets in times of election\n- [Gerrymander tests](https://github.com/PrincetonUniversity/gerrymandertests) - Lots of metrics for quantifying gerrymandering.\n- [Sentiment](https://github.com/JulianMar11/SentimentPoliticalCompass) - Analyse newspapers with respect to their *political* conviction using entity sentiments of party representatives. \n- [DL Politics](https://github.com/muntisa/Deep-Politics) - Prediction of Spanish *Political* Affinity with Deep Neural Nets: Socialist vs People\'s Party\n- [PAC Money](https://github.com/edmundooo/more-money-more-problems) - Effects of PAC money on US *politics*.\n- [Power Networks](https://github.com/abhiagar90/power_networks) - Constructing a watchdog for Indian corporate and *political* networks\n- [Elite](https://github.com/philippschmalen/Project_tsds) - Political elite in the US.\n- [Debate Analysis](https://github.com/kkirchhoff01/DebateAnalysis) - Program to analyze *political* debates.\n- [Political Affiliation](https://github.com/davidjwiner/political_affiliation_prediction) - Political affiliation prediction using twitter metadata. \n- [Political Ads](https://github.com/philiplbean/facebook_political_ads) - Investigation into Facebook *Political* Ads and Targeting\n- [Political Identity](https://github.com/pgromano/Political-Identity-Analysis) - Multi-axial *political* model.\n- [YT Politics](https://github.com/kmunger/YT_descriptive) -  Mapping *Politics* on YouTube\n- [Political Ideology](https://github.com/albertwebson/Political-Vector-Projector) - Unsupervised learning of *political* ideology by word vector projections\n\n\n<a name=""realestate""></a>\n## Real Estate, Rental & Leasing\n\n<a name=""realestate-real""></a>\n**Real Estate**\n\n- [Finding Donuts](https://github.com/GretelDePaepe/FindingDonuts) - Finding real estate opportunities by predicting transforming neighbourhoods. \n- [Neighbourhood](https://github.com/denadai2/real-estate-neighborhood-prediction) - Predicting real estate prices from the urban environment.\n- [Real Estate Classification](https://github.com/Sardhendu/PropertyClassification) - Classifying the type of property given Real Estate, satellite and Street view Images\n- [Recommender](https://github.com/hyattsaleh15/RealStateRecommender) - This tools aims to recommend a user the top 5 real estate properties that matches their search.\n- [House Price](https://github.com/Shreyas3108/house-price-prediction) - Predicting *house* prices using Linear Regression and GBR\n- [House Price Portland](https://github.com/girishkuniyal/Predict-housing-prices-in-Portland) - Predict housing prices in Portland. \n- [Zillow Prediction](https://github.com/eswar3/Zillow-prediction-models) - Zillow valuation prediction as performed on Kaggle.\n- [Real Estate](https://github.com/denadai2/real-estate-neighborhood-prediction) - Predicting real estate prices from the urban environment.\n\n<a name=""realestate-rent""></a>\n**Rental & Leasing**\n\n- [Analysing Rentals](https://github.com/ual/rental-listings) - Analyzing and visualizing rental listings data. \n- [Interest Prediction](https://github.com/mratsim/Apartment-Interest-Prediction) - Predict people interest in renting specific NYC apartments.\n- [Housing Uni vs Non-Uni](https://github.com/5x12/pwc_europe_data_analytics_hackathon) - The effect on university lodging after the GFC.\n- [Predict Household Poverty](https://github.com/Featuretools/predict-household-poverty) -  Predict the poverty of households in Costa Rica using automated feature engineering.\n- [Airbnb public analytics competition](http://inseaddataanalytics.github.io/INSEADAnalytics/groupprojects/AirbnbReport2016Jan.html): - Now strategic management. \n\n\n<a name=""utilities""></a>\n## Utilities\n\n<a name=""utilities-elec""></a>\n**Electricity**\n\n- [Electricity Price](https://github.com/luqmanhakim/research-on-sp-wholesale/blob/master/research-on-sp-wholesale-plan.ipynb) - Electricity price comparison Singapore. \n- [Electricity-Coal Correlation](https://github.com/richardddli/state_electricity_rates) - Determining the correlation between state electricity rates and coal generation over the past decade.\n- [Electricity Capacity](https://github.com/datadesk/california-electricity-capacity-analysis) - A Los Angeles Times analysis of California\'s costly power glut.\n- [Electricity Systems](https://github.com/PyPSA/WHOBS) - Optimal Wind+Hydrogen+Other+Battery+Solar (WHOBS) *electricity* systems for European countries.\n- [Load Disaggregation](https://github.com/pipette/Electricity-load-disaggregation) - Smart meter load disaggregation with Hidden Markov Models\n- [Price Forecasting](https://github.com/farwacheema/DA-electricity-price-forecasting) - Forecasting Day-Ahead *electricity* prices in the German bidding zone with deep neural networks.\n- [Carbon Index](https://github.com/gschivley/carbon-index) - Calculation of *electricity* CO\xe2\x82\x82 intensity at national, state, and NERC regions from 2001-present.\n- [Demand Forecasting](https://github.com/hvantil/ElectricityDemandForecasting) - *Electricity* demand forecasting for Austin.\n- [Electricity Consumption](https://github.com/un-modelling/Electricity_Consumption_Surveys)  - Estimating *Electricity* Consumption from Household Surveys\n- [Household power consumption](https://github.com/amirrezaeian/Individual-household-electric-power-consumption-Data-Set-) - Individual household power consumption LSTM.\n- [Electricity French Distribution](http://inseaddataanalytics.github.io/INSEADAnalytics/groupprojects/group_energy.html) - An analysis of electricity data provided by the French Distribution Network (RTE)\n- [Renewable Power Plants](https://github.com/Open-Power-System-Data/renewable_power_plants)  - Time series of cumulated installed capacity.\n- [ Wind Farm Flow](https://github.com/FUSED-Wind/FUSED-Wake) - A repository of wind plant flow models connected to FUSED-Wind.\n- [Power Plant](https://github.com/YungChunLu/UCI-Power-Plant) - The dataset contains 9568 data points collected from a Combined Cycle Power Plant over 6 years (2006-2011).\n\n\n\n<a name=""utilities-coal""></a>\n**Coal, Oil & Gas**\n\n- [Coal Phase Out](https://github.com/samarthiith/DE_CoalPhaseOut) - Generation adequacy issues with Germany\xe2\x80\x99s coal phaseout. \n- [Coal Prediction](https://github.com/Jean-njoroge/coal-exploratory/tree/master/notebooks) - Predicting coal production. \n- [Oil & Gas](https://github.com/sdasadia/Oil-Natural-Gas-Price-Prediction) - Oil & *Natural* *Gas* price prediction using ARIMA & Neural Networks\n- [Gas Formula](https://github.com/cep-kse/natural_gas_formula) -  Calculating potential economic effect of price indexation formula.\n- [Demand Prediction](https://github.com/victorpena1/Natural-Gas-Demand-Prediction) - Natural gas demand prediction.\n- [Consumption Forecasting](https://github.com/williamadams1/natural-gas-consumption-forecasting) - Natural gas consumption forecasting. \n- [Gas Trade](https://github.com/bahuisman/NatGasModel) - World Model for *Natural* *Gas* Trade.\n\n<a name=""utilities-water""></a>\n**Water & Pollution**\n\n- [Safe Water](https://github.com/codeforboston/safe-water) - Predict health-based drinking water violations in the United States.\n- [Hydrology Data](https://github.com/mroberge/hydrofunctions) - A suite of convenience functions for exploring water data in Python.\n- [Water Observatory](https://github.com/sentinel-hub/water-observatory-backend) - Monitoring water levels of lakes and reservoirs using satellite imagery.\n- [Water Pipelines](https://github.com/wassname/pipe-segmentation) - Using machine learning to find water pipelines in aerial images. \n- [Water Modelling](https://github.com/awracms/awra_cms_older) - Australian Water Resource Assessment (AWRA) Community Modelling System.\n- [Drought Restrictions](https://github.com/datadesk/california-ccscore-analysis) - A Los Angeles Times analysis of water usage after the state eased drought restrictions\n- [Flood Prediction](https://github.com/cadrev/lstm-flood-prediction) - Applying LSTM on river water level data\n- [Sewage Overflow](https://github.com/jesseanddd/sewer-overflow) -  Insights into the sanitary sewage overflow (SSO). - This has been removed\n- [Water Accounting](https://github.com/johnpfay/USWaterAccounting) - Assembles water budget data for the US from existing data source\n- [Air Quality Prediction](https://github.com/txytju/air-quality-prediction) - Predict air quality(aq) in Beijing and London in the next 48 hours.\n\n<a name=""utilities-trans""></a>\n**Transportation**\n\n- [Transdim](https://github.com/xinychen/transdim) - Creating accurate and efficient solutions for the spatio-temporal traffic data imputation and prediction tasks.\n- [Transport Recommendation](https://github.com/AlanConstantine/KDD-Cup-2019-CAMMTR) - Context-Aware Multi-Modal Transportation Recommendation \n- [Transport Data](https://github.com/CityofToronto/bdit_data-sources) - Data and notebooks for Toronto transport. \n- [Transport Demand](https://github.com/pawelmorawiecki/traffic_jam_Nairobi) - Predicting demand for public transportation in Nairobi.\n- [Demand Estimation](https://github.com/Lemma1/DPFE) - Implementation of dynamic origin-destination demand estimation.\n- [Congestion Analysis](https://github.com/hackoregon/transportation-congestion-analysis) -  Transportation systems analysis\n- [TS Analysis](https://github.com/nishanthgampa/Time-Series-Analysis-on-Transportation-Data) - Time series analysis on transportation data.\n- [Network Graph Subway](https://github.com/fangshulin/Vulnerability-Analysis-for-Transportation-Networks) - Vulnerability analysis for transportation networks. - Have been taken down\n- [Transportation Inefficiencies](https://github.com/akpen/Stockholm-0.1) - Quantifying the inefficiencies of Transportation Networks\n- [Train Optimisation](https://github.com/crowdAI/train-schedule-optimisation-challenge-starter-kit) - Train schedule optimisation \n- [Traffic Prediction](https://github.com/mratsim/McKinsey-SmartCities-Traffic-Prediction) - multi attention recurrent neural networks for time-series (city traffic) \n- [Predict Crashes](https://github.com/Data4Democracy/crash-model) - Crash prediction modelling application that leverages multiple data sources\n- [AI Supply chain](https://github.com/llSourcell/AI_Supply_Chain) - Supply chain optimisation system. \n- [Transfer Learning Flight Delay](https://github.com/cavaunpeu/flight-delays) - Using variation encoders in Keras to predict flight delay. \n- [Replenishment](https://github.com/pratishthakapoor/RetailReplenishement/tree/master/Code) - Retail replenishment code for supply chain management.\n\n\n<a name=""wholesale""></a>\n## Wholesale & Retail\n\n<a name=""wholesale-whole""></a>\n**Wholesale**\n\n- [Customer Analysis](https://github.com/kralmachine/WholesaleCustomerAnalysis) - Wholesale customer analysis.\n- [Distribution](https://github.com/Semionn/JB-wholesale-distribution-analysis) - JB wholesale distribution analysis. \n- [Clustering](https://github.com/prakhardogra921/Clustering-Analysis-on-customers-of-a-wholesale-distributor) -  Unsupervised learning techniques are applied on product spending data collected for customers \n- [Market Basket Analysis](https://github.com/tstreamDOTh/Instacart-Market-Basket-Analysis) - Instacart public dataset to report which products are often shopped together.\n\n<a name=""wholesale-retail""></a>\n**Retail**\n\n- [Retail Analysis](https://github.com/SarahMestiri/online-retail-case) - Studying Online *Retail* Dataset and getting insights from it.\n- [Online Insights](https://github.com/roshank1605A04/Online-Retail-Transactions-of-UK) - Analyzing the Online Transactions in UK\n- [Retail Use-case](https://github.com/IBM-DSE/CyberShop-Analytics) - Notebooks & Data for CyberShop *Retail* Use Case\n- [Dwell Time](https://github.com/arvindkarir/retail) - Customer dwell time and other analysis. \n- [Retail Cohort](https://github.com/finnqiao/cohort_online_retail) - Cohort analysis. \n\nSponsors\n------------------\n- [Triplebyte](https://triplebyte.com/a/Nosq7GM/s) -  is building an objective and empirically validated software engineering recruitment process. We don\xe2\x80\x99t look at resumes, just at whether you can code. \n- [DataScienceProject](https://www.reddit.com/r/datascienceproject/) - Subscribe to the new reddit sub for datascience projects.\n- [FirmAI](https://www.firmai.org/) - Responsible open source business automation. \n\n\n\n'"
33,llSourcell/Learn_Machine_Learning_in_3_Months,llSourcell,"This is the code for ""Learn Machine Learning in 3 Months"" by Siraj Raval on Youtube ",2018-03-02 10:59:53,2020-06-18 19:20:56,,2417,7308,"b'# Learn_Machine_Learning_in_3_Months\n\nThis is the Curriculum for ""Learn Machine Learning in 3 Months"" [this](https://youtu.be/Cr6VqTRO1v0) video by Siraj Raval on Youtube \n\n# Month 1\n\n## Week 1 Linear Algebra\nhttps://www.youtube.com/watch?v=kjBOesZCoqc&index=1&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab\nhttps://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/\n## Week 2 Calculus\nhttps://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr\n## Week 3 Probability\nhttps://www.edx.org/course/introduction-probability-science-mitx-6-041x-2\n## Week 4 Algorithms\nhttps://www.edx.org/course/algorithm-design-analysis-pennx-sd3x\n\n# Month 2\n\n## Week 1 \n#### Learn python for data science\nhttps://www.youtube.com/watch?v=T5pRlIbr6gg&list=PL2-dafEMk2A6QKz1mrk1uIGfHkC1zZ6UU\n#### Math of Intelligence\nhttps://www.youtube.com/watch?v=xRJCOz3AfYY&list=PL2-dafEMk2A7mu0bSksCGMJEmeddU_H4D\n#### Intro to Tensorflow\nhttps://www.youtube.com/watch?v=2FmcHiLCwTU&list=PL2-dafEMk2A7EEME489DsI468AB0wQsMV\n\n## Week 2 \nIntro to ML (Udacity)\nhttps://eu.udacity.com/course/intro-to-machine-learning--ud120\n\n## Week 3-4\nML Project Ideas\nhttps://github.com/NirantK/awesome-project-ideas\n\n# Month 3 (Deep Learning)\n\n## Week 1 \nIntro to Deep Learning\nhttps://www.youtube.com/watch?v=vOppzHpvTiQ&list=PL2-dafEMk2A7YdKv4XfKpfbTH5z6rEEj3\n\n## Week 2 \nDeep Learning by Fast.AI\nhttp://course.fast.ai/\n\n## Week 3-4 \nRe-implement DL projects from my github\nhttps://github.com/llSourcell?tab=repositories\n\n---\n\n*Additional Resources:*   \n- People in ML to [follow on Twitter](https://www.quora.com/Who-should-I-follow-on-Twitter-to-get-useful-and-reliable-machine-learning-information ""Quora.com"")\n- Join the [""Wizards"" Slack channel](http://wizards.herokuapp.com/ ""Herokuapp.com"")\n'"
34,dformoso/machine-learning-mindmap,dformoso,"A mindmap summarising Machine Learning concepts, from Data Analysis to Deep Learning.",2017-08-10 04:29:24,2020-06-16 07:28:31,,786,4445,"b""# Machine Learning Mindmap / Cheatsheet\nA Mindmap summarising Machine Learning concepts, from Data Analysis to Deep Learning.\n\n## Overview\nMachine Learning is a subfield of computer science that gives computers the ability to learn without being explicitly programmed. It explores the study and construction of algorithms that can learn from and make predictions on data.\n\nMachine Learning is as fascinating as it is broad in scope. It spans over multiple fields in Mathematics, Computer Science, and Neuroscience. This is an attempt to summarize this enormous field in one .PDF file.\n\n## Download\nDownload the PDF here:\n> https://github.com/dformoso/machine-learning-mindmap/blob/master/Machine%20Learning.pdf\n\nSame, but with a white background:\n> https://github.com/dformoso/machine-learning-mindmap/blob/master/Machine%20Learning%20-%20White%20BG.pdf\n\nI've built the mindmap with MindNode for Mac. https://mindnode.com\n\n## Companion Notebook\nThis Mindmap/Cheatsheet has a companion Jupyter Notebook that runs through most of the Data Science steps that can be found at the following link:\n> https://github.com/dformoso/sklearn-classification\n\n## Mindmap on Deep Learning\nHere's another mindmap which focuses only on Deep Learning\n> https://github.com/dformoso/deeplearning-mindmap\n\n## 1. Process\nThe Data Science it's not a set-and-forget effort, but a process that requires design, implementation and maintenance. The PDF contains a quick overview of what's involved. Here's a quick screenshot.\n\n![alt text](https://github.com/dformoso/machine-learning-mindmap/blob/master/images/Process.png)\n\n## 2. Data Processing\nFirst, we'll need some data. We must find it, collect it, clean it, and about 5 other steps. Here's a sample of what's required.\n\n![alt text](https://github.com/dformoso/machine-learning-mindmap/blob/master/images/Data%20Processing.png)\n\n## 3. Mathematics\nMachine Learning is a house built on Math bricks. Browse through the most common components, and send your feedback if you see something missing.\n\n![alt text](https://github.com/dformoso/machine-learning-mindmap/blob/master/images/Mathematics.png)\n\n## 4. Concepts\nA partial list of the types, categories, approaches, libraries, and methodology.\n\n![alt text](https://github.com/dformoso/machine-learning-mindmap/blob/master/images/Concepts.png)\n\n## 5. Models\nA sampling of the most popular models. Send your comments to add more.\n\n![alt text](https://github.com/dformoso/machine-learning-mindmap/blob/master/images/Models.png)\n\n\n## References\nI'm planning to build a more complete list of references in the future. For now, these are some of the sources I've used to create this Mindmap.\n\n~~~\n Stanford and Oxford Lectures. CS20SI, CS224d.\n> Books: \n  > Deep Learning - Goodfellow. \n  > Pattern Recognition and Machine Learning - Bishop. \n  > The Elements of Statistical Learning - Hastie.\n- Colah's Blog. http://colah.github.io\n- Kaggle Notebooks.\n- Tensorflow Documentation pages.\n- Google Cloud Data Engineer certification materials.\n- Multiple Wikipedia articles.\n~~~\n\n\n## About Me\nTwitter:\n> https://twitter.com/danielmartinezf\n\nLinkedin:\n>https://www.linkedin.com/in/danielmartinezformoso/\n\nEmail:\n> daniel.martinez.formoso@gmail.com\n"""
35,rasbt/python-machine-learning-book-2nd-edition,rasbt,"The ""Python Machine Learning (2nd edition)"" book code repository and info resource",2017-02-09 05:45:15,2020-06-18 12:22:35,Jupyter Notebook,2486,5780,"b'## Python Machine Learning (2nd Ed.) Code Repository\n\n[![Build Status](https://travis-ci.com/rasbt/python-machine-learning-book-2nd-edition.svg?token=zvSsJVLJFKzB2yqaeKN1&branch=master)](https://travis-ci.com/rasbt/python-machine-learning-book-2nd-edition)\n![Python 3.6](https://img.shields.io/badge/Python-3.6-blue.svg)\n![License](https://img.shields.io/badge/Code%20License-MIT-blue.svg)\n\n\n*Please note that a new edition (3rd edition) is now available as of December 2019. The code repository link for the 3rd edition is https://github.com/rasbt/python-machine-learning-book-3rd-edition.*\n\n\n**Python Machine Learning, 2nd Ed.**  \n\npublished September 20th, 2017\n\nPaperback: 622 pages  \nPublisher: Packt Publishing  \nLanguage: English\n\nISBN-10: 1787125939  \nISBN-13: 978-1787125933  \nKindle ASIN: B0742K7HYF  \n\n[<img src=""./images/cover_1.jpg"" width=""348"">](https://www.amazon.com/Python-Machine-Learning-scikit-learn-TensorFlow/dp/1787125939)\n\n\n## Links\n\n- [Amazon Page](https://www.amazon.com/Python-Machine-Learning-scikit-learn-TensorFlow/dp/1787125939)\n- [Packt Page](https://www.packtpub.com/big-data-and-business-intelligence/python-machine-learning-second-edition)\n\n\n\n## Table of Contents and Code Notebooks\n\n**Helpful installation and setup instructions can be found in the [README.md file of Chapter 1](code/ch01/README.md)**\n\nTo access the code materials for a given chapter, simply click on the `open dir` links next to the chapter headlines to navigate to the chapter subdirectories located in the [code/](code/) subdirectory. You can also click on the `ipynb` links below to open and view the Jupyter notebook of each chapter directly on GitHub.\n\nIn addition, the [code/](code/) subdirectories also contain .py script files, which were created from the Jupyter Notebooks. However, I highly recommend working with the Jupyter notebook if possible in your computing environment. Not only do the Jupyter notebooks contain the images and section headings for easier navigation, but they also allow for a stepwise execution of individual code snippets, which -- in my opinion -- provide a better learning experience.\n\n**Please note that these are just the code examples accompanying the book, which I uploaded for your convenience; be aware that these notebooks may not be useful without the formulae and descriptive text.**   \n\n\n1. Machine Learning - Giving Computers the Ability to Learn from Data [[open dir](./code/ch01)] [[ipynb](./code/ch01/ch01.ipynb)] \n2. Training Machine Learning Algorithms for Classification [[open dir](./code/ch02)] [[ipynb](./code/ch02/ch02.ipynb)] \n3. A Tour of Machine Learning Classifiers Using Scikit-Learn [[open dir](./code/ch03)] [[ipynb](./code/ch03/ch03.ipynb)] \n4. Building Good Training Sets \xe2\x80\x93 Data Pre-Processing [[open dir](./code/ch04)] [[ipynb](./code/ch04/ch04.ipynb)] \n5. Compressing Data via Dimensionality Reduction [[open dir](./code/ch05)] [[ipynb](./code/ch05/ch05.ipynb)] \n6. Learning Best Practices for Model Evaluation and Hyperparameter Optimization [[open dir](./code/ch06)] [[ipynb](./code/ch06/ch06.ipynb)]\n7. Combining Different Models for Ensemble Learning [[open dir](./code/ch07)] [[ipynb](./code/ch07/ch07.ipynb)]\n8. Applying Machine Learning to Sentiment Analysis [[open dir](./code/ch08)] [[ipynb](./code/ch08/ch08.ipynb)] \n9. Embedding a Machine Learning Model into a Web Application [[open dir](./code/ch09)] [[ipynb](./code/ch09/ch09.ipynb)] \n10. Predicting Continuous Target Variables with Regression Analysis [[open dir](./code/ch10)] [[ipynb](./code/ch10/ch10.ipynb)] \n11. Working with Unlabeled Data \xe2\x80\x93 Clustering Analysis [[open dir](./code/ch11)] [[ipynb](./code/ch11/ch11.ipynb)] \n12. Implementing a Multi-layer Artificial Neural Network from Scratch [[open dir](./code/ch12)] [[ipynb](./code/ch12/ch12.ipynb)] \n13. Parallelizing Neural Network Training with TensorFlow [[open dir](./code/ch13)] [[ipynb](./code/ch13/ch13.ipynb)] \n14. Going Deeper: The Mechanics of TensorFlow [[open dir](./code/ch14)] [[ipynb](./code/ch14/ch14.ipynb)] \n15. Classifying Images with Deep Convolutional Neural Networks [[open dir](./code/ch15)] [[ipynb](./code/ch15/ch15.ipynb)] \n16. Modeling Sequential Data Using Recurrent Neural Networks [[open dir](./code/ch16)] [[ipynb](./code/ch16/ch16.ipynb)] \n\n### What\xe2\x80\x99s new in the second edition from the first edition?\n\n> Oh, there are so many things that we improved or added; where should I start!? The one issue on top of my priority list was to fix all the nasty typos that were introduced during the layout stage or my oversight. I really appreciated all the helpful feedback from readers in this manner! Furthermore, I addressed all the feedback about sections that may have been confusing or a bit unclear, reworded paragraphs, and added additional explanations. Also, special thanks go to the excellent editors of the second edition, who helped a lot along the way! \n\n> Also, the figures and plots became much prettier. While readers liked the graphic content a lot, some people criticized the PowerPoint-esque style and layout. Thus, I decided to overhaul every little figure with a hopefully more pleasing choice of fonts and colors. Also, the data plots look much nicer now, thanks to the matplotlib team who put a lot of work in matplotlib 2.0 and its new styling theme.\n\n> Beyond all these cosmetic fixes, new sections were added here and there. Among these is, for example, is a section on dealing with imbalanced datasets, which several readers were missing in the first edition and short section on Latent Dirichlet Allocation among others.\n\n> As time and the software world moved on after the first edition was released in September 2015, we decided to replace the introduction to deep learning via Theano. No worries, we didn\'t remove it but it got a substantial overhaul and is now based on TensorFlow, which has become a major player in my research toolbox since its open source release by Google in November 2015. \nAlong with the new introduction to deep learning using TensorFlow, the biggest additions to this new edition are three brand new chapters focussing on deep learning applications: A more detailed overview of the TensorFlow mechanics, an introduction to convolutional neural networks for image classification, and an introduction to recurrent neural networks for natural language processing. Of course, and in a similar vein as the rest of the book, these new chapters do not only provide readers with practical instructions and examples but also introduce the fundamental mathematics behind those concepts, which are an essential building block for understanding how deep learning works.\n\n[ [Excerpt from ""Machine Learning can be useful in almost every problem domain:"" An interview with Sebastian Raschka](https://www.packtpub.com/books/content/machine-learning-useful-every-problem-domain-interview-sebastian-raschka/) ]\n\n\n--- \n\n<br>\n<br>\n\nRaschka, Sebastian, and Vahid Mirjalili. *Python Machine Learning, 2nd Ed*. Packt Publishing, 2017.\n\n    @book{RaschkaMirjalili2017,  \n    address = {Birmingham, UK},  \n    author = {Raschka, Sebastian and Mirjalili, Vahid},  \n    edition = {2},  \n    isbn = {978-1787125933},  \n    keywords = {Clustering,Data Science,Deep Learning,  \n                Machine Learning,Neural Networks,Programming,  \n                Supervised Learning},  \n    publisher = {Packt Publishing},  \n    title = {{Python Machine Learning, 2nd Ed.}},  \n    year = {2017}  \n    }\n\n# Translations\n\n### German\n\n- ISBN-10: 3958457339\n- ISBN-13: 978-3958457331\n- [Amazon.de link](https://www.amazon.de/Machine-Learning-Python-Scikit-Learn-TensorFlow/dp/3958457339/ref=tmm_pap_swatch_0?_encoding=UTF8&qid=1513601461&sr=8-5)\n- [Publisher link](https://mitp.de/IT-WEB/Programmierung/Machine-Learning-mit-Python-oxid.html)\n\n![](images/cover-german.jpg)\n\n\n### Japanese\n\n- ISBN-10: 4295003379\n- ISBN-13: 978-4295003373\n- [Amazon.co.jp link](https://www.amazon.co.jp/Python-\xe6\xa9\x9f\xe6\xa2\xb0\xe5\xad\xa6\xe7\xbf\x92\xe3\x83\x97\xe3\x83\xad\xe3\x82\xb0\xe3\x83\xa9\xe3\x83\x9f\xe3\x83\xb3\xe3\x82\xb0-\xe9\x81\x94\xe4\xba\xba\xe3\x83\x87\xe3\x83\xbc\xe3\x82\xbf\xe3\x82\xb5\xe3\x82\xa4\xe3\x82\xa8\xe3\x83\xb3\xe3\x83\x86\xe3\x82\xa3\xe3\x82\xb9\xe3\x83\x88\xe3\x81\xab\xe3\x82\x88\xe3\x82\x8b\xe7\x90\x86\xe8\xab\x96\xe3\x81\xa8\xe5\xae\x9f\xe8\xb7\xb5-impress-gear/dp/4295003379/ref=tmm_pap_swatch_0)\n\n![](images/cover-japanese.jpg)\n'"
36,shuhuai007/Machine-Learning-Session,shuhuai007,,2018-11-01 15:18:42,2020-06-18 16:08:04,,731,3304,b'## \xe5\x9c\xa8B\xe7\xab\x99\xe4\xb8\x8a\xe4\xbc\xa0\xe4\xba\x86\xe4\xb8\x80\xe7\xb3\xbb\xe5\x88\x97\xe5\x85\xb3\xe4\xba\x8e\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9a\x84\xe8\xa7\x86\xe9\xa2\x91\xef\xbc\x8c\xe6\xaf\x8f\xe4\xb8\xaa\xe9\x83\xa8\xe5\x88\x86\xe5\x9d\x87\xe6\x98\xaf\xe4\xb8\x80\xe4\xba\x9b\xe6\xaf\x94\xe8\xbe\x83\xe5\x9f\xba\xe7\xa1\x80\xe7\x9a\x84\xe5\x85\xa5\xe9\x97\xa8\xe6\x8e\xa8\xe5\xaf\xbc\xef\xbc\x8c\xe7\x9b\xae\xe7\x9a\x84\xe6\x98\xaf\xe5\xb8\xae\xe5\x8a\xa9\xe8\xb5\xb7\xe6\xad\xa5\xef\xbc\x8c\xe8\xb5\xb7\xe5\x88\xb0\xe6\x8a\x9b\xe7\xa0\x96\xe5\xbc\x95\xe7\x8e\x89\xe7\x9a\x84\xe4\xbd\x9c\xe7\x94\xa8\n\n## \xe8\xa7\x86\xe9\xa2\x91\xe6\xac\xa1\xe5\xba\x8f\n#### [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0-\xe7\x99\xbd\xe6\x9d\xbf\xe6\x8e\xa8\xe5\xaf\xbc\xe7\xb3\xbb\xe5\x88\x97-\xe5\xbc\x80\xe7\xaf\x87](https://www.bilibili.com/video/av31950221/)\n#### [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0-\xe7\x99\xbd\xe6\x9d\xbf\xe6\x8e\xa8\xe5\xaf\xbc\xe7\xb3\xbb\xe5\x88\x97-\xe6\x95\xb0\xe5\xad\xa6\xe5\x9f\xba\xe7\xa1\x80](https://www.bilibili.com/video/av32905863/)\n#### [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0-\xe7\x99\xbd\xe6\x9d\xbf\xe6\x8e\xa8\xe5\xaf\xbc\xe7\xb3\xbb\xe5\x88\x97-\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92(Linear Regression)](https://www.bilibili.com/video/av31989606/)\n#### [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0-\xe7\x99\xbd\xe6\x9d\xbf\xe6\x8e\xa8\xe5\xaf\xbc\xe7\xb3\xbb\xe5\x88\x97-\xe7\xba\xbf\xe6\x80\xa7\xe5\x88\x86\xe7\xb1\xbb(Linear Classification)](https://www.bilibili.com/video/av33101528/)\n#### [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0-\xe7\x99\xbd\xe6\x9d\xbf\xe6\x8e\xa8\xe5\xaf\xbc\xe7\xb3\xbb\xe5\x88\x97-\xe9\x99\x8d\xe7\xbb\xb4](https://www.bilibili.com/video/av32709936/)\n#### [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0-\xe7\x99\xbd\xe6\x9d\xbf\xe6\x8e\xa8\xe5\xaf\xbc\xe7\xb3\xbb\xe5\x88\x97-\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba(SVM)](https://www.bilibili.com/video/av28186618/)\n#### [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0-\xe7\x99\xbd\xe6\x9d\xbf\xe6\x8e\xa8\xe5\xaf\xbc\xe7\xb3\xbb\xe5\x88\x97-\xe6\xa0\xb8\xe6\x96\xb9\xe6\xb3\x95(Kernel Method)](https://www.bilibili.com/video/av34731384/)\n#### [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0-\xe7\x99\xbd\xe6\x9d\xbf\xe6\x8e\xa8\xe5\xaf\xbc\xe7\xb3\xbb\xe5\x88\x97-\xe6\x8c\x87\xe6\x95\xb0\xe6\x97\x8f\xe5\x88\x86\xe5\xb8\x83](https://www.bilibili.com/video/av33360526/)\n#### [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0-\xe7\x99\xbd\xe6\x9d\xbf\xe6\x8e\xa8\xe5\xaf\xbc\xe7\xb3\xbb\xe5\x88\x97-\xe6\xa6\x82\xe7\x8e\x87\xe5\x9b\xbe\xe6\xa8\xa1\xe5\x9e\x8b](https://www.bilibili.com/video/av33545406/)\n#### [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0-\xe7\x99\xbd\xe6\x9d\xbf\xe6\x8e\xa8\xe5\xaf\xbc\xe7\xb3\xbb\xe5\x88\x97-EM\xe7\xae\x97\xe6\xb3\x95](https://www.bilibili.com/video/av31906558/)\n#### [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0-\xe7\x99\xbd\xe6\x9d\xbf\xe6\x8e\xa8\xe5\xaf\xbc\xe7\xb3\xbb\xe5\x88\x97-\xe9\xab\x98\xe6\x96\xaf\xe6\xb7\xb7\xe5\x90\x88\xe6\xa8\xa1\xe5\x9e\x8b(GMM)](https://www.bilibili.com/video/av35183585/)\n#### [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0-\xe7\x99\xbd\xe6\x9d\xbf\xe6\x8e\xa8\xe5\xaf\xbc\xe7\xb3\xbb\xe5\x88\x97-\xe5\x8f\x98\xe5\x88\x86\xe6\x8e\xa8\xe6\x96\xad(Variational Inference)](https://www.bilibili.com/video/av32047507/)\n#### [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0-\xe7\x99\xbd\xe6\x9d\xbf\xe6\x8e\xa8\xe5\xaf\xbc\xe7\xb3\xbb\xe5\x88\x97-MCMC](https://www.bilibili.com/video/av32430563/)\n#### [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0-\xe7\x99\xbd\xe6\x9d\xbf\xe6\x8e\xa8\xe5\xaf\xbc\xe7\xb3\xbb\xe5\x88\x97-\xe9\x9a\x90\xe9\xa9\xac\xe5\xb0\x94\xe5\x8f\xaf\xe5\xa4\xab\xe6\xa8\xa1\xe5\x9e\x8b(HMM)](https://www.bilibili.com/video/av32471608/)\n#### [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0-\xe7\x99\xbd\xe6\x9d\xbf\xe6\x8e\xa8\xe5\xaf\xbc\xe7\xb3\xbb\xe5\x88\x97-\xe7\xba\xbf\xe6\x80\xa7\xe5\x8a\xa8\xe6\x80\x81\xe7\xb3\xbb\xe7\xbb\x9f-\xe5\x8d\xa1\xe6\x9b\xbc\xe6\xbb\xa4\xe6\xb3\xa2(Kalman Filter)](https://www.bilibili.com/video/av32563186/)\n#### [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0-\xe7\x99\xbd\xe6\x9d\xbf\xe6\x8e\xa8\xe5\xaf\xbc\xe7\xb3\xbb\xe5\x88\x97-\xe9\x9d\x9e\xe7\xba\xbf\xe6\x80\xa7\xe5\x8a\xa8\xe6\x80\x81\xe7\xb3\xbb\xe7\xbb\x9f-\xe7\xb2\x92\xe5\xad\x90\xe6\xbb\xa4\xe6\xb3\xa2(Particle Filter)](https://www.bilibili.com/video/av32636259/)\n#### [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0-\xe7\x99\xbd\xe6\x9d\xbf\xe6\x8e\xa8\xe5\xaf\xbc\xe7\xb3\xbb\xe5\x88\x97-\xe6\x9d\xa1\xe4\xbb\xb6\xe9\x9a\x8f\xe6\x9c\xba\xe5\x9c\xba(CRF)](https://www.bilibili.com/video/av34444816/)\n#### [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0-\xe7\x99\xbd\xe6\x9d\xbf\xe6\x8e\xa8\xe5\xaf\xbc\xe7\xb3\xbb\xe5\x88\x97-\xe9\xab\x98\xe6\x96\xaf\xe7\xbd\x91\xe7\xbb\x9c(Gaussian Network)](https://www.bilibili.com/video/av35538998/)\n#### [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0-\xe7\x99\xbd\xe6\x9d\xbf\xe6\x8e\xa8\xe5\xaf\xbc\xe7\xb3\xbb\xe5\x88\x97-\xe8\xb4\x9d\xe5\x8f\xb6\xe6\x96\xaf\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92(Bayesian Linear Regression)](https://www.bilibili.com/video/av35685274/)\n#### [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0-\xe7\x99\xbd\xe6\x9d\xbf\xe6\x8e\xa8\xe5\xaf\xbc\xe7\xb3\xbb\xe5\x88\x97-\xe9\xab\x98\xe6\x96\xaf\xe8\xbf\x87\xe7\xa8\x8b\xe5\x9b\x9e\xe5\xbd\x92(Gaussian Process Regression)](https://www.bilibili.com/video/av35626047/)\n#### [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0-\xe7\x99\xbd\xe6\x9d\xbf\xe6\x8e\xa8\xe5\xaf\xbc\xe7\xb3\xbb\xe5\x88\x97-\xe5\x8f\x97\xe9\x99\x90\xe7\x8e\xbb\xe5\xb0\x94\xe5\x85\xb9\xe6\x9b\xbc\xe6\x9c\xba(Restricted Boltzmann Machine)](https://www.bilibili.com/video/av37510919/)\n'
37,soulmachine/machine-learning-cheat-sheet,soulmachine,Classical equations and diagrams in machine learning,2013-05-09 07:43:59,2020-06-17 19:37:45,TeX,731,3051,"b'Machine learning cheat sheet\n============================\n\nThis cheat sheet contains many classical equations and diagrams on machine learning, which will help you quickly recall knowledge and ideas on machine learning.\n\nThe cheat sheet will also appeal to someone who is preparing for a job interview related to machine learning.\n\n\n## Download PDF\n[machine-learning-cheat-sheet.pdf](https://github.com/soulmachine/machine-learning-cheat-sheet/raw/master/machine-learning-cheat-sheet.pdf) \n\n\n## How to compile\n\n    docker pull soulmachine/texlive\n    docker run -it --rm -v $(pwd):/data -w /data soulmachine/texlive xelatex -synctex=1 --enable-write18 -interaction=nonstopmode machine-learning-cheat-sheet.tex\n\n\n## LaTeX template\nThis open-source book adopts the [Springer latex template](http://www.springer.com/authors/book+authors?SGWID=0-154102-12-970131-0).\n\n\n## How to compile on Windows\n1. Install [Tex Live 2014](http://www.tug.org/texlive/), then add its `bin` path for example `D:\\texlive\\2012\\bin\\win32` to he PATH environment variable.\n2. Install [TeXstudio](http://texstudio.sourceforge.net/).\n3. Configure TeXstudio.  \n    Run TeXstudio, click `Options-->Configure Texstudio-->Commands`, set `XeLaTex` to `xelatex -synctex=1 -interaction=nonstopmode %.tex`.\n    \n    Click `Options-->Configure Texstudio-->Build`,   \n    set `Build & View` to `Compile & View`,  \n    set `Default Compiler` to `XeLaTex`,  \n    set `PDF Viewer` to `Internal PDF Viewer(windowed)`, so that when previewing it will pop up a standalone window, which will be convenient.\n4. Compile. Use Open `machine-learning-cheat-sheet.tex` with TeXstudio\xef\xbc\x8cclick the green arrow on the menu bar, then it will start to compile.  \n    In the messages window below we can see the compilation command that TeXstudio is using is `xelatex -synctex=1 --enable-write18 -interaction=nonstopmode ""machine-learning-cheat-sheet"".tex`\n'"
38,chiphuyen/machine-learning-systems-design,chiphuyen,A booklet on machine learning systems design with exercises,2019-11-24 23:16:28,2020-06-18 20:03:57,HTML,600,4447,"b""# Machine Learning Systems Design\n\nThis booklet covers four main steps of designing a machine learning system:\n\n1. Project setup\n2. Data pipeline\n3. Modeling: selecting, training, and debugging\n4. Serving: testing, deploying, and maintaining\n\nIt comes with links to practical resources that explain each aspect in more details. It also suggests case studies written by machine learning engineers at major tech companies who have deployed machine learning systems to solve real-world problems.\n\nAt the end, the booklet contains 27 open-ended machine learning systems design questions that might come up in machine learning interviews. The answers for these questions will be published in the book **Machine Learning Interviews**. You can look at and contribute to community answers to these questions on GitHub [here](https://github.com/chiphuyen/machine-learning-systems-design/tree/master/answers). You can read more about the book and sign up for the book's mailing list [here](https://huyenchip.com/2019/07/21/machine-learning-interviews.html).\n\n## Read\nTo read the booklet, you can clone the repository and find the [HTML](https://github.com/chiphuyen/machine-learning-systems-design/tree/master/build/build1/consolidated.html) and [PDF](https://github.com/chiphuyen/machine-learning-systems-design/tree/master/build/build1/consolidated.pdf) versions in the folder `build`.\n\n## Contribute\nThis is work-in-progress so any type of contribution is very much appreciated. Here are a few ways you can contribute:\n\n1. Improve the text by fixing any lexical, grammatical, or technical error\n1. Add more relevant resources to each aspect of the machine learning project flow\n1. Add/edit questions\n1. Add/edit answers\n1. Other\n\nThis book was created using the wonderful [`magicbook`](https://github.com/magicbookproject/magicbook) package. For detailed instructions on how to use the package, see their GitHub repo. The package requires that you have `node`. If you're on Mac, you can install `node` using:\n\n```\nbrew install node\n```\n\nInstall `magicbook` with:\n\n```\nnpm install magicbook\n```\n\nClone this repository:\n\n```\ngit clone https://github.com/chiphuyen/machine-learning-systems-design.git\ncd machine-learning-systems-design\n```\n\nAfter you've made changes to the content in the `content` folder, you can build the booklet by the following steps:\n\n```\nmagicbook build\n```\n\nYou'll find the generated HTML and PDF files in the folder `build`.\n\n## Acknowledgment\n\nI'd like to thank Ben Krause for being a great friend and helping me with this draft!\n\n\n## Citation\n"""
39,ty4z2008/Qix,ty4z2008,Machine Learning、Deep Learning、PostgreSQL、Distributed System、Node.Js、Golang,2014-04-20 11:03:15,2020-06-18 13:43:09,,4715,13262,"b'\n[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com) ![GitHub stars](https://img.shields.io/github/stars/ty4z2008/qix.svg?style=plastic) ![GitHub forks](https://img.shields.io/github/forks/ty4z2008/qix.svg?color=blue&style=plastic) \n\n## About Me\n\nWeiBo: [@\xe5\xbb\x96\xe5\x90\x9b_Jun](http://weibo.com/ty4z2008)\n\nTwitter: [@\xe5\xbb\x96\xe5\x90\x9b](https://twitter.com/ty4z2008)\n\nE-Mail: ty4z2008@gmail.com\n\nScale System Channel: [https://t.me/scalesystem](https://t.me/scalesystem)\n\n**NOTE** \n\nThere may be some incorrect information in the article. I hope i can correct error with you.  you can contact me with Email or PR\n\n## Pull Request welcome:blush:\n\n## My translation\n\n### node-mysql document translate\n\n- [node-mysql offcial document](https://github.com/felixge/node-mysql/blob/master/Readme.md)\n\n- [node-mysql Chinese document](https://github.com/ty4z2008/Qix/blob/master/node.md)\n\n## Machine Learning And deep learning Resources\n\n- [Chapter 1](https://github.com/ty4z2008/Qix/blob/master/dl.md)\n\n- [Chapter 2](https://github.com/ty4z2008/Qix/blob/master/dl2.md)\n\n## Golang learning resources\n\n- [Chapter 1](https://github.com/ty4z2008/Qix/blob/master/golang.md)\n\n\n## PostgreSQL database resources\n\n- [Chapter 1](https://github.com/ty4z2008/Qix/blob/master/pg.md)\n\n\n## Distributed system resources\n\n- [Chapter 1](https://github.com/ty4z2008/Qix/blob/master/ds.md)\n\n## Database system resources\n\n- [Chapter 1](https://github.com/ty4z2008/Qix/blob/master/db.md)\n\n\n\n## Additional notes\n\nDear friends. In order to respect to  the efforts   of authorship. In the reading process, when you find that resource the authorship is incorrect I also want you to[Submit feedback](https://github.com/ty4z2008/Qix/issues)\xe3\x80\x82Thanks buddy\xef\xbc\x81\n\n## License\n\n[MIT License](https://github.com/ty4z2008/Qix/blob/master/License.md)\n'"
40,Unity-Technologies/ml-agents,Unity-Technologies,Unity Machine Learning Agents Toolkit,2017-09-08 21:09:04,2020-06-18 12:08:50,C#,2435,8916,"b'<img src=""docs/images/image-banner.png"" align=""middle"" width=""3000""/>\n\n# Unity ML-Agents Toolkit\n\n[![docs badge](https://img.shields.io/badge/docs-reference-blue.svg)](https://github.com/Unity-Technologies/ml-agents/tree/release_3_docs/docs/)\n\n[![license badge](https://img.shields.io/badge/license-Apache--2.0-green.svg)](LICENSE)\n\n([latest release](https://github.com/Unity-Technologies/ml-agents/releases/tag/latest_release))\n([all releases](https://github.com/Unity-Technologies/ml-agents/releases))\n\n**The Unity Machine Learning Agents Toolkit** (ML-Agents) is an open-source\nproject that enables games and simulations to serve as environments for\ntraining intelligent agents. Agents can be trained using reinforcement learning,\nimitation learning, neuroevolution, or other machine learning methods through a\nsimple-to-use Python API. We also provide implementations (based on TensorFlow)\nof state-of-the-art algorithms to enable game developers and hobbyists to easily\ntrain intelligent agents for 2D, 3D and VR/AR games. These trained agents can be\nused for multiple purposes, including controlling NPC behavior (in a variety of\nsettings such as multi-agent and adversarial), automated testing of game builds\nand evaluating different game design decisions pre-release. The ML-Agents\nToolkit is mutually beneficial for both game developers and AI researchers as it\nprovides a central platform where advances in AI can be evaluated on Unity\xe2\x80\x99s\nrich environments and then made accessible to the wider research and game\ndeveloper communities.\n\n## Features\n\n- 15+ [example Unity environments](docs/Learning-Environment-Examples.md)\n- Support for multiple environment configurations and training scenarios\n- Flexible Unity SDK that can be integrated into your game or custom Unity scene\n- Training using two deep reinforcement learning algorithms, Proximal Policy\n  Optimization (PPO) and Soft Actor-Critic (SAC)\n- Built-in support for Imitation Learning through Behavioral Cloning or\n  Generative Adversarial Imitation Learning\n- Self-play mechanism for training agents in adversarial scenarios\n- Easily definable Curriculum Learning scenarios for complex tasks\n- Train robust agents using environment randomization\n- Flexible agent control with On Demand Decision Making\n- Train using multiple concurrent Unity environment instances\n- Utilizes the [Unity Inference Engine](docs/Unity-Inference-Engine.md) to\n  provide native cross-platform support\n- Unity environment [control from Python](docs/Python-API.md)\n- Wrap Unity learning environments as a [gym](gym-unity/README.md)\n\nSee our [ML-Agents Overview](docs/ML-Agents-Overview.md) page for detailed\ndescriptions of all these features.\n\n## Releases & Documentation\n\n**Our latest, stable release is `Release 3`. Click\n[here](https://github.com/Unity-Technologies/ml-agents/tree/release_3_docs/docs/Readme.md)\nto get started with the latest release of ML-Agents.**\n\nThe table below lists all our releases, including our `master` branch which is\nunder active development and may be unstable. A few helpful guidelines:\n- The [Versioning page](docs/Versioning.md) overviews how we manage our GitHub\n  releases and the versioning process for each of the ML-Agents components.\n- The [Releases page](https://github.com/Unity-Technologies/ml-agents/releases)\n  contains details of the changes between releases.\n- The [Migration page](docs/Migrating.md) contains details on how to upgrade\n  from earlier releases of the ML-Agents Toolkit.\n- The **Documentation** links in the table below include installation and usage\n  instructions specific to each release. Remember to always use the\n  documentation that corresponds to the release version you\'re using.\n\n| **Version** | **Release Date** | **Source** | **Documentation** | **Download** |\n|:-------:|:------:|:-------------:|:-------:|:------------:|\n| **master (unstable)** | -- | [source](https://github.com/Unity-Technologies/ml-agents/tree/master) | [docs](https://github.com/Unity-Technologies/ml-agents/tree/master/docs/Readme.md) | [download](https://github.com/Unity-Technologies/ml-agents/archive/master.zip) |\n| **Release 3** | **June 10, 2020** | **[source](https://github.com/Unity-Technologies/ml-agents/tree/release_3)** | **[docs](https://github.com/Unity-Technologies/ml-agents/tree/release_3_docs/docs/Readme.md)** | **[download](https://github.com/Unity-Technologies/ml-agents/archive/release_3.zip)** |\n| **Release 2** | May 20, 2020 | [source](https://github.com/Unity-Technologies/ml-agents/tree/release_2) | [docs](https://github.com/Unity-Technologies/ml-agents/tree/release_2_docs/docs/Readme.md) | [download](https://github.com/Unity-Technologies/ml-agents/archive/release_2.zip) |\n| **Release 1** | April 30, 2020 | [source](https://github.com/Unity-Technologies/ml-agents/tree/release_1) | [docs](https://github.com/Unity-Technologies/ml-agents/tree/release_1_docs/docs/Readme.md) | [download](https://github.com/Unity-Technologies/ml-agents/archive/release_1.zip) |\n| **0.15.1** | March 30, 2020 | [source](https://github.com/Unity-Technologies/ml-agents/tree/0.15.1) | [docs](https://github.com/Unity-Technologies/ml-agents/tree/0.15.1/docs/Readme.md) | [download](https://github.com/Unity-Technologies/ml-agents/archive/0.15.1.zip) |\n| **0.15.0** | March 18, 2020 | [source](https://github.com/Unity-Technologies/ml-agents/tree/0.15.0) | [docs](https://github.com/Unity-Technologies/ml-agents/tree/0.15.0/docs/Readme.md) | [download](https://github.com/Unity-Technologies/ml-agents/archive/0.15.0.zip) |\n| **0.14.1** | February 26, 2020 | [source](https://github.com/Unity-Technologies/ml-agents/tree/0.14.1) | [docs](https://github.com/Unity-Technologies/ml-agents/tree/0.14.1/docs/Readme.md) | [download](https://github.com/Unity-Technologies/ml-agents/archive/0.14.1.zip) |\n| **0.14.0** | February 13, 2020 | [source](https://github.com/Unity-Technologies/ml-agents/tree/0.14.0) | [docs](https://github.com/Unity-Technologies/ml-agents/tree/0.14.0/docs/Readme.md) | [download](https://github.com/Unity-Technologies/ml-agents/archive/0.14.0.zip) |\n| **0.13.1** | January 21, 2020 | [source](https://github.com/Unity-Technologies/ml-agents/tree/0.13.1) | [docs](https://github.com/Unity-Technologies/ml-agents/tree/0.13.1/docs/Readme.md) | [download](https://github.com/Unity-Technologies/ml-agents/archive/0.13.1.zip) |\n| **0.13.0** | January 8, 2020 | [source](https://github.com/Unity-Technologies/ml-agents/tree/0.13.0) | [docs](https://github.com/Unity-Technologies/ml-agents/tree/0.13.0/docs/Readme.md) | [download](https://github.com/Unity-Technologies/ml-agents/archive/0.13.0.zip) |\n## Citation\n\nIf you are a researcher interested in a discussion of Unity as an AI platform,\nsee a pre-print of our\n[reference paper on Unity and the ML-Agents Toolkit](https://arxiv.org/abs/1809.02627).\n\nIf you use Unity or the ML-Agents Toolkit to conduct research, we ask that you\ncite the following paper as a reference:\n\nJuliani, A., Berges, V., Teng, E., Cohen, A., Harper, J., Elion, C., Goy, C.,\nGao, Y., Henry, H., Mattar, M., Lange, D. (2020). Unity: A General Platform for\nIntelligent Agents. _arXiv preprint\n[arXiv:1809.02627](https://arxiv.org/abs/1809.02627)._\nhttps://github.com/Unity-Technologies/ml-agents.\n\n## Additional Resources\n\nWe have published a series of blog posts that are relevant for ML-Agents:\n\n- (May 12, 2020)\n  [Announcing ML-Agents Unity Package v1.0!](https://blogs.unity3d.com/2020/05/12/announcing-ml-agents-unity-package-v1-0/)\n- (February 28, 2020)\n  [Training intelligent adversaries using self-play with ML-Agents](https://blogs.unity3d.com/2020/02/28/training-intelligent-adversaries-using-self-play-with-ml-agents/)\n- (November 11, 2019)\n  [Training your agents 7 times faster with ML-Agents](https://blogs.unity3d.com/2019/11/11/training-your-agents-7-times-faster-with-ml-agents/)\n- (October 21, 2019)\n  [The AI@Unity interns help shape the world](https://blogs.unity3d.com/2019/10/21/the-aiunity-interns-help-shape-the-world/)\n- (April 15, 2019)\n  [Unity ML-Agents Toolkit v0.8: Faster training on real games](https://blogs.unity3d.com/2019/04/15/unity-ml-agents-toolkit-v0-8-faster-training-on-real-games/)\n- (March 1, 2019)\n  [Unity ML-Agents Toolkit v0.7: A leap towards cross-platform inference](https://blogs.unity3d.com/2019/03/01/unity-ml-agents-toolkit-v0-7-a-leap-towards-cross-platform-inference/)\n- (December 17, 2018)\n  [ML-Agents Toolkit v0.6: Improved usability of Brains and Imitation Learning](https://blogs.unity3d.com/2018/12/17/ml-agents-toolkit-v0-6-improved-usability-of-brains-and-imitation-learning/)\n- (October 2, 2018)\n  [Puppo, The Corgi: Cuteness Overload with the Unity ML-Agents Toolkit](https://blogs.unity3d.com/2018/10/02/puppo-the-corgi-cuteness-overload-with-the-unity-ml-agents-toolkit/)\n- (September 11, 2018)\n  [ML-Agents Toolkit v0.5, new resources for AI researchers available now](https://blogs.unity3d.com/2018/09/11/ml-agents-toolkit-v0-5-new-resources-for-ai-researchers-available-now/)\n- (June 26, 2018)\n  [Solving sparse-reward tasks with Curiosity](https://blogs.unity3d.com/2018/06/26/solving-sparse-reward-tasks-with-curiosity/)\n- (June 19, 2018)\n  [Unity ML-Agents Toolkit v0.4 and Udacity Deep Reinforcement Learning Nanodegree](https://blogs.unity3d.com/2018/06/19/unity-ml-agents-toolkit-v0-4-and-udacity-deep-reinforcement-learning-nanodegree/)\n- (May 24, 2018)\n  [Imitation Learning in Unity: The Workflow](https://blogs.unity3d.com/2018/05/24/imitation-learning-in-unity-the-workflow/)\n- (March 15, 2018)\n  [ML-Agents Toolkit v0.3 Beta released: Imitation Learning, feedback-driven features, and more](https://blogs.unity3d.com/2018/03/15/ml-agents-v0-3-beta-released-imitation-learning-feedback-driven-features-and-more/)\n- (December 11, 2017)\n  [Using Machine Learning Agents in a real game: a beginner\xe2\x80\x99s guide](https://blogs.unity3d.com/2017/12/11/using-machine-learning-agents-in-a-real-game-a-beginners-guide/)\n- (December 8, 2017)\n  [Introducing ML-Agents Toolkit v0.2: Curriculum Learning, new environments, and more](https://blogs.unity3d.com/2017/12/08/introducing-ml-agents-v0-2-curriculum-learning-new-environments-and-more/)\n- (September 19, 2017)\n  [Introducing: Unity Machine Learning Agents Toolkit](https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/)\n- Overviewing reinforcement learning concepts\n  ([multi-armed bandit](https://blogs.unity3d.com/2017/06/26/unity-ai-themed-blog-entries/)\n  and\n  [Q-learning](https://blogs.unity3d.com/2017/08/22/unity-ai-reinforcement-learning-with-q-learning/))\n\nIn addition to our own documentation, here are some additional, relevant\narticles:\n\n- [A Game Developer Learns Machine Learning](https://mikecann.co.uk/machine-learning/a-game-developer-learns-machine-learning-intent/)\n- [Explore Unity Technologies ML-Agents Exclusively on Intel Architecture](https://software.intel.com/en-us/articles/explore-unity-technologies-ml-agents-exclusively-on-intel-architecture)\n- [ML-Agents Penguins tutorial](https://learn.unity.com/project/ml-agents-penguins)\n\n## Community and Feedback\n\nThe ML-Agents Toolkit is an open-source project and we encourage and welcome\ncontributions. If you wish to contribute, be sure to review our\n[contribution guidelines](com.unity.ml-agents/CONTRIBUTING.md) and\n[code of conduct](CODE_OF_CONDUCT.md).\n\nFor problems with the installation and setup of the ML-Agents Toolkit, or\ndiscussions about how to best setup or train your agents, please create a new\nthread on the\n[Unity ML-Agents forum](https://forum.unity.com/forums/ml-agents.453/) and make\nsure to include as much detail as possible. If you run into any other problems\nusing the ML-Agents Toolkit or have a specific feature request, please\n[submit a GitHub issue](https://github.com/Unity-Technologies/ml-agents/issues).\n\nYour opinion matters a great deal to us. Only by hearing your thoughts on the\nUnity ML-Agents Toolkit can we continue to improve and grow. Please take a few\nminutes to\n[let us know about it](https://github.com/Unity-Technologies/ml-agents/issues/1454).\n\nFor any other questions or feedback, connect directly with the ML-Agents team at\nml-agents@unity3d.com.\n\n## License\n\n[Apache License 2.0](LICENSE)\n'"
41,zotroneneis/machine_learning_basics,zotroneneis,Plain python implementations of basic machine learning algorithms,2018-02-19 09:55:58,2020-06-18 11:20:55,Jupyter Notebook,602,3129,"b'# Machine learning basics\n\nThis repository contains implementations of basic machine learning algorithms in plain Python (Python Version 3.6+). All algorithms are implemented from scratch without using additional machine learning libraries. The intention of these notebooks is to provide a basic understanding of the algorithms and their underlying structure, *not* to provide the most efficient implementations. \n\n- [Linear Regression](linear_regression.ipynb)\n- [Logistic Regression](logistic_regression.ipynb)\n- [Perceptron](perceptron.ipynb)\n- [k-nearest-neighbor](k_nearest_neighbour.ipynb)\n- [k-Means clustering](kmeans.ipynb)\n- [Simple neural network with one hidden layer](simple_neural_net.ipynb)\n- [Multinomial Logistic Regression](softmax_regression.ipynb)\n- [Decision tree for classification](decision_tree_classification.ipynb)\n- [Decision tree for regression](decision_tree_regression.ipynb)\n  \n  \n![alt text](figures/decision_tree_predictions.png)\n\n\n## Data preprocessing\n\nAfter several requests I started preparing notebooks on how to preprocess datasets for machine learning. Within the next months I will add one notebook for each kind of dataset (text, images, ...). As before, the intention of these notebooks is to provide a basic understanding of the preprocessing steps, *not* to provide the most efficient implementations. \n\n- [Image preprocessing](image_preprocessing.ipynb)\n- [Preprocessing a numerical/categorical dataset](data_preprocessing.ipynb)\n\n![alt text](figures/image_preprocessing.png)\n\n\n## Feedback\n\nIf you have a favorite algorithm that should be included or spot a mistake in one of the notebooks, please let me know by creating a new issue.\n\n## License\n\nSee the LICENSE file for license rights and limitations (MIT).\n'"
42,Borye/machine-learning-coursera-1,Borye,This repo is specially created for all the work done my me as a part of Coursera's Machine Learning Course.,2014-08-28 10:48:18,2020-06-16 08:07:03,,950,1071,"b""machine-learning-coursera\n=========================\n\nThis repo is specially created for all the work done my me as a part of Coursera's Machine Learning Course.\n"""
43,tirthajyoti/Machine-Learning-with-Python,tirthajyoti,Practice and tutorial-style notebooks  covering wide variety of machine learning techniques,2017-07-17 03:06:13,2020-06-17 06:14:32,Jupyter Notebook,870,1311,"b'[![License](https://img.shields.io/badge/License-BSD%202--Clause-orange.svg)](https://opensource.org/licenses/BSD-2-Clause)\n[![GitHub forks](https://img.shields.io/github/forks/tirthajyoti/Machine-Learning-with-Python.svg)](https://github.com/tirthajyoti/Machine-Learning-with-Python/network)\n[![GitHub stars](https://img.shields.io/github/stars/tirthajyoti/Machine-Learning-with-Python.svg)](https://github.com/tirthajyoti/Machine-Learning-with-Python/stargazers)\n[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](https://github.com/tirthajyoti/Machine-Learning-with-Python/pulls)\n\n# Python Machine Learning Jupyter Notebooks ([ML website](https://machine-learning-with-python.readthedocs.io/en/latest/))\n\n### Dr. Tirthajyoti Sarkar, Fremont, California ([Please feel free to connect on LinkedIn here](https://www.linkedin.com/in/tirthajyoti-sarkar-2127aa7))\n---\n\n## Requirements\n* **Python 3.6+**\n* **NumPy (`pip install numpy`)**\n* **Pandas (`pip install pandas`)**\n* **Scikit-learn (`pip install scikit-learn`)**\n* **SciPy (`pip install scipy`)**\n* **Statsmodels (`pip install statsmodels`)**\n* **MatplotLib (`pip install matplotlib`)**\n* **Seaborn (`pip install seaborn`)**\n* **Sympy (`pip install sympy`)**\n* **Flask (`pip install flask`)**\n* **WTForms (`pip install wtforms`)**\n* **Tensorflow (`pip install tensorflow>=1.15`)**\n* **Keras (`pip install keras`)**\n* **pdpipe (`pip install pdpipe`)**\n\n---\n\nYou can start with this article that I wrote in Heartbeat magazine (on Medium platform): \n### [""Some Essential Hacks and Tricks for Machine Learning with Python""](https://heartbeat.fritz.ai/some-essential-hacks-and-tricks-for-machine-learning-with-python-5478bc6593f2)\n<img src=""https://cookieegroup.com/wp-content/uploads/2018/10/2-1.png"" width=""450"" height=""300""/>\n\n## Essential tutorial-type notebooks on Pandas and Numpy\nJupyter notebooks covering a wide range of functions and operations on the topics of NumPy, Pandans, Seaborn, Matplotlib etc.\n\n* [Detailed Numpy operations](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Pandas%20and%20Numpy/Numpy_operations.ipynb)\n* [Detailed Pandas operations](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Pandas%20and%20Numpy/Pandas_Operations.ipynb)\n* [Numpy and Pandas quick basics](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Pandas%20and%20Numpy/Numpy_Pandas_Quick.ipynb)\n* [Matplotlib and Seaborn quick basics](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Pandas%20and%20Numpy/Matplotlib_Seaborn_basics.ipynb)\n* [Advanced Pandas operations](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Pandas%20and%20Numpy/Advanced%20Pandas%20Operations.ipynb)\n* [How to read various data sources](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Pandas%20and%20Numpy/Read_data_various_sources/How%20to%20read%20various%20sources%20in%20a%20DataFrame.ipynb)\n* [PDF reading and table processing demo](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Pandas%20and%20Numpy/Read_data_various_sources/PDF%20table%20reading%20and%20processing%20demo.ipynb)\n* [How fast are Numpy operations compared to pure Python code?](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Pandas%20and%20Numpy/How%20fast%20are%20NumPy%20ops.ipynb) (Read my [article](https://towardsdatascience.com/why-you-should-forget-for-loop-for-data-science-code-and-embrace-vectorization-696632622d5f) on Medium related to this topic)\n* [Fast reading from Numpy using .npy file format](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Pandas%20and%20Numpy/Numpy_Reading.ipynb) (Read my [article](https://towardsdatascience.com/why-you-should-start-using-npy-file-more-often-df2a13cc0161) on Medium on this topic)\n\n## Tutorial-type notebooks covering regression, classification, clustering, dimensionality reduction, and some basic neural network algorithms\n\n### Regression\n* Simple linear regression with t-statistic generation\n<img src=""https://slideplayer.com/slide/6053182/20/images/10/Simple+Linear+Regression+Model.jpg"" width=""400"" height=""300""/>\n\n* [Multiple ways to perform linear regression in Python and their speed comparison](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Regression/Linear_Regression_Methods.ipynb) ([check the article I wrote on freeCodeCamp](https://medium.freecodecamp.org/data-science-with-python-8-ways-to-do-linear-regression-and-measure-their-speed-b5577d75f8b))\n\n* [Multi-variate regression with regularization](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Regression/Multi-variate%20LASSO%20regression%20with%20CV.ipynb)\n<img src=""https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/L1_and_L2_balls.svg/300px-L1_and_L2_balls.svg.png""/>\n\n* Polynomial regression using ***scikit-learn pipeline feature*** ([check the article I wrote on *Towards Data Science*](https://towardsdatascience.com/machine-learning-with-python-easy-and-robust-method-to-fit-nonlinear-data-19e8a1ddbd49))\n\n* [Decision trees and Random Forest regression](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Regression/Random_Forest_Regression.ipynb) (showing how the Random Forest works as a robust/regularized meta-estimator rejecting overfitting)\n\n* [Detailed visual analytics and goodness-of-fit diagnostic tests for a linear regression problem](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Regression/Regression_Diagnostics.ipynb)\n\n* [Robust linear regression using `HuberRegressor` from Scikit-learn](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Regression/Robust%20Linear%20Regression.ipynb)\n\n-----\n\n### Classification\n* Logistic regression/classification ([Here is the Notebook](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Classification/Logistic_Regression_Classification.ipynb))\n<img src=""https://qph.fs.quoracdn.net/main-qimg-914b29e777e78b44b67246b66a4d6d71""/>\n\n* _k_-nearest neighbor classification ([Here is the Notebook](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Classification/KNN_Classification.ipynb))\n\n* Decision trees and Random Forest Classification ([Here is the Notebook](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Classification/DecisionTrees_RandomForest_Classification.ipynb))\n\n* Support vector machine classification ([Here is the Notebook](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Classification/Support_Vector_Machine_Classification.ipynb)) (**[check the article I wrote in Towards Data Science on SVM and sorting algorithm](https://towardsdatascience.com/how-the-good-old-sorting-algorithm-helps-a-great-machine-learning-technique-9e744020254b))**\n\n<img src=""https://docs.opencv.org/2.4/_images/optimal-hyperplane.png""/>\n\n* Naive Bayes classification ([Here is the Notebook](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Classification/Naive_Bayes_Classification.ipynb))\n\n---\n\n### Clustering\n<img src=""https://i.ytimg.com/vi/IJt62uaZR-M/maxresdefault.jpg"" width=""450"" height=""300""/>\n\n* _K_-means clustering ([Here is the Notebook](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Clustering-Dimensionality-Reduction/K_Means_Clustering_Practice.ipynb))\n\n* Affinity propagation (showing its time complexity and the effect of damping factor) ([Here is the Notebook](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Clustering-Dimensionality-Reduction/Affinity_Propagation.ipynb))\n\n* Mean-shift technique (showing its time complexity and the effect of noise on cluster discovery) ([Here is the Notebook](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Clustering-Dimensionality-Reduction/Mean_Shift_Clustering.ipynb))\n\n* DBSCAN (showing how it can generically detect areas of high density irrespective of cluster shapes, which the k-means fails to do) ([Here is the Notebook](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Clustering-Dimensionality-Reduction/DBScan_Clustering.ipynb))\n\n* Hierarchical clustering with Dendograms showing how to choose optimal number of clusters ([Here is the Notebook](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Clustering-Dimensionality-Reduction/Hierarchical_Clustering.ipynb))\n\n<img src=""https://www.researchgate.net/profile/Carsten_Walther/publication/273456906/figure/fig3/AS:294866065084419@1447312956501/Example-of-hierarchical-clustering-clusters-are-consecutively-merged-with-the-most.png"" width=""700"" height=""400""/>\n\n---\n\n### Dimensionality reduction\n* Principal component analysis\n\n<img src=""https://i.ytimg.com/vi/QP43Iy-QQWY/maxresdefault.jpg"" width=""450"" height=""300""/>\n\n---\n\n### Deep Learning/Neural Network\n* [Demo notebook to illustrate the superiority of deep neural network for complex nonlinear function approximation task](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Function%20Approximation%20by%20Neural%20Network/Polynomial%20regression%20-%20linear%20and%20neural%20network.ipynb)\n* Step-by-step building of 1-hidden-layer and 2-hidden-layer dense network using basic TensorFlow methods\n\n---\n\n### Random data generation using symbolic expressions\n* How to use [Sympy package](https://www.sympy.org/en/index.html) to generate random datasets using symbolic mathematical expressions.\n\n* Here is my article on Medium on this topic: [Random regression and classification problem generation with symbolic expression](https://towardsdatascience.com/random-regression-and-classification-problem-generation-with-symbolic-expression-a4e190e37b8d)\n\n---\n\n### Synthetic data generation techniques\n* [Notebooks here](https://github.com/tirthajyoti/Machine-Learning-with-Python/tree/master/Synthetic_data_generation)\n\n### Simple deployment examples (serving ML models on web API)\n* [Serving a linear regression model through a simple HTTP server interface](https://github.com/tirthajyoti/Machine-Learning-with-Python/tree/master/Deployment/Linear_regression). User needs to request predictions by executing a Python script. Uses `Flask` and `Gunicorn`.\n\n* [Serving a recurrent neural network (RNN) through a HTTP webpage](https://github.com/tirthajyoti/Machine-Learning-with-Python/tree/master/Deployment/rnn_app), complete with a web form, where users can input parameters and click a button to generate text based on the pre-trained RNN model. Uses `Flask`, `Jinja`, `Keras`/`TensorFlow`, `WTForms`.\n\n---\n\n### Object-oriented programming with machine learning\nImplementing some of the core OOP principles in a machine learning context by [building your own Scikit-learn-like estimator, and making it better](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/OOP_in_ML/Class_MyLinearRegression.ipynb).\n\nSee my articles on Medium on this topic.\n\n* [Object-oriented programming for data scientists: Build your ML estimator](https://towardsdatascience.com/object-oriented-programming-for-data-scientists-build-your-ml-estimator-7da416751f64)\n* [How a simple mix of object-oriented programming can sharpen your deep learning prototype](https://towardsdatascience.com/how-a-simple-mix-of-object-oriented-programming-can-sharpen-your-deep-learning-prototype-19893bd969bd)\n\n'"
44,rhiever/Data-Analysis-and-Machine-Learning-Projects,rhiever,"Repository of teaching materials, code, and data for my data analysis and machine learning projects.",2015-02-12 23:03:58,2020-06-18 06:20:09,Jupyter Notebook,1788,4713,"b'![Python 2.7](https://img.shields.io/badge/python-2.7-blue.svg)\n![Python 3.5](https://img.shields.io/badge/python-3.5-blue.svg)\n![License](https://img.shields.io/badge/license-MIT%20License-blue.svg)\n\n# Randy Olson\'s data analysis and machine learning projects\n\n\xc2\xa9 2016-2018 Randal S. Olson\n\nThis is a repository of teaching materials, code, and data for my data analysis and machine learning projects.\n\nEach repository will (usually) correspond to one of the blog posts on my [web site](http://www.randalolson.com/blog/).\n\nBe sure to check the documentation (usually in IPython Notebook format) in the directory you\'re interested in for the notes on the analysis, data usage terms, etc.\n\nIf you don\'t have the necessary software installed to run IPython Notebook, don\'t fret. You can use [nbviewer](http://nbviewer.ipython.org/) to view a notebook on the web.\n\nFor example, if you want to view the notebook in the `wheres-waldo-path-optimization` directory, copy the [full link](https://github.com/rhiever/Data-Analysis-and-Machine-Learning-Projects/blob/master/wheres-waldo-path-optimization/Where\'s%20Waldo%20path%20optimization.ipynb) to the notebook then paste it into [nbviewer](http://nbviewer.ipython.org/github/rhiever/Data-Analysis-and-Machine-Learning-Projects/blob/master/wheres-waldo-path-optimization/Where%27s%20Waldo%20path%20optimization.ipynb).\n\n## License\n\n### Instructional Material\n\nAll instructional material in this repository is made available under the [Creative Commons Attribution license](https://creativecommons.org/licenses/by/4.0/). The following is a human-readable summary of (and not a substitute for) the [full legal text of the CC BY 4.0 license](https://creativecommons.org/licenses/by/4.0/legalcode).\n\nYou are free to:\n\n* **Share**\xe2\x80\x94copy and redistribute the material in any medium or format\n* **Adapt**\xe2\x80\x94remix, transform, and build upon the material\n\nfor any purpose, even commercially.\n\nThe licensor cannot revoke these freedoms as long as you follow the license terms.\n\nUnder the following terms:\n\n* **Attribution**\xe2\x80\x94You must give appropriate credit (mentioning that your work is derived from work that is \xc2\xa9 Randal S. Olson and, where practical, linking to http://www.randalolson.com/), provide a [link to the license](https://creativecommons.org/licenses/by/4.0/), and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\n\n**No additional restrictions**\xe2\x80\x94You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.\n\n**Notices:**\n\n* You do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation.\n* No warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material.\n\n### Software\n\nExcept where otherwise noted, the example programs and other software provided in this repository are made available under the [OSI](http://opensource.org/)-approved [MIT license](http://opensource.org/licenses/mit-license.html).\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n'"
45,EthicalML/awesome-production-machine-learning,EthicalML,"A curated list of awesome open source libraries to deploy, monitor, version and scale your machine learning",2018-08-15 14:28:41,2020-06-18 17:49:26,,528,3626,"b'[![Awesome](images/awesome.svg)](https://github.com/sindresorhus/awesome)\n[![Maintenance](https://img.shields.io/badge/Maintained%3F-YES-green.svg)](https://github.com/EthicalML/awesome-production-machine-learning/graphs/commit-activity)\n![GitHub](https://img.shields.io/badge/Release-PROD-yellow.svg)\n![GitHub](https://img.shields.io/badge/Languages-MULTI-blue.svg)\n![GitHub](https://img.shields.io/badge/License-MIT-lightgrey.svg)\n[![GitHub](https://img.shields.io/twitter/follow/axsaucedo.svg?label=Follow)](https://twitter.com/AxSaucedo/)\n\n\n# Awesome production machine learning\n\nThis repository contains a curated list of awesome open source libraries that will help you deploy, monitor, version, scale, and secure your production machine learning.\n\n## Quick links to sections in this page\n\n| | | |\n|-|-|-|\n|[\xf0\x9f\x94\x8d Explaining predictions & models](#explaining-black-box-models-and-datasets) |[\xf0\x9f\x94\x8f Privacy preserving ML](#privacy-preserving-machine-learning) | [\xf0\x9f\x93\x9c Model & data versioning](#model-and-data-versioning)|\n|[\xf0\x9f\x8f\x81 Model Training Orchestration](#model-training-orchestration)|[\xf0\x9f\x92\xaa Model Serving and Monitoring](#model-serving-and-monitoring)|[\xf0\x9f\xa4\x96 Neural Architecture Search](#neural-architecture-search)|\n| [\xf0\x9f\x93\x93 Reproducible Notebooks](#data-science-notebook-frameworks) | [\xf0\x9f\x93\x8a Visualisation frameworks](#industrial-strength-visualisation-libraries) | [\xf0\x9f\x94\xa0 Industry-strength NLP](#industrial-strength-nlp) |\n| [\xf0\x9f\xa7\xb5 Data pipelines & ETL](#data-pipeline-etl-frameworks) | [\xf0\x9f\x8f\xb7\xef\xb8\x8f Data Labelling](#data-labelling-tools-and-frameworks) |[\xf0\x9f\x97\x9e\xef\xb8\x8f Data storage](#data-storage-optimisation) |\n| [\xf0\x9f\x93\xa1 Functions as a service](#function-as-a-service-frameworks)| [\xf0\x9f\x97\xba\xef\xb8\x8f Computation distribution](#computation-load-distribution-frameworks) | [\xf0\x9f\x93\xa5 Model serialisation](#model-serialisation-formats) |\n| [\xf0\x9f\xa7\xae Optimized calculation frameworks](#optimized-calculation-frameworks)| [\xf0\x9f\x92\xb8 Data Stream Processing](#data-stream-processing) | [:red_circle: Outlier and Anomaly Detection](#outlier-and-anomaly-detection) |\n| [\xf0\x9f\x8c\x80 Feature engineering](#feature-engineering-automation) | [\xf0\x9f\x8e\x81 Feature Stores](#feature-stores) | [\xe2\x9a\x94 Adversarial Robustness](#adversarial-robustness-libraries) |\n|[\xf0\x9f\x92\xb0 Commercial Platforms](#commercial-platforms)\n\n## 10 Min Video Overview\n\n<table>\n  <tr>\n    <td width=""30%"">\n        This <a href=""https://www.youtube.com/watch?v=Ynb6X0KZKxY"">10 minute video</a> provides an overview of the motivations for machine learning operations as well as a high level overview on some of the tools in this repo.\n    </td>\n    <td width=""70%"">\n        <a href=""https://www.youtube.com/watch?v=Ynb6X0KZKxY""><img src=""images/video.png""></a>\n    </td>\n  </tr>\n</table>\n\n## Want to receive recurrent updates on this repo and other advancements?\n\n<table>\n  <tr>\n    <td width=""30%"">\n         You can join the <a href=""https://ethical.institute/mle.html"">Machine Learning Engineer</a> newsletter. You will receive updates on open source frameworks, tutorials and articles curated by machine learning professionals.\n    </td>\n    <td width=""70%"">\n        <a href=""https://ethical.institute/mle.html""><img src=""images/mleng.png""></a>\n    </td>\n  </tr>\n  <tr>\n    <td width=""30%"">\n         Also check out the <a href=""https://github.com/EthicalML/awesome-artificial-intelligence-guidelines/"">Awesome Artificial Intelligence Guidelines</a> List, where we aim to map the landscape of ""Frameworks"", ""Codes of Ethics"", ""Guidelines"", ""Regulations"", etc related to Artificial Intelligence.\n    </td>\n    <td width=""70%"">\n        <a href=""https://github.com/EthicalML/awesome-artificial-intelligence-guidelines/""><img src=""images/guidelines.jpg""></a>\n    </td>\n  </tr>\n</table>\n\n\n# Main Content\n\n## Explaining Black Box Models and Datasets\n\n* [Aequitas](https://github.com/dssg/aequitas) ![](https://img.shields.io/github/stars/dssg/aequitas.svg?style=social) - An open-source bias audit toolkit for data scientists, machine learning researchers, and policymakers to audit machine learning models for discrimination and bias, and to make informed and equitable decisions around developing and deploying predictive risk-assessment tools.\n* [Alibi](https://github.com/SeldonIO/alibi) ![](https://img.shields.io/github/stars/SeldonIO/alibi.svg?style=social) - Alibi is an open source Python library aimed at machine learning model inspection and interpretation. The initial focus on the library is on black-box, instance based model explanations.\n* [anchor](https://github.com/marcotcr/anchor) ![](https://img.shields.io/github/stars/marcotcr/anchor.svg?style=social) - Code for the paper [""High precision model agnostic explanations""](https://homes.cs.washington.edu/~marcotcr/aaai18.pdf), a model-agnostic system that explains the behaviour of complex models with high-precision rules called anchors.\n* [captum](https://github.com/pytorch/captum) ![](https://img.shields.io/github/stars/pytorch/captum.svg?style=social) - model interpretability and understanding library for PyTorch developed by Facebook. It contains general purpose implementations of integrated gradients, saliency maps, smoothgrad, vargrad and others for PyTorch models.\n* [casme](https://github.com/kondiz/casme) ![](https://img.shields.io/github/stars/kondiz/casme.svg?style=social) - Example of using classifier-agnostic saliency map extraction on ImageNet presented on the paper [""Classifier-agnostic saliency map extraction""](https://arxiv.org/abs/1805.08249).\n* [ContrastiveExplanation (Foil Trees)](https://github.com/MarcelRobeer/ContrastiveExplanation) ![](https://img.shields.io/github/stars/MarcelRobeer/ContrastiveExplanation.svg?style=social) - Python script for model agnostic contrastive/counterfactual explanations for machine learning. Accompanying code for the paper [""Contrastive Explanations with Local Foil Trees""](https://arxiv.org/abs/1806.07470).\n* [DeepLIFT](https://github.com/kundajelab/deeplift) ![](https://img.shields.io/github/stars/kundajelab/deeplift.svg?style=social) - Codebase that contains the methods in the paper [""Learning important features through propagating activation differences""](https://arxiv.org/abs/1704.02685). Here is the [slides](https://docs.google.com/file/d/0B15F_QN41VQXSXRFMzgtS01UOU0/edit?filetype=mspresentation) and the [video](https://vimeo.com/238275076) of the 15 minute talk given at ICML.\n* [DeepVis Toolbox](https://github.com/yosinski/deep-visualization-toolbox) ![](https://img.shields.io/github/stars/yosinski/deep-visualization-toolbox.svg?style=social) - This is the code required to run the Deep Visualization Toolbox, as well as to generate the neuron-by-neuron visualizations using regularized optimization. The toolbox and methods are described casually [here](http://yosinski.com/deepvis) and more formally in this [paper](https://arxiv.org/abs/1506.06579).\n* [ELI5](https://github.com/TeamHG-Memex/eli5) ![](https://img.shields.io/github/stars/TeamHG-Memex/eli5.svg?style=social) - ""Explain Like I\'m 5"" is a Python package which helps to debug machine learning classifiers and explain their predictions.\n* [FACETS](https://pair-code.github.io/facets/) - Facets contains two robust visualizations to aid in understanding and analyzing machine learning datasets. Get a sense of the shape of each feature of your dataset using Facets Overview, or explore individual observations using Facets Dive.\n* [Fairlearn](https://fairlearn.github.io) ![](https://img.shields.io/github/stars/fairlearn/fairlearn.svg?style=social) - Fairlearn is a python toolkit to assess and mitigate unfairness in machine learning models.\n* [FairML](https://github.com/adebayoj/fairml) ![](https://img.shields.io/github/stars/adebayoj/fairml.svg?style=social) - FairML is a python toolbox auditing the machine learning models for bias.\n* [fairness](https://github.com/algofairness/fairness-comparison) ![](https://img.shields.io/github/stars/algofairness/fairness-comparison.svg?style=social) - This repository is meant to facilitate the benchmarking of fairness aware machine learning algorithms based on [this paper](https://arxiv.org/abs/1802.04422).\n* [GEBI - Global Explanations for Bias Identification](https://github.com/AgaMiko/GEBI) ![](https://img.shields.io/github/stars/AgaMiko/GEBI.svg?style=social) - An attention-based summarized post-hoc explanations for detection and identification of bias in data. We propose a global explanation and introduce a step-by-step framework on how to detect and test bias. Python package for image data.\n* [IBM AI Explainability 360](https://github.com/IBM/AIX360/) ![](https://img.shields.io/github/stars/IBM/AIX360.svg?style=social) - Interpretability and explainability of data and machine learning models including a comprehensive set of algorithms that cover different dimensions of explanations along with proxy explainability metrics.\n* [IBM AI Fairness 360](https://github.com/IBM/AIF360) ![](https://img.shields.io/github/stars/IBM/AIF360.svg?style=social) - A comprehensive set of fairness metrics for datasets and machine learning models, explanations for these metrics, and algorithms to mitigate bias in datasets and models.\n* [iNNvestigate](https://github.com/albermax/innvestigate) ![](https://img.shields.io/github/stars/albermax/innvestigate.svg?style=social) - An open-source library for analyzing Keras models visually by methods such as [DeepTaylor-Decomposition](https://www.sciencedirect.com/science/article/pii/S0031320316303582), [PatternNet](https://openreview.net/forum?id=Hkn7CBaTW), [Saliency Maps](https://arxiv.org/abs/1312.6034), and [Integrated Gradients](https://arxiv.org/abs/1703.01365).\n* [Integrated-Gradients](https://github.com/ankurtaly/Integrated-Gradients) ![](https://img.shields.io/github/stars/ankurtaly/Integrated-Gradients.svg?style=social) - This repository provides code for implementing integrated gradients for networks with image inputs.\n* [InterpretML](https://interpret.ml/) ![](https://img.shields.io/github/stars/InterpretML/interpret.svg?style=social) - InterpretML is an open-source package for training interpretable models and explaining blackbox systems.\n* [keras-vis](https://github.com/raghakot/keras-vis) ![](https://img.shields.io/github/stars/raghakot/keras-vis.svg?style=social) -  keras-vis is a high-level toolkit for visualizing and debugging your trained keras neural net models. Currently supported visualizations include: Activation maximization, Saliency maps, Class activation maps.\n* [L2X](https://github.com/Jianbo-Lab/L2X) ![](https://img.shields.io/github/stars/Jianbo-Lab/L2X.svg?style=social) - Code for replicating the experiments in the paper [""Learning to Explain: An Information-Theoretic Perspective on Model Interpretation""](https://arxiv.org/pdf/1802.07814.pdf) at ICML 2018\n* [Lightwood](https://github.com/mindsdb/lightwood) ![](https://img.shields.io/github/stars/mindsdb/lightwood.svg?style=social) -  A Pytorch based framework that breaks down machine learning problems into smaller blocks that can be glued together seamlessly with an objective to build predictive models with one line of code.\n* [LIME](https://github.com/marcotcr/lime) ![](https://img.shields.io/github/stars/marcotcr/lime.svg?style=social) - Local Interpretable Model-agnostic Explanations for machine learning models.\n* [LOFO Importance](https://github.com/aerdem4/lofo-importance) ![](https://img.shields.io/github/stars/aerdem4/lofo-importance.svg?style=social) - LOFO (Leave One Feature Out) Importance calculates the importances of a set of features based on a metric of choice, for a model of choice, by iteratively removing each feature from the set, and evaluating the performance of the model, with a validation scheme of choice, based on the chosen metric.\n* [MindsDB](https://github.com/mindsdb/mindsdb) ![](https://img.shields.io/github/stars/mindsdb/mindsdb.svg?style=social) -   MindsDB is an Explainable AutoML framework for developers. With MindsDB you can build, train and use state of the art ML models in as simple as one line of code.\n* [mljar-supervised](https://github.com/mljar/mljar-supervised) ![](https://img.shields.io/github/stars/mljar/mljar-supervised.svg?style=social) - An Automated Machine Learning (AutoML) python package for tabular data. It can handle: Binary Classification, MultiClass Classification and Regression. It provides feature engineering, explanations and markdown reports.\n* [pyBreakDown](https://github.com/MI2DataLab/pyBreakDown) ![](https://img.shields.io/github/stars/MI2DataLab/pyBreakDown.svg?style=social) - A model agnostic tool for decomposition of predictions from black boxes. Break Down Table shows contributions of every variable to a final prediction.\n* [rationale](https://github.com/taolei87/rcnn/tree/master/code/rationale) ![](https://img.shields.io/github/stars/taolei87/rcnn.svg?style=social) - Code to implement learning rationales behind predictions with code for paper [""Rationalizing Neural Predictions""](https://github.com/taolei87/rcnn/tree/master/code/rationale)\n* [responsibly](https://github.com/ResponsiblyAI/responsibly) ![](https://img.shields.io/github/stars/ResponsiblyAI/responsibly.svg?style=social) - Toolkit for auditing and mitigating bias and fairness of machine learning systems\n* [SHAP](https://github.com/slundberg/shap) ![](https://img.shields.io/github/stars/slundberg/shap.svg?style=social) - SHapley Additive exPlanations is a unified approach to explain the output of any machine learning model.\n* [Skater](https://github.com/datascienceinc/Skater) ![](https://img.shields.io/github/stars/datascienceinc/Skater.svg?style=social) - Skater is a unified framework to enable Model Interpretation for all forms of model to help one build an Interpretable machine learning system often needed for real world use-cases\n* [Tensorboard\'s Tensorboard WhatIf](https://pair-code.github.io/what-if-tool/) ![](https://img.shields.io/github/stars/tensorflow/tensorboard.svg?style=social) - Tensorboard screen to analyse the interactions between inference results and data inputs.\n* [Tensorflow\'s cleverhans](https://github.com/tensorflow/cleverhans) ![](https://img.shields.io/github/stars/tensorflow/cleverhans.svg?style=social) - An adversarial example library for constructing attacks, building defenses, and benchmarking both. A python library to benchmark system\'s vulnerability to [adversarial examples](http://karpathy.github.io/2015/03/30/breaking-convnets/)\n* [tensorflow\'s lucid](https://github.com/tensorflow/lucid) ![](https://img.shields.io/github/stars/tensorflow/lucid.svg?style=social) - Lucid is a collection of infrastructure and tools for research in neural network interpretability.\n* [tensorflow\'s Model Analysis](https://github.com/tensorflow/model-analysis) ![](https://img.shields.io/github/stars/tensorflow/model-analysis.svg?style=social) - TensorFlow Model Analysis (TFMA) is a library for evaluating TensorFlow models. It allows users to evaluate their models on large amounts of data in a distributed manner, using the same metrics defined in their trainer.\n* [themis-ml](https://github.com/cosmicBboy/themis-ml) ![](https://img.shields.io/github/stars/cosmicBboy/themis-ml.svg?style=social) - themis-ml is a Python library built on top of pandas and sklearn that implements fairness-aware machine learning algorithms.\n* [Themis](https://github.com/LASER-UMASS/Themis) ![](https://img.shields.io/github/stars/LASER-UMASS/Themis.svg?style=social) - Themis is a testing-based approach for measuring discrimination in a software system.\n* [TreeInterpreter](https://github.com/andosa/treeinterpreter) ![](https://img.shields.io/github/stars/andosa/treeinterpreter.svg?style=social) - Package for interpreting scikit-learn\'s decision tree and random forest predictions. Allows decomposing each prediction into bias and feature contribution components as described in http://blog.datadive.net/interpreting-random-forests/.\n* [woe](https://github.com/boredbird/woe) ![](https://img.shields.io/github/stars/boredbird/woe.svg?style=social) - Tools for WoE Transformation mostly used in ScoreCard Model for credit rating\n* [XAI - eXplainableAI](https://github.com/EthicalML/xai) ![](https://img.shields.io/github/stars/EthicalML/XAI.svg?style=social) - An eXplainability toolbox for machine learning.\n\n\n## Privacy Preserving Machine Learning\n* [Google\'s Differential Privacy](https://github.com/google/differential-privacy) ![](https://img.shields.io/github/stars/google/differential-privacy.svg?style=social) - This is a C++ library of \xce\xb5-differentially private algorithms, which can be used to produce aggregate statistics over numeric data sets containing private or sensitive information.\n* [Intel Homomorphic Encryption Backend](https://github.com/NervanaSystems/he-transformer) ![](https://img.shields.io/github/stars/NervanaSystems/he-transformer.svg?style=social) - The Intel HE transformer for nGraph is a Homomorphic Encryption (HE) backend to the Intel nGraph Compiler, Intel\'s graph compiler for Artificial Neural Networks.\n* [Microsoft SEAL](https://github.com/microsoft/SEAL) ![](https://img.shields.io/github/stars/microsoft/SEAL.svg?style=social) - Microsoft SEAL is an easy-to-use open-source (MIT licensed) homomorphic encryption library developed by the Cryptography Research group at Microsoft.\n* [PySyft](https://github.com/OpenMined/PySyft) ![](https://img.shields.io/github/stars/OpenMined/PySyft.svg?style=social) - A Python library for secure, private Deep Learning. PySyft decouples private data from model training, using Multi-Party Computation (MPC) within PyTorch.\n* [Substra](https://github.com/SubstraFoundation/substra)![](https://img.shields.io/github/stars/SubstraFoundation/substra.svg?style=social) - Substra is an open-source framework for privacy-preserving, traceable and collaborative Machine Learning.\n* [Tensorflow Privacy](https://github.com/tensorflow/privacy) ![](https://img.shields.io/github/stars/tensorflow/privacy.svg?style=social) - A Python library that includes implementations of TensorFlow optimizers for training machine learning models with differential privacy.\n* [TF Encrypted](https://github.com/tf-encrypted/tf-encrypted) ![](https://img.shields.io/github/stars/tf-encrypted/tf-encrypted.svg?style=social) - A Framework for Confidential Machine Learning on Encrypted Data in TensorFlow.\n* [Uber SQL Differencial Privacy](https://github.com/uber/sql-differential-privacy) ![](https://img.shields.io/github/stars/uber/sql-differential-privacy.svg?style=social) - Uber\'s open source framework that enforces differential privacy for general-purpose SQL queries.\n\n\n## Model and Data Versioning\n* [Apache Marvin](https://github.com/apache/incubator-marvin) ![](https://img.shields.io/github/stars/apache/incubator-marvin.svg?style=social) is a platform for model deployment and versioning that hides all complexity under the hood: data scientists just need to set up the server and write their code in an extended jupyter notebook.\n* [Catalyst](https://github.com/catalyst-team/catalyst) ![](https://img.shields.io/github/stars/catalyst-team/catalyst.svg?style=social) - High-level utils for PyTorch DL & RL research. It was developed with a focus on reproducibility, fast experimentation and code/ideas reusing.\n* [D6tflow](https://github.com/d6t/d6tflow) ![](https://img.shields.io/github/stars/d6t/d6tflow.svg?style=social) - A python library that allows for building complex data science workflows on Python.\n* [DAGsHub](https://dagshub.com) - The home for data science collaboration. A platform, based on DVC, for data science project management and collaboration.\n* [Data Version Control (DVC)](https://github.com/iterative/dvc) ![](https://img.shields.io/github/stars/iterative/dvc.svg?style=social) - A git fork that allows for version management of models.\n* [FGLab](https://github.com/Kaixhin/FGLab) ![](https://img.shields.io/github/stars/Kaixhin/FGLab.svg?style=social) - Machine learning dashboard, designed to make prototyping experiments easier.\n* [Flor](https://github.com/ucbrise/flor/blob/master/rtd/index.rst) ![](https://img.shields.io/github/stars/ucbrise/flor.svg?style=social) - Easy to use logger and automatic version controller made for data scientists who write ML code\n* [Hangar](https://github.com/tensorwerk/hangar-py) ![](https://img.shields.io/github/stars/tensorwerk/hangar-py.svg?style=social) - Version control for tensor data, git-like semantics on numerical data with high speed and efficiency.\n* [Kedro](https://github.com/quantumblacklabs/kedro/) ![](https://img.shields.io/github/stars/quantumblacklabs/kedro.svg?style=social) - Kedro is a workflow development tool that helps you build data pipelines that are robust, scalable, deployable, reproducible and versioned. Visualization of the kedro workflows can be done by [`kedro-viz`](https://github.com/quantumblacklabs/kedro-viz)\n* [MLflow](https://github.com/mlflow/mlflow) ![](https://img.shields.io/github/stars/mlflow/mlflow.svg?style=social) - Open source platform to manage the ML lifecycle, including experimentation, reproducibility and deployment.\n* [MLWatcher](https://github.com/anodot/MLWatcher) ![](https://img.shields.io/github/stars/anodot/MLWatcher.svg?style=social) - MLWatcher is a python agent that records a large variety of time-serie metrics of your running ML classification algorithm. It enables you to monitor in real time.\n* [ModelChimp](https://github.com/ModelChimp/modelchimp/) ![](https://img.shields.io/github/stars/ModelChimp/modelchimp.svg?style=social) - Framework to track and compare all the results and parameters from machine learning models [(Video)](https://vimeo.com/271246650)\n* [ModelDB](https://github.com/VertaAI/modeldb/) ![](https://img.shields.io/github/stars/mitdbg/modeldb.svg?style=social) - An open-source system to version machine learning models including their ingredients code, data, config, and environment and to track ML metadata across the model lifecycle.\n* [Pachyderm](https://github.com/pachyderm/pachyderm) ![](https://img.shields.io/github/stars/pachyderm/pachyderm.svg?style=social) - Open source distributed processing framework build on Kubernetes focused mainly on dynamic building of production machine learning pipelines - [(Video)](https://www.youtube.com/watch?v=LamKVhe2RSM)\n* [Polyaxon](https://github.com/polyaxon/polyaxon) ![](https://img.shields.io/github/stars/polyaxon/polyaxon.svg?style=social) - A platform for reproducible and scalable machine learning and deep learning on kubernetes. - [(Video)](https://www.youtube.com/watch?v=Iexwrka_hys)\n* [PredictionIO](https://github.com/apache/predictionio) ![](https://img.shields.io/github/stars/apache/predictionio.svg?style=social) - An open source Machine Learning Server built on top of a state-of-the-art open source stack for developers and data scientists to create predictive engines for any machine learning task\n* [Quilt Data](https://github.com/quiltdata/quilt) ![](https://img.shields.io/github/stars/quiltdata/quilt.svg?style=social) - Versioning, reproducibility and deployment of data and models.\n* [Sacred](https://github.com/IDSIA/sacred) ![](https://img.shields.io/github/stars/IDSIA/sacred.svg?style=social) - Tool to help you configure, organize, log and reproduce machine learning experiments.\n* [steppy](https://github.com/neptune-ml/steppy) ![](https://img.shields.io/github/stars/neptune-ml/steppy.svg?style=social) - Lightweight, Python3 library for fast and reproducible machine learning experimentation. Introduces simple interface that enables clean machine learning pipeline design.\n* [Studio.ML](https://github.com/studioml/studio) ![](https://img.shields.io/github/stars/studioml/studio.svg?style=social) - Model management framework which minimizes the overhead involved with scheduling, running, monitoring and managing artifacts of your machine learning experiments.\n* [TRAINS](https://github.com/allegroai/trains) ![](https://img.shields.io/github/stars/allegroai/trains.svg?style=social) - Auto-Magical Experiment Manager & Version Control for AI.\n\n## Model Training Orchestration\n* [cnvrg CORE](https://cnvrg.io/platform/core/) - cnvrg CORE offers everything a data scientist needs to manage, build and automate high impact ML models from research to production. ([Video](https://www.youtube.com/watch?v=WrbW3gTxmQM))\n* [Hopsworks](https://github.com/logicalclocks/hopsworks) ![](https://img.shields.io/github/stars/logicalclocks/hopsworks.svg?style=social) - Hopsworks is a data-intensive platform for the design and operation of machine learning pipelines that includes a Feature Store. [(Video)](https://www.youtube.com/watch?v=v1DrnY8caVU).\n* [Kubeflow](https://github.com/kubeflow/kubeflow) ![](https://img.shields.io/github/stars/kubeflow/kubeflow.svg?style=social) - A cloud native platform for machine learning based on Google\xe2\x80\x99s internal machine learning pipelines.\n* [MLeap](https://github.com/combust/mleap) ![](https://img.shields.io/github/stars/combust/mleap.svg?style=social) - Standardisation of pipeline and model serialization for Spark, Tensorflow and sklearn\n* [NVIDIA TensorRT](https://github.com/NVIDIA/TensorRT) - TensorRT is a C++ library for high performance inference on NVIDIA GPUs and deep learning accelerators.\n* [Open Platform for AI](https://github.com/Microsoft/pai) ![](https://img.shields.io/github/stars/Microsoft/pai.svg?style=social) - Platform that provides complete AI model training and resource management capabilities.\n* [PyCaret](https://pycaret.org/) ![](https://img.shields.io/github/stars/pycaret/pycaret.svg?style=social)) - low-code library for training and deploying models (scikit-learn, XGBoost, LightGBM, spaCy)\n* [Redis-ML](https://github.com/RedisLabsModules/redis-ml) ![](https://img.shields.io/github/stars/RedisLabsModules/redis-ml.svg?style=social) - Module available from unstable branch that supports a subset of ML models as Redis data types. (Replaced by Redis AI)\n* [Skaffold](https://github.com/GoogleContainerTools/skaffold) ![]() - Skaffold is a command line tool that facilitates continuous development for Kubernetes applications. You can iterate on your application source code locally then deploy to local or remote Kubernetes clusters.\n* [Tensorflow Extended (TFX)](https://github.com/tensorflow/tfx) ![](https://img.shields.io/github/stars/tensorflow/tfx.svg?style=social) - Production oriented configuration framework for ML based on TensorFlow, incl. monitoring and model version management.\n\n## Model Serving and Monitoring\n* [BentoML](https://github.com/bentoml/BentoML) ![](https://img.shields.io/github/stars/bentoml/bentoml.svg?style=social) - BentoML is an open source framework for high performance ML model serving\n* [Clipper](https://github.com/ucbrise/clipper) ![](https://img.shields.io/github/stars/ucbrise/clipper.svg?style=social) - Model server project from Berkeley\'s Rise Rise Lab which includes a standard RESTful API and supports TensorFlow, Scikit-learn and Caffe models\n* [Cortex](https://github.com/cortexlabs/cortex) ![]() - Cortex is an open source platform for deploying machine learning models\xe2\x80\x94trained with nearly any framework\xe2\x80\x94as production web services.\n* [DeepDetect](https://github.com/beniz/deepdetect) ![](https://img.shields.io/github/stars/beniz/deepdetect.svg?style=social) - Machine Learning production server for TensorFlow, XGBoost and Cafe models written in C++ and maintained by Jolibrain\n* [ForestFlow](https://github.com/ForestFlow/ForestFlow)![](https://img.shields.io/github/stars/forestflow/forestflow.svg?style=social) - Cloud-native machine learning model server.\n* [Jina](https://github.com/jina-ai/jina)  ![](https://img.shields.io/github/stars/jina-ai/jina.svg?style=social) - Cloud native search framework that   supports to use deep learning/state of the art AI models for search.\n* [KFServing](https://github.com/kubeflow/kfserving) ![](https://img.shields.io/github/stars/kubeflow/kfserving.svg?style=social) - Serverless framework to deploy and monitor machine learning models in Kubernetes - [(Video)](https://www.youtube.com/watch?v=hGIvlFADMhU)\n* [Model Server for Apache MXNet (MMS)](https://github.com/awslabs/mxnet-model-server) ![](https://img.shields.io/github/stars/awslabs/mxnet-model-server.svg?style=social) - A model server for Apache MXNet from Amazon Web Services that is able to run MXNet models as well as Gluon models (Amazon\'s SageMaker runs a custom version of MMS under the hood)\n* [NVIDIA TensorRT Inference Server](https://github.com/NVIDIA/tensorrt-inference-server) - TensorRT Inference Server is an inference microservice that lets you serve deep learning models in production while maximizing GPU utilization.\n* [OpenScoring](https://github.com/openscoring/openscoring) ![](https://img.shields.io/github/stars/openscoring/openscoring.svg?style=social) - REST web service for scoring PMML models built and maintained by OpenScoring.io\n* [Redis-AI](https://github.com/RedisAI/RedisAI) ![](https://img.shields.io/github/stars/RedisAI/RedisAI.svg?style=social) - A Redis module for serving tensors and executing deep learning models. Expect changes in the API and internals.\n* [Seldon Core](https://github.com/SeldonIO/seldon-core) ![](https://img.shields.io/github/stars/SeldonIO/seldon-core.svg?style=social) - Open source platform for deploying and monitoring machine learning models in kubernetes - [(Video)](https://www.youtube.com/watch?v=pDlapGtecbY)\n* [Tensorflow Serving](https://www.tensorflow.org/serving/) ![](https://img.shields.io/github/stars/tensorflow/serving.svg?style=social) - High-performant framework to serve Tensorflow models via grpc protocol able to handle 100k requests per second per core\n\n## Adversarial Robustness Libraries\n* [AdvBox](https://github.com/advboxes/AdvBox) ![](https://img.shields.io/github/stars/advboxes/AdvBox.svg?style=social) - generate adversarial examples from the command line with 0 coding using PaddlePaddle, PyTorch, Caffe2, MxNet, Keras, and TensorFlow. Includes 10 attacks and also 6 defenses. Used to implement [StealthTshirt](https://github.com/advboxes/AdvBox/blob/master/applications/StealthTshirt/README.md) at DEFCON!\n* [Adversarial DNN Playground](https://github.com/QData/AdversarialDNN-Playground) ![](https://img.shields.io/github/stars/QData/AdversarialDNN-Playground.svg?style=social) - think [TensorFlow Playground](https://playground.tensorflow.org/), but for Adversarial Examples! A visualization tool designed for learning and teaching - the attack library is limited in size, but it has a nice front-end to it with buttons you can press!\n* [AdverTorch](https://github.com/BorealisAI/advertorch) ![](https://img.shields.io/github/stars/BorealisAI/advertorch.svg?style=social) - library for adversarial attacks / defenses specifically for PyTorch.\n* [Alibi Detect](https://github.com/SeldonIO/alibi-detect) ![](https://img.shields.io/github/stars/SeldonIO/alibi-detect.svg?style=social) - alibi-detect is a Python package focused on outlier, adversarial and concept drift detection. The package aims to cover both online and offline detectors for tabular data, text, images and time series. The outlier detection methods should allow the user to identify global, contextual and collective outliers.\n* [Artificial Adversary](https://github.com/airbnb/artificial-adversary) ![](https://img.shields.io/github/stars/airbnb/artificial-adversary.svg?style=social) AirBnB\'s library to generate text that reads the same to a human but passes adversarial classifiers.\n* [CleverHans](https://github.com/tensorflow/cleverhans) ![](https://img.shields.io/github/stars/tensorflow/cleverhans.svg?style=social) - library for testing adversarial attacks / defenses maintained by some of the most important names in adversarial ML, namely Ian Goodfellow (ex-Google Brain, now Apple) and Nicolas Papernot (Google Brain). Comes with some nice tutorials!\n* [DEEPSEC](https://github.com/kleincup/DEEPSEC) ![](https://img.shields.io/github/stars/kleincup/DEEPSEC.svg?style=social) - another systematic tool for attacking and defending deep learning models.\n* [EvadeML](https://github.com/mzweilin/EvadeML-Zoo) ![](https://img.shields.io/github/stars/mzweilin/EvadeML-Zoo.svg?style=social) - benchmarking and visualization tool for adversarial ML maintained by Weilin Xu, a PhD at University of Virginia, working with David Evans. Has a tutorial on re-implementation of one of the most important adversarial defense papers - [feature squeezing](https://arxiv.org/abs/1704.01155) (same team).\n* [Foolbox](https://github.com/bethgelab/foolbox) ![](https://img.shields.io/github/stars/bethgelab/foolbox.svg?style=social) - second biggest adversarial library. Has an even longer list of attacks - but no defenses or evaluation metrics. Geared more towards computer vision. Code easier to understand / modify than ART - also better for exploring blackbox attacks on surrogate models.\n* [IBM Adversarial Robustness 360 Toolbox (ART)](https://github.com/IBM/adversarial-robustness-toolbox) ![](https://img.shields.io/github/stars/IBM/adversarial-robustness-toolbox.svg?style=social) - at the time of writing this is the most complete off-the-shelf resource for testing adversarial attacks and defenses. It includes a library of 15 attacks, 10 empirical defenses, and some nice evaluation metrics. Neural networks only.\n* [MIA](https://github.com/spring-epfl/mia) ![](https://img.shields.io/github/stars/spring-epfl/mia.svg?style=social) - A library for running membership inference attacks (MIA) against machine learning models.\n* [Nicolas Carlini\xe2\x80\x99s Adversarial ML reading list](https://nicholas.carlini.com/writing/2018/adversarial-machine-learning-reading-list.html) - not a library, but a curated list of the most important adversarial papers by one of the leading minds in Adversarial ML, Nicholas Carlini. If you want to discover the 10 papers that matter the most - I would start here.\n* [Robust ML](https://www.robust-ml.org/defenses/) - another robustness resource maintained by some of the leading names in adversarial ML. They specifically focus on defenses, and ones that have published code available next to papers. Practical and useful.\n* [TextFool](https://github.com/bogdan-kulynych/textfool) ![](https://img.shields.io/github/stars/bogdan-kulynych/textfool.svg?style=social) - plausible looking adversarial examples for text generation.\n* [Trickster](https://github.com/spring-epfl/trickster) ![](https://img.shields.io/github/stars/spring-epfl/trickster.svg?style=social) - Library and experiments for attacking machine learning in discrete domains using graph search.\n\n\n## Neural Architecture Search\n* [Autokeras](https://github.com/jhfjhfj1/autokeras) ![](https://img.shields.io/github/stars/jhfjhfj1/autokeras.svg?style=social) - AutoML library for Keras based on [""Auto-Keras: Efficient Neural Architecture Search with Network Morphism""](https://arxiv.org/abs/1806.10282).\n* [Determined](https://github.com/determined-ai/determined) ![](https://img.shields.io/github/stars/determined-ai/determined.svg?style=social) - Hyperparameter search and distributed training platform for deep learning (supports Tensorflow and Pytorch).\n* [ENAS via Parameter Sharing](https://github.com/melodyguan/enas) - Efficient Neural Architecture Search via Parameter Sharing by [authors of paper](https://arxiv.org/abs/1802.03268).\n* [ENAS-PyTorch](https://github.com/carpedm20/ENAS-pytorch) ![](https://img.shields.io/github/stars/carpedm20/ENAS-pytorch.svg?style=social) - Efficient Neural Architecture Search (ENAS) in PyTorch based [on this paper](https://arxiv.org/abs/1802.03268).\n* [ENAS-Tensorflow](https://github.com/MINGUKKANG/ENAS-Tensorflow) ![](https://img.shields.io/github/stars/MINGUKKANG/ENAS-Tensorflow.svg?style=social) - Efficient Neural Architecture search via parameter sharing(ENAS) micro search Tensorflow code for windows user.\n* [Katib](https://github.com/kubeflow/katib) ![](https://img.shields.io/github/stars/kubeflow/katib.svg?style=social) - A Kubernetes-based system for Hyperparameter Tuning and Neural Architecture Search.\n* [Maggy](https://github.com/logicalclocks/maggy) ![](https://img.shields.io/github/stars/logicalclocks/maggy.svg?style=social) - Asynchronous, directed Hyperparameter search and parallel ablation studies on Apache Spark [(Video)](https://www.youtube.com/watch?v=0Hd1iYEL03w).\n* [Neural Architecture Search with Controller RNN](https://github.com/titu1994/neural-architecture-search) ![](https://img.shields.io/github/stars/titu1994/neural-architecture-search.svg?style=social) - Basic implementation of Controller RNN from [Neural Architecture Search with Reinforcement Learning](https://arxiv.org/abs/1611.01578) and [Learning Transferable Architectures for Scalable Image Recognition](https://arxiv.org/abs/1707.07012).\n* [Neural Network Intelligence](https://github.com/Microsoft/nni) ![](https://img.shields.io/github/stars/Microsoft/nni.svg?style=social) - NNI (Neural Network Intelligence) is a toolkit to help users run automated machine learning (AutoML) experiments.\n\n## Data Science Notebook Frameworks\n* [Binder](https://mybinder.org/) - Binder hosts notebooks in an executable environment (for free).\n* [H2O Flow](https://github.com/h2oai/h2o-flow) - Jupyter notebook-like interface for H2O to create, save and re-use ""flows""\n* [Hydrogen](https://atom.io/packages/hydrogen) - A plugin for ATOM that enables it to become a jupyter-notebook-like interface that prints the outputs directly in the editor.\n* [Jupyter Notebooks](https://github.com/jupyter/notebook) ![](https://img.shields.io/github/stars/jupyter/notebook.svg?style=social) - Web interface python sandbox environments for reproducible development\n* [ML Workspace](https://github.com/ml-tooling/ml-workspace) ![](https://img.shields.io/github/stars/ml-tooling/ml-workspace.svg?style=social) - All-in-one web IDE for machine learning and data science. Combines Jupyter, VS Code, Tensorflow, and many other tools/libraries into one Docker image.\n* [Papermill](https://github.com/nteract/papermill) ![](https://img.shields.io/github/stars/nteract/papermill.svg?style=social) - Papermill is a library for parameterizing notebooks and executing them like Python scripts.\n* [Polynote](https://github.com/ml-tooling/ml-workspace) ![](https://img.shields.io/github/stars/stencila/stencila.svg?style=social) - Polynote is an experimental polyglot notebook environment. Currently, it supports Scala and Python (with or without Spark), SQL, and Vega.\n* [RMarkdown](https://github.com/rstudio/rmarkdown) ![](https://img.shields.io/github/stars/rstudio/rmarkdown.svg?style=social) - The rmarkdown package is a next generation implementation of R Markdown based on Pandoc.\n* [Stencila](https://github.com/stencila/stencila) ![](https://img.shields.io/github/stars/stencila/stencila.svg?style=social) - Stencila is a platform for creating, collaborating on, and sharing data driven content. Content that is transparent and reproducible.\n* [Voil\xc3\xa0](https://github.com/voila-dashboards/voila) ![](https://img.shields.io/github/stars/voila-dashboards/voila.svg?style=social) - Voil\xc3\xa0 turns Jupyter notebooks into standalone web applications that can e.g. be used as dashboards.\n\n\n## Industrial Strength Visualisation libraries\n* [Bokeh](https://github.com/bokeh/bokeh) ![](https://img.shields.io/github/stars/bokeh/bokeh.svg?style=social) - Bokeh is an interactive visualization library for Python that enables beautiful and meaningful visual presentation of data in modern web browsers.\n* [Geoplotlib](https://github.com/andrea-cuttone/geoplotlib) ![](https://img.shields.io/github/stars/andrea-cuttone/geoplotlib.svg?style=social) - geoplotlib is a python toolbox for visualizing geographical data and making maps\n* [ggplot2](https://github.com/tidyverse/ggplot2) ![](https://img.shields.io/github/stars/tidyverse/ggplot2.svg?style=social) - An implementation of the grammar of graphics for R.\n* [matplotlib](https://github.com/matplotlib/matplotlib) ![](https://img.shields.io/github/stars/matplotlib/matplotlib.svg?style=social) - A Python 2D plotting library which produces publication-quality figures in a variety of hardcopy formats and interactive environments across platforms.\n* [Missigno](https://github.com/ResidentMario/missingno) ![](https://img.shields.io/github/stars/ResidentMario/missingno.svg?style=social) - missingno provides a small toolset of flexible and easy-to-use missing data visualizations and utilities that allows you to get a quick visual summary of the completeness (or lack thereof) of your dataset.\n* [PDPBox](https://github.com/SauceCat/PDPbox) ![](https://img.shields.io/github/stars/SauceCat/PDPbox.svg?style=social) - This repository is inspired by ICEbox. The goal is to visualize the impact of certain features towards model prediction for any supervised learning algorithm. (now support all scikit-learn algorithms)\n* [Perspective](https://github.com/finos/perspective) ![](https://img.shields.io/github/stars/finos/perspective.svg?style=social) Streaming pivot visualization via WebAssembly https://perspective.finos.org/\n* [Pixiedust](https://github.com/pixiedust/pixiedust) ![](https://img.shields.io/github/stars/pixiedust/pixiedust.svg?style=social) - PixieDust is a productivity tool for Python or Scala notebooks, which lets a developer encapsulate business logic into something easy for your customers to consume.\n* [Plotly Dash](https://github.com/plotly/dash) ![](https://img.shields.io/github/stars/plotly/dash.svg?style=social) - Dash is a Python framework for building analytical web applications without the need to write javascript.\n* [Plotly.py](https://github.com/plotly/plotly.py) ![](https://img.shields.io/github/stars/plotly/plotly.py.svg?style=social) - An interactive, open source, and browser-based graphing library for Python.\n* [PyCEbox](https://github.com/AustinRochford/PyCEbox) ![](https://img.shields.io/github/stars/AustinRochford/PyCEbox.svg?style=social) - Python Individual Conditional Expectation Plot Toolbox\n* [pygal](https://github.com/Kozea/pygal) ![](https://img.shields.io/github/stars/Kozea/pygal.svg?style=social) - pygal is a dynamic SVG charting library written in python\n* [Redash](https://github.com/getredash/redash) ![](https://img.shields.io/github/stars/getredash/redash.svg?style=social) - Redash is anopen source visualisation framework that is built to allow easy access to big datasets leveraging multiple backends.\n* [seaborn](https://github.com/mwaskom/seaborn) ![](https://img.shields.io/github/stars/mwaskom/seaborn.svg?style=social) - Seaborn is a Python visualization library based on matplotlib. It provides a high-level interface for drawing attractive statistical graphics.\n* [Streamlit](https://github.com/streamlit/streamlit) ![](https://img.shields.io/github/stars/streamlit/streamlit.svg?style=social) - Streamlit lets you create apps for your machine learning projects with deceptively simple Python scripts. It supports hot-reloading, so your app updates live as you edit and save your file\n* [XKCD-style plots](http://jakevdp.github.io/blog/2013/07/10/XKCD-plots-in-matplotlib/) - An XKCD theme for matblotlib visualisations\n* [yellowbrick](https://github.com/DistrictDataLabs/yellowbrick) ![](https://img.shields.io/github/stars/DistrictDataLabs/yellowbrick.svg?style=social) - yellowbrick is a matplotlib-based model evaluation plots for scikit-learn and other machine learning libraries.\n\n## Industrial Strength NLP\n* [Blackstone](https://github.com/ICLRandD/Blackstone) ![](https://img.shields.io/github/stars/ICLRandD/Blackstone.svg?style=social) - Blackstone is a spaCy model and library for processing long-form, unstructured legal text. Blackstone is an experimental research project from the Incorporated Council of Law Reporting for England and Wales\' research lab, ICLR&D.\n* [CTRL](https://github.com/salesforce/ctrl) ![](https://img.shields.io/github/stars/salesforce/ctrl.svg?style=social) - A Conditional Transformer Language Model for Controllable Generation released by SalesForce\n* [Facebook\'s XLM](https://github.com/facebookresearch/XLM) ![](https://img.shields.io/github/stars/facebookresearch/XLM.svg?style=social) - PyTorch original implementation of Cross-lingual Language Model Pretraining which includes BERT, XLM, NMT, XNLI, PKM, etc.\n* [Flair](https://github.com/zalandoresearch/flair) ![](https://img.shields.io/github/stars/zalandoresearch/flair.svg?style=social) - Simple framework for state-of-the-art NLP developed by Zalando which builds directly on PyTorch.\n* [Github\'s Semantic](https://github.com/github/semantic) ![](https://img.shields.io/github/stars/github/semantic.svg?style=social) - Github\'s text library for parsing, analyzing, and comparing source code across many languages .\n* [GluonNLP](https://github.com/dmlc/gluon-nlp) ![](https://img.shields.io/github/stars/dmlc/gluon-nlp.svg?style=social) - GluonNLP is a toolkit that enables easy text preprocessing, datasets loading and neural models building to help you speed up your Natural Language Processing (NLP) research.\n* [GNES](https://github.com/gnes-ai/gnes) ![](https://img.shields.io/github/stars/gnes-ai/gnes.svg?style=social) - Generic Neural Elastic Search is a cloud-native semantic search system based on deep neural networks.\n* [Grover](https://github.com/rowanz/grover) ![](https://img.shields.io/github/stars/rowanz/grover.svg?style=social) - Grover is a model for Neural Fake News -- both generation and detection. However, it probably can also be used for other generation tasks.\n* [Kashgari](https://github.com/BrikerMan/Kashgari) ![](https://img.shields.io/github/stars/BrikerMan/Kashgari.svg?style=social) - Kashgari is a simple and powerful NLP Transfer learning framework, build a state-of-art model in 5 minutes for named entity recognition (NER), part-of-speech tagging (PoS), and text classification tasks.\n* [OpenAI GPT-2](https://github.com/openai/gpt-2) ![](https://img.shields.io/github/stars/openai/gpt-2.svg?style=social) - OpenAI\'s code from their paper [""Language Models are Unsupervised Multitask Learners""](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf).\n* [sense2vec](https://github.com/explosion/sense2vec) ![](https://img.shields.io/github/stars/explosion/sense2vec.svg?style=social) - A Pytorch library that allows for training and using sense2vec models, which are models that leverage the same approach than word2vec, but also leverage part-of-speech attributes for each token, which allows it to be ""meaning-aware""\n* [Snorkel](https://github.com/snorkel-team/snorkel) ![](https://img.shields.io/github/stars/snorkel-team/snorkel.svg?style=social) - Snorkel is a system for quickly generating training data with weak supervision https://snorkel.org.\n* [SpaCy](https://github.com/explosion/spaCy) ![](https://img.shields.io/github/stars/explosion/spaCy.svg?style=social) - Industrial-strength natural language processing library built with python and cython by the explosion.ai team.\n* [Stable Baselines](https://github.com/hill-a/stable-baselines) ![](https://img.shields.io/github/stars/hill-a/stable-baselines.svg?style=social) - A fork of OpenAI Baselines, implementations of reinforcement learning algorithms http://stable-baselines.readthedocs.io/.\n* [Tensorflow Lingvo](https://github.com/tensorflow/lingvo) ![](https://img.shields.io/github/stars/tensorflow/lingvo.svg?style=social) - A framework for building neural networks in Tensorflow, particularly sequence models. [Lingvo: A TensorFlow Framework for Sequence Modeling](https://blog.tensorflow.org/2019/02/lingvo-tensorflow-framework-for-sequence-modeling.html).\n* [Tensorflow Text](https://github.com/tensorflow/text) ![](https://img.shields.io/github/stars/tensorflow/text.svg?style=social) - TensorFlow Text provides a collection of text related classes and ops ready to use with TensorFlow 2.0.\n* [Wav2Letter++](https://code.fb.com/ai-research/wav2letter/) - A speech to text system developed by Facebook\'s FAIR teams.\n* [YouTokenToMe](https://github.com/vkcom/youtokentome) ![](https://img.shields.io/github/stars/vkcom/youtokentome.svg?style=social) - YouTokenToMe is an unsupervised text tokenizer focused on computational efficiency. It currently implements fast Byte Pair Encoding (BPE) [Sennrich et al.].\n* [\xf0\x9f\xa4\x97 Transformers](https://github.com/huggingface/transformers) ![](https://img.shields.io/github/stars/huggingface/transformers.svg?style=social) - Huggingface\'s library of state-of-the-art pretrained models for Natural Language Processing (NLP).\n\n## Data Pipeline ETL Frameworks\n* [Apache Airflow](https://airflow.apache.org/) - Data Pipeline framework built in Python, including scheduler, DAG definition and a UI for visualisation\n* [Apache Nifi](https://github.com/apache/nifi) ![](https://img.shields.io/github/stars/apache/nifi.svg?style=social) - Apache NiFi was made for dataflow. It supports highly configurable directed graphs of data routing, transformation, and system mediation logic.\n* [Argo Workflows](https://github.com/argoproj/argo) ![](https://img.shields.io/github/stars/argoproj/argo.svg?style=social) - Argo Workflows is an open source container-native workflow engine for orchestrating parallel jobs on Kubernetes. Argo Workflows is implemented as a Kubernetes CRD (Custom Resource Definition).\n* [Azkaban](https://azkaban.github.io/) ![](https://img.shields.io/github/stars/azkaban/azkaban.svg?style=social) - Azkaban is a batch workflow job scheduler created at LinkedIn to run Hadoop jobs. Azkaban resolves the ordering through job dependencies and provides an easy to use web user interface to maintain and track your workflows.\n* [Chronos](https://github.com/mesos/chronos) ![](https://img.shields.io/github/stars/mesos/chronos.svg?style=social) - More of a job scheduler for Mesos than ETL pipeline. [OUTDATED]\n* [Genie](https://github.com/Netflix/genie) ![](https://img.shields.io/github/stars/Netflix/genie.svg?style=social) - Job orchestration engine to interface and trigger the execution of jobs from Hadoop-based systems\n* [Gokart](https://github.com/m3dev/gokart) ![](https://img.shields.io/github/stars/m3dev/gokart.svg?style=social) - Wrapper of the data pipeline Luigi\n* [Luigi](https://github.com/spotify/luigi) ![](https://img.shields.io/github/stars/spotify/luigi.svg?style=social) - Luigi is a Python module that helps you build complex pipelines of batch jobs, handling dependency resolution, workflow management, visualisation, etc\n* [Metaflow](https://metaflow.org/) ![](https://img.shields.io/github/stars/netflix/metaflow.svg?style=social) - A framework for data scientists to easily build and manage real-life data science projects.\n* [Neuraxle](https://github.com/Neuraxio/Neuraxle) ![](https://img.shields.io/github/stars/Neuraxio/Neuraxle.svg?style=social) - A framework for building neat pipelines, providing the right abstractions to chain your data transformation and prediction steps with data streaming, as well as doing hyperparameter searches (AutoML).\n* [Oozie](http://oozie.apache.org/) - Workflow scheduler for Hadoop jobs\n* [PipelineX](https://github.com/Minyus/pipelinex) ![](https://img.shields.io/github/stars/Minyus/pipelinex.svg?style=social) - Based on Kedro and MLflow. Full comparison given at https://github.com/Minyus/Python_Packages_for_Pipeline_Workflow\n* [Prefect Core](https://github.com/PrefectHQ/prefect) ![](https://img.shields.io/github/stars/PrefectHQ/prefect.svg?style=social) - Workflow management system that makes it easy to take your data pipelines and add semantics like retries, logging, dynamic mapping, caching, failure notifications, and more.\n\n## Data Labelling Tools and Frameworks\n* [COCO Annotator](https://github.com/jsbroks/coco-annotator) ![](https://img.shields.io/github/stars/jsbroks/coco-annotator.svg) - Web-based image segmentation tool for object detection, localization and keypoints\n* [Computer Vision Annotation Tool (CVAT)](https://github.com/opencv/cvat) ![](https://img.shields.io/github/stars/opencv/cvat.svg?style=social) - OpenCV\'s web-based annotation tool for both VIDEOS and images for computer algorithms.\n* [Doccano](https://github.com/chakki-works/doccano) ![](https://img.shields.io/github/stars/chakki-works/doccano.svg?style=social) - Open source text annotation tools for humans, providing functionality for sentiment analysis, named entity recognition, and machine translation.\n* [ImageTagger](https://github.com/bit-bots/imagetagger) ![](https://img.shields.io/github/stars/bit-bots/imagetagger.svg?style=social) - Image labelling tool with support for collaboration, supporting bounding box, polygon, line, point labelling, label export, etc.\n* [ImgLab](https://github.com/NaturalIntelligence/imglab) ![](https://img.shields.io/github/stars/NaturalIntelligence/imglab.svg?style=social) - Image annotation tool for bounding boxes with auto-suggestion and extensibility for plugins.\n* [Label Studio](https://github.com/heartexlabs/label-studio) ![](https://img.shields.io/github/stars/heartexlabs/label-studio.svg?style=social) - Multi-domain data labeling and annotation tool with standardized output format\n* [Labelimg](https://github.com/tzutalin/labelImg) ![](https://img.shields.io/github/stars/tzutalin/labelImg.svg?style=social) - Open source graphical image annotation tool writen in Python using QT for graphical interface focusing primarily on bounding boxes.\n* [MedTagger](https://github.com/medtagger/MedTagger) ![](https://img.shields.io/github/stars/medtagger/MedTagger.svg?style=social) - A collaborative framework for annotating medical datasets using crowdsourcing.\n* [OpenLabeling](https://github.com/Cartucho/OpenLabeling) ![](https://img.shields.io/github/stars/Cartucho/OpenLabeling.svg?style=social) - Open source tool for labelling images with support for labels, edges, as well as image resizing and zooming in.\n* [PixelAnnotationTool](https://github.com/abreheret/PixelAnnotationTool) ![](https://img.shields.io/github/stars/abreheret/PixelAnnotationTool.svg?style=social) - Image annotation tool with ability to ""colour"" on the images to select labels for segmentation. Process is semi-automated with the [watershed marked algorithm of OpenCV](docs.opencv.org/3.1.0/d7/d1b/group__imgproc__misc.html#ga3267243e4d3f95165d55a618c65ac6e1)\n* [Semantic Segmentation Editor](https://github.com/Hitachi-Automotive-And-Industry-Lab/semantic-segmentation-editor) ![](https://img.shields.io/github/stars/Hitachi-Automotive-And-Industry-Lab/semantic-segmentation-editor.svg?style=social) - Hitachi\'s Open source tool for labelling camera and LIDAR data.\n* [Superintendent](https://github.com/janfreyberg/superintendent) ![](https://img.shields.io/github/stars/janfreyberg/superintendent.svg?style=social) - superintendent provides an ipywidget-based interactive labelling tool for your data. \n* [VGG Image Annotator (VIA)](http://www.robots.ox.ac.uk/~vgg/software/via/) - A simple and standalone manual annotation software for image, audio and video. VIA runs in a web browser and does not require any installation or setup.\n* [Visual Object Tagging Tool (VOTT)](https://github.com/Microsoft/VoTT) ![](https://img.shields.io/github/stars/Microsoft/VoTT.svg?style=social) - Microsoft\'s Open Source electron app for labelling videos and images for object detection models (with active learning functionality)\n\n## Data Storage Optimisation\n* [Alluxio](https://www.alluxio.org/docs/1.8/en/Overview.html) - A virtual distributed storage system that bridges the gab between computation frameworks and storage systems.\n* [Apache Arrow](https://arrow.apache.org/) - In-memory columnar representation of data compatible with Pandas, Hadoop-based systems, etc\n* [Apache Druid](https://github.com/apache/druid) ![](https://img.shields.io/github/stars/apache/druid.svg?) - A high performance real-time analytics database. https://druid.apache.org/. [An introduction to Druid, your Interactive Analytics at (big) Scale](https://towardsdatascience.com/introduction-to-druid-4bf285b92b5a).\n* [Apache Ignite](https://github.com/apache/ignite) ![](https://img.shields.io/github/stars/apache/ignite.svg?) - A memory-centric distributed database, caching, and processing platform for transactional, analytical, and streaming workloads delivering in-memory speeds at petabyte scale. [TensorFlow on Apache Ignite](https://blog.tensorflow.org/2019/02/tensorflow-on-apache-ignite.html), [Distributed ML in Apache Ignite](https://www.youtube.com/watch?v=Xt4PWQ__YPw)\n* [Apache Kafka](https://kafka.apache.org/) - Distributed streaming platform framework\n* [Apache Parquet](https://parquet.apache.org/) - On-disk columnar representation of data compatible with Pandas, Hadoop-based systems, etc\n* [Apache Pinot](https://github.com/apache/incubator-pinot) ![](https://img.shields.io/github/stars/apache/incubator-pinot.svg?) - A realtime distributed OLAP datastore https://pinot.apache.org. [Comparison of the Open Source OLAP Systems for Big Data: ClickHouse, Druid, and Pinot](https://medium.com/@leventov/comparison-of-the-open-source-olap-systems-for-big-data-clickhouse-druid-and-pinot-8e042a5ed1c7).\n* [BayesDB](http://probcomp.csail.mit.edu/software/bayesdb/) - Database that allows for built-in non-parametric Bayesian model discovery and queryingi for data on a database-like interface - [(Video)](https://www.youtube.com/watch?v=2ws84s6iD1o)\n* [ClickHouse](https://clickhouse.yandex/) ![](https://img.shields.io/github/stars/ClickHouse/ClickHouse.svg?) - ClickHouse is an open source column oriented database management system supported by Yandex - [(Video)](https://\n* [EdgeDB](https://edgedb.com/) - NoSQL interface for Postgres that allows for object interaction to data stored\n* [HopsFS](https://github.com/hopshadoop/hops) ![](https://img.shields.io/github/stars/hopshadoop/hops.svg?style=social) - HDFS-compatible file system with scale-out strongly consistent metadata.\n* [InfluxDB](https://github.com/influxdata/influxdb) ![](https://img.shields.io/github/stars/influxdata/influxdb.svg?) Scalable datastore for metrics, events, and real-time analytics.\n* [TimescaleDB](https://github.com/timescale/timescaledb) ![](https://img.shields.io/github/stars/timescale/timescaledb.svg?) An open-source time-series SQL database optimized for fast ingest and complex queries. Packaged as a PostgreSQL extension. [Time-series ML in TimescaleDB](https://docs.timescale.com/latest/tutorials/tutorial-forecasting)\nwww.youtube.com/watch?v=zbjub8BQPyE)\n\n## Function as a Service Frameworks\n* [Apache OpenWhisk](https://github.com/apache/incubator-openwhisk) ![](https://img.shields.io/github/stars/apache/incubator-openwhisk.svg?style=social) - Open source, distributed serverless platform that executes functions in response to events at any scale.\n* [Fission](https://github.com/fission/fission) ![](https://img.shields.io/github/stars/fission/fission.svg?style=social) - (Early Alpha) Serverless functions as a service framework on Kubernetes\n* [Hydrosphere Mist](https://github.com/Hydrospheredata/mist) ![](https://img.shields.io/github/stars/Hydrospheredata/mist.svg?style=social) - Serverless proxy for Apache Spark clusters\n* [Hydrosphere ML Lambda](https://github.com/Hydrospheredata/hydro-serving) ![](https://img.shields.io/github/stars/Hydrospheredata/hydro-serving.svg?style=social) - Open source model management cluster for deploying, serving and monitoring machine learning models and ad-hoc algorithms with a FaaS architecture\n* [KNative Serving](https://github.com/knative/serving) ![](https://img.shields.io/github/stars/knative/serving.svg?style=social) - Kubernetes based serverless microservices with ""scale-to-zero"" functionality.\n* [OpenFaaS](https://github.com/openfaas/faas) ![](https://img.shields.io/github/stars/openfaas/faas.svg?style=social) - Serverless functions framework with RESTful API on Kubernetes\n\n## Computation load distribution frameworks\n* [Apache Spark MLlib](https://spark.apache.org/mllib/) - Apache Spark\'s scalable machine learning library in Java, Scala, Python and R\n* [Beam](https://github.com/apache/beam) ![](https://img.shields.io/github/stars/apache/beam.svg?style=social) Apache Beam is a unified programming model for Batch and Streaming https://beam.apache.org/\n* [BigDL](https://bigdl-project.github.io/) - Deep learning framework on top of Spark/Hadoop to distribute data and computations across a HDFS system\n* [Dask](http://dask.pydata.org/en/latest/) - Distributed parallel processing framework for Pandas and NumPy computations - [(Video)](https://www.youtube.com/watch?v=RA_2qdipVng)\n* [DEAP](https://github.com/DEAP/deap) ![](https://img.shields.io/github/stars/DEAP/deap.svg?style=social) - A novel evolutionary computation framework for rapid prototyping and testing of ideas. It seeks to make algorithms explicit and data structures transparent. It works in perfect harmony with parallelisation mechanisms such as multiprocessing and SCOOP.\n* [Hadoop Open Platform-as-a-service (HOPS)](https://www.hops.io/) - A multi-tenancy open source framework with RESTful API for data science on Hadoop which enables for Spark, Tensorflow/Keras, it is Python-first, and provides a lot of features\n* [Horovod](https://github.com/uber/horovod) ![](https://img.shields.io/github/stars/uber/horovod.svg?style=social) - Uber\'s distributed training framework for TensorFlow, Keras, and PyTorch\n* [NumPyWren](https://github.com/Vaishaal/numpywren) ![](https://img.shields.io/github/stars/Vaishaal/numpywren.svg?style=social) - Scientific computing framework build on top of pywren to enable numpy-like distributed computations\n* [PyWren](http://pywren.io) - Answer the question of the ""cloud button"" for python function execution. It\'s a framework that abstracts AWS Lambda to enable data scientists to execute any Python function - [(Video)](https://www.youtube.com/watch?v=OskQytBBdJU)\n* [Ray](https://github.com/ray-project/ray) ![](https://img.shields.io/github/stars/ray-project/ray.svg?style=social) - Ray is a flexible, high-performance distributed execution framework for machine learning ([VIDEO](https://www.youtube.com/watch?v=D_oz7E4v-U0))\n* [Vespa](https://github.com/vespa-engine/vespa) ![](https://img.shields.io/github/stars/vespa-engine/vespa.svg?style=social) Vespa is an engine for low-latency computation over large data sets. https://vespa.ai\n\n\n## Model serialisation formats\n* [Java PMML API](https://github.com/jpmml) - Java libraries for consuming and producing PMML files containing models from different frameworks, including:\n    * [pyspark2pmml](https://github.com/jpmml/pyspark2pmml)\n    * [r2pmml](https://github.com/jpmml/r2pmml)\n    * [sklearn2pmml](https://github.com/jpmml/jpmml-sklearn)\n    * [sparklyr2pmml](https://github.com/jpmml/sparklyr2pmml)\n* [MMdnn](https://github.com/Microsoft/MMdnn) ![](https://img.shields.io/github/stars/Microsoft/MMdnn.svg?style=social) - Cross-framework solution to convert, visualize and diagnose deep neural network models.\n* [Neural Network Exchange Format (NNEF)](https://www.khronos.org/nnef) - A standard format to store models across Torch, Caffe, TensorFlow, Theano, Chainer, Caffe2, PyTorch, and MXNet\n* [ONNX](https://github.com/onnx/onnx) ![](https://img.shields.io/github/stars/onnx/onnx.svg?style=social) - Open Neural Network Exchange Format\n* [PFA](http://dmg.org/pfa/index.html) - Created by the same organisation as PMML, the Predicted Format for Analytics is an emerging standard for statistical models and data transformation engines.\n* [PMML](http://dmg.org/pmml/v4-3/GeneralStructure.html) - The Predictive Model Markup Language standard in XML - ([Video](https://www.youtube.com/watch?v=_5pZm2PZ8Q8))_\n\n\n## Optimized calculation frameworks\n* [CuDF](https://github.com/rapidsai/cudf) ![](https://img.shields.io/github/stars/rapidsai/cudf.svg?style=social) cuDF - GPU DataFrame Library http://rapids.ai\n* [CuML](https://github.com/rapidsai/cuml) ![](https://img.shields.io/github/stars/rapidsai/cuml.svg?style=social) cuML - RAPIDS Machine Learning Library\n* [CuPy](https://github.com/cupy/cupy) ![](https://img.shields.io/github/stars/cupy/cupy.svg?style=social) NumPy-like API accelerated with CUDA\n* [Modin](https://github.com/modin-project/modin) ![](https://img.shields.io/github/stars/modin-project/modin.svg?style=social) - Speed up your Pandas workflows by changing a single line of code \n* [Numba](https://github.com/numba/numba) ![](https://img.shields.io/github/stars/numba/numba.svg?style=social)  - A compiler for Python array and numerical functions\n* [NumpyGroupies](https://github.com/ml31415/numpy-groupies) ![](https://img.shields.io/github/stars/ml31415/numpy-groupies.svg?style=social) Optimised tools for group-indexing operations: aggregated sum and more\n* [Weld](https://github.com/weld-project/weld) ![](https://img.shields.io/github/stars/weld-project/weld.svg?style=social) High-performance runtime for data analytics applications, [Interview with Weld\xe2\x80\x99s main contributor](https://notamonadtutorial.com/weld-accelerating-numpy-scikit-and-pandas-as-much-as-100x-with-rust-and-llvm-12ec1c630a1)\n\n## Data Stream Processing\n* [Apache Flink](https://github.com/apache/flink) ![](https://img.shields.io/github/stars/apache/flink.svg?style=social) - Open source stream processing framework with powerful stream and batch processing capabilities.\n* [Apache Samza](http://samza.apache.org/) ![](https://img.shields.io/github/stars/apache/samza.svg?style=social) - Distributed stream processing framework. It uses Apache Kafka for messaging, and Apache Hadoop YARN to provide fault tolerance, processor isolation, security, and resource management.\n* [Brooklin](https://github.com/linkedin/Brooklin/) ![](https://img.shields.io/github/stars/linkedin/Brooklin.svg?style=social) - Distributed stream processing framework. It uses Apache Kafka for messaging, and Apache Hadoop YARN to provide fault tolerance, processor isolation, security, and resource management.\n* [Faust](https://github.com/robinhood/faust) ![](https://img.shields.io/github/stars/robinhood/faust.svg?style=social) - Streaming library built on top of Python\'s Asyncio library using the async kafka client inspired by the kafka streaming library.\n* [Kafka Streams](https://kafka.apache.org/documentation/streams/) ![](https://img.shields.io/github/stars/apache/kafka.svg?style=social) - Kafka client library for buliding applications and microservices where the input and output are stored in kafka clusters\n* [Spark Streaming](https://spark.apache.org/streaming/) ![](https://img.shields.io/github/stars/apache/spark.svg?style=social) - Micro-batch processing for streams using the apache spark framework as a backend supporting stateful exactly-once semantics\n\n## Outlier and Anomaly Detection\n* [adtk](https://github.com/arundo/adtk) ![](https://img.shields.io/github/stars/arundo/adtk.svg)  - A Python toolkit for rule-based/unsupervised anomaly detection in time series.  \n* [Alibi-Detect](https://github.com/SeldonIO/alibi-detect) ![](https://img.shields.io/github/stars/seldonio/alibi-detect.svg) - Algorithms for outlier and adversarial instance detection, concept drift and metrics.\n* [dBoost](https://github.com/cpitclaudel/dBoost) ![](https://img.shields.io/github/stars/cpitclaudel/dBoost.svg) - Outlier detection in heterogeneous datasets using automatic tuple expansion. [Paper](https://dspace.mit.edu/bitstream/handle/1721.1/101150/MIT-CSAIL-TR-2016-002.pdf?sequence=1).\n* [Deequ](https://github.com/awslabs/deequ) ![](https://img.shields.io/github/stars/awslabs/deequ.svg) - A library built on top of Apache Spark for defining ""unit tests for data"", which measure data quality in large datasets.\n* [Deep Anomaly Detection with Outlier Exposure](https://github.com/hendrycks/outlier-exposure) ![](https://img.shields.io/github/stars/hendrycks/outlier-exposure.svg) - Outlier Exposure (OE) is a method for improving anomaly detection performance in deep learning models. [Paper](https://arxiv.org/pdf/1812.04606.pdf)\n* [PyOD](https://github.com/yzhao062/pyod) ![](https://img.shields.io/github/stars/yzhao062/pyod.svg) - A Python Toolbox for Scalable Outlier Detection (Anomaly Detection). \n* [SUOD (Scalable Unsupervised Outlier Detection)](https://github.com/yzhao062/SUOD) ![](https://img.shields.io/github/stars/yzhao062/SUOD.svg) - An Acceleration System for Large-scale Outlier Detection (Anomaly Detection) \n* [Tensorflow Data Validation (TFDV)](https://github.com/tensorflow/data-validation) ![](https://img.shields.io/github/stars/tensorflow/data-validation.svg) - Library for exploring and validating machine learning data.\n\n\n## Feature Engineering Automation\n* [auto-sklearn](https://automl.github.io/auto-sklearn/) ![](https://img.shields.io/github/stars/automl/auto-sklearn.svg?style=social) - Framework to automate algorithm and hyperparameter tuning for sklearn\n* [AutoML-GS](https://github.com/minimaxir/automl-gs) ![](https://img.shields.io/github/stars/blue-yonder/tsfresh.svg?style=social) - Automatic feature and model search with code generation in Python, on top of common data science libraries (tensorflow, sklearn, etc)\n* [automl](https://github.com/ClimbsRocks/auto_ml) ![](https://img.shields.io/github/stars/ClimbsRocks/automl.svg?style=social) - Automated feature engineering, feature/model selection, hyperparam. optimisation\n* [Colombus](http://i.stanford.edu/hazy/victor/columbus/) - A scalable framework to perform exploratory feature selection implemented in R\n* [Feature Engine](https://github.com/solegalli/feature_engine) ![](https://img.shields.io/github/stars/solegalli/feature_engine.svg?style=social) - Feature-engine is a Python library that contains several transformers to engineer features for use in machine learning models. \n* [Featuretools](https://www.featuretools.com/) - An open source framework for automated feature engineering\n* [sklearn-deap](https://github.com/rsteca/sklearn-deap) ![](https://img.shields.io/github/stars/rsteca/sklearn-deap.svg?style=social) Use evolutionary algorithms instead of gridsearch in scikit-learn.\n* [TPOT](https://epistasislab.github.io/tpot/) ![](https://img.shields.io/github/stars/epistasislab/tpot.svg?style=social) - Automation of sklearn pipeline creation (including feature selection, pre-processor, etc)\n* [tsfresh](https://github.com/blue-yonder/tsfresh) ![](https://img.shields.io/github/stars/blue-yonder/tsfresh.svg?style=social) - Automatic extraction of relevant features from time series\n* [mljar-supervised](https://github.com/mljar/mljar-supervised) ![](https://img.shields.io/github/stars/mljar/mljar-supervised.svg?style=social) - An Automated Machine Learning (AutoML) python package for tabular data. It can handle: Binary Classification, MultiClass Classification and Regression. It provides feature engineering, explanations and markdown reports.\n\n\n## Feature Stores\n* [Feature Store for Machine Learning (FEAST)](https://github.com/feast-dev/feast)  ![](https://img.shields.io/github/stars/feast-dev/feast.svg?style=social) - Feast (Feature Store) is a tool for managing and serving machine learning features. Feast is the bridge between models and data.\n* [Hopsworks Feature Store](https://github.com/logicalclocks/hopsworks) ![](https://img.shields.io/github/stars/logicalclocks/hopsworks.svg?style=social) - Offline/Online Feature Store for ML [(Video)](https://www.youtube.com/watch?v=N1BjPk1smdg).\n* [Ivory](https://github.com/antony-a1/ivory)  ![](https://img.shields.io/github/stars/antony-a1/ivory.svg?style=social) - ivory defines a specification for how to store feature data and provides a set of tools for querying it. It does not provide any tooling for producing feature data in the first place. All ivory commands run as MapReduce jobs so it assumed that feature data is maintained on HDFS.\n* [Veri](https://github.com/bgokden/veri) ![](https://img.shields.io/github/stars/bgokden/veri.svg?style=social) - Veri is a Feature Label Store. Feature Label store allows storing features as keys and labels as values. Querying values is only possible with knn using features. Veri also supports creating sub sample spaces of data by default.\n\n\n## Commercial Platforms\n* [Algorithmia](https://algorithmia.com/) - Cloud platform to build, deploy and serve machine learning models [(Video)](https://www.youtube.com/watch?v=qcsrPY0koyY)\n* [allegro ai Enterprise](https://allegro.ai/enterprise) - Automagical open-source ML & DL experiment manager and ML-Ops solution.\n* [Amazon SageMaker](https://aws.amazon.com/sagemaker/) - End-to-end machine learning development and deployment interface where you are able to build notebooks that use EC2 instances as backend, and then can host models exposed on an API\n* [bigml](https://bigml.com/) - E2E machine learning platform.\n* [cnvrg.io](https://cnvrg.io) - An end-to-end platform to manage, build and automate machine learning\n* [Comet.ml](http://comet.ml) - Machine learning experiment management. Free for open source and students [(Video)](https://www.youtube.com/watch?v=xaybRkapeNE)\n* [D2iQ KUDO Kubeflow](https://d2iq.com/solutions/ksphere/kudo-kubeflow) - Enterprise MLOps platform that runs in the cloud, on premises (incl. air-gapped), or on the edge; based on Kubeflow and open-source [KUDO](https://kudo.dev/) operators.\n* [Dataiku](https://www.dataiku.com/) - Collaborative data science platform powering both self-service analytics and the operationalization of machine learning models in production.\n* [DataRobot](https://www.datarobot.com/) - Automated machine learning platform which enables users to build and deploy machine learning models.\n* [Datatron](https://datatron.com/) - Machine Learning Model Governance Platform for all your AI models in production for large Enterprises.\n* [Datmo](https://datmo.com/) - Workflow tools for monitoring your deployed models to experiment and optimize models in production.\n* [deepsense AIOps](https://aiops.deepsense.ai/) - Enhances multi-cloud & data center IT Operations via traffic analysis, risk analysis, anomaly detection, predictive maintenance, root cause analysis, service ticket analysis and event consolidation.\n* [Deep Cognition Deep Learning Studio](https://deepcognition.ai/) - E2E platform for deep learning.\n* [deepsense Safety](https://safety.deepsense.ai/) - AI-driven solution to increase worksite safety via safety procedure check, thread detection and hazardous zones monitoring.\n* [deepsense Quality](https://quality.deepsense.ai/) - Automating laborious quality control tasks.\n* [Google Cloud Machine Learning Engine](https://cloud.google.com/ml-engine/) - Managed service that enables developers and data scientists to build and bring machine learning models to production.\n* [IBM Watson Machine Learning](https://www.ibm.com/cloud/machine-learning) - Create, train, and deploy self-learning models using an automated, collaborative workflow.\n* [Labelbox](https://labelbox.com/) - Image labelling service with support for semantic segmentation (brush & superpixels), bounding boxes and nested classifications.\n* [Logical Clocks Hopsworks](https://www.logicalclocks.com/) - Enterprise version of Hopsworks with a Feature Store and scale-out ML pipeline design and operation.\n* [MCenter](https://www.parallelm.com/product/) - MLOps platform automates the deployment, ongoing optimization, and governance of machine learning applications in production.\n* [Microsoft Azure Machine Learning service](https://azure.microsoft.com/en-us/services/machine-learning-service/) - Build, train, and deploy models from the cloud to the edge.\n* [MLJAR](https://mljar.com/) - Platform for rapid prototyping, developing and deploying machine learning models.\n* [neptune.ml](https://neptune.ml) - community-friendly platform supporting data scientists in creating and sharing machine learning models. Neptune facilitates teamwork, infrastructure management, models comparison and reproducibility.\n* [Prodigy](https://prodi.gy/) - Active learning-based data annotation. Allows to train a model and pick most \'uncertain\' samples for labeling from an unlabeled pool.\n* [Skafos](https://metismachine.com/products/) - Skafos platform bridges the gap between data science, devops and engineering; continuous deployment, automation and monitoring.\n* [SKIL](https://skymind.ai/platform) - Software distribution designed to help enterprise IT teams manage, deploy, and retrain machine learning models at scale.\n* [Skytree 16.0](http://skytree.net) - End to end machine learning platform [(Video)](https://www.youtube.com/watch?v=XuCwpnU-F1k)\n* [Spell](https://spell.run) - Flexible end-to-end MLOps / Machine Learning Platform. [(Video)](https://www.youtube.com/watch?v=J7xo-STHx1k)\n* [Talend Studio](https://www.talend.com/)\n* [Valohai](https://valohai.com/) - Machine orchestration, version control and pipeline management for deep learning.\n'"
46,dipanjanS/practical-machine-learning-with-python,dipanjanS,Master the essential skills needed to recognize and solve complex real-world problems with Machine Learning and Deep Learning by leveraging the highly popular Python Machine Learning Eco-system.,2017-07-29 10:31:36,2020-06-18 16:28:46,Jupyter Notebook,1247,1522,"b'# Practical Machine Learning with Python\n### A Problem-Solver\'s Guide to Building Real-World Intelligent Systems\n\n*""Data is the new oil""* is a saying which you must have heard by now along with the huge interest building up around Big Data and Machine Learning in the recent past along with Artificial Intelligence and Deep Learning. Besides this, data scientists have been termed as having *""The sexiest job in the 21st Century""* which makes it all the more worthwhile to build up some valuable expertise in these areas. Getting started with machine learning in the real world can be overwhelming with the vast amount of resources out there on the web.\n\n[*__""Practical Machine Learning with Python""__*](https://github.com/dipanjanS/practical-machine-learning-with-python#contents)  follows a structured and comprehensive three-tiered approach packed with concepts, methodologies, hands-on examples, and code. This book is packed with over 500 pages of useful information which helps its readers master the essential skills needed to recognize and solve complex problems with Machine Learning and Deep Learning by following a data-driven mindset. By using real-world case studies that leverage the popular Python Machine Learning ecosystem, this book is your perfect companion for learning the art and science of Machine Learning to become a successful practitioner. The concepts, techniques, tools, frameworks, and methodologies used in this book will teach you how to think, design, build, and execute Machine Learning systems and projects successfully.\n\nThis repository contains all the code, notebooks and examples used in this book. We will also be adding bonus content here from time to time. So keep watching this space!\n\n## Get the book \n<div>\n<a target=""_blank"" href=""https://www.apress.com/us/book/9781484232064"">\n  <img src=""./media/banners/apress_logo.png"" alt=""apress"" align=""left""/>\n</a>\n<a target=""_blank"" href=""http://www.springer.com/us/book/9781484232064"">\n  <img src=""./media/banners/springer_logo.png"" alt=""springer"" align=""left""/>\n</a>\n<a target=""_blank"" href=""https://www.amazon.com/Practical-Machine-Learning-Python-Problem-Solvers/dp/1484232062/ref=sr_1_10?ie=UTF8&qid=1513756537&sr=8-10&keywords=practical+machine+learning+with+python"">\n  <img src=""./media/banners/amazon_logo.jpg"" alt=""amazon"" align=""left""/>\n</a>\n<br>\n</div>\n<br>\n<div>\n</div>\n<br><br>\n\n## About the book \n<a target=""_blank"" href=""https://www.amazon.com/Practical-Machine-Learning-Python-Problem-Solvers/dp/1484232062/ref=sr_1_10?ie=UTF8&qid=1513756537&sr=8-10&keywords=practical+machine+learning+with+python"">\n  <img src=""./media/banners/cover_front.jpg"" alt=""Book Cover"" width=""250"" align=""left""/>\n</a>\n\nMaster the essential skills needed to recognize and solve complex problems with machine learning and deep learning. Using real-world examples that leverage the popular Python machine learning ecosystem, this book is your perfect companion for learning the art and science of machine learning to become a successful practitioner. The concepts, techniques, tools, frameworks, and methodologies used in this book will teach you how to think, design, build, and execute machine learning systems and projects successfully. \n\nWe focus on leveraging the latest state-of-the-art data analysis, machine learning and deep learning frameworks including [`scikit-learn`](http://scikit-learn.org/stable/), [`pandas`](https://pandas.pydata.org/), [`statsmodels`](http://www.statsmodels.org/stable/index.html), [`spaCy`](https://spacy.io/), [`nltk`](http://www.nltk.org/), [`gensim`](https://radimrehurek.com/gensim/), [`tensorflow`](https://www.tensorflow.org/), [`keras`](https://keras.io/), [`skater`](https://www.datascience.com/resources/tools/skater) and several others to process, wrangle, analyze, visualize and model on real-world datasets and problems! With a learn-by-doing approach, we try to abstract out complex theory and concepts (while presenting the essentials wherever necessary), which often tends to hold back practitioners from leveraging the true power of machine learning to solve their own problems.\n\n<div style=\'font-size:0.5em;\'><sup>\nEdition: 1st &emsp; Pages: 532 &emsp; Language: English<br/>\n Book Title: Practical Machine Learning with Python &emsp; Publisher: Apress (a part of Springer) &emsp; Copyright: Dipanjan Sarkar, Raghav Bali, Tushar Sharma<br/>  \n Print ISBN: 978-1-4842-3206-4 &emsp; Online ISBN: 978-1-4842-3207-1 &emsp; DOI: 10.1007/978-1-4842-3207-1<br/>\n</div>\n<br>\n\n[*__Practical Machine Learning with Python__*](https://github.com/dipanjanS/practical-machine-learning-with-python#contents) follows a structured and comprehensive three-tiered approach packed with hands-on examples and code.\n\n - [__Part 1__](https://github.com/dipanjanS/practical-machine-learning-with-python#contents) focuses on understanding machine learning concepts and tools. This includes machine learning basics with a broad overview of algorithms, techniques, concepts and applications, followed by a tour of the entire Python machine learning ecosystem. Brief guides for useful machine learning tools, libraries and frameworks are also covered.\n\n - [__Part 2__](https://github.com/dipanjanS/practical-machine-learning-with-python#contents) details standard machine learning pipelines, with an emphasis on data processing analysis, feature engineering, and modeling. You will learn how to process, wrangle, summarize and visualize data in its various forms. Feature engineering and selection methodologies will be covered in detail with real-world datasets followed by model building, tuning, interpretation and deployment.\n\n - [__Part 3__](https://github.com/dipanjanS/practical-machine-learning-with-python#contents) explores multiple real-world case studies spanning diverse domains and industries like *retail*, *transportation*, *movies*, *music*, *marketing*, *computer vision* and *finance*. For each case study, you will learn the application of various machine learning techniques and methods. The hands-on examples will help you become familiar with state-of-the-art machine learning tools and techniques and understand what algorithms are best suited for any problem.\n\n[*__Practical Machine Learning with Python__*](https://github.com/dipanjanS/practical-machine-learning-with-python#contents) will empower you to start solving your own problems with machine learning today!\n<br>\n\n## [Contents](https://github.com/dipanjanS/practical-machine-learning-with-python/tree/master/notebooks#book-contents)  \n\n - [__Part I: Understanding Machine Learning__](https://github.com/dipanjanS/practical-machine-learning-with-python/tree/master/notebooks#part-i-understanding-machine-learning)\n    - [Chapter 1: Machine Learning Basics](https://github.com/dipanjanS/practical-machine-learning-with-python/tree/master/notebooks/Ch01_Machine_Learning_Basics#chapter-1-machine-learning-basics)\n    - [Chapter 2: The Python Machine Learning Ecosystem](https://github.com/dipanjanS/practical-machine-learning-with-python/tree/master/notebooks/Ch02_The_Python_ML_Ecosystem#chapter-2-the-python-machine-learning-ecosystem)\n - [__Part II: The Machine Learning Pipeline__](https://github.com/dipanjanS/practical-machine-learning-with-python/tree/master/notebooks#part-ii-the-machine-learning-pipeline)\n    - [Chapter 3: Processing, Wrangling and Visualizing Data](https://github.com/dipanjanS/practical-machine-learning-with-python/tree/master/notebooks/Ch03_Processing_Wrangling_and_Visualizing_Data#chapter-3-processing-wrangling-and-visualizing-data)\n    - [Chapter 4: Feature Engineering and Selection](https://github.com/dipanjanS/practical-machine-learning-with-python/tree/master/notebooks/Ch04_Feature_Engineering_and_Selection#chapter-4-feature-engineering-and-selection)\n    - [Chapter 5: Building, Tuning and Deploying Models](https://github.com/dipanjanS/practical-machine-learning-with-python/tree/master/notebooks/Ch05_Building_Tuning_and_Deploying_Models#chapter-5-building-tuning-and-deploying-models)\n - [__Part III: Real-World Case Studies__](https://github.com/dipanjanS/practical-machine-learning-with-python/tree/master/notebooks#part-iii-real-world-case-studies)\n    - [Chapter 6: Analyzing Bike Sharing Trends](https://github.com/dipanjanS/practical-machine-learning-with-python/tree/master/notebooks/Ch06_Analyzing_Bike_Sharing_Trends#chapter-6-analyzing-bike-sharing-trends)\n    - [Chapter 7: Analyzing Movie Reviews Sentiment](https://github.com/dipanjanS/practical-machine-learning-with-python/tree/master/notebooks/Ch07_Analyzing_Movie_Reviews_Sentiment#chapter-7-analyzing-movie-reviews-sentiment)\n    - [Chapter 8: Customer Segmentation and Effective Cross Selling](https://github.com/dipanjanS/practical-machine-learning-with-python/tree/master/notebooks/Ch08_Customer_Segmentation_and_Effective_Cross_Selling#chapter-8-customer-segmentation-and-effective-cross-selling)\n    - [Chapter 9: Analyzing Wine Types and Quality](https://github.com/dipanjanS/practical-machine-learning-with-python/tree/master/notebooks/Ch09_Analyzing_Wine_Types_and_Quality#chapter-9-analyzing-wine-types-and-quality)\n    - [Chapter 10: Analyzing Music Trends and Recommendations](https://github.com/dipanjanS/practical-machine-learning-with-python/tree/master/notebooks/Ch10_Analyzing_Music_Trends_and_Recommendations#chapter-10-analyzing-music-trends-and-recommendations)\n    - [Chapter 11: Forecasting Stock and Commodity Prices](https://github.com/dipanjanS/practical-machine-learning-with-python/tree/master/notebooks/Ch11_Forecasting_Stock_and_Commodity_Prices#chapter-11-forecasting-stock-and-commodity-prices)\n    - [Chapter 12: Deep Learning for Computer Vision](https://github.com/dipanjanS/practical-machine-learning-with-python/tree/master/notebooks/Ch12_Deep_Learning_for_Computer_Vision#chapter-12-deep-learning-for-computer-vision)\n\n## What You\'ll Learn\n\n - Execute end-to-end machine learning projects and systems\n - Implement hands-on examples with industry standard, open source, robust machine learning tools and frameworks\n - Review case studies depicting applications of machine learning and deep learning on diverse domains and industries\n - Apply a wide range of machine learning models including regression, classification, and clustering.\n - Understand and apply the latest models and methodologies from deep learning including CNNs, RNNs, LSTMs and transfer learning.\n \n## Powered by the following Frameworks\n\n| | | | | |\n:---:|:---:|:---:|:---:|:---:\n<a target=""_blank"" href=""https://anaconda.org/""><img src=""./media/banners/anaconda_logo.jpg"" alt=""anaconda"" /></a>|<a target=""_blank"" href=""http://jupyter.org/""><img src=""./media/banners/jupyter_logo.jpg"" alt=""jupyter"" /></a>|<a target=""_blank"" href=""http://www.numpy.org/""><img src=""./media/banners/numpy_logo.jpg"" alt=""numpy"" /></a>|<a target=""_blank"" href=""https://www.scipy.org/""><img src=""./media/banners/scipy_logo.jpg"" alt=""scipy"" /></a>|<a target=""_blank"" href=""https://pandas.pydata.org/""><img src=""./media/banners/pandas_logo.jpg"" alt=""pandas"" /></a>\n<a target=""_blank"" href=""http://www.statsmodels.org/stable/index.html""><img src=""./media/banners/statsmodels_logo.jpg"" alt=""statsmodels"" /></a>|<a target=""_blank"" href=""http://docs.python-requests.org/en/master/""><img src=""./media/banners/requests_logo.jpg"" alt=""requests"" /></a>|<a target=""_blank"" href=""http://www.nltk.org/""><img src=""./media/banners/nltk_logo.jpg"" alt=""nltk"" /></a>|<a target=""_blank"" href=""https://radimrehurek.com/gensim/""><img src=""./media/banners/gensim_logo.jpg"" alt=""gensim"" /></a>|<a target=""_blank"" href=""https://spacy.io/""><img src=""./media/banners/spacy_logo.jpg"" alt=""spacy"" /></a>\n<a target=""_blank"" href=""http://scikit-learn.org/stable/""><img src=""./media/banners/scikit-learn_logo.jpg"" alt=""scikit-learn"" /></a>|<a target=""_blank"" href=""https://www.datascience.com/resources/tools/skater""><img src=""./media/banners/skater_logo.png"" alt=""skater"" /></a>|<a target=""_blank"" href=""https://facebook.github.io/prophet/""><img src=""./media/banners/prophet_logo.jpg"" alt=""prophet"" /></a>|<a target=""_blank"" href=""https://keras.io/""><img src=""./media/banners/keras_logo.jpg"" alt=""keras"" /></a>|<a target=""_blank"" href=""https://www.tensorflow.org/""><img src=""./media/banners/tensorflow_logo.jpg"" alt=""tensorflow"" /></a>\n<a target=""_blank"" href=""https://matplotlib.org/""><img src=""./media/banners/matplotlib_logo.jpg"" alt=""matplotlib"" /></a>|<a target=""_blank"" href=""https://orange.biolab.si/""><img src=""./media/banners/orange_logo.jpg"" alt=""orange"" /></a>|<a target=""_blank"" href=""https://seaborn.pydata.org/""><img src=""./media/banners/seaborn_logo.jpg"" alt=""seaborn"" /></a>|<a target=""_blank"" href=""https://plot.ly/""><img src=""./media/banners/plotly_logo.jpg"" alt=""plotly"" /></a>|<a target=""_blank"" href=""https://www.crummy.com/software/BeautifulSoup/bs4/doc/""><img src=""./media/banners/bs_logo.jpg"" alt=""beautiful soup"" /></a>\n<br>\n\n## Audience\n\nThis book has been specially written for IT professionals, analysts, developers, data scientists, engineers, graduate students and anyone with an interest to analyze and derive insights from data!\n<br>\n\n## Acknowledgements\nTBA\n<br>\n'"
47,sjwhitworth/golearn,sjwhitworth,Machine Learning for Go,2013-12-26 13:06:14,2020-06-18 08:31:57,Go,1015,7226,"b'GoLearn\n=======\n\n<img src=""http://talks.golang.org/2013/advconc/gopherhat.jpg"" width=125><br>\n[![GoDoc](https://godoc.org/github.com/sjwhitworth/golearn?status.png)](https://godoc.org/github.com/sjwhitworth/golearn)\n[![Build Status](https://travis-ci.org/sjwhitworth/golearn.png?branch=master)](https://travis-ci.org/sjwhitworth/golearn)<br>\n[![Code Coverage](https://codecov.io/gh/sjwhitworth/golearn/branch/master/graph/badge.svg)](https://codecov.io/gh/sjwhitworth/golearn)\n\n[![Support via Gittip](https://rawgithub.com/twolfson/gittip-badge/0.2.0/dist/gittip.png)](https://www.gittip.com/sjwhitworth/)\n\nGoLearn is a \'batteries included\' machine learning library for Go. **Simplicity**, paired with customisability, is the goal.\nWe are in active development, and would love comments from users out in the wild. Drop us a line on Twitter.\n\ntwitter: [@golearn_ml](http://www.twitter.com/golearn_ml)\n\nInstall\n=======\n\nSee [here](https://github.com/sjwhitworth/golearn/wiki/Installation) for installation instructions.\n\nGetting Started\n=======\n\nData are loaded in as Instances. You can then perform matrix like operations on them, and pass them to estimators.\nGoLearn implements the scikit-learn interface of Fit/Predict, so you can easily swap out estimators for trial and error.\nGoLearn also includes helper functions for data, like cross validation, and train and test splitting.\n\n```go\npackage main\n\nimport (\n\t""fmt""\n\n\t""github.com/sjwhitworth/golearn/base""\n\t""github.com/sjwhitworth/golearn/evaluation""\n\t""github.com/sjwhitworth/golearn/knn""\n)\n\nfunc main() {\n\t// Load in a dataset, with headers. Header attributes will be stored.\n\t// Think of instances as a Data Frame structure in R or Pandas.\n\t// You can also create instances from scratch.\n\trawData, err := base.ParseCSVToInstances(""datasets/iris.csv"", false)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\t// Print a pleasant summary of your data.\n\tfmt.Println(rawData)\n\n\t//Initialises a new KNN classifier\n\tcls := knn.NewKnnClassifier(""euclidean"", ""linear"", 2)\n\n\t//Do a training-test split\n\ttrainData, testData := base.InstancesTrainTestSplit(rawData, 0.50)\n\tcls.Fit(trainData)\n\n\t//Calculates the Euclidean distance and returns the most popular label\n\tpredictions, err := cls.Predict(testData)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\t// Prints precision/recall metrics\n\tconfusionMat, err := evaluation.GetConfusionMatrix(testData, predictions)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(""Unable to get confusion matrix: %s"", err.Error()))\n\t}\n\tfmt.Println(evaluation.GetSummary(confusionMat))\n}\n```\n\n```\nIris-virginica\t28\t2\t  56\t0.9333\t0.9333  0.9333\nIris-setosa\t    29\t0\t  59\t1.0000  1.0000\t1.0000\nIris-versicolor\t27\t2\t  57\t0.9310\t0.9310  0.9310\nOverall accuracy: 0.9545\n```\n\nExamples\n========\n\nGoLearn comes with practical examples. Dive in and see what is going on.\n\n```bash\ncd $GOPATH/src/github.com/sjwhitworth/golearn/examples/knnclassifier\ngo run knnclassifier_iris.go\n```\n```bash\ncd $GOPATH/src/github.com/sjwhitworth/golearn/examples/instances\ngo run instances.go\n```\n```bash\ncd $GOPATH/src/github.com/sjwhitworth/golearn/examples/trees\ngo run trees.go\n```\n\nDocs\n====\n\n * [English](https://github.com/sjwhitworth/golearn/wiki)\n * [\xe4\xb8\xad\xe6\x96\x87\xe6\x96\x87\xe6\xa1\xa3(\xe7\xae\x80\xe4\xbd\x93)](doc/zh_CN/Home.md)\n * [\xe4\xb8\xad\xe6\x96\x87\xe6\x96\x87\xe6\xa1\xa3(\xe7\xb9\x81\xe4\xbd\x93)](doc/zh_TW/Home.md)\n\nJoin the team\n=============\n\nPlease send me a mail at stephenjameswhitworth@gmail.com\n'"
48,ethen8181/machine-learning,ethen8181,:earth_americas: machine learning tutorials (mainly in Python3) ,2015-07-24 03:35:49,2020-06-14 18:12:43,HTML,380,1621,"b""- [machine-learning](#machine-learning)\n  - [Documentation Listings](#documentation-listings)\n    - [model deployment](#model-deployment)\n    - [bandits](#bandits)\n    - [search](#search)\n    - [time series](#time-series)\n    - [projects](#projects)\n    - [ab tests](#ab-tests)\n    - [model selection](#model-selection)\n    - [big data](#big-data)\n    - [dim reduct](#dim-reduct)\n    - [recsys](#recsys)\n    - [trees](#trees)\n    - [clustering](#clustering)\n    - [data science is software](#data-science-is-software)\n    - [deep learning](#deep-learning)\n    - [keras](#keras)\n    - [text classification](#text-classification)\n    - [networkx](#networkx)\n    - [association rule](#association-rule)\n    - [regularization](#regularization)\n    - [ga](#ga)\n    - [unbalanced](#unbalanced)\n    - [clustering old](#clustering-old)\n    - [linear regression](#linear-regression)\n  - [Python Programming](#python-programming)\n\n# machine-learning\n\n[![license](https://img.shields.io/github/license/mashape/apistatus.svg)](https://github.com/ethen8181/machine-learning/blob/master/LICENSE)\n![Python 3.5](https://img.shields.io/badge/python-3.5-blue.svg)\n![Python 3.6](https://img.shields.io/badge/python-3.6-blue.svg)\n\nThis is a continuously updated repository that documents personal journey on learning data science, machine learning related topics.\n\n**Goal:** Introduce machine learning contents in Jupyter Notebook format. The content aims to strike a good balance between mathematical notations, educational implementation from scratch using Python's scientific stack including numpy, numba, scipy, pandas, matplotlib, etc. and open-source library usage such as scikit-learn, pyspark, gensim, keras, pytorch, tensorflow, etc.\n\n\n## Documentation Listings\n\n### model deployment\n\n- FastAPI & Azure Kubernetes Cluster. End to end example of training a model and hosting it as a service. [[folder](https://github.com/ethen8181/machine-learning/blob/master/model_deployment/fastapi_kubernetes)]\n\n### bandits\n\nIntroduction to Multi-armed Bandits. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/bandits/multi_armed_bandits.ipynb)][[html](http://ethen8181.github.io/machine-learning/bandits/multi_armed_bandits.html)]\n\n### search\n\nInformation Retrieval, some examples are demonstrated using ElasticSearch.\n\n- Introduction to BM25 (Best Match). [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/search/bm25_intro.ipynb)][[html](http://ethen8181.github.io/machine-learning/search/bm25_intro.html)]\n\n### time series\n\nForecasting methods for timeseries-based data.\n\n- Getting started with time series analysis with Exponential Smoothing (Holt-Winters). [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/time_series/1_exponential_smoothing.ipynb)][[html](http://ethen8181.github.io/machine-learning/time_series/1_exponential_smoothing.html)]\n- Framing time series problem as supervised-learning. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/time_series/3_supervised_time_series.ipynb)][[html](http://ethen8181.github.io/machine-learning/time_series/3_supervised_time_series.html)]\n- First Foray Into Discrete/Fast Fourier Transformation. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/time_series/fft/fft.ipynb)][[html](http://ethen8181.github.io/machine-learning/time_series/fft/fft.html)]\n\n### projects\n\nEnd to end project including data preprocessing, model building.\n\n- [Kaggle: Don't Get Kicked](https://www.kaggle.com/c/DontGetKicked): Predict if a car purchased at auction is a unfortunate purchase. [[folder](https://github.com/ethen8181/machine-learning/blob/master/projects/kaggle_dont_get_kicked/)]\n- [Kaggle: Rossman Store Sales](https://www.kaggle.com/c/rossmann-store-sales/): Predicting daily store sales. Also introduces deep learning for tabular data. [[folder](https://github.com/ethen8181/machine-learning/blob/master/projects/kaggle_rossman_store_sales/)]\n- [Kaggle: Quora Insincere Questions Classification](https://www.kaggle.com/c/quora-insincere-questions-classification/): Predicting insincere questions. [[folder](https://github.com/ethen8181/machine-learning/blob/master/projects/kaggle_quora_insincere/)]\n- mlutils: Machine learning utility function package [[folder](https://github.com/ethen8181/machine-learning/blob/master/projects/mlutils/)]\n\n### ab tests\n\nA/B testing, a.k.a experimental design. Includes: Quick review of necessary statistic concepts. Methods and workflow/thought-process for conducting the test and caveats to look out for.\n\n- Frequentist A/B testing (includes a quick review of concepts such as p-value, confidence interval). [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/ab_tests/frequentist_ab_test.ipynb)][[html](http://ethen8181.github.io/machine-learning/ab_tests/frequentist_ab_test.html)]\n- Quantile Regression and its application in A/B testing.\n    - Quick Introduction to Quantile Regression. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/ab_tests/quantile_regression/quantile_regression.ipynb)][[html](http://ethen8181.github.io/machine-learning/ab_tests/quantile_regression/quantile_regression.html)]\n    - Quantile Regression's application in A/B testing. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/ab_tests/quantile_regression/ab_test_regression.ipynb)][[html](http://ethen8181.github.io/machine-learning/ab_tests/quantile_regression/ab_test_regression.html)]\n- Casual Inference\n    - Propensity Score Matching. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/ab_tests/causal_inference/matching.ipynb)][[html](http://ethen8181.github.io/machine-learning/ab_tests/causal_inference/matching.html)]\n\n### model selection\n\nMethods for selecting, improving, evaluating models/algorithms.\n\n- K-fold cross validation, grid/random search from scratch. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/model_selection/model_selection.ipynb)][[html](http://ethen8181.github.io/machine-learning/model_selection/model_selection.html)]\n- AUC (Area under the ROC curve and precision/recall curve) from scratch (includes the process of building a custom scikit-learn transformer). [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/model_selection/auc/auc.ipynb)][[html](http://ethen8181.github.io/machine-learning/model_selection/auc/auc.html)]\n- Evaluation metrics for imbalanced dataset. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/model_selection/imbalanced/imbalanced_metrics.ipynb)][[html](http://ethen8181.github.io/machine-learning/model_selection/imbalanced/imbalanced_metrics.html)]\n- Detecting collinearity amongst features (Variance Inflation Factor for numeric features and Cramer's V statistics for categorical features), also introduces Linear Regression from a Maximum Likelihood perspective and the R-squared evaluation metric. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/model_selection/collinearity.ipynb)][[html](http://ethen8181.github.io/machine-learning/model_selection/collinearity.html)]\n- Curated tips and tricks for technical and soft skills. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/model_selection/tips_and_tricks/tips_and_tricks.ipynb)][[html](http://ethen8181.github.io/machine-learning/model_selection/tips_and_tricks/tips_and_tricks.html)]\n- Partial Dependece Plot (PDP), model-agnostic approach for directional feature influence. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/model_selection/partial_dependence/partial_dependence.ipynb)][[html](http://ethen8181.github.io/machine-learning/model_selection/partial_dependence/partial_dependence.html)]\n- Kullback-Leibler (KL) Divergence. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/model_selection/kl_divergence.ipynb)][[html](http://ethen8181.github.io/machine-learning/model_selection/kl_divergence.html)]\n- Probability Calibration for classification models. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/model_selection/prob_calibration/prob_calibration.ipynb)][[html](http://ethen8181.github.io/machine-learning/model_selection/prob_calibration/prob_calibration.html)]\n\n### big data\n\nExploring big data tools, such as Spark and H2O.ai. For those interested there's also a [pyspark rdd cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_Cheat_Sheet_Python.pdf) and [pyspark dataframe cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_SQL_Cheat_Sheet_Python.pdf) that may come in handy.\n\n- Local Hadoop cluster installation on Mac. [[markdown](https://github.com/ethen8181/machine-learning/tree/master/big_data/local_hadoop.md)]\n- PySpark installation on Mac. [[markdown](https://github.com/ethen8181/machine-learning/tree/master/big_data/spark_installation.md)]\n- Examples of manipulating with data (crimes data) and building a RandomForest model with PySpark MLlib. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/big_data/spark_crime.ipynb)][[html](http://ethen8181.github.io/machine-learning/big_data/spark_crime.html)]\n- PCA with PySpark MLlib. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/big_data/spark_pca.ipynb)][[html](http://ethen8181.github.io/machine-learning/big_data/spark_pca.html)]\n- Tuning Spark Partitions. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/big_data/spark_partitions.ipynb)][[html](http://ethen8181.github.io/machine-learning/big_data/spark_partitions.html)]\n- H2O API walkthrough (using GBM as an example). [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/big_data/h2o/h2o_api_walkthrough.ipynb)][[html](http://ethen8181.github.io/machine-learning/big_data/h2o/h2o_api_walkthrough.html)]\n- Spark MLlib Binary Classification (using GBM as an example). [[raw zeppelin notebook](https://github.com/ethen8181/machine-learning/blob/master/big_data/sparkml/sparkml.json)][[Zepl](https://www.zepl.com/explore)]\n\n### dim reduct\n\nDimensionality reduction methods.\n\n- Principal Component Analysis (PCA) from scratch. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/dim_reduct/PCA.ipynb)][[html](http://ethen8181.github.io/machine-learning/dim_reduct/PCA.html)]\n- Introduction to Singular Value Decomposition (SVD), also known as Latent Semantic Analysis/Indexing (LSA/LSI). [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/dim_reduct/svd.ipynb)][[html](http://ethen8181.github.io/machine-learning/dim_reduct/svd.html)]\n\n### recsys\n\nRecommendation system with a focus on matrix factorization methods. Starters into the field should go through the first notebook to understand the basics of matrix factorization methods.\n\n- Alternating Least Squares with Weighted Regularization (ALS-WR) from scratch. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/recsys/1_ALSWR.ipynb)][[html](http://ethen8181.github.io/machine-learning/recsys/1_ALSWR.html)]\n- ALS-WR for implicit feedback data from scratch & Mean Average Precision at k (mapk) and Normalized Cumulative Discounted Gain (ndcg) evaluation. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/recsys/2_implicit.ipynb)][[html](http://ethen8181.github.io/machine-learning/recsys/2_implicit.html)]\n- Bayesian Personalized Ranking (BPR) from scratch & AUC evaluation. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/recsys/4_bpr.ipynb)][[html](http://ethen8181.github.io/machine-learning/recsys/4_bpr.html)]\n- WARP (Weighted Approximate-Rank Pairwise) Loss using lightfm. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/recsys/5_warp.ipynb)][[html](http://ethen8181.github.io/machine-learning/recsys/5_warp.html)]\n- Factorization Machine from scratch. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/recsys/factorization_machine/factorization_machine.ipynb)][[html](http://ethen8181.github.io/machine-learning/recsys/factorization_machine/factorization_machine.html)]\n- Content-Based Recommenders:\n    - (Text) Content-Based Recommenders. Introducing Approximate Nearest Neighborhood (ANN) - Locality Sensitive Hashing (LSH) for cosine distance from scratch. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/recsys/content_based/lsh_text.ipynb)][[html](http://ethen8181.github.io/machine-learning/recsys/content_based/lsh_text.html)]\n- Approximate Nearest Neighborhood (ANN):\n    -  Benchmarking ANN implementations (nmslib). [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/recsys/ann_benchmarks/ann_benchmarks.ipynb)][[html](http://ethen8181.github.io/machine-learning/recsys/ann_benchmarks/ann_benchmarks.html)]\n- Calibrated Recommendation for reducing bias/increasing diversity in recommendation. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/recsys/calibration/calibrated_reco.ipynb)][[html](http://ethen8181.github.io/machine-learning/recsys/calibration/calibrated_reco.html)]\n- Maximum Inner Product for Speeding Up Generating Recommendations. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/recsys/max_inner_product/max_inner_product.ipynb)][[html](http://ethen8181.github.io/machine-learning/recsys/max_inner_product/max_inner_product.html)]\n\n### trees\n\nTree-based models for both regression and classification tasks.\n\n- Decision Tree from scratch. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/trees/decision_tree.ipynb)][[html](http://ethen8181.github.io/machine-learning/trees/decision_tree.html)]\n- Random Forest from scratch and Extra Trees. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/trees/random_forest.ipynb)][[html](http://ethen8181.github.io/machine-learning/trees/random_forest.html)]\n- Gradient Boosting Machine (GBM) from scratch. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/trees/gbm/gbm.ipynb)][[html](http://ethen8181.github.io/machine-learning/trees/gbm/gbm.html)]\n- Xgboost API walkthrough (includes hyperparmeter tuning via scikit-learn like API). [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/trees/xgboost.ipynb)][[html](http://ethen8181.github.io/machine-learning/trees/xgboost.html)]\n- LightGBM API walkthrough and a discussion about categorical features in tree-based models. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/trees/lightgbm.ipynb)][[html](http://ethen8181.github.io/machine-learning/trees/lightgbm.html)]\n- Monotonic Constraint with Boosted Tree. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/trees/monotonic.ipynb)][[html](http://ethen8181.github.io/machine-learning/trees/monotonic.html)]\n\n### clustering\n\nTF-IDF and Topic Modeling are techniques specifically used for text analytics.\n\n- TF-IDF (text frequency - inverse document frequency) from scratch. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/clustering/tfidf/tfidf.ipynb)][[html](http://ethen8181.github.io/machine-learning/clustering/tfidf/tfidf.html)]\n- K-means, K-means++ from scratch; Elbow method for choosing K. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/clustering/kmeans.ipynb)][[html](http://ethen8181.github.io/machine-learning/clustering/kmeans.html)]\n- Gaussian Mixture Model from scratch; AIC and BIC for choosing the number of Gaussians. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/clustering/GMM/GMM.ipynb)][[html](http://ethen8181.github.io/machine-learning/clustering/GMM/GMM.html)]\n- Topic Modeling with gensim's Latent Dirichlet Allocation(LDA). [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/clustering/topic_model/LDA.ipynb)][[html](http://ethen8181.github.io/machine-learning/clustering/topic_model/LDA.html)]\n\n### data science is software  \n\nBest practices for doing data science in Python.\n\n- View [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/data_science_is_software/notebooks/data_science_is_software.ipynb)][[html](http://ethen8181.github.io/machine-learning/data_science_is_software/notebooks/data_science_is_software.html)]\n\n### deep learning\n\nCurated notes on deep learning.\n\n- Softmax Regression from scratch. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/softmax.ipynb)][[html](http://ethen8181.github.io/machine-learning/deep_learning/softmax.html)]\n- Softmax Regression - Tensorflow hello world. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/softmax_tensorflow.ipynb)][[html](http://ethen8181.github.io/machine-learning/deep_learning/softmax_tensorflow.html)]\n- Multi-layers Neural Network - Tensorflow. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/nn_tensorflow.ipynb)][[html](http://ethen8181.github.io/machine-learning/deep_learning/nn_tensorflow.html)]\n- Convolutional Neural Network (CNN) - Tensorflow. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/cnn_image_tensorflow.ipynb)][[html](http://ethen8181.github.io/machine-learning/deep_learning/cnn_image_tensorflow.html)]\n- Recurrent Neural Network (RNN).\n    - Vanilla RNN - Tensorflow. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/rnn/1_tensorflow_rnn.ipynb)][[html](http://ethen8181.github.io/machine-learning/deep_learning/rnn/1_tensorflow_rnn.html)]\n    - Long Short Term Memory (LSTM) - Tensorflow. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/rnn/2_tensorflow_lstm.ipynb)][[html](http://ethen8181.github.io/machine-learning/deep_learning/rnn/2_tensorflow_lstm.html)]\n    - RNN, LSTM - PyTorch hello world. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/rnn/1_pytorch_rnn.ipynb)][[html](http://ethen8181.github.io/machine-learning/deep_learning/rnn/1_pytorch_rnn.html)]\n- Word2vec (skipgram + negative sampling) using Gensim. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/word2vec/word2vec_detailed.ipynb)][[html](http://ethen8181.github.io/machine-learning/deep_learning/word2vec/word2vec_detailed.html)]\n- Sequence to Sequence Neural Network (Seq2Seq).\n    - Seq2Seq for German to English Machine Translation - PyTorch. Includes quick intro to torchtext [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/seq2seq/1_torch_seq2seq_intro.ipynb)][[html](http://ethen8181.github.io/machine-learning/deep_learning/seq2seq/1_torch_seq2seq_intro.html)]\n    - Seq2Seq with Attention for German to English Machine Translation - PyTorch. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/seq2seq/2_torch_seq2seq_attention.ipynb)][[html](http://ethen8181.github.io/machine-learning/deep_learning/seq2seq/2_torch_seq2seq_attention.html)]\n- Subword Tokenization.\n    - Byte Pair Encoding (BPE) from scratch and quick walkthrough of sentencepiece. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/subword/bpe.ipynb)][[html](http://ethen8181.github.io/machine-learning/deep_learning/subword/bpe.html)]\n- Fasttext.\n    - MultiLabel Text Classification with Fasttext and Huggingface Tokenizers. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/multi_label/fasttext.ipynb)][[html](http://ethen8181.github.io/machine-learning/deep_learning/multi_label/fasttext.html)]\n    - Product Quantization for Model Compression. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/multi_label/product_quantization.ipynb)][[html](http://ethen8181.github.io/machine-learning/deep_learning/multi_label/product_quantization.html)]\n    - Approximate Nearest Neighborhood Search with Navigable Small World. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/multi_label/nsw.ipynb)][[html](http://ethen8181.github.io/machine-learning/deep_learning/multi_label/nsw.html)]\n\n### keras\n\nFor those interested there's also a [keras cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Keras_Cheat_Sheet_Python.pdf) that may come in handy.\n\n- Multi-layers Neural Network (keras basics). [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/keras/nn_keras_basics.ipynb)][[html](http://ethen8181.github.io/machine-learning/keras/nn_keras_basics.html)]\n- Multi-layers Neural Network hyperparameter tuning via scikit-learn like API. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/keras/nn_keras_hyperparameter_tuning.ipynb)][[html](http://ethen8181.github.io/machine-learning/keras/nn_keras_hyperparameter_tuning.html)]\n- Convolutional Neural Network (CNN)\n    - Image classification basics. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/keras/cnn_image_keras.ipynb)][[html](http://ethen8181.github.io/machine-learning/keras/cnn_image_keras.html)]\n    - Introduction to Residual Networks (ResNets) and Class Activation Maps (CAM). [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/keras/resnet_cam/resnet_cam.ipynb)][[html](http://ethen8181.github.io/machine-learning/keras/resnet_cam/resnet_cam.html)]\n- Recurrent Neural Network (RNN) - language modeling basics. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/keras/rnn_language_model_basic_keras.ipynb)][[html](http://ethen8181.github.io/machine-learning/keras/rnn_language_model_basic_keras.html)]\n- Text Classification\n    - Word2vec for Text Classification. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/keras/text_classification/word2vec_text_classification.ipynb)][[html](http://ethen8181.github.io/machine-learning/keras/text_classification/word2vec_text_classification.html)]\n    - Leveraging Pre-trained Word Embedding for Text Classification. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/keras/text_classification/keras_pretrained_embedding.ipynb)][[html](http://ethen8181.github.io/machine-learning/keras/text_classification/keras_pretrained_embedding.html)]\n    - Sentencepiece Subword tokenization for Text Classification. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/keras/text_classification/keras_subword_tokenization.ipynb)][[html](http://ethen8181.github.io/machine-learning/keras/text_classification/keras_subword_tokenization.html)]\n\n### text classification\n\nDeep learning techniques for text classification are categorized in its own section.\n\n- Building intuition with spam classification using scikit-learn (scikit-learn hello world). [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/text_classification/basics/basics.ipynb)][[html](http://ethen8181.github.io/machine-learning/text_classification/basics/basics.html)]\n- Bernoulli and Multinomial Naive Bayes from scratch. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/text_classification/naive_bayes/naive_bayes.ipynb)][[html](http://ethen8181.github.io/machine-learning/text_classification/naive_bayes/naive_bayes.html)]\n- Logistic Regression (stochastic gradient descent) from scratch. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/text_classification/logistic.ipynb)][[html](http://ethen8181.github.io/machine-learning/text_classification/logistic.html)]\n- Chi-square feature selection from scratch. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/text_classification/chisquare.ipynb)][[html](http://ethen8181.github.io/machine-learning/text_classification/chisquare.html)]\n\n### networkx\n\nGraph library other than `networkx` are also discussed.\n\n- PyCon 2016: Practical Network Analysis Made Simple. Quickstart to networkx's API. Includes some basic graph plotting and algorithms. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/networkx/networkx.ipynb)][[html](http://ethen8181.github.io/machine-learning/networkx/networkx.html)]\n- Short Walkthrough of PageRank. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/networkx/page_rank.ipynb)][[html](http://ethen8181.github.io/machine-learning/networkx/page_rank.html)]\n- Influence Maximization from scratch. Includes discussion on Independent Cascade (IC), Submodular Optimization algorithms including Greedy and Lazy Greedy, a.k.a Cost Efficient Lazy Forward (CELF) [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/networkx/max_influence/max_influence.ipynb)][[html](http://ethen8181.github.io/machine-learning/networkx/max_influence/max_influence.html)]\n\n### association rule\n\nAlso known as market-basket analysis.\n\n- Apriori from scratch. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/association_rule/apriori.ipynb)][[html](http://ethen8181.github.io/machine-learning/association_rule/apriori.html)]\n- Using R's arules package (aprori) on tabular data. [[Rmarkdown](http://ethen8181.github.io/machine-learning/association_rule/R/apriori.html)]\n\n### regularization\n\nBuilding intuition on Ridge and Lasso regularization using scikit-learn.\n \n- View [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/regularization/regularization.ipynb)][[html](http://ethen8181.github.io/machine-learning/regularization/regularization.html)]\n\n### ga\n\nGenetic Algorithm. Math-free explanation and code from scratch.\n\n- Start from a simple optimization problem and extending it to traveling salesman problem (tsp).\n- View [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/ga/ga.ipynb)][[html](http://ethen8181.github.io/machine-learning/ga/ga.html)]\n\n### unbalanced\n\nChoosing the optimal cutoff value for logistic regression using cost-sensitive mistakes (meaning when the cost of misclassification might differ between the two classes) when your dataset consists of unbalanced binary classes. e.g. Majority of the data points in the dataset have a positive outcome, while few have negative, or vice versa. The notion can be extended to any other classification algorithm that can predict class\xe2\x80\x99s probability, this documentation just uses logistic regression for illustration purpose.\n\n- Visualize two by two standard confusion matrix and ROC curve with costs using ggplot2.\n- View [[Rmarkdown](http://ethen8181.github.io/machine-learning/unbalanced/unbalanced.html)]\n\n### clustering old\n\nA collection of scattered old clustering documents in R.\n\n- Toy sample code of the LDA algorithm (gibbs sampling) and the topicmodels library. [[Rmarkdown](http://ethen8181.github.io/machine-learning/clustering_old/topic_model/LDA.html)]\n- k-shingle, Minhash and Locality Sensitive Hashing for solving the problem of finding textually similar documents. [[Rmarkdown](http://ethen8181.github.io/machine-learning/clustering_old/text_similarity/text_similarity.html)]\n- Introducing tf-idf (term frequency-inverse document frequency), a text mining technique. Also uses it to perform text clustering via hierarchical clustering. [[Rmarkdown](http://ethen8181.github.io/machine-learning/clustering_old/tf_idf/tf_idf.html)]\n- Some useful evaluations when working with hierarchical clustering and K-means clustering (K-means++ is used here). Including Calinski-Harabasz index for determine the right K (cluster number) for clustering and boostrap evaluation of the clustering result\xe2\x80\x99s stability. [[Rmarkdown](http://ethen8181.github.io/machine-learning/clustering_old/clustering/clustering.html)]\n\n### linear regression\n\n- Training Linear Regression with gradient descent in R, briefly covers the interpretation and visualization of linear regression's summary output. [[Rmarkdown](http://ethen8181.github.io/machine-learning/linear_regression/linear_regession.html)]\n\n\n## Python Programming\n\n- Extremely Quick Guide to Unicode. [[markdown](https://github.com/ethen8181/machine-learning/blob/master/python/unicode.md)]\n- Quick Example of Factory Design Pattern. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/python/factory_pattern.ipynb)][[html](http://ethen8181.github.io/machine-learning/python/factory_pattern.html)]\n- Parallel programming with Python (threading, multiprocessing, concurrent.futures, joblib). [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/python/parallel.ipynb)][[html](http://ethen8181.github.io/machine-learning/python/parallel.html)]\n- Understanding iterables, iterator and generators. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/python/iterator/iterator.ipynb)][[html](http://ethen8181.github.io/machine-learning/python/iterator/iterator.html)]\n- Cohort analysis. Visualizing user retention by cohort with seaborn's heatmap and illustrating pandas's unstack. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/python/cohort/cohort.ipynb)][[html](http://ethen8181.github.io/machine-learning/python/cohort/cohort.html)]\n- Logging module. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/python/logging.ipynb)][[html](http://ethen8181.github.io/machine-learning/python/logging.html)]\n- Data structure, algorithms from scratch. [[folder](https://github.com/ethen8181/machine-learning/tree/master/python/algorithms)]\n- Cython and Numba quickstart for high performance Python. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/python/cython/cython.ipynb)][[html](http://ethen8181.github.io/machine-learning/python/cython/cython.html)]\n- Optimizing Pandas (e.g. reduce memory usage using category type). [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/python/pandas/pandas.ipynb)][[html](http://ethen8181.github.io/machine-learning/python/pandas/pandas.html)]\n- Unittest. [[Python script](https://github.com/ethen8181/machine-learning/blob/master/python/test.py)]\n- Using built-in data structure and algorithm. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/python/python3_cookbook/1_data_structure.ipynb)][[html](http://ethen8181.github.io/machine-learning/python/python3_cookbook/1_data_structure.html)]\n- Tricks with strings and text. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/python/python3_cookbook/2_strings_and_text.ipynb)][[html](http://ethen8181.github.io/machine-learning/python/python3_cookbook/2_strings_and_text.html)]\n- Python's decorators (useful script for logging and timing function). [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/python/decorators/decorators.ipynb)][[html](http://ethen8181.github.io/machine-learning/python/decorators/decorators.html)]\n- Pandas's pivot table. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/python/pivot_table/pivot_table.ipynb)][[html](http://ethen8181.github.io/machine-learning/python/pivot_table/pivot_table.html)]\n- Quick introduction to classmethod, staticmethod and property. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/python/class.ipynb)][[html](http://ethen8181.github.io/machine-learning/python/class.html)]\n"""
49,ljpzzz/machinelearning,ljpzzz,My blogs and code for machine learning. http://cnblogs.com/pinard,2016-05-12 07:06:34,2020-06-18 09:14:18,Jupyter Notebook,2313,4208,"b'# \xe5\x88\x98\xe5\xbb\xba\xe5\xb9\xb3Pinard\xe7\x9a\x84\xe5\x8d\x9a\xe5\xae\xa2\xe9\x85\x8d\xe5\xa5\x97\xe4\xbb\xa3\xe7\xa0\x81\n\nhttp://www.cnblogs.com/pinard \xe5\x88\x98\xe5\xbb\xba\xe5\xb9\xb3Pinard\n\n\xe4\xb9\x8b\xe5\x89\x8d\xe4\xb8\x8d\xe5\xb0\x91\xe6\x9c\x8b\xe5\x8f\x8b\xe5\x8f\x8d\xe5\xba\x94\xe6\x88\x91\xe5\x8d\x9a\xe5\xae\xa2\xe4\xb8\xad\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81\xe9\x83\xbd\xe6\x98\xaf\xe8\xbf\x9e\xe7\xbb\xad\xe7\x9a\x84\xe7\x89\x87\xe6\xae\xb5\xef\xbc\x8c\xe4\xb8\x8d\xe5\xa5\xbd\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe8\xbf\x99\xe9\x87\x8c\xe6\x8a\x8a\xe6\x96\x87\xe7\xab\xa0\xe5\x92\x8c\xe4\xbb\xa3\xe7\xa0\x81\xe5\x81\x9a\xe4\xb8\x80\xe4\xb8\xaa\xe6\x95\xb4\xe7\x90\x86\xe3\x80\x82\n\xe4\xbb\xa3\xe7\xa0\x81\xe6\x9c\x89\xe9\x83\xa8\xe5\x88\x86\xe6\x9d\xa5\xe6\xba\x90\xe4\xba\x8e\xe7\xbd\x91\xe7\xbb\x9c\xef\xbc\x8c\xe5\xb7\xb2\xe5\x8a\xa0\xe4\xb8\x8a\xe7\x9b\xb8\xe5\x85\xb3\xe6\x96\xb9\xe7\x89\x88\xe6\x9d\x83\xe4\xbf\xa1\xe6\x81\xaf\xe3\x80\x82\xe9\x83\xa8\xe5\x88\x86\xe4\xb8\xba\xe8\x87\xaa\xe5\xb7\xb1\xe5\x8e\x9f\xe5\x88\x9b\xef\xbc\x8c\xe5\xb7\xb2\xe5\x8a\xa0\xe4\xb8\x8a\xe6\x88\x91\xe7\x9a\x84\xe7\x89\x88\xe6\x9d\x83\xe4\xbf\xa1\xe6\x81\xaf\xe3\x80\x82\n\n## \xe7\x9b\xae\xe5\xbd\x95\n\n* [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x9f\xba\xe7\xa1\x80\xe4\xb8\x8e\xe5\x9b\x9e\xe5\xbd\x92\xe7\xae\x97\xe6\xb3\x95](#2)\n\n* [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x88\x86\xe7\xb1\xbb\xe7\xae\x97\xe6\xb3\x95](#3)\n\n* [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\x81\x9a\xe7\xb1\xbb\xe7\xae\x97\xe6\xb3\x95](#4)\n\n* [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe9\x99\x8d\xe7\xbb\xb4\xe7\xae\x97\xe6\xb3\x95](#5)\n\n* [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe9\x9b\x86\xe6\x88\x90\xe5\xad\xa6\xe4\xb9\xa0\xe7\xae\x97\xe6\xb3\x95](#6)\n\n* [\xe6\x95\xb0\xe5\xad\xa6\xe7\xbb\x9f\xe8\xae\xa1\xe5\xad\xa6](#7)\n\n* [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x85\xb3\xe8\x81\x94\xe7\xae\x97\xe6\xb3\x95](#8)\n\n* [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x8e\xa8\xe8\x8d\x90\xe7\xae\x97\xe6\xb3\x95](#9)\n\n* [\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe7\xae\x97\xe6\xb3\x95](#10)\n\n* [\xe8\x87\xaa\xe7\x84\xb6\xe8\xaf\xad\xe8\xa8\x80\xe5\xa4\x84\xe7\x90\x86\xe7\xae\x97\xe6\xb3\x95](#11)\n\n* [\xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0\xe7\xae\x97\xe6\xb3\x95](#1)\n\n* [\xe7\x89\xb9\xe5\xbe\x81\xe5\xb7\xa5\xe7\xa8\x8b\xe4\xb8\x8e\xe7\xae\x97\xe6\xb3\x95\xe8\x90\xbd\xe5\x9c\xb0](#12)\n\n## \xe6\xb3\xa8\xe6\x84\x8f\n\n2016-2017\xe5\xb9\xb4\xe5\x86\x99\xe7\x9a\x84\xe5\x8d\x9a\xe5\xae\xa2\xe4\xbd\xbf\xe7\x94\xa8\xe7\x9a\x84python\xe7\x89\x88\xe6\x9c\xac\xe6\x98\xaf2.7\xef\xbc\x8c 2018\xe5\xb9\xb4\xe5\x9b\xa0\xe4\xb8\xbaTensorFlow\xe5\xaf\xb9Python3\xe7\x9a\x84\xe4\xb8\x80\xe4\xba\x9b\xe8\xa6\x81\xe6\xb1\x82\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xe5\x86\x99\xe5\x8d\x9a\xe5\xae\xa2\xe4\xbd\xbf\xe7\x94\xa8\xe7\x9a\x84Python\xe7\x89\x88\xe6\x9c\xac\xe6\x98\xaf3.6\xe3\x80\x82\xe5\xb0\x91\xe9\x83\xa8\xe5\x88\x862016\xef\xbc\x8c2017\xe5\xb9\xb4\xe7\x9a\x84\xe5\x8d\x9a\xe5\xae\xa2\xe4\xbb\xa3\xe7\xa0\x81\xe6\x97\xa0\xe6\xb3\x95\xe6\x89\xbe\xe5\x88\xb0\xef\xbc\x8c\xe9\x87\x8d\xe6\x96\xb0\xe7\x94\xa8Python3.6\xe8\xb7\x91\xe8\xbf\x87\xe4\xb8\x8a\xe4\xbc\xa0\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe5\x8f\xaf\xe8\x83\xbd\xe4\xbc\x9a\xe5\x87\xba\xe7\x8e\xb0\xe5\x92\x8c\xe5\x8d\x9a\xe5\xae\xa2\xe4\xb8\xad\xe4\xbb\xa3\xe7\xa0\x81\xe7\xa8\x8d\xe6\x9c\x89\xe4\xb8\x8d\xe4\xb8\x80\xe8\x87\xb4\xe7\x9a\x84\xe5\x9c\xb0\xe6\x96\xb9\xef\xbc\x8c\xe4\xb8\xbb\xe8\xa6\x81\xe6\xb6\x89\xe5\x8f\x8a\xe5\x88\xb0print\xe7\x9a\x84\xe8\xaf\xad\xe6\xb3\x95\xe5\x92\x8crange\xe7\x9a\x84\xe7\x94\xa8\xe6\xb3\x95\xef\xbc\x8c\xe8\x8b\xa5\xe9\x81\x87\xe5\x88\xb0\xe9\x97\xae\xe9\xa2\x98\xef\xbc\x8c\xe7\xa8\x8d\xe5\xbe\xae\xe4\xbf\xae\xe6\x94\xb9\xe5\x8d\xb3\xe5\x8f\xaf\xe8\xb7\x91\xe9\x80\x9a\xe3\x80\x82\n\n## [\xe8\xb5\x9e\xe5\x8a\xa9\xe6\x88\x91](#13)\n\n<h3 id=""1"">\xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0\xe6\x96\x87\xe7\xab\xa0\xe4\xb8\x8e\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a:</h3>\n\n|\xe6\x96\x87\xe7\xab\xa0 | \xe4\xbb\xa3\xe7\xa0\x81|\n---|---\n[\xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x88\xe4\xb8\x80\xef\xbc\x89\xe6\xa8\xa1\xe5\x9e\x8b\xe5\x9f\xba\xe7\xa1\x80](https://www.cnblogs.com/pinard/p/9385570.html)| [\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/introduction.py)\n[\xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x88\xe4\xba\x8c\xef\xbc\x89\xe9\xa9\xac\xe5\xb0\x94\xe7\xa7\x91\xe5\xa4\xab\xe5\x86\xb3\xe7\xad\x96\xe8\xbf\x87\xe7\xa8\x8b(MDP)](https://www.cnblogs.com/pinard/p/9426283.html) | \xe6\x97\xa0\n[\xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x88\xe4\xb8\x89\xef\xbc\x89\xe7\x94\xa8\xe5\x8a\xa8\xe6\x80\x81\xe8\xa7\x84\xe5\x88\x92\xef\xbc\x88DP\xef\xbc\x89\xe6\xb1\x82\xe8\xa7\xa3](https://www.cnblogs.com/pinard/p/9463815.html) | \xe6\x97\xa0\n[\xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x88\xe5\x9b\x9b\xef\xbc\x89\xe7\x94\xa8\xe8\x92\x99\xe7\x89\xb9\xe5\x8d\xa1\xe7\xbd\x97\xe6\xb3\x95\xef\xbc\x88MC\xef\xbc\x89\xe6\xb1\x82\xe8\xa7\xa3](https://www.cnblogs.com/pinard/p/9492980.html) | \xe6\x97\xa0\n[\xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x88\xe4\xba\x94\xef\xbc\x89\xe7\x94\xa8\xe6\x97\xb6\xe5\xba\x8f\xe5\xb7\xae\xe5\x88\x86\xe6\xb3\x95\xef\xbc\x88TD\xef\xbc\x89\xe6\xb1\x82\xe8\xa7\xa3](https://www.cnblogs.com/pinard/p/9529828.html) | \xe6\x97\xa0\n[\xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x88\xe5\x85\xad\xef\xbc\x89\xe6\x97\xb6\xe5\xba\x8f\xe5\xb7\xae\xe5\x88\x86\xe5\x9c\xa8\xe7\xba\xbf\xe6\x8e\xa7\xe5\x88\xb6\xe7\xae\x97\xe6\xb3\x95SARSA](https://www.cnblogs.com/pinard/p/9614290.html)  | [\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/sarsa_windy_world.py)\n[\xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x88\xe4\xb8\x83\xef\xbc\x89\xe6\x97\xb6\xe5\xba\x8f\xe5\xb7\xae\xe5\x88\x86\xe7\xa6\xbb\xe7\xba\xbf\xe6\x8e\xa7\xe5\x88\xb6\xe7\xae\x97\xe6\xb3\x95Q-Learning](https://www.cnblogs.com/pinard/p/9669263.html)  | [\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/q_learning_windy_world.py)\n[\xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x88\xe5\x85\xab\xef\xbc\x89\xe4\xbb\xb7\xe5\x80\xbc\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84\xe8\xbf\x91\xe4\xbc\xbc\xe8\xa1\xa8\xe7\xa4\xba\xe4\xb8\x8eDeep Q-Learning](https://www.cnblogs.com/pinard/p/9714655.html)  | [\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/dqn.py)\n[\xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x88\xe4\xb9\x9d\xef\xbc\x89Deep Q-Learning\xe8\xbf\x9b\xe9\x98\xb6\xe4\xb9\x8bNature DQN](https://www.cnblogs.com/pinard/p/9756075.html)  | [\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/nature_dqn.py)\n[\xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x88\xe5\x8d\x81\xef\xbc\x89Double DQN (DDQN)](https://www.cnblogs.com/pinard/p/9778063.html)  | [\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/ddqn.py)\n[\xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0(\xe5\x8d\x81\xe4\xb8\x80) Prioritized Replay DQN](https://www.cnblogs.com/pinard/p/9797695.html)  | [\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/ddqn_prioritised_replay.py)\n[\xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0(\xe5\x8d\x81\xe4\xba\x8c) Dueling DQN](https://www.cnblogs.com/pinard/p/9923859.html)  | [\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/duel_dqn.py)\n[\xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0(\xe5\x8d\x81\xe4\xb8\x89) \xe7\xad\x96\xe7\x95\xa5\xe6\xa2\xaf\xe5\xba\xa6(Policy Gradient)](https://www.cnblogs.com/pinard/p/10137696.html)  | [\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/policy_gradient.py)\n[\xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0(\xe5\x8d\x81\xe5\x9b\x9b) Actor-Critic](https://www.cnblogs.com/pinard/p/10272023.html)  | [\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/actor_critic.py)\n[\xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0(\xe5\x8d\x81\xe4\xba\x94) A3C](https://www.cnblogs.com/pinard/p/10334127.html)  | [\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/a3c.py)\n[\xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0(\xe5\x8d\x81\xe5\x85\xad) \xe6\xb7\xb1\xe5\xba\xa6\xe7\xa1\xae\xe5\xae\x9a\xe6\x80\xa7\xe7\xad\x96\xe7\x95\xa5\xe6\xa2\xaf\xe5\xba\xa6(DDPG)](https://www.cnblogs.com/pinard/p/10345762.html)  | [\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/ddpg.py)\n[\xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0(\xe5\x8d\x81\xe4\xb8\x83) \xe5\x9f\xba\xe4\xba\x8e\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0\xe4\xb8\x8eDyna\xe7\xae\x97\xe6\xb3\x95\xe6\xa1\x86\xe6\x9e\xb6](https://www.cnblogs.com/pinard/p/10384424.html) | \xe6\x97\xa0\n[\xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0(\xe5\x8d\x81\xe5\x85\xab) \xe5\x9f\xba\xe4\xba\x8e\xe6\xa8\xa1\xe6\x8b\x9f\xe7\x9a\x84\xe6\x90\x9c\xe7\xb4\xa2\xe4\xb8\x8e\xe8\x92\x99\xe7\x89\xb9\xe5\x8d\xa1\xe7\xbd\x97\xe6\xa0\x91\xe6\x90\x9c\xe7\xb4\xa2(MCTS)](https://www.cnblogs.com/pinard/p/10470571.html) | \xe6\x97\xa0\n[\xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0(\xe5\x8d\x81\xe4\xb9\x9d) AlphaGo Zero\xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0\xe5\x8e\x9f\xe7\x90\x86](https://www.cnblogs.com/pinard/p/10609228.html) | \xe6\x97\xa0\n\n\n<h3 id=""2"">\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x9f\xba\xe7\xa1\x80\xe4\xb8\x8e\xe5\x9b\x9e\xe5\xbd\x92\xe7\xae\x97\xe6\xb3\x95\xe6\x96\x87\xe7\xab\xa0\xe4\xb8\x8e\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a</h3>\n\n|\xe6\x96\x87\xe7\xab\xa0 | \xe4\xbb\xa3\xe7\xa0\x81|\n---|---\n[\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xef\xbc\x88Gradient Descent\xef\xbc\x89\xe5\xb0\x8f\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/5970503.html) | \xe6\x97\xa0\n[\xe6\x9c\x80\xe5\xb0\x8f\xe4\xba\x8c\xe4\xb9\x98\xe6\xb3\x95\xe5\xb0\x8f\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/5976811.html) |\xe6\x97\xa0\n[\xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81(Cross Validation)\xe5\x8e\x9f\xe7\x90\x86\xe5\xb0\x8f\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/5992719.html) | \xe6\x97\xa0\n[\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\xe4\xb8\x8e\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\xef\xbc\x8cRoC\xe6\x9b\xb2\xe7\xba\xbf\xe4\xb8\x8ePR\xe6\x9b\xb2\xe7\xba\xbf](https://www.cnblogs.com/pinard/p/5993450.html) |\xe6\x97\xa0\n[\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe5\x8e\x9f\xe7\x90\x86\xe5\xb0\x8f\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6004041.html) |\xe6\x97\xa0\n[\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xa0\x94\xe7\xa9\xb6\xe4\xb8\x8e\xe5\xbc\x80\xe5\x8f\x91\xe5\xb9\xb3\xe5\x8f\xb0\xe7\x9a\x84\xe9\x80\x89\xe6\x8b\xa9](https://www.cnblogs.com/pinard/p/6007200.html) | \xe6\x97\xa0\n[scikit-learn \xe5\x92\x8cpandas \xe5\x9f\xba\xe4\xba\x8ewindows\xe5\x8d\x95\xe6\x9c\xba\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\x8e\xaf\xe5\xa2\x83\xe7\x9a\x84\xe6\x90\xad\xe5\xbb\xba](https://www.cnblogs.com/pinard/p/6013484.html) |\xe6\x97\xa0\n[\xe7\x94\xa8scikit-learn\xe5\x92\x8cpandas\xe5\xad\xa6\xe4\xb9\xa0\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92](https://www.cnblogs.com/pinard/p/6016029.html) |[\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/linear-regression.ipynb)\n[Lasso\xe5\x9b\x9e\xe5\xbd\x92\xe7\xae\x97\xe6\xb3\x95\xef\xbc\x9a \xe5\x9d\x90\xe6\xa0\x87\xe8\xbd\xb4\xe4\xb8\x8b\xe9\x99\x8d\xe6\xb3\x95\xe4\xb8\x8e\xe6\x9c\x80\xe5\xb0\x8f\xe8\xa7\x92\xe5\x9b\x9e\xe5\xbd\x92\xe6\xb3\x95\xe5\xb0\x8f\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6018889.html) | \xe6\x97\xa0\n[\xe7\x94\xa8scikit-learn\xe5\x92\x8cpandas\xe5\xad\xa6\xe4\xb9\xa0Ridge\xe5\x9b\x9e\xe5\xbd\x92](https://www.cnblogs.com/pinard/p/6023000.html) | [\xe4\xbb\xa3\xe7\xa0\x811](https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/ridge_regression_1.ipynb) [\xe4\xbb\xa3\xe7\xa0\x812](https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/ridge_regression.ipynb)\n[scikit-learn \xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe7\xae\x97\xe6\xb3\x95\xe5\xba\x93\xe5\xb0\x8f\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6026343.html)|\xe6\x97\xa0\n[\xe5\xbc\x82\xe5\xb8\xb8\xe7\x82\xb9\xe6\xa3\x80\xe6\xb5\x8b\xe7\xae\x97\xe6\xb3\x95\xe5\xb0\x8f\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/9314198.html)|\xe6\x97\xa0\n\n<h3 id=""3"">\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x88\x86\xe7\xb1\xbb\xe7\xae\x97\xe6\xb3\x95\xe6\x96\x87\xe7\xab\xa0\xe4\xb8\x8e\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a</h3>\n\n|\xe6\x96\x87\xe7\xab\xa0 | \xe4\xbb\xa3\xe7\xa0\x81|\n---|---\n[\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92\xe5\x8e\x9f\xe7\x90\x86\xe5\xb0\x8f\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6029432.html) |\xe6\x97\xa0\n[scikit-learn \xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92\xe7\xb1\xbb\xe5\xba\x93\xe4\xbd\xbf\xe7\x94\xa8\xe5\xb0\x8f\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6035872.html) |\xe6\x97\xa0\n[\xe6\x84\x9f\xe7\x9f\xa5\xe6\x9c\xba\xe5\x8e\x9f\xe7\x90\x86\xe5\xb0\x8f\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6042320.html) |\xe6\x97\xa0\n[\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe7\xae\x97\xe6\xb3\x95\xe5\x8e\x9f\xe7\x90\x86(\xe4\xb8\x8a)](https://www.cnblogs.com/pinard/p/6050306.html) |\xe6\x97\xa0\n[\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe7\xae\x97\xe6\xb3\x95\xe5\x8e\x9f\xe7\x90\x86(\xe4\xb8\x8b)](https://www.cnblogs.com/pinard/p/6053344.html)|\xe6\x97\xa0\n[scikit-learn\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe7\xae\x97\xe6\xb3\x95\xe7\xb1\xbb\xe5\xba\x93\xe4\xbd\xbf\xe7\x94\xa8\xe5\xb0\x8f\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6056319.html) |[\xe4\xbb\xa3\xe7\xa0\x811](https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/decision_tree_classifier.ipynb) [\xe4\xbb\xa3\xe7\xa0\x812](https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/decision_tree_classifier_1.ipynb)\n[K\xe8\xbf\x91\xe9\x82\xbb\xe6\xb3\x95(KNN)\xe5\x8e\x9f\xe7\x90\x86\xe5\xb0\x8f\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6061661.html) |\xe6\x97\xa0\n[scikit-learn K\xe8\xbf\x91\xe9\x82\xbb\xe6\xb3\x95\xe7\xb1\xbb\xe5\xba\x93\xe4\xbd\xbf\xe7\x94\xa8\xe5\xb0\x8f\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6065607.html) |[\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/knn_classifier.ipynb)\n[\xe6\x9c\xb4\xe7\xb4\xa0\xe8\xb4\x9d\xe5\x8f\xb6\xe6\x96\xaf\xe7\xae\x97\xe6\xb3\x95\xe5\x8e\x9f\xe7\x90\x86\xe5\xb0\x8f\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6069267.html) |\xe6\x97\xa0\n[scikit-learn \xe6\x9c\xb4\xe7\xb4\xa0\xe8\xb4\x9d\xe5\x8f\xb6\xe6\x96\xaf\xe7\xb1\xbb\xe5\xba\x93\xe4\xbd\xbf\xe7\x94\xa8\xe5\xb0\x8f\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6074222.html)| [\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/native_bayes.ipynb)\n[\xe6\x9c\x80\xe5\xa4\xa7\xe7\x86\xb5\xe6\xa8\xa1\xe5\x9e\x8b\xe5\x8e\x9f\xe7\x90\x86\xe5\xb0\x8f\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6093948.html)|\xe6\x97\xa0\n[\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba\xe5\x8e\x9f\xe7\x90\x86(\xe4\xb8\x80) \xe7\xba\xbf\xe6\x80\xa7\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba](https://www.cnblogs.com/pinard/p/6097604.html)|\xe6\x97\xa0\n[\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba\xe5\x8e\x9f\xe7\x90\x86(\xe4\xba\x8c) \xe7\xba\xbf\xe6\x80\xa7\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba\xe7\x9a\x84\xe8\xbd\xaf\xe9\x97\xb4\xe9\x9a\x94\xe6\x9c\x80\xe5\xa4\xa7\xe5\x8c\x96\xe6\xa8\xa1\xe5\x9e\x8b](https://www.cnblogs.com/pinard/p/6100722.html)|\xe6\x97\xa0\n[\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba\xe5\x8e\x9f\xe7\x90\x86(\xe4\xb8\x89)\xe7\xba\xbf\xe6\x80\xa7\xe4\xb8\x8d\xe5\x8f\xaf\xe5\x88\x86\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba\xe4\xb8\x8e\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0](https://www.cnblogs.com/pinard/p/6103615.html)|\xe6\x97\xa0\n[\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba\xe5\x8e\x9f\xe7\x90\x86(\xe5\x9b\x9b)SMO\xe7\xae\x97\xe6\xb3\x95\xe5\x8e\x9f\xe7\x90\x86](https://www.cnblogs.com/pinard/p/6111471.html)|\xe6\x97\xa0\n[\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba\xe5\x8e\x9f\xe7\x90\x86(\xe4\xba\x94)\xe7\xba\xbf\xe6\x80\xa7\xe6\x94\xaf\xe6\x8c\x81\xe5\x9b\x9e\xe5\xbd\x92](https://www.cnblogs.com/pinard/p/6113120.html)|\xe6\x97\xa0\n[scikit-learn \xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba\xe7\xae\x97\xe6\xb3\x95\xe5\xba\x93\xe4\xbd\xbf\xe7\x94\xa8\xe5\xb0\x8f\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6117515.html)|\xe6\x97\xa0\n[\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba\xe9\xab\x98\xe6\x96\xaf\xe6\xa0\xb8\xe8\xb0\x83\xe5\x8f\x82\xe5\xb0\x8f\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6126077.html) | [\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/svm_classifier.ipynb)\n\n<h3 id=""7"">\xe6\x95\xb0\xe5\xad\xa6\xe7\xbb\x9f\xe8\xae\xa1\xe5\xad\xa6\xe6\x96\x87\xe7\xab\xa0\xe4\xb8\x8e\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a</h3>\n\n|\xe6\x96\x87\xe7\xab\xa0 | \xe4\xbb\xa3\xe7\xa0\x81|\n---|---\n[\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xae\x97\xe6\xb3\x95\xe7\x9a\x84\xe9\x9a\x8f\xe6\x9c\xba\xe6\x95\xb0\xe6\x8d\xae\xe7\x94\x9f\xe6\x88\x90](https://www.cnblogs.com/pinard/p/6047802.html) | [\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/mathematics/random_data_generation.ipynb)\n[MCMC(\xe4\xb8\x80)\xe8\x92\x99\xe7\x89\xb9\xe5\x8d\xa1\xe7\xbd\x97\xe6\x96\xb9\xe6\xb3\x95](https://www.cnblogs.com/pinard/p/6625739.html)|\xe6\x97\xa0\n[MCMC(\xe4\xba\x8c)\xe9\xa9\xac\xe5\xb0\x94\xe7\xa7\x91\xe5\xa4\xab\xe9\x93\xbe](https://www.cnblogs.com/pinard/p/6632399.html)| [\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/mathematics/mcmc_2.ipynb)\n[MCMC(\xe4\xb8\x89)MCMC\xe9\x87\x87\xe6\xa0\xb7\xe5\x92\x8cM-H\xe9\x87\x87\xe6\xa0\xb7](https://www.cnblogs.com/pinard/p/6638955.html)|[\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/mathematics/mcmc_3_4.ipynb)\n[MCMC(\xe5\x9b\x9b)Gibbs\xe9\x87\x87\xe6\xa0\xb7](https://www.cnblogs.com/pinard/p/6645766.html)|[\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/mathematics/mcmc_3_4.ipynb)\n[\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe4\xb8\xad\xe7\x9a\x84\xe7\x9f\xa9\xe9\x98\xb5\xe5\x90\x91\xe9\x87\x8f\xe6\xb1\x82\xe5\xaf\xbc(\xe4\xb8\x80) \xe6\xb1\x82\xe5\xaf\xbc\xe5\xae\x9a\xe4\xb9\x89\xe4\xb8\x8e\xe6\xb1\x82\xe5\xaf\xbc\xe5\xb8\x83\xe5\xb1\x80](https://www.cnblogs.com/pinard/p/10750718.html)|\xe6\x97\xa0\n[\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe4\xb8\xad\xe7\x9a\x84\xe7\x9f\xa9\xe9\x98\xb5\xe5\x90\x91\xe9\x87\x8f\xe6\xb1\x82\xe5\xaf\xbc(\xe4\xba\x8c) \xe7\x9f\xa9\xe9\x98\xb5\xe5\x90\x91\xe9\x87\x8f\xe6\xb1\x82\xe5\xaf\xbc\xe4\xb9\x8b\xe5\xae\x9a\xe4\xb9\x89\xe6\xb3\x95](https://www.cnblogs.com/pinard/p/10773942.html)|\xe6\x97\xa0\n[\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe4\xb8\xad\xe7\x9a\x84\xe7\x9f\xa9\xe9\x98\xb5\xe5\x90\x91\xe9\x87\x8f\xe6\xb1\x82\xe5\xaf\xbc(\xe4\xb8\x89) \xe7\x9f\xa9\xe9\x98\xb5\xe5\x90\x91\xe9\x87\x8f\xe6\xb1\x82\xe5\xaf\xbc\xe4\xb9\x8b\xe5\xbe\xae\xe5\x88\x86\xe6\xb3\x95](https://www.cnblogs.com/pinard/p/10791506.html)|\xe6\x97\xa0\n[\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe4\xb8\xad\xe7\x9a\x84\xe7\x9f\xa9\xe9\x98\xb5\xe5\x90\x91\xe9\x87\x8f\xe6\xb1\x82\xe5\xaf\xbc(\xe5\x9b\x9b) \xe7\x9f\xa9\xe9\x98\xb5\xe5\x90\x91\xe9\x87\x8f\xe6\xb1\x82\xe5\xaf\xbc\xe9\x93\xbe\xe5\xbc\x8f\xe6\xb3\x95\xe5\x88\x99](https://www.cnblogs.com/pinard/p/10825264.html)|\xe6\x97\xa0\n[\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe4\xb8\xad\xe7\x9a\x84\xe7\x9f\xa9\xe9\x98\xb5\xe5\x90\x91\xe9\x87\x8f\xe6\xb1\x82\xe5\xaf\xbc(\xe4\xba\x94) \xe7\x9f\xa9\xe9\x98\xb5\xe5\xaf\xb9\xe7\x9f\xa9\xe9\x98\xb5\xe7\x9a\x84\xe6\xb1\x82\xe5\xaf\xbc](https://www.cnblogs.com/pinard/p/10930902.html)|\xe6\x97\xa0\n\n\n<h3 id=""6"">\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe9\x9b\x86\xe6\x88\x90\xe5\xad\xa6\xe4\xb9\xa0\xe6\x96\x87\xe7\xab\xa0\xe4\xb8\x8e\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a</h3>\n\n|\xe6\x96\x87\xe7\xab\xa0 | \xe4\xbb\xa3\xe7\xa0\x81|\n---|---\n[\xe9\x9b\x86\xe6\x88\x90\xe5\xad\xa6\xe4\xb9\xa0\xe5\x8e\x9f\xe7\x90\x86\xe5\xb0\x8f\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6131423.html) | \xe6\x97\xa0\n[\xe9\x9b\x86\xe6\x88\x90\xe5\xad\xa6\xe4\xb9\xa0\xe4\xb9\x8bAdaboost\xe7\xae\x97\xe6\xb3\x95\xe5\x8e\x9f\xe7\x90\x86\xe5\xb0\x8f\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6133937.html) | \xe6\x97\xa0\n[scikit-learn Adaboost\xe7\xb1\xbb\xe5\xba\x93\xe4\xbd\xbf\xe7\x94\xa8\xe5\xb0\x8f\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6136914.html) | [\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/ensemble-learning/adaboost-classifier.ipynb)\n[\xe6\xa2\xaf\xe5\xba\xa6\xe6\x8f\x90\xe5\x8d\x87\xe6\xa0\x91(GBDT)\xe5\x8e\x9f\xe7\x90\x86\xe5\xb0\x8f\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6140514.html) | \xe6\x97\xa0\n[scikit-learn \xe6\xa2\xaf\xe5\xba\xa6\xe6\x8f\x90\xe5\x8d\x87\xe6\xa0\x91(GBDT)\xe8\xb0\x83\xe5\x8f\x82\xe5\xb0\x8f\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6143927.html)| [\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/ensemble-learning/gbdt_classifier.ipynb)\n[Bagging\xe4\xb8\x8e\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\xe7\xae\x97\xe6\xb3\x95\xe5\x8e\x9f\xe7\x90\x86\xe5\xb0\x8f\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6156009.html) | \xe6\x97\xa0\n[scikit-learn\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\xe8\xb0\x83\xe5\x8f\x82\xe5\xb0\x8f\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6160412.html) |  [\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/ensemble-learning/random_forest_classifier.ipynb)\n[XGBoost\xe7\xae\x97\xe6\xb3\x95\xe5\x8e\x9f\xe7\x90\x86\xe5\xb0\x8f\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/10979808.html) | \xe6\x97\xa0\n[XGBoost\xe7\xb1\xbb\xe5\xba\x93\xe4\xbd\xbf\xe7\x94\xa8\xe5\xb0\x8f\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/11114748.html) |  [\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/ensemble-learning/xgboost-example.ipynb)\n\n\n<h3 id=""4"">\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\x81\x9a\xe7\xb1\xbb\xe7\xae\x97\xe6\xb3\x95\xe6\x96\x87\xe7\xab\xa0\xe4\xb8\x8e\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a</h3>\n\n|\xe6\x96\x87\xe7\xab\xa0 | \xe4\xbb\xa3\xe7\xa0\x81|\n---|---\n[K-Means\xe8\x81\x9a\xe7\xb1\xbb\xe7\xae\x97\xe6\xb3\x95\xe5\x8e\x9f\xe7\x90\x86](https://www.cnblogs.com/pinard/p/6164214.html)|\xe6\x97\xa0\n[\xe7\x94\xa8scikit-learn\xe5\xad\xa6\xe4\xb9\xa0K-Means\xe8\x81\x9a\xe7\xb1\xbb](https://www.cnblogs.com/pinard/p/6169370.html) | [\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/kmeans_cluster.ipynb)\n[BIRCH\xe8\x81\x9a\xe7\xb1\xbb\xe7\xae\x97\xe6\xb3\x95\xe5\x8e\x9f\xe7\x90\x86](https://www.cnblogs.com/pinard/p/6179132.html)|\xe6\x97\xa0\n[\xe7\x94\xa8scikit-learn\xe5\xad\xa6\xe4\xb9\xa0BIRCH\xe8\x81\x9a\xe7\xb1\xbb](https://www.cnblogs.com/pinard/p/6200579.html) | [\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/birch_cluster.ipynb)\n[DBSCAN\xe5\xaf\x86\xe5\xba\xa6\xe8\x81\x9a\xe7\xb1\xbb\xe7\xae\x97\xe6\xb3\x95](https://www.cnblogs.com/pinard/p/6208966.html)|\xe6\x97\xa0\n[\xe7\x94\xa8scikit-learn\xe5\xad\xa6\xe4\xb9\xa0DBSCAN\xe8\x81\x9a\xe7\xb1\xbb](https://www.cnblogs.com/pinard/p/6217852.html)|[\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/dbscan_cluster.ipynb)\n[\xe8\xb0\xb1\xe8\x81\x9a\xe7\xb1\xbb\xef\xbc\x88spectral clustering\xef\xbc\x89\xe5\x8e\x9f\xe7\x90\x86\xe6\x80\xbb\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6221564.html) |\xe6\x97\xa0\n[\xe7\x94\xa8scikit-learn\xe5\xad\xa6\xe4\xb9\xa0\xe8\xb0\xb1\xe8\x81\x9a\xe7\xb1\xbb](https://www.cnblogs.com/pinard/p/6235920.html)|[\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/spectral_cluster.ipynb)\n\n<h3 id=""5"">\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe9\x99\x8d\xe7\xbb\xb4\xe7\xae\x97\xe6\xb3\x95\xe6\x96\x87\xe7\xab\xa0\xe4\xb8\x8e\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a</h3>\n\n|\xe6\x96\x87\xe7\xab\xa0 | \xe4\xbb\xa3\xe7\xa0\x81|\n---|---\n[\xe4\xb8\xbb\xe6\x88\x90\xe5\x88\x86\xe5\x88\x86\xe6\x9e\x90\xef\xbc\x88PCA\xef\xbc\x89\xe5\x8e\x9f\xe7\x90\x86\xe6\x80\xbb\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6239403.html)|\xe6\x97\xa0\n[\xe7\x94\xa8scikit-learn\xe5\xad\xa6\xe4\xb9\xa0\xe4\xb8\xbb\xe6\x88\x90\xe5\x88\x86\xe5\x88\x86\xe6\x9e\x90(PCA)](https://www.cnblogs.com/pinard/p/6243025.html)|[\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/pca.ipynb)\n[\xe7\xba\xbf\xe6\x80\xa7\xe5\x88\xa4\xe5\x88\xab\xe5\x88\x86\xe6\x9e\x90LDA\xe5\x8e\x9f\xe7\x90\x86\xe6\x80\xbb\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6244265.html)|\xe6\x97\xa0\n[\xe7\x94\xa8scikit-learn\xe8\xbf\x9b\xe8\xa1\x8cLDA\xe9\x99\x8d\xe7\xbb\xb4](https://www.cnblogs.com/pinard/p/6249328.html)|[\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/lda.ipynb)\n[\xe5\xa5\x87\xe5\xbc\x82\xe5\x80\xbc\xe5\x88\x86\xe8\xa7\xa3(SVD)\xe5\x8e\x9f\xe7\x90\x86\xe4\xb8\x8e\xe5\x9c\xa8\xe9\x99\x8d\xe7\xbb\xb4\xe4\xb8\xad\xe7\x9a\x84\xe5\xba\x94\xe7\x94\xa8](https://www.cnblogs.com/pinard/p/6251584.html)|\xe6\x97\xa0\n[\xe5\xb1\x80\xe9\x83\xa8\xe7\xba\xbf\xe6\x80\xa7\xe5\xb5\x8c\xe5\x85\xa5(LLE)\xe5\x8e\x9f\xe7\x90\x86\xe6\x80\xbb\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6266408.html)|\xe6\x97\xa0\n[\xe7\x94\xa8scikit-learn\xe7\xa0\x94\xe7\xa9\xb6\xe5\xb1\x80\xe9\x83\xa8\xe7\xba\xbf\xe6\x80\xa7\xe5\xb5\x8c\xe5\x85\xa5(LLE)](https://www.cnblogs.com/pinard/p/6273377.html) |[\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/lle.ipynb)\n\n<h3 id=""8"">\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x85\xb3\xe8\x81\x94\xe7\xae\x97\xe6\xb3\x95\xe6\x96\x87\xe7\xab\xa0\xe4\xb8\x8e\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a</h3>\n\n|\xe6\x96\x87\xe7\xab\xa0 | \xe4\xbb\xa3\xe7\xa0\x81|\n---|---\n[\xe5\x85\xb8\xe5\x9e\x8b\xe5\x85\xb3\xe8\x81\x94\xe5\x88\x86\xe6\x9e\x90(CCA)\xe5\x8e\x9f\xe7\x90\x86\xe6\x80\xbb\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6288716.html)|\xe6\x97\xa0\n[Apriori\xe7\xae\x97\xe6\xb3\x95\xe5\x8e\x9f\xe7\x90\x86\xe6\x80\xbb\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6293298.html)|\xe6\x97\xa0\n[FP Tree\xe7\xae\x97\xe6\xb3\x95\xe5\x8e\x9f\xe7\x90\x86\xe6\x80\xbb\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6307064.html)|\xe6\x97\xa0\n[PrefixSpan\xe7\xae\x97\xe6\xb3\x95\xe5\x8e\x9f\xe7\x90\x86\xe6\x80\xbb\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6323182.html)|\xe6\x97\xa0\n[\xe7\x94\xa8Spark\xe5\xad\xa6\xe4\xb9\xa0FP Tree\xe7\xae\x97\xe6\xb3\x95\xe5\x92\x8cPrefixSpan\xe7\xae\x97\xe6\xb3\x95](https://www.cnblogs.com/pinard/p/6340162.html)| [\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/fp_tree_prefixspan.ipynb)\n[\xe6\x97\xa5\xe5\xbf\x97\xe5\x92\x8c\xe5\x91\x8a\xe8\xad\xa6\xe6\x95\xb0\xe6\x8d\xae\xe6\x8c\x96\xe6\x8e\x98\xe7\xbb\x8f\xe9\xaa\x8c\xe8\xb0\x88](https://www.cnblogs.com/pinard/p/6039099.html) | \xe6\x97\xa0\n\n<h3 id=""9"">\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x8e\xa8\xe8\x8d\x90\xe7\xae\x97\xe6\xb3\x95\xe6\x96\x87\xe7\xab\xa0\xe4\xb8\x8e\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a</h3>\n\n|\xe6\x96\x87\xe7\xab\xa0 | \xe4\xbb\xa3\xe7\xa0\x81|\n---|---\n[\xe5\x8d\x8f\xe5\x90\x8c\xe8\xbf\x87\xe6\xbb\xa4\xe6\x8e\xa8\xe8\x8d\x90\xe7\xae\x97\xe6\xb3\x95\xe6\x80\xbb\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6349233.html)|\xe6\x97\xa0\n[\xe7\x9f\xa9\xe9\x98\xb5\xe5\x88\x86\xe8\xa7\xa3\xe5\x9c\xa8\xe5\x8d\x8f\xe5\x90\x8c\xe8\xbf\x87\xe6\xbb\xa4\xe6\x8e\xa8\xe8\x8d\x90\xe7\xae\x97\xe6\xb3\x95\xe4\xb8\xad\xe7\x9a\x84\xe5\xba\x94\xe7\x94\xa8](https://www.cnblogs.com/pinard/p/6351319.html)|\xe6\x97\xa0\n[SimRank\xe5\x8d\x8f\xe5\x90\x8c\xe8\xbf\x87\xe6\xbb\xa4\xe6\x8e\xa8\xe8\x8d\x90\xe7\xae\x97\xe6\xb3\x95](https://www.cnblogs.com/pinard/p/6362647.html)|\xe6\x97\xa0\n[\xe7\x94\xa8Spark\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9f\xa9\xe9\x98\xb5\xe5\x88\x86\xe8\xa7\xa3\xe6\x8e\xa8\xe8\x8d\x90\xe7\xae\x97\xe6\xb3\x95](https://www.cnblogs.com/pinard/p/6364932.html)|[\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/matrix_factorization.ipynb)\n[\xe5\x88\x86\xe8\xa7\xa3\xe6\x9c\xba(Factorization Machines)\xe6\x8e\xa8\xe8\x8d\x90\xe7\xae\x97\xe6\xb3\x95\xe5\x8e\x9f\xe7\x90\x86](https://www.cnblogs.com/pinard/p/6370127.html)|\xe6\x97\xa0\n[\xe8\xb4\x9d\xe5\x8f\xb6\xe6\x96\xaf\xe4\xb8\xaa\xe6\x80\xa7\xe5\x8c\x96\xe6\x8e\x92\xe5\xba\x8f(BPR)\xe7\xae\x97\xe6\xb3\x95\xe5\xb0\x8f\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/9128682.html)|\xe6\x97\xa0\n[\xe7\x94\xa8tensorflow\xe5\xad\xa6\xe4\xb9\xa0\xe8\xb4\x9d\xe5\x8f\xb6\xe6\x96\xaf\xe4\xb8\xaa\xe6\x80\xa7\xe5\x8c\x96\xe6\x8e\x92\xe5\xba\x8f(BPR)](https://www.cnblogs.com/pinard/p/9163481.html)| [\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/bpr.ipynb)\n\n<h3 id=""10"">\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe7\xae\x97\xe6\xb3\x95\xe6\x96\x87\xe7\xab\xa0\xe4\xb8\x8e\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a</h3>\n\n|\xe6\x96\x87\xe7\xab\xa0 | \xe4\xbb\xa3\xe7\xa0\x81|\n---|---\n[\xe6\xb7\xb1\xe5\xba\xa6\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xef\xbc\x88DNN\xef\xbc\x89\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xb8\x8e\xe5\x89\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\xe7\xae\x97\xe6\xb3\x95](https://www.cnblogs.com/pinard/p/6418668.html)|\xe6\x97\xa0\n[\xe6\xb7\xb1\xe5\xba\xa6\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xef\xbc\x88DNN\xef\xbc\x89\xe5\x8f\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\xe7\xae\x97\xe6\xb3\x95(BP)](https://www.cnblogs.com/pinard/p/6422831.html)|\xe6\x97\xa0\n[\xe6\xb7\xb1\xe5\xba\xa6\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xef\xbc\x88DNN\xef\xbc\x89\xe6\x8d\x9f\xe5\xa4\xb1\xe5\x87\xbd\xe6\x95\xb0\xe5\x92\x8c\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84\xe9\x80\x89\xe6\x8b\xa9](https://www.cnblogs.com/pinard/p/6437495.html)|\xe6\x97\xa0\n[\xe6\xb7\xb1\xe5\xba\xa6\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xef\xbc\x88DNN\xef\xbc\x89\xe7\x9a\x84\xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96](https://www.cnblogs.com/pinard/p/6472666.html)|\xe6\x97\xa0\n[\xe5\x8d\xb7\xe7\xa7\xaf\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c(CNN)\xe6\xa8\xa1\xe5\x9e\x8b\xe7\xbb\x93\xe6\x9e\x84](https://www.cnblogs.com/pinard/p/6483207.html)|\xe6\x97\xa0\n[\xe5\x8d\xb7\xe7\xa7\xaf\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c(CNN)\xe5\x89\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\xe7\xae\x97\xe6\xb3\x95](https://www.cnblogs.com/pinard/p/6489633.html)|\xe6\x97\xa0\n[\xe5\x8d\xb7\xe7\xa7\xaf\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c(CNN)\xe5\x8f\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\xe7\xae\x97\xe6\xb3\x95](https://www.cnblogs.com/pinard/p/6494810.html)|\xe6\x97\xa0\n[\xe5\xbe\xaa\xe7\x8e\xaf\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c(RNN)\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xb8\x8e\xe5\x89\x8d\xe5\x90\x91\xe5\x8f\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\xe7\xae\x97\xe6\xb3\x95](https://www.cnblogs.com/pinard/p/6509630.html)|\xe6\x97\xa0\n[LSTM\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xb8\x8e\xe5\x89\x8d\xe5\x90\x91\xe5\x8f\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\xe7\xae\x97\xe6\xb3\x95](https://www.cnblogs.com/pinard/p/6519110.html)|\xe6\x97\xa0\n[\xe5\x8f\x97\xe9\x99\x90\xe7\x8e\xbb\xe5\xb0\x94\xe5\x85\xb9\xe6\x9b\xbc\xe6\x9c\xba\xef\xbc\x88RBM\xef\xbc\x89\xe5\x8e\x9f\xe7\x90\x86\xe6\x80\xbb\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6530523.html)|\xe6\x97\xa0\n\n<h3 id=""11"">\xe8\x87\xaa\xe7\x84\xb6\xe8\xaf\xad\xe8\xa8\x80\xe5\xa4\x84\xe7\x90\x86\xe6\x96\x87\xe7\xab\xa0\xe4\xb8\x8e\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a</h3>\n\n|\xe6\x96\x87\xe7\xab\xa0 | \xe4\xbb\xa3\xe7\xa0\x81|\n---|---\n[\xe6\x96\x87\xe6\x9c\xac\xe6\x8c\x96\xe6\x8e\x98\xe7\x9a\x84\xe5\x88\x86\xe8\xaf\x8d\xe5\x8e\x9f\xe7\x90\x86](https://www.cnblogs.com/pinard/p/6677078.html)|\xe6\x97\xa0\n[\xe6\x96\x87\xe6\x9c\xac\xe6\x8c\x96\xe6\x8e\x98\xe9\xa2\x84\xe5\xa4\x84\xe7\x90\x86\xe4\xb9\x8b\xe5\x90\x91\xe9\x87\x8f\xe5\x8c\x96\xe4\xb8\x8eHash Trick](https://www.cnblogs.com/pinard/p/6688348.html)|[\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/natural-language-processing/hash_trick.ipynb)\n[\xe6\x96\x87\xe6\x9c\xac\xe6\x8c\x96\xe6\x8e\x98\xe9\xa2\x84\xe5\xa4\x84\xe7\x90\x86\xe4\xb9\x8bTF-IDF](https://www.cnblogs.com/pinard/p/6693230.html)|[\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/natural-language-processing/tf-idf.ipynb)\n[\xe4\xb8\xad\xe6\x96\x87\xe6\x96\x87\xe6\x9c\xac\xe6\x8c\x96\xe6\x8e\x98\xe9\xa2\x84\xe5\xa4\x84\xe7\x90\x86\xe6\xb5\x81\xe7\xa8\x8b\xe6\x80\xbb\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6744056.html)|[\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/natural-language-processing/chinese_digging.ipynb)\n[\xe8\x8b\xb1\xe6\x96\x87\xe6\x96\x87\xe6\x9c\xac\xe6\x8c\x96\xe6\x8e\x98\xe9\xa2\x84\xe5\xa4\x84\xe7\x90\x86\xe6\xb5\x81\xe7\xa8\x8b\xe6\x80\xbb\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6756534.html)|[\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/natural-language-processing/english_digging.ipynb)\n[\xe6\x96\x87\xe6\x9c\xac\xe4\xb8\xbb\xe9\xa2\x98\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xb9\x8b\xe6\xbd\x9c\xe5\x9c\xa8\xe8\xaf\xad\xe4\xb9\x89\xe7\xb4\xa2\xe5\xbc\x95(LSI)](https://www.cnblogs.com/pinard/p/6805861.html)|\xe6\x97\xa0\n[\xe6\x96\x87\xe6\x9c\xac\xe4\xb8\xbb\xe9\xa2\x98\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xb9\x8b\xe9\x9d\x9e\xe8\xb4\x9f\xe7\x9f\xa9\xe9\x98\xb5\xe5\x88\x86\xe8\xa7\xa3(NMF)](https://www.cnblogs.com/pinard/p/6812011.html)|[\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/natural-language-processing/nmf.ipynb)\n[\xe6\x96\x87\xe6\x9c\xac\xe4\xb8\xbb\xe9\xa2\x98\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xb9\x8bLDA(\xe4\xb8\x80) LDA\xe5\x9f\xba\xe7\xa1\x80](https://www.cnblogs.com/pinard/p/6831308.html)|\xe6\x97\xa0\n[\xe6\x96\x87\xe6\x9c\xac\xe4\xb8\xbb\xe9\xa2\x98\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xb9\x8bLDA(\xe4\xba\x8c) LDA\xe6\xb1\x82\xe8\xa7\xa3\xe4\xb9\x8bGibbs\xe9\x87\x87\xe6\xa0\xb7\xe7\xae\x97\xe6\xb3\x95](https://www.cnblogs.com/pinard/p/6867828.html)|\xe6\x97\xa0\n[\xe6\x96\x87\xe6\x9c\xac\xe4\xb8\xbb\xe9\xa2\x98\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xb9\x8bLDA(\xe4\xb8\x89) LDA\xe6\xb1\x82\xe8\xa7\xa3\xe4\xb9\x8b\xe5\x8f\x98\xe5\x88\x86\xe6\x8e\xa8\xe6\x96\xadEM\xe7\xae\x97\xe6\xb3\x95](https://www.cnblogs.com/pinard/p/6873703.html)|\xe6\x97\xa0\n[\xe7\x94\xa8scikit-learn\xe5\xad\xa6\xe4\xb9\xa0LDA\xe4\xb8\xbb\xe9\xa2\x98\xe6\xa8\xa1\xe5\x9e\x8b](https://www.cnblogs.com/pinard/p/6908150.html)|[\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/natural-language-processing/lda.ipynb)\n[EM\xe7\xae\x97\xe6\xb3\x95\xe5\x8e\x9f\xe7\x90\x86\xe6\x80\xbb\xe7\xbb\x93](https://www.cnblogs.com/pinard/p/6912636.html)|\xe6\x97\xa0\n[\xe9\x9a\x90\xe9\xa9\xac\xe5\xb0\x94\xe7\xa7\x91\xe5\xa4\xab\xe6\xa8\xa1\xe5\x9e\x8bHMM\xef\xbc\x88\xe4\xb8\x80\xef\xbc\x89HMM\xe6\xa8\xa1\xe5\x9e\x8b](https://www.cnblogs.com/pinard/p/6945257.html)|\xe6\x97\xa0\n[\xe9\x9a\x90\xe9\xa9\xac\xe5\xb0\x94\xe7\xa7\x91\xe5\xa4\xab\xe6\xa8\xa1\xe5\x9e\x8bHMM\xef\xbc\x88\xe4\xba\x8c\xef\xbc\x89\xe5\x89\x8d\xe5\x90\x91\xe5\x90\x8e\xe5\x90\x91\xe7\xae\x97\xe6\xb3\x95\xe8\xaf\x84\xe4\xbc\xb0\xe8\xa7\x82\xe5\xaf\x9f\xe5\xba\x8f\xe5\x88\x97\xe6\xa6\x82\xe7\x8e\x87](https://www.cnblogs.com/pinard/p/6955871.html)|\xe6\x97\xa0\n[\xe9\x9a\x90\xe9\xa9\xac\xe5\xb0\x94\xe7\xa7\x91\xe5\xa4\xab\xe6\xa8\xa1\xe5\x9e\x8bHMM\xef\xbc\x88\xe4\xb8\x89\xef\xbc\x89\xe9\xb2\x8d\xe5\xa7\x86-\xe9\x9f\xa6\xe5\xb0\x94\xe5\xa5\x87\xe7\xae\x97\xe6\xb3\x95\xe6\xb1\x82\xe8\xa7\xa3HMM\xe5\x8f\x82\xe6\x95\xb0](https://www.cnblogs.com/pinard/p/6972299.html)|\xe6\x97\xa0\n[\xe9\x9a\x90\xe9\xa9\xac\xe5\xb0\x94\xe7\xa7\x91\xe5\xa4\xab\xe6\xa8\xa1\xe5\x9e\x8bHMM\xef\xbc\x88\xe5\x9b\x9b\xef\xbc\x89\xe7\xbb\xb4\xe7\x89\xb9\xe6\xaf\x94\xe7\xae\x97\xe6\xb3\x95\xe8\xa7\xa3\xe7\xa0\x81\xe9\x9a\x90\xe8\x97\x8f\xe7\x8a\xb6\xe6\x80\x81\xe5\xba\x8f\xe5\x88\x97](https://www.cnblogs.com/pinard/p/6991852.html)|\xe6\x97\xa0\n[\xe7\x94\xa8hmmlearn\xe5\xad\xa6\xe4\xb9\xa0\xe9\x9a\x90\xe9\xa9\xac\xe5\xb0\x94\xe7\xa7\x91\xe5\xa4\xab\xe6\xa8\xa1\xe5\x9e\x8bHMM](https://www.cnblogs.com/pinard/p/7001397.html)|[\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/natural-language-processing/hmm.ipynb)\n[\xe6\x9d\xa1\xe4\xbb\xb6\xe9\x9a\x8f\xe6\x9c\xba\xe5\x9c\xbaCRF(\xe4\xb8\x80)\xe4\xbb\x8e\xe9\x9a\x8f\xe6\x9c\xba\xe5\x9c\xba\xe5\x88\xb0\xe7\xba\xbf\xe6\x80\xa7\xe9\x93\xbe\xe6\x9d\xa1\xe4\xbb\xb6\xe9\x9a\x8f\xe6\x9c\xba\xe5\x9c\xba](https://www.cnblogs.com/pinard/p/7048333.html)|\xe6\x97\xa0\n[\xe6\x9d\xa1\xe4\xbb\xb6\xe9\x9a\x8f\xe6\x9c\xba\xe5\x9c\xbaCRF(\xe4\xba\x8c) \xe5\x89\x8d\xe5\x90\x91\xe5\x90\x8e\xe5\x90\x91\xe7\xae\x97\xe6\xb3\x95\xe8\xaf\x84\xe4\xbc\xb0\xe6\xa0\x87\xe8\xae\xb0\xe5\xba\x8f\xe5\x88\x97\xe6\xa6\x82\xe7\x8e\x87](https://www.cnblogs.com/pinard/p/7055072.html)|\xe6\x97\xa0\n[\xe6\x9d\xa1\xe4\xbb\xb6\xe9\x9a\x8f\xe6\x9c\xba\xe5\x9c\xbaCRF(\xe4\xb8\x89) \xe6\xa8\xa1\xe5\x9e\x8b\xe5\xad\xa6\xe4\xb9\xa0\xe4\xb8\x8e\xe7\xbb\xb4\xe7\x89\xb9\xe6\xaf\x94\xe7\xae\x97\xe6\xb3\x95\xe8\xa7\xa3\xe7\xa0\x81](https://www.cnblogs.com/pinard/p/7068574.html)|\xe6\x97\xa0\n[word2vec\xe5\x8e\x9f\xe7\x90\x86(\xe4\xb8\x80) CBOW\xe4\xb8\x8eSkip-Gram\xe6\xa8\xa1\xe5\x9e\x8b\xe5\x9f\xba\xe7\xa1\x80](https://www.cnblogs.com/pinard/p/7160330.html)|\xe6\x97\xa0\n[word2vec\xe5\x8e\x9f\xe7\x90\x86(\xe4\xba\x8c) \xe5\x9f\xba\xe4\xba\x8eHierarchical Softmax\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b](https://www.cnblogs.com/pinard/p/7243513.html)|\xe6\x97\xa0\n[word2vec\xe5\x8e\x9f\xe7\x90\x86(\xe4\xb8\x89) \xe5\x9f\xba\xe4\xba\x8eNegative Sampling\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b](https://www.cnblogs.com/pinard/p/7249903.html)|\xe6\x97\xa0\n[\xe7\x94\xa8gensim\xe5\xad\xa6\xe4\xb9\xa0word2vec](https://www.cnblogs.com/pinard/p/7278324.html)|[\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/natural-language-processing/word2vec.ipynb)\n\n<h3 id=""12"">\xe7\x89\xb9\xe5\xbe\x81\xe5\xb7\xa5\xe7\xa8\x8b\xe4\xb8\x8e\xe7\xae\x97\xe6\xb3\x95\xe8\x90\xbd\xe5\x9c\xb0\xe6\x96\x87\xe7\xab\xa0\xe4\xb8\x8e\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x9a</h3>\n\n|\xe6\x96\x87\xe7\xab\xa0 | \xe4\xbb\xa3\xe7\xa0\x81|\n---|---\n[\xe7\x89\xb9\xe5\xbe\x81\xe5\xb7\xa5\xe7\xa8\x8b\xe4\xb9\x8b\xe7\x89\xb9\xe5\xbe\x81\xe9\x80\x89\xe6\x8b\xa9](https://www.cnblogs.com/pinard/p/9032759.html)|\xe6\x97\xa0\n[\xe7\x89\xb9\xe5\xbe\x81\xe5\xb7\xa5\xe7\xa8\x8b\xe4\xb9\x8b\xe7\x89\xb9\xe5\xbe\x81\xe8\xa1\xa8\xe8\xbe\xbe](https://www.cnblogs.com/pinard/p/9061549.html)|\xe6\x97\xa0\n[\xe7\x89\xb9\xe5\xbe\x81\xe5\xb7\xa5\xe7\xa8\x8b\xe4\xb9\x8b\xe7\x89\xb9\xe5\xbe\x81\xe9\xa2\x84\xe5\xa4\x84\xe7\x90\x86](https://www.cnblogs.com/pinard/p/9093890.html)|\xe6\x97\xa0\n[\xe7\x94\xa8PMML\xe5\xae\x9e\xe7\x8e\xb0\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe8\xb7\xa8\xe5\xb9\xb3\xe5\x8f\xb0\xe4\xb8\x8a\xe7\xba\xbf](https://www.cnblogs.com/pinard/p/9220199.html)|[\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/model-in-product/sklearn-jpmml)\n[tensorflow\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe8\xb7\xa8\xe5\xb9\xb3\xe5\x8f\xb0\xe4\xb8\x8a\xe7\xba\xbf](https://www.cnblogs.com/pinard/p/9251296.html)|[\xe4\xbb\xa3\xe7\xa0\x81](https://github.com/ljpzzz/machinelearning/blob/master/model-in-product/tensorflow-java)\n\n<h3 id=""13"">\xe8\xb5\x9e\xe5\x8a\xa9\xe6\x88\x91</h3>\n\n\xe4\xbd\xa0\xe7\x9a\x84\xe6\x94\xaf\xe6\x8c\x81\xe6\x98\xaf\xe6\x88\x91\xe5\x86\x99\xe4\xbd\x9c\xe7\x9a\x84\xe5\x8a\xa8\xe5\x8a\x9b(1.\xe5\xbe\xae\xe4\xbf\xa1/2.\xe6\x94\xaf\xe4\xbb\x98\xe5\xae\x9d)\xef\xbc\x9a\n\n![\xe5\xbe\xae\xe4\xbf\xa1\xe8\xb5\x9e\xe5\x8a\xa9](./assert/invoice.bmp)\n\n\n![\xe6\x94\xaf\xe4\xbb\x98\xe5\xae\x9d\xe8\xb5\x9e\xe5\x8a\xa9](./assert/invoice_ali.bmp)\n\nLicense MIT.\n'"
50,xxg1413/MachineLearning,xxg1413,Machine Learning,2016-03-10 14:08:13,2020-05-31 02:58:24,Jupyter Notebook,257,405,"b""## Machine Learning\n\n\n## \xe8\xaf\xbe\xe7\xa8\x8b\n\n#### [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0](https://github.com/xxg1413/coursera/tree/master/Machine%20Learning-Andrew%20Ng) -- \xe5\x90\xb4\xe6\x81\xa9\xe8\xbe\xbe -- \xe6\x96\xaf\xe5\x9d\xa6\xe7\xa6\x8f\xe5\xa4\xa7\xe5\xad\xa6\n\n- \xe8\xaf\xbe\xe7\xa8\x8b\xe8\xbf\x9b\xe5\xba\xa6\xef\xbc\x9a 100%\n- \xe4\xbd\x9c\xe4\xb8\x9a\xef\xbc\x9a\n\t- [Octave] - \xe4\xbd\xbf\xe7\x94\xa8Octave\xef\xbc\x8c\xe9\xbb\x98\xe8\xae\xa4\xe7\x89\x88\xe6\x9c\xac  100%\n\t- [Jupyter Notebook](https://github.com/xxg1413/coursera/tree/master/Machine%20Learning-Andrew%20Ng/Jupyter%20Notebook) - \xe4\xbd\xbf\xe7\x94\xa8numpy,pandas,scikit-learn,matplotlib,tensorflow\xe7\xad\x89\xe5\xba\x93\xe7\x9a\x84Python3\xe7\x89\x88  12%\n\n\n#### \xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0 -- \xe6\x9e\x97\xe8\xbb\x92\xe7\x94\xb0 -- \xe5\x8f\xb0\xe6\xb9\xbe\xe5\xa4\xa7\xe5\xad\xa6\n- [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x9f\xba\xe7\x9f\xb3](https://github.com/xxg1413/coursera/tree/master/Machine%20Learning%20Foundations)\n- [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x8a\x80\xe6\xb3\x95](https://github.com/xxg1413/coursera/tree/master/Machine%20Learning%20Techniques)\n\n\n\n\n#### [CS231n: \xe9\x9d\xa2\xe5\x90\x91\xe8\xa7\x86\xe8\xa7\x89\xe8\xaf\x86\xe5\x88\xab\xe7\x9a\x84\xe5\x8d\xb7\xe7\xa7\xaf\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c--Fei-Fei Li & Andrej Karpathy & Justin Johnson -- \xe6\x96\xaf\xe5\x9d\xa6\xe7\xa6\x8f\xe5\xa4\xa7\xe5\xad\xa6](https://github.com/xxg1413/coursera/tree/master/CS231n:%20Convolutional%20Neural%20Networks%20for%20Visual%20Recognition)\n\n- \xe8\xaf\xbe\xe7\xa8\x8b\xe8\xbf\x9b\xe5\xba\xa6\xef\xbc\x9a \xe7\xac\xac2\xe9\x9b\x86\n- \xe4\xbd\x9c\xe4\xb8\x9a\xef\xbc\x9a\n\t- \xe4\xbd\x9c\xe4\xb8\x9a1\n\t- \xe4\xbd\x9c\xe4\xb8\x9a2\n\t- \xe4\xbd\x9c\xe4\xb8\x9a3 \n\n\n#### [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe4\xb8\xad\xe7\x9a\x84\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c--Geoffrey Hinton-\xe5\xa4\x9a\xe4\xbc\xa6\xe5\xa4\x9a\xe5\xa4\xa7\xe5\xad\xa6](https://github.com/xxg1413/coursera/tree/master/Neural%20Networks%20for%20Machine%20Learning)\n- \xe8\xaf\xbe\xe7\xa8\x8b\xe8\xbf\x9b\xe5\xba\xa6\xef\xbc\x9a Lecture2\n- \xe4\xbd\x9c\xe4\xb8\x9a\xef\xbc\x9a\n\t- Octave - \xe4\xbd\xbf\xe7\x94\xa8Octave\xef\xbc\x8c\xe9\xbb\x98\xe8\xae\xa4\xe7\x89\x88\xe6\x9c\xac  \n\t- Tensorflow \xe7\x89\x88\xe6\x9c\xac\n\n## \xe8\xaf\xbb\xe4\xb9\xa6\n- [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xb3\xbb\xe7\xbb\x9f\xe8\xae\xbe\xe8\xae\xa1](https://github.com/xxg1413/MachineLearning/tree/master/Building%20Machine%20Learning%20Systems)\n\t- \xe8\xbf\x9b\xe5\xba\xa6\xef\xbc\x9a100%\n\t- \xe9\xa1\xb9\xe7\x9b\xae\xef\xbc\x9a\xe5\xaf\xbb\xe6\x89\xbe\xe5\xae\x9e\xe9\x99\x85\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x83\xe4\xb9\xa0\n\t\n- [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xae\x9e\xe6\x88\x98](https://github.com/xxg1413/MachineLearning/tree/master/Machine%20Learning%20in%20Action)\n\t- \xe8\xbf\x9b\xe5\xba\xa6\xef\xbc\x9a\xe7\xac\xac2\xe7\xab\xa0\n\t- \xe9\xa1\xb9\xe7\x9b\xae\xef\xbc\x9a\n\t\n- [Python\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe6\x9e\x90\xe5\x9f\xba\xe7\xa1\x80\xe6\x95\x99\xe7\xa8\x8b:NumPy\xe5\xad\xa6\xe4\xb9\xa0\xe6\x8c\x87\xe5\x8d\x97](https://github.com/xxg1413/MachineLearning/tree/master/NumPy%20Beginner's%20Guide)\n\t- \xe8\xbf\x9b\xe5\xba\xa6\xef\xbc\x9a100% \n\t- \xe9\xa1\xb9\xe7\x9b\xae\xef\xbc\x9anumpy\xe5\x85\xa5\xe9\x97\xa8\n\t\n- [Python\xe6\x95\xb0\xe6\x8d\xae\xe6\x8c\x96\xe6\x8e\x98\xe5\x85\xa5\xe9\x97\xa8\xe4\xb8\x8e\xe5\xae\x9e\xe8\xb7\xb5](https://github.com/xxg1413/MachineLearning/tree/master/Learning%20Data%20Mining%20with%20Python)\n\t- \xe8\xbf\x9b\xe5\xba\xa6\xef\xbc\x9aChapter3\n\t- \xe9\xa1\xb9\xe7\x9b\xae\xef\xbc\x9a\n\t\n- [\xe9\x9b\x86\xe4\xbd\x93\xe6\x99\xba\xe6\x85\xa7\xe7\xbc\x96\xe7\xa8\x8b](https://github.com/xxg1413/MachineLearning/tree/master/Programming%20Collective%20Intelligence/)\n\t- \xe8\xbf\x9b\xe5\xba\xa6\xef\xbc\x9a100%\n\t- \xe9\xa1\xb9\xe7\x9b\xae\xef\xbc\x9a\xe4\xbd\xbf\xe7\x94\xa8\xe5\xba\x93\xe9\x87\x8d\xe5\x86\x99\xe6\x89\x80\xe6\x9c\x89\xe4\xbe\x8b\xe5\xad\x90\n\t\n- [R\xe8\xaf\xad\xe8\xa8\x80-\xe5\xae\x9e\xe7\x94\xa8\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe6\x9e\x90\xe5\x92\x8c\xe5\x8f\xaf\xe8\xa7\x86\xe5\x8c\x96\xe6\x8a\x80\xe6\x9c\xaf](https://github.com/xxg1413/MachineLearning/tree/master/R%20for%20Everyone/)\n\t- \xe8\xbf\x9b\xe5\xba\xa6\xef\xbc\x9a100%\n\t- \xe9\xa1\xb9\xe7\x9b\xae\xef\xbc\x9a\t\n\t\n- [Python\xe7\xbd\x91\xe7\xbb\x9c\xe6\x95\xb0\xe6\x8d\xae\xe9\x87\x87\xe9\x9b\x86](https://github.com/xxg1413/MachineLearning/tree/master/Web%20Scraping%20with%20Python/)\n\t- \xe8\xbf\x9b\xe5\xba\xa6\xef\xbc\x9a100%\n\t- \xe9\xa1\xb9\xe7\x9b\xae\xef\xbc\x9a\xe7\x88\xac\xe8\x99\xab\xe7\xb3\xbb\xe7\xbb\x9f\n\t\n\n\n## \xe7\xab\x9e\xe8\xb5\x9b\n- [Kaggle\xe7\xbb\x83\xe4\xb9\xa0\xe9\xa2\x98\xe9\xa2\x98\xe8\xa7\xa3](https://github.com/xxg1413/MachineLearning/tree/master/Kaggle/)\n- [Euler\xe9\xa1\xb9\xe7\x9b\xae\xe9\xa2\x98\xe8\xa7\xa3](https://github.com/xxg1413/MachineLearning/tree/master/Euler/)\n\n\n\n## \xe5\x85\xa5\xe9\x97\xa8\n- [numpy](https://github.com/xxg1413/MachineLearning/tree/master/numpy-tutorial/)\n- [pandas](https://github.com/xxg1413/MachineLearning/tree/master/pandas-tutorial/)\n- [sklearn](https://github.com/xxg1413/MachineLearning/tree/master/sklearn-tutorial/)\n- [tensorflow](https://github.com/xxg1413/Tensorflow/tree/master/tutorial)\n\n\n## Spark\n- [Introduction to Apache Spark](https://github.com/xxg1413/edx/tree/master/Introduction%20to%20Apache%20Spark)  \n- [Distributed Machine Learning with Apache Spark](https://github.com/xxg1413/edx/tree/master/Distributed%20Machine%20Learning%20with%20Apache%20Spark)\n- [Big Data Analysis with Apache Spark]()\n\n\n\n## \xe9\xa1\xb9\xe7\x9b\xae\xe5\x88\x97\xe8\xa1\xa8\n"""
51,trainindata/deploying-machine-learning-models,trainindata,"Example Repo for the Udemy Course ""Deployment of Machine Learning Models""",2019-01-09 20:30:46,2020-06-16 06:09:34,Python,1506,189,"b'# Deployment of Machine Learning Models\nAccompanying repo for the online course Deployment of Machine Learning Models.\n\nFor the documentation, visit the [course on Udemy](https://www.udemy.com/deployment-of-machine-learning-models/?couponCode=TIDREPO).\n'"
52,warmheartli/MachineLearningCourse,warmheartli,机器学习精简入门教程,2016-06-23 01:22:30,2020-06-15 08:36:46,,267,768,"b'MachineLearningCourse\n==============\n_\xe8\xaf\xbb\xe6\x9c\xac\xe4\xba\xba\xe6\x9b\xb4\xe5\xa4\x9a\xe5\x8e\x9f\xe5\x88\x9b\xe6\x96\x87\xe7\xab\xa0\xef\xbc\x8c\xe6\xac\xa2\xe8\xbf\x8e\xe5\x85\xb3\xe6\xb3\xa8\xe5\xbe\xae\xe4\xbf\xa1\xe8\xae\xa2\xe9\x98\x85\xe5\x8f\xb7_\n\n<img src=""https://github.com/warmheartli/MachineLearningCourse/blob/master/weixinpub.jpg"" width = ""150"" height = ""150"" alt=""SharEDITor"" />\n\n_\xe6\xac\xa2\xe8\xbf\x8e\xe5\x85\xb3\xe6\xb3\xa8\xe6\x88\x91\xe7\x9a\x84\xe5\x8f\xa6\xe5\xa4\x96\xe4\xb8\xa4\xe4\xb8\xaagithub\xe9\xa1\xb9\xe7\x9b\xae_\n * [_\xe6\x95\x99\xe4\xbd\xa0\xe6\x88\x90\xe4\xb8\xba\xe5\x85\xa8\xe6\xa0\x88\xe5\xb7\xa5\xe7\xa8\x8b\xe5\xb8\x88_](https://github.com/warmheartli/FullStackDeveloperCourse)\n * [_\xe8\x87\xaa\xe5\xb7\xb1\xe5\x8a\xa8\xe6\x89\x8b\xe5\x81\x9a\xe8\x81\x8a\xe5\xa4\xa9\xe6\x9c\xba\xe5\x99\xa8\xe4\xba\xba\xe6\x95\x99\xe7\xa8\x8b_](https://github.com/warmheartli/ChatBotCourse)\n\n\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xb2\xbe\xe7\xae\x80\xe5\x85\xa5\xe9\x97\xa8\xe6\x95\x99\xe7\xa8\x8b\n==============\n * [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x95\x99\xe7\xa8\x8b \xe4\xb8\x80-\xe4\xb8\x8d\xe6\x87\x82\xe8\xbf\x99\xe4\xba\x9b\xe7\xba\xbf\xe6\x80\xa7\xe4\xbb\xa3\xe6\x95\xb0\xe7\x9f\xa5\xe8\xaf\x86 \xe5\x88\xab\xe8\xaf\xb4\xe4\xbd\xa0\xe6\x98\xaf\xe6\x90\x9e\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9a\x84](http://www.shareditor.com/blogshow/?blogId=1)(2016-04-01)\n * [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x95\x99\xe7\xa8\x8b \xe4\xba\x8c-\xe5\xae\x89\xe8\xa3\x85octave\xe7\xbb\x98\xe5\x88\xb63D\xe5\x87\xbd\xe6\x95\xb0\xe5\x9b\xbe\xe5\x83\x8f](http://www.shareditor.com/blogshow/?blogId=28)(2016-04-30)\n * [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x95\x99\xe7\xa8\x8b \xe4\xb8\x89-\xe7\x94\xa8scikit-learn\xe6\xb1\x82\xe8\xa7\xa3\xe4\xb8\x80\xe5\x85\x83\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe9\x97\xae\xe9\xa2\x98](http://www.shareditor.com/blogshow/?blogId=53)(2016-05-30)\n * [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x95\x99\xe7\xa8\x8b \xe5\x9b\x9b-\xe7\x94\xa8scikit-learn\xe6\xb1\x82\xe8\xa7\xa3\xe5\xa4\x9a\xe5\x85\x83\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe9\x97\xae\xe9\xa2\x98](http://www.shareditor.com/blogshow/?blogId=54)(2016-05-30)\n * [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x95\x99\xe7\xa8\x8b \xe4\xba\x94-\xe7\x94\xa8matplotlib\xe7\xbb\x98\xe5\x88\xb6\xe7\xb2\xbe\xe7\xbe\x8e\xe7\x9a\x84\xe5\x9b\xbe\xe8\xa1\xa8](http://www.shareditor.com/blogshow/?blogId=55)(2016-05-31)\n * [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x95\x99\xe7\xa8\x8b \xe5\x85\xad-\xe7\x94\xa8scikit-learn\xe6\xb1\x82\xe8\xa7\xa3\xe5\xa4\x9a\xe9\xa1\xb9\xe5\xbc\x8f\xe5\x9b\x9e\xe5\xbd\x92\xe9\x97\xae\xe9\xa2\x98](http://www.shareditor.com/blogshow/?blogId=56)(2016-06-01)\n * [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x95\x99\xe7\xa8\x8b \xe4\xb8\x83-\xe7\x94\xa8\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xe6\xb3\x95(SGD)\xe5\x81\x9a\xe7\xba\xbf\xe6\x80\xa7\xe6\x8b\x9f\xe5\x90\x88](http://www.shareditor.com/blogshow/?blogId=57)(2016-06-01)\n * [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x95\x99\xe7\xa8\x8b \xe5\x85\xab-\xe7\x94\xa8scikit-learn\xe5\x81\x9a\xe7\x89\xb9\xe5\xbe\x81\xe6\x8f\x90\xe5\x8f\x96](http://www.shareditor.com/blogshow/?blogId=58)(2016-06-01)\n * [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x95\x99\xe7\xa8\x8b \xe4\xb9\x9d-\xe4\xba\x8c\xe5\x85\x83\xe5\x88\x86\xe7\xb1\xbb\xe6\x95\x88\xe6\x9e\x9c\xe7\x9a\x84\xe8\xaf\x84\xe4\xbc\xb0\xe6\x96\xb9\xe6\xb3\x95](http://www.shareditor.com/blogshow/?blogId=59)(2016-06-02)\n * [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x95\x99\xe7\xa8\x8b \xe5\x8d\x81-\xe7\x94\xa8scikit-learn\xe7\x9a\x84\xe7\xbd\x91\xe6\xa0\xbc\xe6\x90\x9c\xe7\xb4\xa2\xe5\xbf\xab\xe9\x80\x9f\xe6\x89\xbe\xe5\x88\xb0\xe6\x9c\x80\xe4\xbc\x98\xe6\xa8\xa1\xe5\x9e\x8b\xe5\x8f\x82\xe6\x95\xb0](http://www.shareditor.com/blogshow/?blogId=60)(2016-06-02)\n * [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x95\x99\xe7\xa8\x8b \xe5\x8d\x81\xe4\xb8\x80-\xe7\x94\xa8scikit-learn\xe5\x81\x9a\xe8\x81\x9a\xe7\xb1\xbb\xe5\x88\x86\xe6\x9e\x90](http://www.shareditor.com/blogshow/?blogId=61)(2016-06-03)\n * [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x95\x99\xe7\xa8\x8b \xe5\x8d\x81\xe4\xba\x8c-\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe5\x8e\x9f\xe7\x90\x86](http://www.shareditor.com/blogshow/?blogId=91)(2016-07-29)\n * [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x95\x99\xe7\xa8\x8b \xe5\x8d\x81\xe4\xb8\x89-\xe7\x94\xa8scikit-learn\xe5\x81\x9a\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92](http://www.shareditor.com/blogshow/?blogId=93)(2016-08-03)\n * [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x95\x99\xe7\xa8\x8b \xe5\x8d\x81\xe5\x9b\x9b-\xe5\x88\xa9\xe7\x94\xa8tensorflow\xe5\x81\x9a\xe6\x89\x8b\xe5\x86\x99\xe6\x95\xb0\xe5\xad\x97\xe8\xaf\x86\xe5\x88\xab](http://www.shareditor.com/blogshow/?blogId=94)(2016-08-03)\n * [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x95\x99\xe7\xa8\x8b \xe5\x8d\x81\xe4\xba\x94-\xe7\xbb\x86\xe8\xa7\xa3\xe5\x8d\xb7\xe7\xa7\xaf\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c](http://www.shareditor.com/blogshow/?blogId=95)(2016-08-06)\n * [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x95\x99\xe7\xa8\x8b \xe5\x8d\x81\xe5\x85\xad-\xe6\xb7\xb1\xe7\xa9\xb6\xe7\x86\xb5\xe7\x9a\x84\xe6\xa6\x82\xe5\xbf\xb5\xe5\x92\x8c\xe5\x85\xac\xe5\xbc\x8f\xe4\xbb\xa5\xe5\x8f\x8a\xe6\x9c\x80\xe5\xa4\xa7\xe7\x86\xb5\xe5\x8e\x9f\xe7\x90\x86](http://www.shareditor.com/blogshow/?blogId=98)(2016-08-17)\n * [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x95\x99\xe7\xa8\x8b \xe5\x8d\x81\xe4\xb8\x83-\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92\xe5\x85\xac\xe5\xbc\x8f\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\xa6\xe6\x8e\xa8\xe5\xaf\xbc](http://www.shareditor.com/blogshow/?blogId=102)(2016-08-24)\n * [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x95\x99\xe7\xa8\x8b \xe5\x8d\x81\xe5\x85\xab-R\xe8\xaf\xad\xe8\xa8\x80\xe7\x89\xb9\xe5\xbe\x81\xe5\xb7\xa5\xe7\xa8\x8b\xe5\xae\x9e\xe6\x88\x98](http://www.shareditor.com/blogshow/?blogId=106)(2016-09-01)\n * [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x95\x99\xe7\xa8\x8b \xe5\x8d\x81\xe4\xb9\x9d-\xe7\x9c\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\xa7\x91\xe5\xad\xa6\xe5\xae\xb6\xe6\x98\xaf\xe5\xa6\x82\xe4\xbd\x95\xe6\x89\xbe\xe5\x9b\x9e\xe4\xb8\xa2\xe5\xa4\xb1\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xef\xbc\x88\xe4\xb8\x80\xef\xbc\x89](http://www.shareditor.com/blogshow/?blogId=107)(2016-09-03)\n * [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x95\x99\xe7\xa8\x8b \xe4\xba\x8c\xe5\x8d\x81-\xe7\x9c\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\xa7\x91\xe5\xad\xa6\xe5\xae\xb6\xe6\x98\xaf\xe5\xa6\x82\xe4\xbd\x95\xe6\x89\xbe\xe5\x9b\x9e\xe4\xb8\xa2\xe5\xa4\xb1\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xef\xbc\x88\xe4\xba\x8c\xef\xbc\x89](http://www.shareditor.com/blogshow/?blogId=108)(2016-09-03)\n * [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x95\x99\xe7\xa8\x8b \xe4\xba\x8c\xe5\x8d\x81\xe4\xb8\x80-R\xe8\xaf\xad\xe8\xa8\x80\xe7\x82\xab\xe6\x8a\x80\xe5\xbf\x85\xe5\xa4\x87\xe5\x9f\xba\xe6\x9c\xac\xe5\x8a\x9f](http://www.shareditor.com/blogshow/?blogId=109)(2016-09-06)\n * [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x95\x99\xe7\xa8\x8b \xe4\xba\x8c\xe5\x8d\x81\xe4\xba\x8c-\xe4\xb8\x80\xe5\xb0\x8f\xe6\x97\xb6\xe6\x8e\x8c\xe6\x8f\xa1R\xe8\xaf\xad\xe8\xa8\x80\xe6\x95\xb0\xe6\x8d\xae\xe5\x8f\xaf\xe8\xa7\x86\xe5\x8c\x96](http://www.shareditor.com/blogshow/?blogId=110)(2016-09-13)\n * [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x95\x99\xe7\xa8\x8b \xe4\xba\x8c\xe5\x8d\x81\xe4\xb8\x89-R\xe8\xaf\xad\xe8\xa8\x80\xe5\xbc\xba\xe5\xa4\xa7\xe5\xb7\xa5\xe5\x85\xb7\xe5\x8c\x85ggplot\xe7\xbb\x98\xe5\x9b\xbe\xe4\xbb\xa5\xe5\xa4\x96\xe7\x9a\x84\xe9\x82\xa3\xe4\xba\x9b\xe4\xba\x8b](http://www.shareditor.com/blogshow/?blogId=111)(2016-09-13)\n * [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x95\x99\xe7\xa8\x8b \xe4\xba\x8c\xe5\x8d\x81\xe5\x9b\x9b-[\xe5\x90\x90\xe8\xa1\x80\xe6\x95\xb4\xe7\x90\x86]\xe6\xb6\x89\xe5\x8f\x8a\xe9\x9d\xa2\xe6\x9c\x80\xe5\xb9\xbf\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xb5\x84\xe6\x96\x99\xe5\xa4\xa7\xe5\x85\xa8](http://www.shareditor.com/blogshow/?blogId=123)(2017-02-16)\n'"
53,dotnet/machinelearning,dotnet,ML.NET is an open source and cross-platform machine learning framework for .NET.,2018-05-03 16:20:42,2020-06-18 19:34:34,C#,1514,6961,"b'# Machine Learning for .NET\n\n[ML.NET](https://www.microsoft.com/net/learn/apps/machine-learning-and-ai/ml-dotnet) is a cross-platform open-source machine learning framework which makes machine learning accessible to .NET developers with the same code that powers machine learning across many Microsoft products, including Power BI, Windows Defender, and Azure. \n\nML.NET allows .NET developers to develop/train their own models and infuse custom machine learning into their applications using .NET, even without prior expertise in developing or tuning machine learning models. It provides data loading from files and databases, enables data transformations and includes many ML algorithms.\n\nML.NET enables machine learning (ML) tasks like classification (for example, text classification, sentiment analysis), regression (for example, price prediction), and many other ML tasks such as anomaly detection, time-series-forecast, clustering, ranking, etc.\n\n## Getting started with machine learning by using ML.NET\n\nIf you are new to machine learning, start by learning the basics from this collection of resources targeting ML.NET:\n\n[Learn ML.NET](https://dotnet.microsoft.com/learn/ml-dotnet)\n\n## ML.NET Documentation, tutorials and reference\n\nPlease check our [documentation and tutorials](https://docs.microsoft.com/en-us/dotnet/machine-learning/). \n\nSee the [API Reference documentation](https://docs.microsoft.com/en-us/dotnet/api/?view=ml-dotnet).\n\n## Sample apps\n\nWe have a GitHub repo with [ML.NET sample apps](https://github.com/dotnet/machinelearning-samples) with many scenarios such as Sentiment analysis, Fraud detection, Product Recommender, Price Prediction, Anomaly Detection, Image Classification, Object Detection and many more. \n\nIn addition to the ML.NET samples provided by Microsoft, we\'re also highlighting many more samples created by the community showcased in this separate page [ML.NET Community Samples](https://github.com/dotnet/machinelearning-samples/blob/master/docs/COMMUNITY-SAMPLES.md)\n\n\n## ML.NET videos playlist at YouTube\n\nThe [ML.NET videos playlist](https://aka.ms/mlnetyoutube) on YouTube contains several short videos. Each video focuses on a particular topic of ML.NET.\n\n## Operating systems and processor architectures supported by ML.NET\n\nML.NET runs on Windows, Linux, and macOS using [.NET Core](https://github.com/dotnet/core), or Windows using .NET Framework. \n\n64 bit is supported on all platforms. 32 bit is supported on Windows, except for TensorFlow and LightGBM related functionality.\n\n## ML.NET Nuget packages status\n\n[![NuGet Status](https://img.shields.io/nuget/vpre/Microsoft.ML.svg?style=flat)](https://www.nuget.org/packages/Microsoft.ML/)\n\n## Release notes\n\nCheck out the [release notes](docs/release-notes) to see what\'s new.\n\n## Using ML.NET packages\n\nFirst, ensure you have installed [.NET Core 2.1](https://www.microsoft.com/net/learn/get-started) or later. ML.NET also works on the .NET Framework 4.6.1 or later, but 4.7.2 or later is recommended.\n\nOnce you have an app, you can install the ML.NET NuGet package from the .NET Core CLI using:\n```\ndotnet add package Microsoft.ML\n```\n\nor from the NuGet package manager:\n```\nInstall-Package Microsoft.ML\n```\n\nAlternatively, you can add the Microsoft.ML package from within Visual Studio\'s NuGet package manager or via [Paket](https://github.com/fsprojects/Paket).\n\nDaily NuGet builds of the project are also available in our Azure DevOps feed:\n\n> [https://pkgs.dev.azure.com/dnceng/public/_packaging/MachineLearning/nuget/v3/index.json](https://pkgs.dev.azure.com/dnceng/public/_packaging/MachineLearning/nuget/v3/index.json)\n\n## Building ML.NET (For contributors building ML.NET open source code)\n\nTo build ML.NET from source please visit our [developers guide](docs/project-docs/developer-guide.md).\n\n[![codecov](https://codecov.io/gh/dotnet/machinelearning/branch/master/graph/badge.svg?flag=production)](https://codecov.io/gh/dotnet/machinelearning)\n\n|    | Debug | Release |\n|:---|----------------:|------------------:|\n|**CentOS**|[![Build Status](https://dev.azure.com/dnceng/public/_apis/build/status/dotnet/machinelearning/MachineLearning-CI?branchName=master&jobName=Centos_x64_NetCoreApp31&configuration=Centos_x64_NetCoreApp31%20Debug_Build)](https://dev.azure.com/dnceng/public/_build/latest?definitionId=104&branchName=master)|[![Build Status](https://dev.azure.com/dnceng/public/_apis/build/status/dotnet/machinelearning/MachineLearning-CI?branchName=master&jobName=Centos_x64_NetCoreApp31&configuration=Centos_x64_NetCoreApp31%20Release_Build)](https://dev.azure.com/dnceng/public/_build/latest?definitionId=104&branchName=master)|\n|**Ubuntu**|[![Build Status](https://dev.azure.com/dnceng/public/_apis/build/status/dotnet/machinelearning/MachineLearning-CI?branchName=master&jobName=Ubuntu_x64_NetCoreApp21&configuration=Ubuntu_x64_NetCoreApp21%20Debug_Build)](https://dev.azure.com/dnceng/public/_build/latest?definitionId=104&branchName=master)|[![Build Status](https://dev.azure.com/dnceng/public/_apis/build/status/dotnet/machinelearning/MachineLearning-CI?branchName=master&jobName=Ubuntu_x64_NetCoreApp21&configuration=Ubuntu_x64_NetCoreApp21%20Release_Build)](https://dev.azure.com/dnceng/public/_build/latest?definitionId=104&branchName=master)|\n|**macOS**|[![Build Status](https://dev.azure.com/dnceng/public/_apis/build/status/dotnet/machinelearning/MachineLearning-CI?branchName=master&jobName=MacOS_x64_NetCoreApp21&configuration=MacOS_x64_NetCoreApp21%20Debug_Build)](https://dev.azure.com/dnceng/public/_build/latest?definitionId=104&branchName=master)|[![Build Status](https://dev.azure.com/dnceng/public/_apis/build/status/dotnet/machinelearning/MachineLearning-CI?branchName=master&jobName=MacOS_x64_NetCoreApp21&configuration=MacOS_x64_NetCoreApp21%20Release_Build)](https://dev.azure.com/dnceng/public/_build/latest?definitionId=104&branchName=master)|\n|**Windows x64**|[![Build Status](https://dev.azure.com/dnceng/public/_apis/build/status/dotnet/machinelearning/MachineLearning-CI?branchName=master&jobName=Windows_x64_NetCoreApp21&configuration=Windows_x64_NetCoreApp21%20Debug_Build)](https://dev.azure.com/dnceng/public/_build/latest?definitionId=104&branchName=master)|[![Build Status](https://dev.azure.com/dnceng/public/_apis/build/status/dotnet/machinelearning/MachineLearning-CI?branchName=master&jobName=Windows_x64_NetCoreApp21&configuration=Windows_x64_NetCoreApp21%20Release_Build)](https://dev.azure.com/dnceng/public/_build/latest?definitionId=104&branchName=master)|\n|**Windows FullFramework**|[![Build Status](https://dev.azure.com/dnceng/public/_apis/build/status/dotnet/machinelearning/MachineLearning-CI?branchName=master&jobName=Windows_x64_NetFx461&configuration=Windows_x64_NetFx461%20Debug_Build)](https://dev.azure.com/dnceng/public/_build/latest?definitionId=104&branchName=master)|[![Build Status](https://dev.azure.com/dnceng/public/_apis/build/status/dotnet/machinelearning/MachineLearning-CI?branchName=master&jobName=Windows_x64_NetFx461&configuration=Windows_x64_NetFx461%20Release_Build)](https://dev.azure.com/dnceng/public/_build/latest?definitionId=104&branchName=master)|\n|**Windows x86**|[![Build Status](https://dev.azure.com/dnceng/public/_apis/build/status/dotnet/machinelearning/MachineLearning-CI?branchName=master&jobName=Windows_x86_NetCoreApp21&configuration=Windows_x86_NetCoreApp21%20Debug_Build)](https://dev.azure.com/dnceng/public/_build/latest?definitionId=104&branchName=master)|[![Build Status](https://dev.azure.com/dnceng/public/_apis/build/status/dotnet/machinelearning/MachineLearning-CI?branchName=master&jobName=Windows_x86_NetCoreApp21&configuration=Windows_x86_NetCoreApp21%20Release_Build)](https://dev.azure.com/dnceng/public/_build/latest?definitionId=104&branchName=master)|\n|**Windows NetCore3.1**|[![Build Status](https://dev.azure.com/dnceng/public/_apis/build/status/dotnet/machinelearning/MachineLearning-CI?branchName=master&jobName=Windows_x64_NetCoreApp31&configuration=Windows_x64_NetCoreApp31%20Debug_Build)](https://dev.azure.com/dnceng/public/_build/latest?definitionId=104&branchName=master)|[![Build Status](https://dev.azure.com/dnceng/public/_apis/build/status/dotnet/machinelearning/MachineLearning-CI?branchName=master&jobName=Windows_x64_NetCoreApp31&configuration=Windows_x64_NetCoreApp31%20Release_Build)](https://dev.azure.com/dnceng/public/_build/latest?definitionId=104&branchName=master)|\n\n## Release process and versioning\n\nCheck out the [release process documentation](docs/release-notes) to understand the different kinds of ML.NET releases.\n\n## Contributing\n\nWe welcome contributions! Please review our [contribution guide](CONTRIBUTING.md).\n\n## Community\n\nPlease join our community on Gitter [![Join the chat at https://gitter.im/dotnet/mlnet](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/dotnet/mlnet?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\nThis project has adopted the code of conduct defined by the [Contributor Covenant](https://contributor-covenant.org/) to clarify expected behavior in our community.\nFor more information, see the [.NET Foundation Code of Conduct](https://dotnetfoundation.org/code-of-conduct).\n\n\n## Code examples\n\nHere is a snippet code for training a model to predict sentiment from text samples. You can find complete samples in [samples repo](https://github.com/dotnet/machinelearning-samples).\n\n```C#\nvar dataPath = ""sentiment.csv"";\nvar mlContext = new MLContext();\nvar loader = mlContext.Data.CreateTextLoader(new[]\n    {\n        new TextLoader.Column(""SentimentText"", DataKind.String, 1),\n        new TextLoader.Column(""Label"", DataKind.Boolean, 0),\n    },\n    hasHeader: true,\n    separatorChar: \',\');\nvar data = loader.Load(dataPath);\nvar learningPipeline = mlContext.Transforms.Text.FeaturizeText(""Features"", ""SentimentText"")\n        .Append(mlContext.BinaryClassification.Trainers.FastTree());\nvar model = learningPipeline.Fit(data);\n```\n\nNow from the model we can make inferences (predictions):\n\n```C#\nvar predictionEngine = mlContext.Model.CreatePredictionEngine<SentimentData, SentimentPrediction>(model);\nvar prediction = predictionEngine.Predict(new SentimentData\n{\n    SentimentText = ""Today is a great day!""\n});\nConsole.WriteLine(""prediction: "" + prediction.Prediction);\n```\nA cookbook that shows how to use these APIs for a variety of existing and new scenarios can be found [here](docs/code/MlNetCookBook.md).\n\n## License\n\nML.NET is licensed under the [MIT license](LICENSE) and it is free to use commercially.\n\n## .NET Foundation\n\nML.NET is a [.NET Foundation](https://www.dotnetfoundation.org/projects) project.\n\nThere are many .NET related projects on GitHub.\n\n- [.NET home repo](https://github.com/Microsoft/dotnet)\xc2\xa0- links to 100s of .NET projects, from Microsoft and the community.\n'"
54,fengdu78/machine_learning_beginner,fengdu78,机器学习初学者公众号作品,2019-01-09 08:15:12,2020-06-18 15:04:52,Jupyter Notebook,617,1265,"b'# \xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x88\x9d\xe5\xad\xa6\xe8\x80\x85\xe5\x85\xac\xe4\xbc\x97\xe5\x8f\xb7\n\n![\xe5\x85\xac\xe4\xbc\x97\xe5\x8f\xb7](images/gongzhong.jpg)\n\n\xe6\x9c\xac\xe4\xbb\x93\xe5\xba\x93\xe6\x98\xaf\xe2\x80\x9c\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x88\x9d\xe5\xad\xa6\xe8\x80\x85\xe2\x80\x9d\xe5\x85\xac\xe4\xbc\x97\xe5\x8f\xb7\xe5\x8f\x91\xe5\xb8\x83\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9\xe4\xbb\xa3\xe7\xa0\x81\xe3\x80\x82\n\n\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0qq\xe7\xbe\xa4\xef\xbc\x9a659697409\xef\xbc\x88\xe6\x88\x91\xe4\xbb\xac\xe6\x9c\x899\xe4\xb8\xaa\xe7\xbe\xa4\xef\xbc\x8c\xe5\x8a\xa0\xe8\xbf\x87\xe4\xb8\x80\xe4\xb8\xaa\xe5\xb0\xb1\xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xe5\x8a\xa0\xe4\xba\x86\xef\xbc\x89\n\n## \xe8\xbf\x99\xe4\xb8\xaa\xe4\xbb\x93\xe5\xba\x93\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9\xe7\x9b\xae\xe5\xbd\x95\n\n#### 2019\xe5\xb9\xb4\xe7\xb2\xbe\xe9\x80\x89\xe6\x96\x87\xe7\xab\xa0\n\n[2019](2019/)\n\n#### AI\xe5\x9f\xba\xe7\xa1\x80\n\n[AI_beginner](AI_beginner/)\n\n#### \xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe5\x86\x85\xe5\xae\xb9\n\n- 1.[PyTorch60\xe5\x88\x86\xe9\x92\x9f\xe5\x85\xa5\xe9\x97\xa8\xef\xbc\x88\xe4\xb8\xad\xe6\x96\x87\xe7\xbf\xbb\xe8\xaf\x91\xef\xbc\x89](PyTorch_beginner/)\xef\xbc\x88\xe7\x9b\xae\xe5\xbd\x95\xe5\x90\x8d\xef\xbc\x9aPyTorch_beginner\xef\xbc\x89\n- 2.[Python\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe5\x8e\x9f\xe4\xb9\xa6\xe4\xbb\xa3\xe7\xa0\x81\xe4\xb8\xad\xe6\x96\x87\xe7\xbf\xbb\xe8\xaf\x91](deep-learning-with-python-notebooks/)\xef\xbc\x88\xe7\x9b\xae\xe5\xbd\x95\xe5\x90\x8d\xef\xbc\x9adeep-learning-with-python-notebooks\xef\xbc\x89\n- 3.[\xe5\xbc\xba\xe7\x83\x88\xe6\x8e\xa8\xe8\x8d\x90\xe7\x9a\x84TensorFlow\xe3\x80\x81Pytorch\xe5\x92\x8cKeras\xe7\x9a\x84\xe6\xa0\xb7\xe4\xbe\x8b\xe8\xb5\x84\xe6\xba\x90](deep-learning-with-tensorflow-keras-pytorch/)\xef\xbc\x88\xe7\x9b\xae\xe5\xbd\x95\xe5\x90\x8d\xef\xbc\x9adeep-learning-with-tensorflow-keras-pytorch\xef\xbc\x89\n\n#### Python\xe5\x9f\xba\xe7\xa1\x80\n\n- 1.[\xe4\xb8\xa4\xe5\xa4\xa9\xe5\x85\xa5\xe9\x97\xa8Python](python-start/)(\xe7\x9b\xae\xe5\xbd\x95\xe5\x90\x8d\xef\xbc\x9apython-start)\n- 2.[\xe9\x80\x82\xe5\x90\x88\xe5\x88\x9d\xe5\xad\xa6\xe8\x80\x85\xe5\xbf\xab\xe9\x80\x9f\xe5\x85\xa5\xe9\x97\xa8\xe7\x9a\x84Numpy\xe5\xae\x9e\xe6\x88\x98\xe5\x85\xa8\xe9\x9b\x86](numpy/)(\xe7\x9b\xae\xe5\xbd\x95\xe5\x90\x8d\xef\xbc\x9anumpy)\n- 3.[matplotlib\xe5\xad\xa6\xe4\xb9\xa0\xe4\xb9\x8b\xe5\x9f\xba\xe6\x9c\xac\xe4\xbd\xbf\xe7\x94\xa8](matplotlib/)(\xe7\x9b\xae\xe5\xbd\x95\xe5\x90\x8d\xef\xbc\x9amatplotlib)\n- 4.[Sklearn\xe5\x85\xa5\xe9\x97\xa8\xe7\xbb\x8f\xe5\x85\xb8\xe6\xa1\x88\xe4\xbe\x8b](pyparis-2018-sklearn/)(\xe7\x9b\xae\xe5\xbd\x95\xe5\x90\x8d\xef\xbc\x9apyparis-2018-sklearn)\n- 5.[\xe4\xb8\xa4\xe5\xa4\xa9\xe5\xad\xa6\xe4\xbc\x9apandas](pandas/)(\xe7\x9b\xae\xe5\xbd\x95\xe5\x90\x8d\xef\xbc\x9apandas)\n\n\n\n## \xe6\x9c\xac\xe7\xab\x99\xe7\x9a\x84\xe5\x85\xb6\xe4\xbb\x96\xe5\xbc\x80\xe6\xba\x90\xe4\xbb\x93\xe5\xba\x93\n\n#### \xe6\x9c\xac\xe4\xba\xba\xe6\x95\xb4\xe7\x90\x86\n\n- 1.[\xe5\x90\xb4\xe6\x81\xa9\xe8\xbe\xbe\xe8\x80\x81\xe5\xb8\x88\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xaf\xbe\xe7\xa8\x8b\xe4\xb8\xaa\xe4\xba\xba\xe7\xac\x94\xe8\xae\xb0](https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes)\n\n- 2.[deeplearning.ai\xef\xbc\x88\xe5\x90\xb4\xe6\x81\xa9\xe8\xbe\xbe\xe8\x80\x81\xe5\xb8\x88\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe8\xaf\xbe\xe7\xa8\x8b\xe7\xac\x94\xe8\xae\xb0\xe5\x8f\x8a\xe8\xb5\x84\xe6\xba\x90\xef\xbc\x89](https://github.com/fengdu78/deeplearning_ai_books)\n\n- 3.[\xe3\x80\x8a\xe7\xbb\x9f\xe8\xae\xa1\xe5\xad\xa6\xe4\xb9\xa0\xe6\x96\xb9\xe6\xb3\x95\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81\xe5\xae\x9e\xe7\x8e\xb0\xe3\x80\x8b](https://github.com/fengdu78/lihang-code)\n\n\n#### \xe5\xa4\xa7\xe7\xa5\x9e\xe4\xb9\x8b\xe4\xbd\x9c\n\n- 1.[\xe5\xbe\x90\xe4\xba\xa6\xe8\xbe\xbe\xe8\x80\x81\xe5\xb8\x88\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xb5\x84\xe6\x96\x99\xe5\x88\x86\xe4\xba\xab](https://github.com/roboticcam/machine-learning-notes)\n- 2.[\xe5\x8d\x8e\xe6\xa0\xa1\xe4\xb8\x93\xe8\x80\x81\xe5\xb8\x88\xe7\x9a\x84\xe7\xac\x94\xe8\xae\xb0\xe5\x88\x86\xe4\xba\xab](http://www.huaxiaozhuan.com/)\n- 3.[LFD\xe4\xb9\xa0\xe9\xa2\x98\xe8\xa7\xa3\xe7\xad\x94\xef\xbc\x88\xe6\x9e\x97\xe8\xbd\xa9\xe7\x94\xb0\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xaf\xbe\xe7\xa8\x8b\xe5\x86\x85\xe5\xae\xb9\xef\xbc\x89\xef\xbc\x88\xe4\xbd\x9c\xe8\x80\x85\xe7\xa7\xa6\xe8\x87\xbb\xef\xbc\x89](https://github.com/Doraemonzzz/Learning-from-data)\n\n\n\n> \xe4\xbb\xa5\xe4\xb8\x8b\xe4\xb8\xba\xe6\x98\xaf\xe5\x85\xac\xe4\xbc\x97\xe5\x8f\xb7\xe5\x88\x9b\xe7\xab\x8b\xe4\xbb\xa5\xe6\x9d\xa5\xe7\x9a\x84\xe7\xb2\xbe\xe9\x80\x89\xe5\x8e\x9f\xe5\x88\x9b\xe6\x96\x87\xe7\xab\xa0\xef\xbc\x8c\xe9\x80\x82\xe5\x90\x88\xe5\x88\x9d\xe5\xad\xa6\xe8\x80\x85\xe5\x85\xa5\xe9\x97\xa8 AI\xe3\x80\x82\xe6\x9c\xac\xe6\x96\x87\xe5\xbb\xba\xe8\xae\xae\xe7\x94\xa8\xe5\xbe\xae\xe4\xbf\xa1\xe6\x94\xb6\xe8\x97\x8f\xe7\x94\xa8\xe7\xa2\x8e\xe7\x89\x87\xe6\x97\xb6\xe9\x97\xb4\xe5\xad\xa6\xe4\xb9\xa0\xe3\x80\x82\xef\xbc\x88\xe9\xbb\x84\xe6\xb5\xb7\xe5\xb9\xbf\xef\xbc\x89\n\n## \xe4\xb8\x80\xe3\x80\x81\xe5\x89\x8d\xe8\xa8\x80\n\nAI \xe5\x88\x9d\xe5\xad\xa6\xe8\x80\x85\xe6\x9c\x80\xe5\xa4\xa7\xe7\x9a\x84\xe9\x97\xae\xe9\xa2\x98\xe5\xb0\xb1\xe6\x98\xaf\xef\xbc\x9a\n\n**\xe8\xb5\x84\xe6\x96\x99\xe5\xa4\xaa\xe5\xa4\x9a\xef\xbc\x81\xe7\x9c\x8b\xe4\xb8\x8d\xe5\xae\x8c\xef\xbc\x81\xef\xbc\x81\xe4\xb8\x8d\xe7\x9f\xa5\xe9\x81\x93\xe5\xa6\x82\xe4\xbd\x95\xe5\x8f\x96\xe8\x88\x8d\xef\xbc\x81\xef\xbc\x81**\n\n\xe6\x88\x91\xe6\x8a\x8a \xe5\x85\xac\xe4\xbc\x97\xe5\x8f\xb7\xe5\x88\x9b\xe5\x8a\x9e\xe4\xbb\xa5\xe6\x9d\xa5\xe7\x9a\x84\xe5\x8e\x9f\xe5\x88\x9b\xe6\x96\x87\xe7\xab\xa0\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x95\xb4\xe7\x90\x86\xef\xbc\x8c\xe6\x96\x87\xe7\xab\xa0\xe9\x80\x82\xe5\x90\x88**\xe6\x9c\xac\xe7\xa7\x91\xe3\x80\x81\xe7\xa1\x95\xe5\xa3\xab\xe4\xbb\xa5\xe5\x8f\x8a\xe5\x88\x9a\xe6\x8e\xa5\xe8\xa7\xa6\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9a\x84\xe5\x8d\x9a\xe5\xa3\xab**\xe3\x80\x82\n\n\xe5\xad\xa6\xe5\xae\x8c\xe8\xbf\x99\xe4\xba\x9b\xe6\x96\x87\xe7\xab\xa0\xe5\xad\xa6\xe5\xae\x8c\xe4\xbb\xa5\xe5\x90\x8e\xef\xbc\x8c\xe5\xb0\xb1\xe5\x9f\xba\xe6\x9c\xac\xe5\x85\xa5\xe9\x97\xa8\xe4\xba\x86\xe3\x80\x82\n\n\xe5\x85\xa5\xe9\x97\xa8\xe4\xbb\xa5\xe5\x90\x8e\xef\xbc\x8c\xe9\x81\x87\xe5\x88\xb0\xe9\x97\xae\xe9\xa2\x98\xe8\x83\xbd\xe4\xb8\x8a\xe7\xbd\x91\xe6\x90\x9c\xe7\xb4\xa2\xe8\xa7\xa3\xe5\x86\xb3\xe4\xba\x86\xef\xbc\x8c\xe4\xb9\x9f\xe7\x9f\xa5\xe9\x81\x93\xe6\x8e\xa5\xe4\xb8\x8b\xe6\x9d\xa5\xe5\xba\x94\xe8\xaf\xa5\xe5\xad\xa6\xe4\xbb\x80\xe4\xb9\x88\xe3\x80\x82\n\n\xe6\x9c\xac\xe6\x96\x87\xe5\xbb\xba\xe8\xae\xae\xe7\x94\xa8\xe5\xbe\xae\xe4\xbf\xa1\xe6\x94\xb6\xe8\x97\x8f\xef\xbc\x8c\xe5\x88\xa9\xe7\x94\xa8\xe7\xa2\x8e\xe7\x89\x87\xe6\x97\xb6\xe9\x97\xb4\xe5\xad\xa6\xe4\xb9\xa0\xe3\x80\x82\n\n#### \xe4\xbd\x9c\xe8\x80\x85\xe7\xae\x80\xe4\xbb\x8b\xef\xbc\x9a\n\n[\xe9\x82\xa3\xe4\xba\x9b\xe5\xb9\xb4\xe5\x81\x9a\xe7\x9a\x84\xe5\xad\xa6\xe6\x9c\xaf\xe5\x85\xac\xe7\x9b\x8a-\xe4\xbd\xa0\xe4\xb8\x8d\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe4\xba\xba\xe5\x9c\xa8\xe6\x88\x98\xe6\x96\x97](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484487&idx=1&sn=1df61f5f1ae6838f2eef1f4a3c702733&chksm=97048ffba07306edb4e816f8fc6ef8bdeb33ed644e68b4353649697fa0c11044f26c3bf788e8&scene=21#wechat_redirect)\n\n## \xe4\xba\x8c\xe3\x80\x81\xe5\xad\xa6\xe4\xb9\xa0\xe8\xb7\xaf\xe7\xba\xbf\n\n- [\xe9\xa6\x96\xe5\x8f\x91\xef\xbc\x9a](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484737&idx=1&sn=27c52b4bc4ca98d3ab817344b84226cc&chksm=97048efda07307eb78d4f4ec0039a386a658404156b051af0cb715fafa8d2ae66cbe49343bf3&scene=21#wechat_redirect)[\xe9\x80\x82\xe5\x90\x88\xe5\x88\x9d\xe5\xad\xa6\xe8\x80\x85\xe5\x85\xa5\xe9\x97\xa8\xe4\xba\xba\xe5\xb7\xa5\xe6\x99\xba\xe8\x83\xbd\xe7\x9a\x84\xe8\xb7\xaf\xe7\xba\xbf\xe5\x8f\x8a\xe8\xb5\x84\xe6\x96\x99\xe4\xb8\x8b\xe8\xbd\xbd](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484737&idx=1&sn=27c52b4bc4ca98d3ab817344b84226cc&chksm=97048efda07307eb78d4f4ec0039a386a658404156b051af0cb715fafa8d2ae66cbe49343bf3&scene=21#wechat_redirect)\n\n\xe8\xbf\x99\xe7\xaf\x87\xe6\x96\x87\xe7\xab\xa0\xe4\xb8\xba\xe5\x88\x9d\xe5\xad\xa6\xe8\x80\x85\xe6\x8f\x90\xe4\xbe\x9b\xe4\xba\x86\xe5\x85\xa5\xe9\x97\xa8\xe7\x9a\x84\xe8\xb7\xaf\xe7\xba\xbf\xe3\x80\x82\xe5\x8c\x85\xe5\x90\xab\xe6\x95\xb0\xe5\xad\xa6\xe5\x9f\xba\xe7\xa1\x80\xe3\x80\x81python \xe5\x85\xa5\xe9\x97\xa8\xe3\x80\x81\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe3\x80\x81\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe3\x80\x81\xe7\x89\xb9\xe5\xbe\x81\xe5\xb7\xa5\xe7\xa8\x8b\xe5\x85\xa5\xe9\x97\xa8\xe7\xad\x89\xe3\x80\x82\xe5\xb9\xb6\xe6\x8a\x8a\xe4\xbb\xa3\xe7\xa0\x81\xe6\x94\xbe\xe5\x9c\xa8\xe4\xba\x86 github \xe4\xbb\x93\xe5\xba\x93\xef\xbc\x9a\n\nhttps://github.com/fengdu78/Data-Science-Notes\n\n- [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x9c\xa8\xe7\xba\xbf\xe6\x89\x8b\xe5\x86\x8c\xef\xbc\x9a](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247486187&idx=1&sn=3c86ade48695ce102e93fa813c55f126&chksm=97048157a07308419d900bec1ff4699092c62c7ed331a334734a4225db0b2274a7b134153037&scene=21#wechat_redirect)[\xe5\x83\x8f\xe8\x83\x8c\xe6\x89\x98\xe7\xa6\x8f\xe5\x8d\x95\xe8\xaf\x8d\xe4\xb8\x80\xe6\xa0\xb7\xe5\xad\xa6\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247486187&idx=1&sn=3c86ade48695ce102e93fa813c55f126&chksm=97048157a07308419d900bec1ff4699092c62c7ed331a334734a4225db0b2274a7b134153037&scene=21#wechat_redirect)\n\n\xe8\xbf\x99\xe7\xaf\x87\xe6\x96\x87\xe7\xab\xa0\xe5\xb0\x86\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9a\x84\xe7\xb2\xbe\xe5\x8d\x8e\xe9\x83\xa8\xe5\x88\x86\xe5\x81\x9a\xe6\x88\x90\xe4\xba\x86\xe6\x89\x8b\xe5\x86\x8c\xef\xbc\x8c\xe6\x89\x93\xe5\xbc\x80\xe5\xbe\xae\xe4\xbf\xa1\xe5\xb0\xb1\xe8\x83\xbd\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x8c\xe9\x80\x82\xe5\x90\x88\xe5\xb9\xb3\xe6\x97\xb6\xe6\x97\xb6\xe9\x97\xb4\xe5\xb0\x91\xe7\x9a\x84\xe6\x9c\x8b\xe5\x8f\x8b\xe5\xad\xa6\xe4\xb9\xa0\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe5\x9c\xa8\xe9\x80\x9a\xe5\x8b\xa4\xe7\x9a\x84\xe6\x97\xb6\xe5\x80\x99\xe5\x9c\xa8\xe6\x89\x8b\xe6\x9c\xba\xe4\xb8\x8a\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x8c\xe5\xbb\xba\xe8\xae\xae\xe6\x94\xb6\xe8\x97\x8f\xe6\x9c\xac\xe6\x96\x87\xe6\x85\xa2\xe6\x85\xa2\xe5\xad\xa6\xe4\xb9\xa0\n\n## \xe4\xb8\x89\xe3\x80\x81\xe5\x9f\xba\xe7\xa1\x80\xe7\x9f\xa5\xe8\xaf\x86\n\n- [\xe5\xb8\xa6\xe4\xbd\xa0\xe5\xb0\x91\xe8\xb5\xb0\xe5\xbc\xaf\xe8\xb7\xaf\xef\xbc\x81](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247485787&idx=1&sn=d53e991935fc6def2919b2bed6111f8d&chksm=970482e7a0730bf17c9fc7f5a639a21331be477af74b039ec56c0a4eaf0220259733d9852684&scene=21#wechat_redirect)[\xef\xbc\x81](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247485787&idx=1&sn=d53e991935fc6def2919b2bed6111f8d&chksm=970482e7a0730bf17c9fc7f5a639a21331be477af74b039ec56c0a4eaf0220259733d9852684&scene=21#wechat_redirect)[\xe9\xbb\x84\xe5\x8d\x9a\xe6\x95\xb4\xe7\x90\x86\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x95\xb0\xe5\xad\xa6\xe5\x9f\xba\xe7\xa1\x80\xe8\xb5\x84\xe6\x96\x99\xe6\x9d\xa5\xe5\xb8\xae\xe4\xbd\xa0\xef\xbc\x88\xe5\x8f\xaf\xe5\x9c\xa8\xe7\xba\xbf\xe9\x98\x85\xe8\xaf\xbb\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247485787&idx=1&sn=d53e991935fc6def2919b2bed6111f8d&chksm=970482e7a0730bf17c9fc7f5a639a21331be477af74b039ec56c0a4eaf0220259733d9852684&scene=21#wechat_redirect)\n\n\xe4\xb8\x8a\xe9\x9d\xa2\xe8\xbf\x99\xe7\xaf\x87\xe6\x96\x87\xe7\xab\xa0\xe6\x98\xaf\xe6\x95\xb0\xe5\xad\xa6\xe5\x9f\xba\xe7\xa1\x80\xef\xbc\x8c\xe4\xb9\x9f\xe6\x98\xaf\xe4\xbb\xa5\xe4\xb8\x8b\xe4\xba\x94\xe7\xaf\x87\xe6\x96\x87\xe7\xab\xa0\xe7\x9a\x84\xe6\x95\xb4\xe5\x90\x88\xe7\x89\x88\xe6\x9c\xac\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe5\x9c\xa8\xe7\xba\xbf\xe9\x98\x85\xe8\xaf\xbb\xef\xbc\x8c\xe4\xb9\x9f\xe5\x8f\xaf\xe4\xbb\xa5\xe6\xa0\xb9\xe6\x8d\xae\xe9\x9c\x80\xe8\xa6\x81\xe5\x88\x86\xe5\x88\xab\xe9\x98\x85\xe8\xaf\xbb\xe3\x80\x82\n\n- [\xe9\xa6\x96\xe5\x8f\x91\xef\xbc\x9a](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247485293&idx=2&sn=2650e61d6268f667333e86cb52ab1df1&chksm=97048cd1a07305c73229a0b3daf887ac4960fcbd3f378bbc0b40b9b38203fca387b29218fcbd&scene=21#wechat_redirect)[\xe5\x90\xb4\xe6\x81\xa9\xe8\xbe\xbe\xe7\x9a\x84 CS229 \xe7\x9a\x84\xe6\x95\xb0\xe5\xad\xa6\xe5\x9f\xba\xe7\xa1\x80\xef\xbc\x88\xe6\xa6\x82\xe7\x8e\x87\xe8\xae\xba\xef\xbc\x89\xef\xbc\x8c\xe6\x9c\x89\xe4\xba\xba\xe6\x8a\x8a\xe5\xae\x83\xe5\x81\x9a\xe6\x88\x90\xe4\xba\x86\xe5\x9c\xa8\xe7\xba\xbf\xe7\xbf\xbb\xe8\xaf\x91\xe7\x89\x88\xe6\x9c\xac\xef\xbc\x81](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247485293&idx=2&sn=2650e61d6268f667333e86cb52ab1df1&chksm=97048cd1a07305c73229a0b3daf887ac4960fcbd3f378bbc0b40b9b38203fca387b29218fcbd&scene=21#wechat_redirect)\n- [\xe9\xa6\x96\xe5\x8f\x91\xef\xbc\x9a](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247485221&idx=2&sn=105073d243e1d39e10c7ad3dd22043c8&chksm=97048c99a073058fd51d33990ed476ff34acbe22aa7f52cdcd396f2283b22312feafbffb0e5b&scene=21#wechat_redirect)[\xe5\x90\xb4\xe6\x81\xa9\xe8\xbe\xbe\xe7\x9a\x84 CS229 \xe7\x9a\x84\xe6\x95\xb0\xe5\xad\xa6\xe5\x9f\xba\xe7\xa1\x80\xef\xbc\x88\xe7\xba\xbf\xe6\x80\xa7\xe4\xbb\xa3\xe6\x95\xb0\xef\xbc\x89\xef\xbc\x8c\xe6\x9c\x89\xe4\xba\xba\xe6\x8a\x8a\xe5\xae\x83\xe5\x81\x9a\xe6\x88\x90\xe4\xba\x86\xe5\x9c\xa8\xe7\xba\xbf\xe7\xbf\xbb\xe8\xaf\x91\xe7\x89\x88\xe6\x9c\xac\xef\xbc\x81](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247485221&idx=2&sn=105073d243e1d39e10c7ad3dd22043c8&chksm=97048c99a073058fd51d33990ed476ff34acbe22aa7f52cdcd396f2283b22312feafbffb0e5b&scene=21#wechat_redirect)\n- [\xe5\x9c\xa8\xe7\xba\xbf\xe9\x98\x85\xe8\xaf\xbb\xef\xbc\x81](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247485707&idx=3&sn=7d785108792eb64126812de876245387&chksm=970482b7a0730ba1099dcc3e2b05342907c0057d3d61eb125aa99c8649f186a49cad9e8a4660&scene=21#wechat_redirect)[\xef\xbc\x81](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247485707&idx=3&sn=7d785108792eb64126812de876245387&chksm=970482b7a0730ba1099dcc3e2b05342907c0057d3d61eb125aa99c8649f186a49cad9e8a4660&scene=21#wechat_redirect)[\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x95\xb0\xe5\xad\xa6\xe7\xb2\xbe\xe5\x8d\x8e\xef\xbc\x9a](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247485707&idx=3&sn=7d785108792eb64126812de876245387&chksm=970482b7a0730ba1099dcc3e2b05342907c0057d3d61eb125aa99c8649f186a49cad9e8a4660&scene=21#wechat_redirect)[\xe9\xab\x98\xe7\xad\x89\xe6\x95\xb0\xe5\xad\xa6](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247485707&idx=3&sn=7d785108792eb64126812de876245387&chksm=970482b7a0730ba1099dcc3e2b05342907c0057d3d61eb125aa99c8649f186a49cad9e8a4660&scene=21#wechat_redirect)\n- [\xe5\x9c\xa8\xe7\xba\xbf\xe9\x98\x85\xe8\xaf\xbb\xef\xbc\x81](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247485707&idx=3&sn=7d785108792eb64126812de876245387&chksm=970482b7a0730ba1099dcc3e2b05342907c0057d3d61eb125aa99c8649f186a49cad9e8a4660&scene=21#wechat_redirect)[\xef\xbc\x81](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247485707&idx=3&sn=7d785108792eb64126812de876245387&chksm=970482b7a0730ba1099dcc3e2b05342907c0057d3d61eb125aa99c8649f186a49cad9e8a4660&scene=21#wechat_redirect)[\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x95\xb0\xe5\xad\xa6\xe7\xb2\xbe\xe5\x8d\x8e\xef\xbc\x9a](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247485707&idx=3&sn=7d785108792eb64126812de876245387&chksm=970482b7a0730ba1099dcc3e2b05342907c0057d3d61eb125aa99c8649f186a49cad9e8a4660&scene=21#wechat_redirect)[\xe7\xba\xbf\xe6\x80\xa7\xe4\xbb\xa3\xe6\x95\xb0](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247485707&idx=3&sn=7d785108792eb64126812de876245387&chksm=970482b7a0730ba1099dcc3e2b05342907c0057d3d61eb125aa99c8649f186a49cad9e8a4660&scene=21#wechat_redirect)\n- [\xe5\x9c\xa8\xe7\xba\xbf\xe9\x98\x85\xe8\xaf\xbb\xef\xbc\x81\xef\xbc\x81\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x95\xb0\xe5\xad\xa6\xe7\xb2\xbe\xe5\x8d\x8e\xef\xbc\x9a\xe6\xa6\x82\xe7\x8e\x87\xe8\xae\xba\xe4\xb8\x8e\xe6\x95\xb0\xe7\x90\x86\xe7\xbb\x9f\xe8\xae\xa1](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247485707&idx=5&sn=af7c82f85740eac5672080d936869639&chksm=970482b7a0730ba13b6c4be0a40a0dc6c98c500ff9ea29dca61bba592513236144148320636c&scene=21#wechat_redirect)\n\n## \xe5\x9b\x9b\xe3\x80\x81\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\n\n\xe5\x8e\x9f\xe5\x88\x9b\xe4\xbd\x9c\xe5\x93\x81\xe4\xb8\xba\xe4\xbb\xa5\xe4\xb8\x8b\xe4\xb8\x89\xe4\xb8\xaa\xef\xbc\x9a\n\n- [\xe5\x90\xb4\xe6\x81\xa9\xe8\xbe\xbe\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xaf\xbe\xe7\xa8\x8b\xe7\xac\x94\xe8\xae\xb0\xe5\x8f\x8a\xe8\xb5\x84\xe6\xba\x90\xef\xbc\x88github \xe6\xa0\x87\xe6\x98\x9f 12000+\xef\xbc\x8c\xe6\x8f\x90\xe4\xbe\x9b\xe7\x99\xbe\xe5\xba\xa6\xe4\xba\x91\xe9\x95\x9c\xe5\x83\x8f\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484544&idx=1&sn=c5b92a7c4a2bdca10d92ff06dbb315c4&chksm=97048f3ca073062a00c2e961daa9c17585d8b5cb8e73229b5b0364a6fc680b242dd7b409bd23&scene=21#wechat_redirect)\n- [\xe3\x80\x8a\xe7\xbb\x9f\xe8\xae\xa1\xe5\xad\xa6\xe4\xb9\xa0\xe6\x96\xb9\xe6\xb3\x95\xe3\x80\x8b\xe7\x9a\x84 python \xe4\xbb\xa3\xe7\xa0\x81\xe5\xae\x9e\xe7\x8e\xb0\xef\xbc\x88github \xe6\xa0\x87\xe6\x98\x9f 7200+\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484580&idx=1&sn=7cf0ca2e05fc1ed71dff380bf1f60ff6&chksm=97048f18a073060e85ae439fd458bd976bf21366ca2b36ed3aeefda297b47d5c5a91196a4513&scene=21#wechat_redirect)\n- [\xe6\x8e\xa8\xe8\x8d\x90\xef\xbc\x9a](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484360&idx=1&sn=d1859797428994bdb2b265aa4ddb98b9&chksm=97048874a07301627e89152fd2f84ba82d005348f7f04723a4e10facd463b8607691d6510678&scene=21#wechat_redirect)[\xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xae\x9e\xe6\x88\x98\xef\xbc\x9a](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484360&idx=1&sn=d1859797428994bdb2b265aa4ddb98b9&chksm=97048874a07301627e89152fd2f84ba82d005348f7f04723a4e10facd463b8607691d6510678&scene=21#wechat_redirect)[\xe5\x9f\xba\xe4\xba\x8e Scikit-Learn \xe5\x92\x8c TensorFlow\xe3\x80\x8b\xe4\xb8\xad\xe6\x96\x87\xe7\xbf\xbb\xe8\xaf\x91\xe5\x92\x8c\xe4\xbb\xa3\xe7\xa0\x81\xe4\xb8\x8b\xe8\xbd\xbd](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484360&idx=1&sn=d1859797428994bdb2b265aa4ddb98b9&chksm=97048874a07301627e89152fd2f84ba82d005348f7f04723a4e10facd463b8607691d6510678&scene=21#wechat_redirect)\n\n\xe5\x90\x8e\xe6\x9d\xa5\xe5\x8f\x88\xe5\x88\xb6\xe4\xbd\x9c\xe6\x88\x90\xe4\xba\x86\xe5\x9c\xa8\xe7\xba\xbf\xe9\x98\x85\xe8\xaf\xbb\xe7\x89\x88\xe6\x9c\xac\xef\xbc\x9a\n\n- [\xe5\xb8\xa6\xe4\xbd\xa0\xe5\xb0\x91\xe8\xb5\xb0\xe5\xbc\xaf\xe8\xb7\xaf\xef\xbc\x9a](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247485997&idx=1&sn=975216fdafe7e09bc515c944aaf7a26a&chksm=97048191a0730887950f73c6774921eefd0e26da5b3568f100cf6c45f22e783514076624120d&scene=21#wechat_redirect)[\xe4\xba\x94\xe7\xaf\x87\xe6\x96\x87\xe7\xab\xa0\xe5\xad\xa6\xe5\xae\x8c\xe5\x90\xb4\xe6\x81\xa9\xe8\xbe\xbe\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247485997&idx=1&sn=975216fdafe7e09bc515c944aaf7a26a&chksm=97048191a0730887950f73c6774921eefd0e26da5b3568f100cf6c45f22e783514076624120d&scene=21#wechat_redirect)\n- [\xe7\xbb\x8f\xe5\x85\xb8\xe5\xa4\x8d\xe7\x8e\xb0\xef\xbc\x9a](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247486130&idx=2&sn=401a94b7db6e0e531ab3a745d3a1e3ed&chksm=9704810ea073081866aa98753412945734be9e217b8488c26bd0a66d54fbedf9c84f8c07873a&scene=21#wechat_redirect)[\xe3\x80\x8a\xe7\xbb\x9f\xe8\xae\xa1\xe5\xad\xa6\xe4\xb9\xa0\xe6\x96\xb9\xe6\xb3\x95\xe3\x80\x8b\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81\xe5\xae\x9e\xe7\x8e\xb0\xef\xbc\x88\xe5\x9c\xa8\xe7\xba\xbf\xe9\x98\x85\xe8\xaf\xbb\xef\xbc\x81](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247486130&idx=2&sn=401a94b7db6e0e531ab3a745d3a1e3ed&chksm=9704810ea073081866aa98753412945734be9e217b8488c26bd0a66d54fbedf9c84f8c07873a&scene=21#wechat_redirect)[\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247486130&idx=2&sn=401a94b7db6e0e531ab3a745d3a1e3ed&chksm=9704810ea073081866aa98753412945734be9e217b8488c26bd0a66d54fbedf9c84f8c07873a&scene=21#wechat_redirect)\n\n#### \xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9b\xb8\xe5\x85\xb3\n\n- [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xbb\x83\xe4\xb9\xa0\xe6\x95\xb0\xe6\x8d\xae\xe5\x93\xaa\xe9\x87\x8c\xe6\x89\xbe\xef\xbc\x9f](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484828&idx=1&sn=fbd9a75c363580e85d7000fd02ad56af&chksm=97048e20a07307369410f16924178d836587b4407abb4f3e5c9f3017f9adda9b5538fef6f912&scene=21#wechat_redirect)[\xe4\xb8\xa4\xe8\xa1\x8c\xe4\xbb\xa3\xe7\xa0\x81\xe6\x90\x9e\xe5\xae\x9a\xef\xbc\x81](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484828&idx=1&sn=fbd9a75c363580e85d7000fd02ad56af&chksm=97048e20a07307369410f16924178d836587b4407abb4f3e5c9f3017f9adda9b5538fef6f912&scene=21#wechat_redirect)\n- [\xe5\xad\xa6\xe5\xae\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe8\xa7\xa3\xe5\x86\xb3 90%\xe4\xbb\xa5\xe4\xb8\x8a\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe6\x9e\x90\xe9\x97\xae\xe9\xa2\x98-\xe5\x88\xa9\xe7\x94\xa8 python \xe8\xbf\x9b\xe8\xa1\x8c\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe6\x9e\x90\xe7\xac\xac\xe4\xba\x8c\xe7\x89\x88\xef\xbc\x88\xe4\xbb\xa3\xe7\xa0\x81\xe5\x92\x8c\xe4\xb8\xad\xe6\x96\x87\xe7\xac\x94\xe8\xae\xb0\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484383&idx=1&sn=de695ff5e6a3e36a1c54a4a498e36a95&chksm=97048863a07301759227c74c174f6596c9da6fbf40b2fa276f87b1e845c808cacd70b51c7f6a&scene=21#wechat_redirect)\n- [\xe7\x89\xb9\xe5\xbe\x81\xe5\xb7\xa5\xe7\xa8\x8b\xe7\x9a\x84\xe5\xae\x9d\xe5\x85\xb8-\xe3\x80\x8aFeature Engineering for Machine Learning\xe3\x80\x8b\xe7\xbf\xbb\xe8\xaf\x91\xe5\x8f\x8a\xe4\xbb\xa3\xe7\xa0\x81\xe5\xae\x9e\xe7\x8e\xb0](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484297&idx=1&sn=c862ea44abc4f90c52c5d1e9609bd9d7&chksm=97048835a07301239f1bcfcb1ef0eb66058dcb6cce2acfc8f04bbee6660f20d846fbca79a0f0&scene=21#wechat_redirect)\n\n## \xe4\xba\x94\xe3\x80\x81\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\n\n#### \xe5\x90\xb4\xe6\x81\xa9\xe8\xbe\xbe\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe8\xaf\xbe\xe7\xa8\x8b\xe7\xac\x94\xe8\xae\xb0\xe5\x92\x8c\xe8\xb5\x84\xe6\xba\x90\n\n- [\xe5\x90\xb4\xe6\x81\xa9\xe8\xbe\xbe\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe7\xac\x94\xe8\xae\xb0\xe5\x8f\x8a\xe8\xa7\x86\xe9\xa2\x91\xe7\xad\x89\xe8\xb5\x84\xe6\xba\x90\xef\xbc\x88github \xe6\xa0\x87\xe6\x98\x9f 8500+\xef\xbc\x8c\xe6\x8f\x90\xe4\xbe\x9b\xe7\x99\xbe\xe5\xba\xa6\xe4\xba\x91\xe9\x95\x9c\xe5\x83\x8f\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484558&idx=1&sn=d2033198fa6227a4cd561c70a93f2e2a&chksm=97048f32a07306245660808fe46569d8999491108a3d37eb833a27c8f597cd3a2c18852df014&scene=21#wechat_redirect)\n\n#### TensorFlow \xe5\x85\xa5\xe9\x97\xa8\xef\xbc\x9a\n\n- [\xe5\xb8\xa6\xe4\xbd\xa0\xe5\xb0\x91\xe8\xb5\xb0\xe5\xbc\xaf\xe8\xb7\xaf\xef\xbc\x9a](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484633&idx=1&sn=adf2dfee2bf09e6dab0a67d329bd0c50&chksm=97048f65a073067365daa419808913b50872a18ef9bb16a5011f90967eb89c335fb204c027d2&scene=21#wechat_redirect)[\xe5\xbc\xba\xe7\x83\x88\xe6\x8e\xa8\xe8\x8d\x90\xe7\x9a\x84 TensorFlow \xe5\xbf\xab\xe9\x80\x9f\xe5\x85\xa5\xe9\x97\xa8\xe8\xb5\x84\xe6\x96\x99\xe5\x92\x8c\xe7\xbf\xbb\xe8\xaf\x91\xef\xbc\x88\xe5\x8f\xaf\xe4\xb8\x8b\xe8\xbd\xbd\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484633&idx=1&sn=adf2dfee2bf09e6dab0a67d329bd0c50&chksm=97048f65a073067365daa419808913b50872a18ef9bb16a5011f90967eb89c335fb204c027d2&scene=21#wechat_redirect)\n\n#### keras \xe5\x85\xa5\xe9\x97\xa8\xef\xbc\x9a\n\n- [\xe5\xb8\xa6\xe4\xbd\xa0\xe5\xb0\x91\xe8\xb5\xb0\xe5\xbc\xaf\xe8\xb7\xaf\xef\xbc\x9a\xe5\xbc\xba\xe7\x83\x88\xe6\x8e\xa8\xe8\x8d\x90\xe7\x9a\x84 Keras \xe5\xbf\xab\xe9\x80\x9f\xe5\x85\xa5\xe9\x97\xa8\xe8\xb5\x84\xe6\x96\x99\xe5\x92\x8c\xe7\xbf\xbb\xe8\xaf\x91\xef\xbc\x88\xe5\x8f\xaf\xe4\xb8\x8b\xe8\xbd\xbd\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484794&idx=1&sn=9b52adc9138fda3d404dff24e03d14b5&chksm=97048ec6a07307d01ae2c93aa887d3c6ac6ec5f9d2ed5a5b8260182e3f47fae3ea9f08a1a0bf&scene=21#wechat_redirect)\n\n#### Pytorch\xe5\x85\xa5\xe9\x97\xa8\xef\xbc\x9a\n\n- [\xe5\xb8\xa6\xe4\xbd\xa0\xe5\xb0\x91\xe8\xb5\xb0\xe5\xbc\xaf\xe8\xb7\xaf\xef\xbc\x9a](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484721&idx=2&sn=f2c6084354c912d91fbbb7f09adaf4ac&chksm=97048e8da073079b40d8a4cad5c016d762e1668ffd52f2d04bcb702e4530a9a275d73035ca9c&scene=21#wechat_redirect)[\xe5\xbc\xba\xe7\x83\x88\xe6\x8e\xa8\xe8\x8d\x90\xe7\x9a\x84 Pytorch \xe5\xbf\xab\xe9\x80\x9f\xe5\x85\xa5\xe9\x97\xa8\xe8\xb5\x84\xe6\x96\x99\xe5\x92\x8c\xe7\xbf\xbb\xe8\xaf\x91\xef\xbc\x88\xe5\x8f\xaf\xe4\xb8\x8b\xe8\xbd\xbd\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484721&idx=2&sn=f2c6084354c912d91fbbb7f09adaf4ac&chksm=97048e8da073079b40d8a4cad5c016d762e1668ffd52f2d04bcb702e4530a9a275d73035ca9c&scene=21#wechat_redirect)\n\n### \xe5\x85\xb6\xe4\xbb\x96\xe8\xb5\x84\xe6\x96\x99\n\n- [\xe9\xa6\x96\xe5\x8f\x91\xef\xbc\x9a](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484411&idx=1&sn=0f95762a29249ea40b11edd24648c8d0&chksm=97048847a0730151f4bdd1d99ccf454206108fcf7f5b61b100f3dc39a7c46f926fc3da084c72&scene=21#wechat_redirect)[\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe5\x85\xa5\xe9\x97\xa8\xe5\xae\x9d\xe5\x85\xb8-\xe3\x80\x8apython \xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe3\x80\x8b\xe5\x8e\x9f\xe6\x96\x87\xe4\xbb\xa3\xe7\xa0\x81\xe4\xb8\xad\xe6\x96\x87\xe6\xb3\xa8\xe9\x87\x8a\xe7\x89\x88\xe5\x8f\x8a\xe7\x94\xb5\xe5\xad\x90\xe4\xb9\xa6](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484411&idx=1&sn=0f95762a29249ea40b11edd24648c8d0&chksm=97048847a0730151f4bdd1d99ccf454206108fcf7f5b61b100f3dc39a7c46f926fc3da084c72&scene=21#wechat_redirect)\n- [\xe5\xbc\xba\xe7\x83\x88\xe6\x8e\xa8\xe8\x8d\x90\xe7\x9a\x84 TensorFlow\xe3\x80\x81Pytorch \xe5\x92\x8c Keras \xe7\x9a\x84\xe6\xa0\xb7\xe4\xbe\x8b\xe8\xb5\x84\xe6\xba\x90\xef\xbc\x88\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe5\x88\x9d\xe5\xad\xa6\xe8\x80\x85\xe5\xbf\x85\xe9\xa1\xbb\xe6\x94\xb6\xe8\x97\x8f\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484393&idx=1&sn=c22c28eb324e052bdb5a399915c0b1c4&chksm=97048855a073014366257382f64e44b7ef6dcc59a0c3991abe0bb4128c0e471e28cf328ae9e4&scene=21#wechat_redirect)\n- [Ubuntu 18.04 \xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe7\x8e\xaf\xe5\xa2\x83\xe9\x85\x8d\xe7\xbd\xae\xef\xbc\x88CUDA9.0+CUDDN7.4+TensorFolw1.8\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484401&idx=1&sn=73e97612c8a8c6cbb65461f999c024ff&chksm=9704884da073015bfc9e3ee0d5c9765f9a48bee1091da319d024de63bc2d202c9a53ca6057b7&scene=21#wechat_redirect)\n\n## \xe5\x85\xad\xe3\x80\x81Python \xe7\x9b\xb8\xe5\x85\xb3\n\n- [\xe5\xad\xa6\xe4\xb9\xa0 python \xe5\x85\xa5\xe9\x97\xa8\xe7\x9a\x84\xe4\xb8\xaa\xe4\xba\xba\xe5\xbb\xba\xe8\xae\xae\xe5\x8f\x8a\xe8\xb5\x84\xe6\x96\x99](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484426&idx=1&sn=c1971be3d85a8c247a5c77bfd925733d&chksm=97048fb6a07306a0ad6f51f1aa90225c685e46ad5adddf929a110cdd46ed9105ff1c1b1a90e9&scene=21#wechat_redirect)\n- [Python \xe7\x8e\xaf\xe5\xa2\x83\xe7\x9a\x84\xe5\xae\x89\xe8\xa3\x85\xef\xbc\x88Anaconda+Jupyter notebook+Pycharm\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484364&idx=1&sn=2d7cf6b8d8a4647a32459cb3798f3d76&chksm=97048870a0730166a7c2e9be889cb926b98585947d123500d958f2afe5afbfd21a5718684896&scene=21#wechat_redirect)\n- [Python \xe4\xbb\xa3\xe7\xa0\x81\xe5\x86\x99\xe5\xbe\x97\xe4\xb8\x91\xe6\x80\x8e\xe4\xb9\x88\xe5\x8a\x9e\xef\xbc\x9f](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484361&idx=1&sn=086b8b9cbed37fd1932b6a8e6e517e2d&chksm=97048875a07301633726942278aac93d005fc673dcf740b8f6d6c75c544d0254828dc7e60b58&scene=21#wechat_redirect)[\xe6\x8e\xa8\xe8\x8d\x90\xe5\x87\xa0\xe4\xb8\xaa\xe7\xa5\x9e\xe5\x99\xa8\xe6\x8b\xaf\xe6\x95\x91\xe4\xbd\xa0](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484361&idx=1&sn=086b8b9cbed37fd1932b6a8e6e517e2d&chksm=97048875a07301633726942278aac93d005fc673dcf740b8f6d6c75c544d0254828dc7e60b58&scene=21#wechat_redirect)\n- [Numpy \xe7\xbb\x83\xe4\xb9\xa0\xe9\xa2\x98 100 \xe9\xa2\x98-\xe6\x8f\x90\xe9\xab\x98\xe4\xbd\xa0\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe6\x9e\x90\xe6\x8a\x80\xe8\x83\xbd](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484368&idx=1&sn=9ec8ab2ab1f368b877799c90d0cdc671&chksm=9704886ca073017a452532d35129f4923b895c09e43e9e9debaa8261d895540462ab5dbda239&scene=21#wechat_redirect)\n- [Pandas \xe7\xbb\x83\xe4\xb9\xa0\xe9\xa2\x98-\xe6\x8f\x90\xe9\xab\x98\xe4\xbd\xa0\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe6\x9e\x90\xe6\x8a\x80\xe8\x83\xbd](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484373&idx=1&sn=e48f845dccdec3c912e6cd16c7e363a8&chksm=97048869a073017fd8d4dd571807dd220940c7c9d729cf9c45fb66bab37ae0bc741272e79135&scene=21#wechat_redirect)\n- [python \xe7\xbb\x98\xe5\x9b\xbe\xe5\xb7\xa5\xe5\x85\xb7\xe5\x9f\xba\xe7\xa1\x80-matplotlib \xe5\xad\xa6\xe4\xb9\xa0\xe4\xb9\x8b\xe5\x9f\xba\xe6\x9c\xac\xe4\xbd\xbf\xe7\x94\xa8](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484389&idx=1&sn=7ab4f99f76b02a5198740c2b5fde91dc&chksm=97048859a073014f9fda1dc00eef5b47b78c15def4478463bc4bba773790474b225ff9606e8e&scene=21#wechat_redirect)\n- [\xe6\x95\xb0\xe6\x8d\xae\xe5\x8f\xaf\xe8\xa7\x86\xe5\x8c\x96\xe7\x9a\x84\xe5\x88\xa9\xe5\x99\xa8-Seaborn \xe7\xae\x80\xe6\x98\x93\xe5\x85\xa5\xe9\x97\xa8](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484376&idx=1&sn=cd3ac06f4a0125eebb317578db3c4ec5&chksm=97048864a0730172f24c35e922573763213f2a2c0da4a6a8d2787d0f09315a3eac6e37634997&scene=21#wechat_redirect)\n\n## \xe4\xb8\x83\xe3\x80\x81NLP\n\n- [\xe4\xb8\x80\xe4\xba\x9b NLP \xe7\x9a\x84\xe5\x85\xa5\xe9\x97\xa8\xe8\xb5\x84\xe6\x96\x99\xe5\x8f\x82\xe8\x80\x83](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484419&idx=1&sn=3a21e26b420fcd52d17cf3e1a456ee10&chksm=97048fbfa07306a9f0454fa330155e16127f6020525986ccc0fcf182c089b08b9b503c888a95&scene=21#wechat_redirect)\n- [\xe6\x8e\xa8\xe8\x8d\x90\xef\xbc\x9a](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484317&idx=1&sn=83e5d0bc7258c49c2427be4afa6cb588&chksm=97048821a0730137fc9df879f8e0d0ae9cbd88160d40750aaa4b3e5c7accd85e328e7c53c451&scene=21#wechat_redirect)[\xe5\xb8\xb8\xe8\xa7\x81 NLP \xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81\xe5\xae\x9e\xe7\x8e\xb0\xef\xbc\x88\xe5\x9f\xba\xe4\xba\x8e TensorFlow \xe5\x92\x8c PyTorch\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484317&idx=1&sn=83e5d0bc7258c49c2427be4afa6cb588&chksm=97048821a0730137fc9df879f8e0d0ae9cbd88160d40750aaa4b3e5c7accd85e328e7c53c451&scene=21#wechat_redirect)\n- [\xe5\x9b\xbe\xe8\xa7\xa3 word2vec\xef\xbc\x88\xe5\x8e\x9f\xe6\x96\x87\xe7\xbf\xbb\xe8\xaf\x91\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484301&idx=1&sn=ef50f185d8c41be4f54e141a9b4d0923&chksm=97048831a073012770f6b7bab14c3ff61e4215f24b38b9e98b701384ac798f2b6fee964816e6&scene=21#wechat_redirect)\n\n## \xe5\x85\xab\xe3\x80\x81\xe5\xad\xa6\xe6\x9c\xaf\xe6\x8a\x80\xe5\xb7\xa7\n\n- [\xe6\x8e\xa8\xe8\x8d\x90\xe5\x87\xa0\xe4\xb8\xaa\xe6\x8f\x90\xe9\xab\x98\xe5\xb7\xa5\xe4\xbd\x9c\xe6\x95\x88\xe7\x8e\x87\xe7\x9a\x84\xe7\xa5\x9e\xe5\x99\xa8](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484301&idx=1&sn=ef50f185d8c41be4f54e141a9b4d0923&chksm=97048831a073012770f6b7bab14c3ff61e4215f24b38b9e98b701384ac798f2b6fee964816e6&scene=21#wechat_redirect)\n- [\xe7\xa7\x91\xe7\xa0\x94\xe5\xb7\xa5\xe4\xbd\x9c\xe8\x80\x85\xe7\x9a\x84\xe7\xa5\x9e\xe5\x99\xa8--zotero \xe8\xae\xba\xe6\x96\x87\xe7\xae\xa1\xe7\x90\x86\xe5\xb7\xa5\xe5\x85\xb7](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484429&idx=1&sn=5663338e5c76374512fa354d68b5a67d&chksm=97048fb1a07306a70bd1259038701cd7aeca49482a593646d1399166b87071b3ddc35ae4df4d&scene=21#wechat_redirect)\n- [\xe5\x88\x86\xe4\xba\xab\xef\xbc\x9a](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484279&idx=1&sn=786aa47073fa3522f4cce1493fba9f11&chksm=970488cba07301dd977fef7b761843dc6b84d26a62daff79e1121433090538b42aa3de5cb0fb&scene=21#wechat_redirect)[\xe6\x88\x91\xe6\x98\xaf\xe6\x80\x8e\xe4\xb9\x88\xe5\x9c\xa8 github \xe4\xb8\x8a\xe6\x89\xbe\xe5\x88\xb0\xe4\xbc\x98\xe7\xa7\x80\xe7\x9a\x84\xe4\xbb\x93\xe5\xba\x93\xe7\x9a\x84\xef\xbc\x9f](http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247484279&idx=1&sn=786aa47073fa3522f4cce1493fba9f11&chksm=970488cba07301dd977fef7b761843dc6b84d26a62daff79e1121433090538b42aa3de5cb0fb&scene=21#wechat_redirect)\n\n## \xe6\x80\xbb\xe7\xbb\x93\n\n\xe6\x9c\xac\xe6\x96\x87\xe6\x80\xbb\xe7\xbb\x93\xe4\xba\x86\xe2\x80\x9c**\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x88\x9d\xe5\xad\xa6\xe8\x80\x85**\xe2\x80\x9d\xe5\x85\xac\xe4\xbc\x97\xe5\x8f\xb7\xe5\x88\x9b\xe7\xab\x8b\xe4\xbb\xa5\xe6\x9d\xa5\xe7\x9a\x84\xe7\xb2\xbe\xe9\x80\x89**\xe5\x8e\x9f\xe5\x88\x9b**\xe6\x96\x87\xe7\xab\xa0\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe4\xbd\x9c\xe4\xb8\xba AI \xe5\x85\xa5\xe9\x97\xa8\xe7\x9a\x84\xe5\xae\x9d\xe5\x85\xb8\xef\xbc\x8c\xe8\xae\xa9\xe5\x88\x9d\xe5\xad\xa6\xe8\x80\x85\xe5\xb0\x91\xe8\xb5\xb0\xe5\xbc\xaf\xe8\xb7\xaf\xef\xbc\x8c\xe5\xbc\xba\xe7\x83\x88\xe5\xbb\xba\xe8\xae\xae**\xe6\x94\xb6\xe8\x97\x8f**\xe6\x9c\xac\xe6\x96\x87\xef\xbc\x81\n\n--------------------\n\n\n\n# \xe6\x9c\xac\xe7\xab\x992018\xe5\xb9\xb4\xe7\x9a\x84\xe6\x89\x80\xe6\x9c\x89\xe6\x96\x87\xe7\xab\xa0\n\n**\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xb5\x84\xe6\xba\x90**\n\n- [\xe8\x89\xaf\xe5\xbf\x83\xe6\x8e\xa8\xe8\x8d\x90\xef\xbc\x9a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x85\xa5\xe9\x97\xa8\xe8\xb5\x84\xe6\x96\x99\xe6\xb1\x87\xe6\x80\xbb\xe5\x8f\x8a\xe5\xad\xa6\xe4\xb9\xa0\xe5\xbb\xba\xe8\xae\xae\xef\xbc\x882018\xe7\x89\x88\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247484000&idx=1&sn=92f198b840073e79e1a267d15a48a279&chksm=c0791f79f70e966fccd525bc2ecb11d328a12f566ccdc781132ffeeb41c484c1f7757db03911&scene=21#wechat_redirect)\n- [\xe9\xbb\x84\xe6\xb5\xb7\xe5\xb9\xbf\xe5\x8d\x9a\xe5\xa3\xab\xe7\x9a\x84github\xe9\x95\x9c\xe5\x83\x8f\xe4\xb8\x8b\xe8\xbd\xbd\xef\xbc\x88\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x8f\x8a\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe8\xb5\x84\xe6\xba\x90\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483810&idx=1&sn=b35ff5aea7cc2a63c459c7f172263a2d&chksm=c0791cbbf70e95ad2e1cf7109cb50422bc07d0db6cbad502d11d3194aa92c608d5053f218cdd&scene=21#wechat_redirect)\n- [\xe5\x90\xb4\xe6\x81\xa9\xe8\xbe\xbe\xe8\x80\x81\xe5\xb8\x88\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x92\x8c\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe8\xaf\xbe\xe7\xa8\x8b\xe7\xac\x94\xe8\xae\xb0\xe6\x89\x93\xe5\x8d\xb0\xe7\x89\x88](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483678&idx=1&sn=da7de252a11a1097e50381a27cb2cfb1&chksm=c0791c07f70e951178054c7d4acc88becfccf953f83a2d616f8508d8bfa3d31d8cdec0c6979f&scene=21#wechat_redirect)\n- [\xe5\x90\xb4\xe6\x81\xa9\xe8\xbe\xbe\xe8\x80\x81\xe5\xb8\x88\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x95\x99\xe7\xa8\x8b\xe4\xb8\xad\xe6\x96\x87\xe7\xac\x94\xe8\xae\xb0-\xe5\x9c\xa8\xe7\xba\xbf\xe7\x89\x88](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483672&idx=1&sn=1845db207245efc9d33eeede5ea4b99e&chksm=c0791c01f70e9517cfb80b17d0e72836c5c573b33d9bcdc4ec57f02b6b73260d9c3e907a81e0&scene=21#wechat_redirect)\n- [Coursera\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xaf\xbe\xe7\xa8\x8b\xe4\xbb\xa3\xe7\xa0\x81\xe4\xbd\x9c\xe4\xb8\x9a-Python\xe7\x89\x88\xe6\x9c\xac](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483784&idx=1&sn=6c158b9f13ebc612f0fb967323df16c4&chksm=c0791c91f70e95874606edc1a4a0fc38e5063d2634963c793d85c18e5d396be059176bd8d0d6&scene=21#wechat_redirect)\n- [Deeplearning.ai\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe8\xaf\xbe\xe7\xa8\x8b\xe7\xac\x94\xe8\xae\xb0-\xe5\x9c\xa8\xe7\xba\xbf\xe7\x89\x88](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483694&idx=1&sn=f2d7c0be70d0fd17ee6a685cba6f399d&chksm=c0791c37f70e9521daf50bbee06f925505b61ec963397aba08af87925081f019f33ca27ffe5e&scene=21#wechat_redirect)\n- [\xe9\xa6\x96\xe5\x8f\x91\xef\xbc\x9a\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe6\xb5\x8b\xe8\xaf\x95\xe9\xa2\x98\xe4\xb8\xad\xe8\x8b\xb1\xe5\xaf\xb9\xe7\x85\xa7\xe7\x89\x88](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483772&idx=1&sn=7046f9f8d5ae0329c6ab25d1fd8510d3&chksm=c0791c65f70e95734cfb3405658049209036c7097cbb17bc62816523acdc4c2ccca43d1bafdd&scene=21#wechat_redirect)\n- [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xbf\x85\xe5\xa4\x87\xe5\xae\x9d\xe5\x85\xb8-\xe3\x80\x8a\xe7\xbb\x9f\xe8\xae\xa1\xe5\xad\xa6\xe4\xb9\xa0\xe6\x96\xb9\xe6\xb3\x95\xe3\x80\x8b\xe7\x9a\x84python\xe4\xbb\xa3\xe7\xa0\x81\xe5\xae\x9e\xe7\x8e\xb0\xe3\x80\x81\xe7\x94\xb5\xe5\xad\x90\xe4\xb9\xa6\xe5\x8f\x8a\xe8\xaf\xbe\xe4\xbb\xb6](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483911&idx=1&sn=0aa891449692d85382a9b2b5016728bb&chksm=c0791f1ef70e960822c7b67b4216f6c7dc55b2c0f3f75ec7527523daea9ad25b3f86b94d5bec&scene=21#wechat_redirect)\n- [\xe6\x96\xaf\xe5\x9d\xa6\xe7\xa6\x8f\xe5\xa4\xa7\xe5\xad\xa6\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xaf\xbe\xe7\xa8\x8b\xe8\xb5\x84\xe6\x96\x99-\xe5\x90\xb4\xe6\x81\xa9\xe8\xbe\xbe\xe8\x80\x81\xe5\xb8\x88\xe4\xb8\xbb\xe8\xae\xb2\xef\xbc\x882008\xe7\x89\x88\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483778&idx=1&sn=f1fe52a5451eef4e4c6d8463d01621ef&chksm=c0791c9bf70e958d4c57d0f9b2df37ae9cdbed304df030a27161a0ad7f9872926f217e6032d3&scene=21#wechat_redirect)\n- [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xae\xad\xe7\xbb\x83\xe7\xa7\x98\xe7\xb1\x8d\xe5\xae\x8c\xe6\x95\xb4\xe4\xb8\xad\xe6\x96\x87\xe7\x89\x88\xe4\xb8\x8b\xe8\xbd\xbd\xef\xbc\x88\xe5\x90\xb4\xe6\x81\xa9\xe8\xbe\xbe\xe8\x80\x81\xe5\xb8\x88\xe6\x96\xb0\xe4\xbd\x9c\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483815&idx=1&sn=c220c09741e942b6d402f1090a2d72da&chksm=c0791cbef70e95a88745a8df9b3f2f0e2fe93591a21a3f4c331a920d74cdc6bf564ab33ff8df&scene=21#wechat_redirect)\n- [\xe9\xa6\x96\xe5\x8f\x91\xef\xbc\x9a\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe5\x85\xa5\xe9\x97\xa8\xe5\xae\x9d\xe5\x85\xb8-\xe3\x80\x8apython\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe3\x80\x8b\xe5\x8e\x9f\xe6\x96\x87\xe4\xbb\xa3\xe7\xa0\x81\xe4\xb8\xad\xe6\x96\x87\xe6\xb3\xa8\xe9\x87\x8a\xe7\x89\x88\xe5\x8f\x8a\xe7\x94\xb5\xe5\xad\x90\xe4\xb9\xa6](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483804&idx=1&sn=9e862f6d127d70c2619e362c499e15b1&chksm=c0791c85f70e9593cd6106679feaac4b1eace9f717b788f9fbbae05c1b198308c45342ea6992&scene=21#wechat_redirect)\n- [\xe5\xbc\xba\xe7\x83\x88\xe6\x8e\xa8\xe8\x8d\x90\xe7\x9a\x84TensorFlow\xe3\x80\x81Pytorch\xe5\x92\x8cKeras\xe7\x9a\x84\xe6\xa0\xb7\xe4\xbe\x8b\xe8\xb5\x84\xe6\xba\x90\xef\xbc\x88\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe5\x88\x9d\xe5\xad\xa6\xe8\x80\x85\xe5\xbf\x85\xe9\xa1\xbb\xe6\x94\xb6\xe8\x97\x8f\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483961&idx=1&sn=7fa7e3e8a1cd4abf3e3357b2f6448118&chksm=c0791f20f70e9636821676c4302a1113016e547632c8e3872bcf815b41de95a7a5b25f3c5f62&scene=21#wechat_redirect)\n- [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xb0\x8f\xe6\x8a\x84-\xef\xbc\x88\xe5\x83\x8f\xe8\x83\x8c\xe6\x89\x98\xe7\xa6\x8f\xe5\x8d\x95\xe8\xaf\x8d\xe4\xb8\x80\xe6\xa0\xb7\xe7\x90\x86\xe8\xa7\xa3\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483707&idx=1&sn=2f28175ecea445129a5e62441aeebd37&chksm=c0791c22f70e95340f61a978147314dd02bf8ab1bd9c49f3b86f928e371dac0ead6eda64116a&scene=21#wechat_redirect)\n- [\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe5\x88\x9d\xe5\xad\xa6\xe8\x80\x85\xe7\x9a\x84\xe5\x8f\xa6\xe4\xb8\x80\xe4\xbb\xbd\xe5\xb0\x8f\xe6\x8a\x84-\xe3\x80\x8a\xe4\xb8\x80\xe5\xa4\xa9\xe5\xad\xa6\xe6\x87\x82\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x88\xe6\x9d\x8e\xe5\xae\x8f\xe6\xaf\x85\xef\xbc\x89\xe3\x80\x8b\xef\xbc\x88\xe4\xb8\xad\xe6\x96\x87\xe6\xa0\x87\xe6\xb3\xa8\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483860&idx=1&sn=514c1c053e31c4ced3bffe75e02f4b05&chksm=c0791ccdf70e95dba8c32d3b12836359159a2045019e8d5fb45ca578a9846f4601439b42bba3&scene=21#wechat_redirect)\n- [\xe4\xb8\x80\xe4\xba\x9bNLP\xe7\x9a\x84\xe5\x85\xa5\xe9\x97\xa8\xe8\xb5\x84\xe6\x96\x99\xe5\x8f\x82\xe8\x80\x83](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483752&idx=1&sn=779b10f781fd7699040d7fcd5889b998&chksm=c0791c71f70e9567c91c9459641bff333c490a3326e0549fbdc58131fcc9fa5245f8785a54d9&scene=21#wechat_redirect)\n- [\xe9\x9d\xa9\xe5\x91\xbd\xe6\x80\xa7\xe6\x8f\x90\xe5\x8d\x87-\xe5\xae\x87\xe5\xae\x99\xe6\x9c\x80\xe5\xbc\xba\xe7\x9a\x84NLP\xe9\xa2\x84\xe8\xae\xad\xe7\xbb\x83BERT\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x88\xe9\x99\x84\xe5\xae\x98\xe6\x96\xb9\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483930&idx=1&sn=31db561b207aed2b488ddb719ec7513f&chksm=c0791f03f70e9615586cf6be32352d0096da71563e87b20e3b115b206c1804d37bd3703fa5fe&scene=21#wechat_redirect)\n- [50\xe4\xb8\xaa\xe6\x9c\x80\xe4\xbd\xb3\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x85\xac\xe5\x85\xb1\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483877&idx=1&sn=ca49142a7bded5c01ce39e25a004b5bd&chksm=c0791cfcf70e95eab42f6565f487c854c803cb072e225e9a30ebf25910ccef7b61ac794990b3&scene=21#wechat_redirect) \n\n**\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xa4\xa7\xe5\xb8\x88\xe4\xb9\x8b\xe4\xbd\x9c**\n\n- [\xe9\xa6\x96\xe5\x8f\x91\xef\xbc\x9a\xe5\xbe\x90\xe4\xba\xa6\xe8\xbe\xbe\xe8\x80\x81\xe5\xb8\x88\xe7\x9a\x84\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xaf\xbe\xe4\xbb\xb6\xe5\x8f\x8a\xe4\xb8\x8b\xe8\xbd\xbd\xef\xbc\x88\xe4\xb8\xad\xe6\x96\x87\xe7\x9b\xae\xe5\xbd\x95\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483886&idx=1&sn=e3a0c27f24446edb67b877d25007aec6&chksm=c0791cf7f70e95e1c601dc184bb681a7150c61fe5c4173e5abee72b1b3d9be71b5774b3d6a1a&scene=21#wechat_redirect)\n- [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9a\x84\xe5\xae\x9d\xe5\x85\xb8-\xe5\x8d\x8e\xe6\xa0\xa1\xe4\xb8\x93\xe8\x80\x81\xe5\xb8\x88\xe7\x9a\x84\xe7\xac\x94\xe8\xae\xb0](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483789&idx=1&sn=c6cebaaede9d87fc2ea2b38532f89a7b&chksm=c0791c94f70e9582ff738a80d0138fbb7644dfa2e23f8ef83b9f09da92d4bc31f44773befbee&scene=21#wechat_redirect)\n\n**\xe5\xbc\x80\xe6\xba\x90\xe6\xa1\x88\xe4\xbe\x8b\xe5\x92\x8c\xe6\x96\xb9\xe6\xa1\x88**\n\n- [\xe9\xa6\x96\xe5\x8f\x91\xef\xbc\x9a\xe5\x8f\xb0\xe5\xa4\xa7\xe6\x9e\x97\xe8\xbd\xa9\xe7\x94\xb0\xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x9f\xba\xe7\x9f\xb3\xe3\x80\x8b\xe7\xb3\xbb\xe5\x88\x97\xe8\xaf\xbe\xe7\xa8\x8b\xe6\x95\x99\xe6\x9d\x90\xe7\x9a\x84\xe4\xb9\xa0\xe9\xa2\x98\xe8\xa7\xa3\xe7\xad\x94\xe5\x92\x8c\xe5\xae\x9e\xe7\x8e\xb0](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483984&idx=1&sn=0fc0797e69ef856105bf747a43b4fa1e&chksm=c0791f49f70e965f218747c9ff986f3b702df2d5c4b7be80ab267ed9a4a55303c25fb001a83f&scene=21#wechat_redirect)\n- [CTR\xe9\xa2\x84\xe4\xbc\xb0\xe7\xb3\xbb\xe5\x88\x97\xef\xbc\x9aDeepCTR \xe4\xb8\x80\xe4\xb8\xaa\xe5\x9f\xba\xe4\xba\x8e\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9a\x84CTR\xe6\xa8\xa1\xe5\x9e\x8b\xe5\x8c\x85](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483919&idx=1&sn=5fae97fbf1f94a8dec026f08abf0e9c5&chksm=c0791f16f70e9600a2bd47cade5117ad4a64088fca6fc45c51cd0ef6a41f7652650261f058d9&scene=21#wechat_redirect)\n- [\xe5\xbc\x80\xe6\xba\x90-BDCI2018\xe9\x9d\xa2\xe5\x90\x91\xe7\x94\xb5\xe4\xbf\xa1\xe8\xa1\x8c\xe4\xb8\x9a\xe5\xad\x98\xe9\x87\x8f\xe7\x94\xa8\xe6\x88\xb7\xe7\x9a\x84\xe6\x99\xba\xe8\x83\xbd\xe5\xa5\x97\xe9\xa4\x90\xe4\xb8\xaa\xe6\x80\xa7\xe5\x8c\x96\xe5\x8c\xb9\xe9\x85\x8d\xe6\xa8\xa1\xe5\x9e\x8bTop1\xe8\xa7\xa3\xe5\x86\xb3\xe6\x96\xb9\xe6\xa1\x88\xe5\x92\x8c\xe4\xbb\xa3\xe7\xa0\x81](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483956&idx=1&sn=5074fcdc8d63a6f2e9d89884d3f369ee&chksm=c0791f2df70e963bbde6058789f6d64c428c07c1f228b96b0056751d08e1b4cd5c6c752021e2&scene=21#wechat_redirect)\n- [\xe5\xbc\x80\xe6\xba\x90-BDCI2018\xe4\xbe\x9b\xe5\xba\x94\xe9\x93\xbe\xe9\x9c\x80\xe6\xb1\x82\xe9\xa2\x84\xe6\xb5\x8b\xe6\xa8\xa1\xe5\x9e\x8b\xe7\xac\xac\xe4\xb8\x80\xe5\x90\x8d\xe8\xa7\xa3\xe5\x86\xb3\xe6\x96\xb9\xe6\xa1\x88\xe5\x92\x8c\xe4\xbb\xa3\xe7\xa0\x81](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483986&idx=1&sn=0c2c9e185c8a7afba37a212d2af947d5&chksm=c0791f4bf70e965da27dff285473d5b72dc9c58674da3261114a98c174f5fd480f85c4a7b3cc&scene=21#wechat_redirect)\n- [\xe6\xb5\xb7\xe6\xb4\x8b\xe5\xa4\xa7\xe6\x95\xb0\xe6\x8d\xae\xe5\xba\x94\xe7\x94\xa8\xe6\x80\x9d\xe8\x80\x83\xef\xbc\x88\xe9\x99\x84\xe8\xb5\x84\xe6\x96\x99\xe4\xb8\x8b\xe8\xbd\xbd\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483767&idx=1&sn=004de7eff7b8c0621ec25a635bec4b17&chksm=c0791c6ef70e95784174194f028477e1ff9e67b74a1a44a5443c5a659750e0a1610969d6d420&scene=21#wechat_redirect)\n\n**\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xae\xba\xe6\x96\x87**\n\n- [\xe6\x96\xb0\xe8\xae\xba\xe6\x96\x87\xe6\x8e\xa8\xe8\x8d\x90\xef\xbc\x9aAuto-Keras:\xe8\x87\xaa\xe5\x8a\xa8\xe6\x90\x9c\xe7\xb4\xa2\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe7\xbd\x91\xe7\xbb\x9c\xe6\x9e\xb6\xe6\x9e\x84\xe5\x92\x8c\xe8\xb6\x85\xe5\x8f\x82\xe6\x95\xb0](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483820&idx=1&sn=90fcd5fe6262e5a0e22212480e82ed9d&chksm=c0791cb5f70e95a372bc8bf0bfa382bed6a2dd1c0dab036ff4fae2668dccf660f62b2ec3fd07&scene=21#wechat_redirect)\n- [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe6\x96\xb0\xe8\xae\xba\xe6\x96\x87\xe6\x8e\xa8\xe8\x8d\x90-\xef\xbc\x88\xe6\x88\x90\xe5\xaf\xb9\xe5\x85\xb3\xe7\xb3\xbb\xe7\xba\xa6\xe6\x9d\x9f\xe7\x9a\x84\xe9\x9d\x9e\xe8\xb4\x9f\xe7\x9f\xa9\xe9\x98\xb5\xe5\x88\x86\xe8\xa7\xa3\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483746&idx=1&sn=e26b8d4a573f87d28ddef4075d7cbe43&chksm=c0791c7bf70e956d8a3918f5441c85c4228f133b65ab57a1ca05a4a1050c760364e284eec89a&scene=21#wechat_redirect) \n\n**\xe7\xa1\xac\xe4\xbb\xb6\xe5\x92\x8c\xe7\x8e\xaf\xe5\xa2\x83\xe9\x85\x8d\xe7\xbd\xae**\n\n- [Ubuntu 18.04\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe7\x8e\xaf\xe5\xa2\x83\xe9\x85\x8d\xe7\xbd\xae\xef\xbc\x88CUDA9.0+CUDNN7.4+TensorFlow1.8\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483901&idx=1&sn=f02bd7866ad172ef0c9669851dffde2a&chksm=c0791ce4f70e95f2343047e62d513c0106eedebc09cc25d1c45598ede21da8655a974c6a69c5&scene=21#wechat_redirect)\n- [\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe4\xb8\xbb\xe6\x9c\xba\xe7\x8e\xaf\xe5\xa2\x83\xe9\x85\x8d\xe7\xbd\xae: Win10+Nvidia GTX1080i+CUDA8.0+CUDDN6 ](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483665&idx=1&sn=331d52e5b52fd6eb2ba58c16a0fe3458&chksm=c0791c08f70e951e6c47254389112443e9d50ce919a7da25670a636756b090e500bf81580f1c&scene=21#wechat_redirect)\n\n**Python\xe5\x9f\xba\xe7\xa1\x80**\n\n- [\xe5\xad\xa6\xe4\xb9\xa0python\xe5\x85\xa5\xe9\x97\xa8\xe7\x9a\x84\xe4\xb8\xaa\xe4\xba\xba\xe5\xbb\xba\xe8\xae\xae\xe5\x8f\x8a\xe8\xb5\x84\xe6\x96\x99](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483690&idx=1&sn=701cc75092e7213b6a9b04b57b5e15f3&chksm=c0791c33f70e9525a1f48179802f17d50fc4deab5333cb8b142df20e15b6a117df353c168a45&scene=21#wechat_redirect)\n- [\xe4\xb8\xa4\xe5\xa4\xa9\xe5\x85\xa5\xe9\x97\xa8Python\xe5\x9f\xba\xe7\xa1\x80\xef\xbc\x88\xe9\x99\x84\xe4\xbb\xa3\xe7\xa0\x81\xe5\xae\x9e\xe7\x8e\xb0\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483926&idx=1&sn=c19ee22819f98022e01da9343ad4cb85&chksm=c0791f0ff70e9619fd5a02a7cea9ae75bda478eedfcf2accc8ed2853a09b325c331bebfeb8ec&scene=21#wechat_redirect)\n- [\xe5\xad\xa6\xe5\xae\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe8\xa7\xa3\xe5\x86\xb390%\xe4\xbb\xa5\xe4\xb8\x8a\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe6\x9e\x90\xe9\x97\xae\xe9\xa2\x98-\xe5\x88\xa9\xe7\x94\xa8python\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe6\x9e\x90\xe7\xac\xac\xe4\xba\x8c\xe7\x89\x88\xef\xbc\x88\xe4\xbb\xa3\xe7\xa0\x81\xe5\x92\x8c\xe4\xb8\xad\xe6\x96\x87\xe7\xac\x94\xe8\xae\xb0\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247484020&idx=1&sn=c281956f8414f38c48cc8b358f9dcc26&chksm=c0791f6df70e967b33e4f828031dc3f070ca7b8ae855692245cb8f41480686122d56db4600a2&scene=21#wechat_redirect)\n- [python\xe7\xbb\x98\xe5\x9b\xbe\xe5\xb7\xa5\xe5\x85\xb7\xe5\x9f\xba\xe7\xa1\x80-matplotlib\xe5\xad\xa6\xe4\xb9\xa0\xe4\xb9\x8b\xe5\x9f\xba\xe6\x9c\xac\xe4\xbd\xbf\xe7\x94\xa8](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483988&idx=1&sn=0cb80ff3f91f1bf43b14c968ae709576&chksm=c0791f4df70e965b806993b0fe1ead8dc65fa23a010341d0b2f2c5792a66233975895fc43e9e&scene=21#wechat_redirect)\n- [\xe9\x80\x82\xe5\x90\x88\xe5\x88\x9d\xe5\xad\xa6\xe8\x80\x85\xe5\xbf\xab\xe9\x80\x9f\xe5\x85\xa5\xe9\x97\xa8\xe7\x9a\x84Numpy\xe5\xae\x9e\xe6\x88\x98\xe5\x85\xa8\xe9\x9b\x86](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247484006&idx=1&sn=1d0b49c0200e901915a99d29f0dadc79&chksm=c0791f7ff70e966929ed3a9b1358beb3b31a1106084f4332176476eafebf3a407fff2150d5b3&scene=21#wechat_redirect)\n- [python\xe8\xbf\x9b\xe9\x98\xb6\xe4\xb9\x8b\xe5\xa4\x9a\xe8\xbf\x9b\xe7\xa8\x8b ](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247484014&idx=1&sn=25a415e5992f9f20c3e4e03dc1678b53&chksm=c0791f77f70e9661dd63cbf156de58fdc906e96f2a02dcef9bed7c35ab8754d9b255fab99aa1&scene=21#wechat_redirect)\n\n**\xe7\xa7\x91\xe7\xa0\x94\xe5\x85\xa5\xe9\x97\xa8**\n\n- [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\xa6\xe5\x9f\xba\xe7\xa1\x80](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483685&idx=1&sn=1cc418d56344a222a0b6c9a56bdc5026&chksm=c0791c3cf70e952ada01da3a790baa6325c2656a554566716ad96b83c7d1868770514aca8409&scene=21#wechat_redirect)\n- [\xe5\x90\x90\xe8\xa1\x80\xe6\x8e\xa8\xe8\x8d\x90\xe6\x94\xb6\xe8\x97\x8f\xe7\x9a\x84\xe5\xad\xa6\xe4\xbd\x8d\xe8\xae\xba\xe6\x96\x87\xe6\x8e\x92\xe7\x89\x88\xe6\x95\x99\xe7\xa8\x8b\xef\xbc\x88\xe5\xae\x8c\xe6\x95\xb4\xe7\x89\x88\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483979&idx=1&sn=9accf54de60fa6fe8f01cbd22e4df1a8&chksm=c0791f52f70e9644157b1c7a2ac0e3a0ba3e785ce45ff84ca22dbab50f7f0e542d7e6eb24b4f&scene=21#wechat_redirect)\n- [\xe7\xa7\x91\xe7\xa0\x94\xe5\xb7\xa5\xe4\xbd\x9c\xe8\x80\x85\xe7\x9a\x84\xe7\xa5\x9e\xe5\x99\xa8-zotero\xe8\xae\xba\xe6\x96\x87\xe7\xae\xa1\xe7\x90\x86\xe5\xb7\xa5\xe5\x85\xb7](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483673&idx=1&sn=013a1171e4c44ce19ffe0ffb743b45a8&chksm=c0791c00f70e9516ca6835acdfefaf539d3e121890354c6aba45fb6802fa8709f3a41cb856a7&scene=21#wechat_redirect)\n- [\xe5\xa6\x82\xe4\xbd\x95\xe5\x81\x9a\xe8\xa7\x86\xe9\xa2\x91\xe6\x95\x99\xe7\xa8\x8b\xe7\xac\x94\xe8\xae\xb0](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483829&idx=1&sn=75e97f26a4c9112c8efa932f16a63c1a&chksm=c0791cacf70e95ba585cc7bc302107eb5e5a733a58fe927d7016b590e351300306e78513c60b&scene=21#wechat_redirect)\n- [\xe7\xbb\x99\xe5\x88\x9d\xe5\xad\xa6\xe8\x80\x85\xe6\x8e\xa8\xe8\x8d\x90\xe4\xb8\x80\xe4\xb8\xaa\xe6\x91\x86\xe8\x84\xb1\xe5\x8f\x98\xe9\x87\x8f\xe5\x91\xbd\xe5\x90\x8d\xe7\xba\xa0\xe7\xbb\x93\xe7\x9a\x84\xe7\xa5\x9e\xe5\x99\xa8](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483992&idx=1&sn=06c1765f0eb06fd28888b3625c4ccff1&chksm=c0791f41f70e96576c11aa7c301096f5788931ccb4c6adf532d40e6a5de14ef3024f629f4824&scene=21#wechat_redirect)\n- [SQL\xe8\xaf\xad\xe6\xb3\x95\xe5\xa6\x82\xe4\xbd\x95\xe5\x85\xa5\xe9\x97\xa8\xef\xbc\x9f\xef\xbc\x88\xe9\x99\x84\xe8\xb5\x84\xe6\x96\x99\xe4\xb8\x8b\xe8\xbd\xbd\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483760&idx=1&sn=60acdd5afac45fc6d17f5c714389079d&chksm=c0791c69f70e957fbf51c1d213b66817e05b9f5edf9ce128131b4697ceb122798d1bed7eed98&scene=21#wechat_redirect)\n\n**\xe9\xa1\xb9\xe7\x9b\xae\xe5\x90\x88\xe4\xbd\x9c**\n\n- [\xe5\x85\xac\xe4\xbc\x97\xe5\x8f\xb7\xe5\x90\x88\xe4\xbd\x9c\xe6\x8c\x87\xe5\x8d\x97--\xe4\xb8\x8e\xe6\x9c\xac\xe7\xab\x99\xe4\xba\x92\xe7\x9b\xb8\xe6\xb7\xbb\xe5\x8a\xa0\xe9\x95\xbf\xe6\x9c\x9f\xe5\x8f\xaf\xe8\xbd\xac\xe8\xbd\xbd\xe8\xb4\xa6\xe5\x8f\xb7](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483996&idx=1&sn=c0d7eb311071ef1eba98d89e274a35b6&chksm=c0791f45f70e96533089471e6732450739eaa3c07d07e90290652636778eea17e2eac2fa8916&scene=21#wechat_redirect)\n- [\xe8\xb5\xa0\xe4\xba\xba\xe7\x8e\xab\xe7\x91\xb0,\xe6\x89\x8b\xe6\x9c\x89\xe4\xbd\x99\xe9\xa6\x99-\xe6\x9c\x9f\xe5\xbe\x85\xe5\x8d\x8f\xe4\xbd\x9c\xe6\x9b\xb4\xe6\x96\xb0\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9a\x84\xe5\x85\xac\xe7\x9b\x8a\xe9\xa1\xb9\xe7\x9b\xae ](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483924&idx=1&sn=751c23682abc116ec4c2401e942f4d4d&chksm=c0791f0df70e961bb602b004e70b5c3f780ca56fce49490d6e53cfdbbc374ed1c21c73bcf1a2&scene=21#wechat_redirect)\n\n**\xe8\xbf\x87\xe6\x97\xb6\xe6\x96\x87\xe7\xab\xa0**\n\n\xe8\xbf\x87\xe6\x97\xb6\xe8\xb5\x84\xe6\x96\x99\xe6\x8c\x87\xe7\x9a\x84\xe6\x98\xaf\xe6\x96\xb0\xe7\x9a\x84\xe6\x96\x87\xe7\xab\xa0\xe5\xb7\xb2\xe7\xbb\x8f\xe6\xb6\xb5\xe7\x9b\x96\xe4\xba\x86\xe6\x97\xa7\xe6\x96\x87\xe7\xab\xa0\xe5\x86\x85\xe5\xae\xb9\xef\xbc\x8c\xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xe5\x86\x8d\xe7\x9c\x8b\xe4\xba\x86\xe3\x80\x82\n\n- [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xae\x80\xe6\x98\x93\xe5\x85\xa5\xe9\x97\xa8-\xe9\x99\x84\xe6\x8e\xa8\xe8\x8d\x90\xe5\xad\xa6\xe4\xb9\xa0\xe8\xb5\x84\xe6\x96\x99](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483872&idx=1&sn=a8d462ba6bbe582fd35d6a1240c15f86&chksm=c0791cf9f70e95ef60751437a698b0bee4188405bc9bedebea34611a96f7207c10a9b7309bfa&scene=21#wechat_redirect)\n- [\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x88\x9d\xe5\xad\xa6\xe8\x80\x85\xe5\x85\xac\xe4\xbc\x97\xe5\x8f\xb7\xe4\xb8\x8b\xe8\xbd\xbd\xe8\xb5\x84\xe6\xba\x90\xe6\xb1\x87\xe6\x80\xbb\xef\xbc\x88\xe4\xb8\x80\xef\xbc\x89](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483792&idx=1&sn=5fe8d315183102be6f4ad92695d0f475&chksm=c0791c89f70e959fcbeda0ad8290093c8edc70b4fcb310073131bab1d01506795204726b7f07&scene=21#wechat_redirect)\n- [\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe8\x80\x85\xe7\x9a\x84\xe5\x85\xa5\xe9\x97\xa8\xe7\xa6\x8f\xe5\x88\xa9-Keras\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe7\xac\x94\xe8\xae\xb0](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483914&idx=1&sn=cecee99473f6d7d33565389c6de4ed16&chksm=c0791f13f70e9605b69e84ee7e1a1a30ff3b4e78e19b71766831e4fa438d2422fed270b15685&scene=21#wechat_redirect)\n- [9\xe6\x9c\x88\xe5\x9b\xbd\xe5\x86\x85\xe5\xa4\xa7\xe6\x95\xb0\xe6\x8d\xae\xe8\xb5\x9b\xe4\xba\x8b\xe8\xb5\x84\xe8\xae\xaf-\xe5\xa5\x96\xe6\xb1\xa01500\xe4\xb8\x87 ](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483701&idx=1&sn=96ac60cf968284a7ae75b733a52df8bd&chksm=c0791c2cf70e953a45690656f2bd68c25287b2ba0a0c31db4debde5a38808c68ad5d82403e81&scene=21#wechat_redirect)\n\n**\xe6\x9d\x82\xe8\xb0\x88**\n\n- [\xe4\xbd\xa0\xe4\xb8\x8d\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe4\xba\xba\xe5\x9c\xa8\xe6\x88\x98\xe6\x96\x97\xef\xbc\x81](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483699&idx=1&sn=1518fb758a87a89fdf4614952baf4069&chksm=c0791c2af70e953c0cb2289ccf672b1f2968273ce1b01b41a8a874853668681c0381e629db33&scene=21#wechat_redirect)\n- [\xe4\xb8\x8e\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9b\xb8\xe5\x85\xb3\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\xa6\xe5\xae\xb6\xef\xbc\x8c\xe4\xbd\xa0\xe8\xae\xa4\xe8\xaf\x86\xe5\x87\xa0\xe4\xb8\xaa\xef\xbc\x9f](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483740&idx=1&sn=e5cc3739911f4feb4c9bffed09de209b&chksm=c0791c45f70e9553b2eb33459ecc116327018013a288e0de5b33c39052f2103390ea2697f2ce&scene=21#wechat_redirect)\n- [\xe8\xb5\x9a\xe7\x9a\x84\xe9\x92\xb1\xe9\x9c\x80\xe8\xa6\x81\xe6\x9c\x89\xe5\x91\xbd\xe6\x9d\xa5\xe8\x8a\xb1-\xe9\xab\x98\xe8\x96\xaa\xe7\x9a\x84\xe4\xba\x92\xe8\x81\x94\xe7\xbd\x91\xe4\xbb\x8e\xe4\xb8\x9a\xe4\xba\xba\xe5\x91\x98\xe6\x9b\xb4\xe9\x9c\x80\xe8\xa6\x81\xe6\xb3\xa8\xe6\x84\x8f\xe8\xba\xab\xe4\xbd\x93\xe5\x81\xa5\xe5\xba\xb7](http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247483824&idx=1&sn=36f5cdfe9b3830ccb1566d9a4877ffa7&chksm=c0791ca9f70e95bfa5f49d6e411935766a8c1b17a0d831a41f30115a30bbbde485eeb2cf0c95&scene=21#wechat_redirect)\n'"
55,humphd/have-fun-with-machine-learning,humphd,An absolute beginner's guide to Machine Learning and Image Classification with Neural Networks,2016-12-29 17:43:50,2020-06-14 15:22:27,Python,539,4851,"b'# Have Fun with Machine Learning: A Guide for Beginners\nAlso available in [Chinese (Traditional)](README_zh-tw.md).\n\n## Preface\n\nThis is a **hands-on guide** to machine learning for programmers with *no background* in\nAI. Using a neural network doesn\xe2\x80\x99t require a PhD, and you don\xe2\x80\x99t need to be the person who\nmakes the next breakthrough in AI in order to *use* what exists today.  What we have now\nis already breathtaking, and highly usable.  I believe that more of us need to play with\nthis stuff like we would any other open source technology, instead of treating it like a\nresearch topic.\n\nIn this guide our goal will be to write a program that uses machine learning to predict, with a\nhigh degree of certainty, whether the images in [data/untrained-samples](data/untrained-samples)\nare of **dolphins** or **seahorses** using only the images themselves, and without\nhaving seen them before.  Here are two example images we\'ll use:\n\n![A dolphin](data/untrained-samples/dolphin1.jpg?raw=true ""Dolphin"")\n![A seahorse](data/untrained-samples/seahorse1.jpg?raw=true ""Seahorse"")\n\nTo do that we\xe2\x80\x99re going to train and use a [Convolutional Neural Network (CNN)](https://en.wikipedia.org/wiki/Convolutional_neural_network).\nWe\xe2\x80\x99re going to approach this from the point of view of a practitioner vs.\nfrom first principles. There is so much excitement about AI right now,\nbut much of what\xe2\x80\x99s being written feels like being taught to do\ntricks on your bike by a physics professor at a chalkboard instead\nof your friends in the park.\n\nI\xe2\x80\x99ve decided to write this on Github vs. as a blog post\nbecause I\xe2\x80\x99m sure that some of what I\xe2\x80\x99ve written below is misleading, naive, or\njust plain wrong.  I\xe2\x80\x99m still learning myself, and I\xe2\x80\x99ve found the lack of solid\nbeginner documentation an obstacle.  If you see me making a mistake or missing\nimportant details, please send a pull request. \n\nWith all of that out the way, let me show you how to do some tricks on your bike!\n\n## Overview\n\nHere\xe2\x80\x99s what we\xe2\x80\x99re going to explore:\n\n* Setup and use existing, open source machine learning technologies, specifically [Caffe](http://caffe.berkeleyvision.org/) and [DIGITS](https://developer.nvidia.com/digits)\n* Create a dataset of images\n* Train a neural network from scratch\n* Test our neural network on images it has never seen before\n* Improve our neural network\xe2\x80\x99s accuracy by fine tuning existing neural networks (AlexNet and GoogLeNet)\n* Deploy and use our neural network\n\nThis guide won\xe2\x80\x99t teach you how neural networks are designed, cover much theory,\nor use a single mathematical expression.  I don\xe2\x80\x99t pretend to understand most of\nwhat I\xe2\x80\x99m going to show you.  Instead, we\xe2\x80\x99re going to use existing things in\ninteresting ways to solve a hard problem.\n\n> Q: ""I know you said we won\xe2\x80\x99t talk about the theory of neural networks, but I\xe2\x80\x99m\n> feeling like I\xe2\x80\x99d at least like an overview before we get going.  Where should I start?""\n\nThere are literally hundreds of introductions to this, from short posts to full\nonline courses.  Depending on how you like to learn, here are three options\nfor a good starting point:\n\n* This fantastic [blog post](https://jalammar.github.io/visual-interactive-guide-basics-neural-networks/) by J Alammar,\nwhich introduces the concepts of neural networks using intuitive examples.\n* Similarly, [this video](https://www.youtube.com/watch?v=FmpDIaiMIeA) introduction by [Brandon Rohrer](https://www.youtube.com/channel/UCsBKTrp45lTfHa_p49I2AEQ) is a really good intro to\nConvolutional Neural Networks like we\'ll be using\n* If you\xe2\x80\x99d rather have a bit more theory, I\xe2\x80\x99d recommend [this online book](http://neuralnetworksanddeeplearning.com/chap1.html) by [Michael Nielsen](http://michaelnielsen.org/).\n\n## Setup\n\nInstalling the software we\'ll use (Caffe and DIGITS) can be frustrating, depending on your platform\nand OS version.  By far the easiest way to do it is using Docker.  Below we examine how to do it with Docker,\nas well as how to do it natively.\n\n### Option 1a: Installing Caffe Natively\n\nFirst, we\xe2\x80\x99re going to be using the [Caffe deep learning framework](http://caffe.berkeleyvision.org/)\nfrom the Berkely Vision and Learning Center (BSD licensed).\n\n> Q: \xe2\x80\x9cWait a minute, why Caffe? Why not use something like TensorFlow,\n> which everyone is talking about these days\xe2\x80\xa6\xe2\x80\x9d  \n\nThere are a lot of great choices available, and you should look at all the\noptions.  [TensorFlow](https://www.tensorflow.org/) is great, and you should\nplay with it.  However, I\xe2\x80\x99m using Caffe for a number of reasons:\n\n* It\xe2\x80\x99s tailormade for computer vision problems\n* It has support for C++, Python, (with [node.js support](https://github.com/silklabs/node-caffe) coming)\n* It\xe2\x80\x99s fast and stable\n\nBut the **number one reason** I\xe2\x80\x99m using Caffe is that you **don\xe2\x80\x99t need to write any code** to work\nwith it.  You can do everything declaratively (Caffe uses structured text files to define the\nnetwork architecture) and using command-line tools.  Also, you can use some nice front-ends for Caffe to make\ntraining and validating your network a lot easier.  We\xe2\x80\x99ll be using\n[nVidia\xe2\x80\x99s DIGITS](https://developer.nvidia.com/digits) tool below for just this purpose.\n\nCaffe can be a bit of work to get installed.  There are [installation instructions](http://caffe.berkeleyvision.org/installation.html)\nfor various platforms, including some prebuilt Docker or AWS configurations.  \n\n**NOTE:** when making my walkthrough, I used the following non-released version of Caffe from their Github repo:\nhttps://github.com/BVLC/caffe/commit/5a201dd960840c319cefd9fa9e2a40d2c76ddd73\n\nOn a Mac it can be frustrating to get working, with version issues halting\nyour progress at various steps in the build.  It took me a couple of days\nof trial and error.  There are a dozen guides I followed, each with slightly\ndifferent problems.  In the end I found [this one](https://gist.github.com/doctorpangloss/f8463bddce2a91b949639522ea1dcbe4) to be the closest.\nI\xe2\x80\x99d also recommend [this post](https://eddiesmo.wordpress.com/2016/12/20/how-to-set-up-caffe-environment-and-pycaffe-on-os-x-10-12-sierra/),\nwhich is quite recent and links to many of the same discussions I saw. \n\nGetting Caffe installed is by far the hardest thing we\'ll do, which is pretty\nneat, since you\xe2\x80\x99d assume the AI aspects would be harder!  Don\xe2\x80\x99t give up if you have\nissues, it\xe2\x80\x99s worth the pain.  If I was doing this again, I\xe2\x80\x99d probably use an Ubuntu VM\ninstead of trying to do it on Mac directly.  There\'s also a [Caffe Users](https://groups.google.com/forum/#!forum/caffe-users) group, if you need answers.\n\n> Q: \xe2\x80\x9cDo I need powerful hardware to train a neural network? What if I don\xe2\x80\x99t have\n> access to fancy GPUs?\xe2\x80\x9d\n\nIt\xe2\x80\x99s true, deep neural networks require a lot of computing power and energy to\ntrain...if you\xe2\x80\x99re training them from scratch and using massive datasets.\nWe aren\xe2\x80\x99t going to do that.  The secret is to use a pretrained network that someone\nelse has already invested hundreds of hours of compute time training, and then to fine\ntune it to your particular dataset.  We\xe2\x80\x99ll look at how to do this below, but suffice\nit to say that everything I\xe2\x80\x99m going to show you, I\xe2\x80\x99m doing on a year old MacBook\nPro without a fancy GPU.\n\nAs an aside, because I have an integrated Intel graphics card vs. an nVidia GPU,\nI decided to use the [OpenCL Caffe branch](https://github.com/BVLC/caffe/tree/opencl),\nand it\xe2\x80\x99s worked great on my laptop.\n\nWhen you\xe2\x80\x99re done installing Caffe, you should have, or be able to do all of the following:\n\n* A directory that contains your built caffe.  If you did this in the standard way,\nthere will be a `build/` dir which contains everything you need to run caffe,\nthe Python bindings, etc.  The parent dir that contains `build/` will be your\n`CAFFE_ROOT` (we\xe2\x80\x99ll need this later).\n* Running `make test && make runtest` should pass\n* After installing all the Python deps (doing `pip install -r requirements.txt` in `python/`),\nrunning `make pycaffe && make pytest` should pass\n* You should also run `make distribute` in order to create a distributable version of caffe with all necessary headers, binaries, etc. in `distribute/`.\n\nOn my machine, with Caffe fully built, I\xe2\x80\x99ve got the following basic layout in my CAFFE_ROOT dir:\n\n```\ncaffe/\n    build/\n        python/\n        lib/\n        tools/\n            caffe \xe2\x86\x90 this is our main binary \n    distribute/\n        python/\n        lib/\n        include/\n        bin/\n        proto/\n```\n\nAt this point, we have everything we need to train, test, and program with neural\nnetworks.  In the next section we\xe2\x80\x99ll add a user-friendly, web-based front end to\nCaffe called DIGITS, which will make training and testing our networks much easier.\n\n### Option 1b: Installing DIGITS Natively\n\nnVidia\xe2\x80\x99s [Deep Learning GPU Training System, or DIGITS](https://github.com/NVIDIA/DIGITS),\nis BSD-licensed Python web app for training neural networks.  While it\xe2\x80\x99s\npossible to do everything DIGITS does in Caffe at the command-line, or with code,\nusing DIGITS makes it a lot easier to get started.  I also found it more fun, due\nto the great visualizations, real-time charts, and other graphical features.\nSince you\xe2\x80\x99re experimenting and trying to learn, I highly recommend beginning with DIGITS.\n\nThere are quite a few good docs at https://github.com/NVIDIA/DIGITS/tree/master/docs,\nincluding a few [Installation](https://github.com/NVIDIA/DIGITS/blob/master/docs/BuildDigits.md),\n[Configuration](https://github.com/NVIDIA/DIGITS/blob/master/docs/Configuration.md),\nand [Getting Started](https://github.com/NVIDIA/DIGITS/blob/master/docs/GettingStarted.md)\npages.  I\xe2\x80\x99d recommend reading through everything there before you continue, as I\xe2\x80\x99m not\nan expert on everything you can do with DIGITS.  There\'s also a public [DIGITS User Group](https://groups.google.com/forum/#!forum/digits-users) if you have questions you need to ask.\n\nThere are various ways to install and run DIGITS, from Docker to pre-baked packages\non Linux, or you can build it from source. I\xe2\x80\x99m on a Mac, so I built it from source.\n\n**NOTE:** In my walkthrough I\'ve used the following non-released version of DIGITS\nfrom their Github repo: https://github.com/NVIDIA/DIGITS/commit/81be5131821ade454eb47352477015d7c09753d9\n\nBecause it\xe2\x80\x99s just a bunch of Python scripts, it was fairly painless to get working.\nThe one thing you need to do is tell DIGITS where your `CAFFE_ROOT` is by setting\nan environment variable before starting the server:\n\n```bash\nexport CAFFE_ROOT=/path/to/caffe\n./digits-devserver\n```\n\nNOTE: on Mac I had issues with the server scripts assuming my Python binary was\ncalled `python2`, where I only have `python2.7`.  You can symlink it in `/usr/bin`\nor modify the DIGITS startup script(s) to use the proper binary on your system.\n\nOnce the server is started, you can do everything else via your web browser at http://localhost:5000, which is what I\'ll do below.\n\n### Option 2: Caffe and DIGITS using Docker\n\nInstall [Docker](https://www.docker.com/), if not already installed, then run the following command\nin order to pull and run a full Caffe + Digits container.  A few things to note:\n* make sure port 8080 isn\'t allocated by another program. If so, change it to any other port you want.\n* change `/path/to/this/repository` to the location of this cloned repo, and `/data/repo` within the container\nwill be bound to this directory.  This is useful for accessing the images discussed below.\n\n```bash\ndocker run --name digits -d -p 8080:5000 -v /path/to/this/repository:/data/repo kaixhin/digits\n```\n\nNow that we have our container running you can open up your web browser and open\xc2\xa0`http://localhost:8080`. Everything in the repository is now in the container directory `/data/repo`.  That\'s it. You\'ve now got Caffe and DIGITS working.\n\nIf you need shell access, use the following command:\n\n```bash\ndocker exec -it digits /bin/bash\n```\n\n## Training a Neural Network\n\nTraining a neural network involves a few steps:\n\n1. Assemble and prepare a dataset of categorized images\n2. Define the network\xe2\x80\x99s architecture\n3. Train and Validate this network using the prepared dataset\n\nWe\xe2\x80\x99re going to do this 3 different ways, in order to show the difference\nbetween starting from scratch and using a pretrained network, and also to show\nhow to work with two popular pretrained networks (AlexNet, GoogLeNet) that are\ncommonly used with Caffe and DIGITs.\n\nFor our training attempts, we\xe2\x80\x99ll use a small dataset of Dolphins and Seahorses.\nI\xe2\x80\x99ve put the images I used in [data/dolphins-and-seahorses](data/dolphins-and-seahorses).\nYou need at least 2 categories, but could have many more (some of the networks\nwe\xe2\x80\x99ll use were trained on 1000+ image categories).  Our goal is to be able to\ngive an image to our network and have it tell us whether it\xe2\x80\x99s a Dolphin or a Seahorse.\n\n### Prepare the Dataset\n\nThe easiest way to begin is to divide your images into a categorized directory layout:\n\n```\ndolphins-and-seahorses/\n    dolphin/\n        image_0001.jpg\n        image_0002.jpg\n        image_0003.jpg\n        ...\n    seahorse/\n        image_0001.jpg\n        image_0002.jpg\n        image_0003.jpg\n        ...\n```\n\nHere each directory is a category we want to classify, and each image within\nthat category dir an example we\xe2\x80\x99ll use for training and validation. \n\n> Q: \xe2\x80\x9cDo my images have to be the same size?  What about the filenames, do they matter?\xe2\x80\x9d\n\nNo to both. The images sizes will be normalized before we feed them into\nthe network.  We\xe2\x80\x99ll eventually want colour images of 256 x 256 pixels, but\nDIGITS will crop or squash (we\'ll squash) our images automatically in a moment.\nThe filenames are irrelevant--it\xe2\x80\x99s only important which category they are contained\nwithin.\n\n> Q: \xe2\x80\x9cCan I do more complex segmentation of my categories?\xe2\x80\x9d\n\nYes. See https://github.com/NVIDIA/DIGITS/blob/digits-4.0/docs/ImageFolderFormat.md.\n\nWe want to use these images on disk to create a **New Dataset**, and specifically,\na **Classification Dataset**.\n\n![Create New Dataset](images/create-new-dataset.png?raw=true ""Create New Dataset"")\n\nWe\xe2\x80\x99ll use the defaults DIGITS gives us, and point **Training Images** at the path\nto our [data/dolphins-and-seahorses](data/dolphins-and-seahorses) folder.\nDIGITS will use the categories (`dolphin` and `seahorse`) to create a database\nof squashed, 256 x 256 Training (75%) and Testing (25%) images.\n\nGive your Dataset a name,`dolphins-and-seahorses`, and click **Create**.\n\n![New Image Classification Dataset](images/new-image-classification-dataset.png?raw=true ""New Image Classification Dataset"")\n\nThis will create our dataset, which took only 4s on my laptop.  In the end I\nhave 92 Training images (49 dolphin, 43 seahorse) in 2 categories, with 30\nValidation images (16 dolphin, 14 seahorse).  It\xe2\x80\x99s a really small dataset, but perfect\nfor our experimentation and learning purposes, because it won\xe2\x80\x99t take forever to train\nand validate a network that uses it. \n\nYou can **Explore the db** if you want to see the images after they have been squashed. \n\n![Explore the db](images/explore-dataset.png?raw=true ""Explore the db"")\n\n### Training: Attempt 1, from Scratch\n\nBack in the DIGITS Home screen, we need to create a new **Classification Model**:\n\n![Create Classification Model](images/create-classification-model.png?raw=true ""Create Classification Model"")\n\nWe\xe2\x80\x99ll start by training a model that uses our `dolphins-and-seahorses` dataset,\nand the default settings DIGITS provides.  For our first network, we\xe2\x80\x99ll choose to\nuse one of the standard network architectures, [AlexNet (pdf)](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf). [AlexNet\xe2\x80\x99s design](http://vision.stanford.edu/teaching/cs231b_spring1415/slides/alexnet_tugce_kyunghee.pdf)\nwon a major computer vision competition called ImageNet in 2012.  The competition\nrequired categorizing 1000+ image categories across 1.2 million images.\n \n![New Classification Model 1](images/new-image-classification-model-attempt1.png?raw=true ""Model 1"")\n\nCaffe uses structured text files to define network architectures.  These text files\nare based on [Google\xe2\x80\x99s Protocol Buffers](https://developers.google.com/protocol-buffers/).\nYou can read the [full schema](https://github.com/BVLC/caffe/blob/master/src/caffe/proto/caffe.proto) Caffe uses.\nFor the most part we\xe2\x80\x99re not going to work with these, but it\xe2\x80\x99s good to be aware of their\nexistence, since we\xe2\x80\x99ll have to modify them in later steps.  The AlexNet prototxt file\nlooks like this, for example: https://github.com/BVLC/caffe/blob/master/models/bvlc_alexnet/train_val.prototxt. \n\nWe\xe2\x80\x99ll train our network for **30 epochs**, which means that it will learn (with our\ntraining images) then test itself (using our validation images), and adjust the\nnetwork\xe2\x80\x99s weights depending on how well it\xe2\x80\x99s doing, and repeat this process 30 times.\nEach time it completes a cycle we\xe2\x80\x99ll get info about **Accuracy** (0% to 100%,\nwhere higher is better) and what our **Loss** is (the sum of all the mistakes that were\nmade, where lower is better).  Ideally we want a network that is able to predict with\nhigh accuracy, and with few errors (small loss).\n\n**NOTE:** some people have [reported hitting errors in DIGITS](https://github.com/humphd/have-fun-with-machine-learning/issues/17)\ndoing this training run. For many, the problem related to available memory (the process\nneeds a lot of memory to work).  If you\'re using Docker, you might want to try\nincreasing the amount of memory available to DIGITS (in Docker, preferences -> advanced -> memory).\n\nInitially, our network\xe2\x80\x99s accuracy is a bit below 50%.  This makes sense, because at first it\xe2\x80\x99s\njust \xe2\x80\x9cguessing\xe2\x80\x9d between two categories using randomly assigned weights.  Over time\nit\xe2\x80\x99s able to achieve 87.5% accuracy, with a loss of 0.37.  The entire 30 epoch run\ntook me just under 6 minutes.\n\n![Model Attempt 1](images/model-attempt1.png?raw=true ""Model Attempt 1"")\n\nWe can test our model using an image we upload or a URL to an image on the web.\nLet\xe2\x80\x99s test it on a few examples that weren\xe2\x80\x99t in our training/validation dataset:\n\n![Model 1 Classify 1](images/model-attempt1-classify1.png?raw=true ""Model 1 Classify 1"")\n\n![Model 1 Classify 2](images/model-attempt1-classify2.png?raw=true ""Model 1 Classify 2"")\n\nIt almost seems perfect, until we try another:\n\n![Model 1 Classify 3](images/model-attempt1-classify3.png?raw=true ""Model 1 Classify 3"")\n\nHere it falls down completely, and confuses a seahorse for a dolphin, and worse,\ndoes so with a high degree of confidence.\n\nThe reality is that our dataset is too small to be useful for training a really good\nneural network.  We really need 10s or 100s of thousands of images, and with that, a\nlot of computing power to process everything.\n\n### Training: Attempt 2, Fine Tuning AlexNet\n\n#### How Fine Tuning works\n\nDesigning a neural network from scratch, collecting data sufficient to train\nit (e.g., millions of images), and accessing GPUs for weeks to complete the\ntraining is beyond the reach of most of us.  To make it practical for smaller amounts\nof data to be used, we employ a technique called **Transfer Learning**, or **Fine Tuning**.\nFine tuning takes advantage of the layout of deep neural networks, and uses\npretrained networks to do the hard work of initial object detection.\n\nImagine using a neural network to be like looking at something far away with a \npair of binoculars.  You first put the binoculars to your eyes, and everything is\nblurry.  As you adjust the focus, you start to see colours, lines, shapes, and eventually\nyou are able to pick out the shape of a bird, then with some more adjustment you can\nidentify the species of bird.\n\nIn a multi-layered network, the initial layers extract features (e.g., edges), with\nlater layers using these features to detect shapes (e.g., a wheel, an eye), which are\nthen feed into final classification layers that detect items based on accumulated \ncharacteristics from previous layers (e.g., a cat vs. a dog).  A network has to be \nable to go from pixels to circles to eyes to two eyes placed in a particular orientation, \nand so on up to being able to finally conclude that an image depicts a cat.\n\nWhat we\xe2\x80\x99d like to do is to specialize an existing, pretrained network for classifying \na new set of image classes instead of the ones on which it was initially trained. Because\nthe network already knows how to \xe2\x80\x9csee\xe2\x80\x9d features in images, we\xe2\x80\x99d like to retrain \nit to \xe2\x80\x9csee\xe2\x80\x9d our particular image types.  We don\xe2\x80\x99t need to start from scratch with the \nmajority of the layers--we want to transfer the learning already done in these layers \nto our new classification task.  Unlike our previous attempt, which used random weights, \nwe\xe2\x80\x99ll use the existing weights of the final network in our training.  However, we\xe2\x80\x99ll \nthrow away the final classification layer(s) and retrain the network with *our* image \ndataset, fine tuning it to our image classes.\n\nFor this to work, we need a pretrained network that is similar enough to our own data\nthat the learned weights will be useful.  Luckily, the networks we\xe2\x80\x99ll use below were \ntrained on millions of natural images from [ImageNet](http://image-net.org/), which \nis useful across a broad range of classification tasks.\n\nThis technique has been used to do interesting things like screening for eye diseases \nfrom medical imagery, identifying plankton species from microscopic images collected at \nsea, to categorizing the artistic style of Flickr images.\n\nDoing this perfectly, like all of machine learning, requires you to understand the\ndata and network architecture--you have to be careful with overfitting of the data, \nmight need to fix some of the layers, might need to insert new layers, etc. However,\nmy experience is that it \xe2\x80\x9cJust Works\xe2\x80\x9d much of the time, and it\xe2\x80\x99s worth you simply doing\nan experiment to see what you can achieve using our naive approach.\n\n#### Uploading Pretrained Networks\n\nIn our first attempt, we used AlexNet\xe2\x80\x99s architecture, but started with random\nweights in the network\xe2\x80\x99s layers.  What we\xe2\x80\x99d like to do is download and use a\nversion of AlexNet that has already been trained on a massive dataset.\n\nThankfully we can do exactly this.  A snapshot of AlexNet is available for download: https://github.com/BVLC/caffe/tree/master/models/bvlc_alexnet.\nWe need the binary `.caffemodel` file, which is what contains the trained weights, and it\xe2\x80\x99s\navailable for download at http://dl.caffe.berkeleyvision.org/bvlc_alexnet.caffemodel.\n\nWhile you\xe2\x80\x99re downloading pretrained models, let\xe2\x80\x99s get one more at the same time.\nIn 2014, Google won the same ImageNet competition with [GoogLeNet](https://research.google.com/pubs/pub43022.html) (codenamed Inception):\na 22-layer neural network. A snapshot of GoogLeNet is available for download\nas well, see https://github.com/BVLC/caffe/tree/master/models/bvlc_googlenet.\nAgain, we\xe2\x80\x99ll need the `.caffemodel` file with all the pretrained weights,\nwhich is available for download at http://dl.caffe.berkeleyvision.org/bvlc_googlenet.caffemodel. \n\nWith these `.caffemodel` files in hand, we can upload them into DIGITs.  Go to\nthe **Pretrained Models** tab in DIGITs home page and choose **Upload Pretrained Model**:\n\n![Load Pretrained Model](images/load-pretrained-model.png?raw=true ""Load Pretrained Model"")\n\nFor both of these pretrained models, we can use the defaults DIGITs provides\n(i.e., colour, squashed images of 256 x 256).  We just need to provide the \n`Weights (**.caffemodel)` and `Model Definition (original.prototxt)`.\nClick each of those buttons to select a file.\n\nFor the model definitions we can use https://github.com/BVLC/caffe/blob/master/models/bvlc_googlenet/train_val.prototxt\nfor GoogLeNet and https://github.com/BVLC/caffe/blob/master/models/bvlc_alexnet/train_val.prototxt\nfor AlexNet.  We aren\xe2\x80\x99t going to use the classification labels of these networks,\nso we\xe2\x80\x99ll skip adding a `labels.txt` file:\n \n![Upload Pretrained Model](images/upload-pretrained-model.png?raw=true ""Upload Pretrained Model"")\n\nRepeat this process for both AlexNet and GoogLeNet, as we\xe2\x80\x99ll use them both in the coming steps.\n\n> Q: ""Are there other networks that would be good as a basis for fine tuning?""\n\nThe [Caffe Model Zoo](http://caffe.berkeleyvision.org/model_zoo.html) has quite a few other\npretrained networks that could be used, see https://github.com/BVLC/caffe/wiki/Model-Zoo.\n\n#### Fine Tuning AlexNet for Dolphins and Seahorses\n\nTraining a network using a pretrained Caffe Model is similar to starting from scratch,\nthough we have to make a few adjustments.  First, we\xe2\x80\x99ll adjust the **Base Learning Rate**\nto 0.001 from 0.01, since we don\xe2\x80\x99t need to make such large jumps (i.e., we\xe2\x80\x99re fine tuning).\nWe\xe2\x80\x99ll also use a **Pretrained Network**, and **Customize** it.\n\n![New Image Classification](images/new-image-classification-model-attempt2.png?raw=true ""New Image Classification"")\n\nIn the pretrained model\xe2\x80\x99s definition (i.e., prototext), we need to rename all\nreferences to the final **Fully Connected Layer** (where the end result classifications\nhappen).  We do this because we want the model to re-learn new categories from\nour dataset vs. its original training data (i.e., we want to throw away the current\nfinal layer).  We have to rename the last fully connected layer from \xe2\x80\x9cfc8\xe2\x80\x9d to\nsomething else, \xe2\x80\x9cfc9\xe2\x80\x9d for example.  Finally, we also need to adjust the number\nof categories from `1000` to `2`, by changing `num_output` to `2`.\n\nHere are the changes we need to make:\n\n```diff\n@@ -332,8 +332,8 @@\n }\n layer {\n-  name: ""fc8""\n+  name: ""fc9""\n   type: ""InnerProduct""\n   bottom: ""fc7""\n-  top: ""fc8""\n+  top: ""fc9""\n   param {\n     lr_mult: 1\n@@ -345,5 +345,5 @@\n   }\n   inner_product_param {\n-    num_output: 1000\n+    num_output: 2\n     weight_filler {\n       type: ""gaussian""\n@@ -359,5 +359,5 @@\n   name: ""accuracy""\n   type: ""Accuracy""\n-  bottom: ""fc8""\n+  bottom: ""fc9""\n   bottom: ""label""\n   top: ""accuracy""\n@@ -367,5 +367,5 @@\n   name: ""loss""\n   type: ""SoftmaxWithLoss""\n-  bottom: ""fc8""\n+  bottom: ""fc9""\n   bottom: ""label""\n   top: ""loss""\n@@ -375,5 +375,5 @@\n   name: ""softmax""\n   type: ""Softmax""\n-  bottom: ""fc8""\n+  bottom: ""fc9""\n   top: ""softmax""\n   include { stage: ""deploy"" }\n```\n\nI\xe2\x80\x99ve included the fully modified file I\xe2\x80\x99m using in [src/alexnet-customized.prototxt](src/alexnet-customized.prototxt).\n\nThis time our accuracy starts at ~60% and climbs right away to 87.5%, then to 96%\nand all the way up to 100%, with the Loss steadily decreasing. After 5 minutes we\nend up with an accuracy of 100% and a loss of 0.0009.\n\n![Model Attempt 2](images/model-attempt2.png?raw=true ""Model Attempt 2"")\n\nTesting the same seahorse image our previous network got wrong, we see a complete\nreversal: 100% seahorse.\n\n![Model 2 Classify 1](images/model-attempt2-classify1.png?raw=true ""Model 2 Classify 1"")\n\nEven a children\xe2\x80\x99s drawing of a seahorse works:\n\n![Model 2 Classify 2](images/model-attempt2-classify2.png?raw=true ""Model 2 Classify 2"")\n\nThe same goes for a dolphin:\n\n![Model 2 Classify 3](images/model-attempt2-classify3.png?raw=true ""Model 2 Classify 3"")\n\nEven with images that you think might be hard, like this one that has multiple dolphins\nclose together, and with their bodies mostly underwater, it does the right thing:\n\n![Model 2 Classify 4](images/model-attempt2-classify4.png?raw=true ""Model 2 Classify 4"")\n\n### Training: Attempt 3, Fine Tuning GoogLeNet\n\nLike the previous AlexNet model we used for fine tuning, we can use GoogLeNet as well.\nModifying the network is a bit trickier, since you have to redefine three fully\nconnected layers instead of just one.\n\nTo fine tune GoogLeNet for our use case, we need to once again create a\nnew **Classification Model**:\n\n![New Classification Model](images/new-image-classification-model-attempt3.png?raw=true ""New Classification Model"")\n\nWe rename all references to the three fully connected classification layers,\n`loss1/classifier`, `loss2/classifier`, and `loss3/classifier`, and redefine\nthe number of categories (`num_output: 2`).  Here are the changes we need to make\nin order to rename the 3 classifier layers, as well as to change from 1000 to 2 categories:\n\n```diff\n@@ -917,10 +917,10 @@\n   exclude { stage: ""deploy"" }\n }\n layer {\n-  name: ""loss1/classifier""\n+  name: ""loss1a/classifier""\n   type: ""InnerProduct""\n   bottom: ""loss1/fc""\n-  top: ""loss1/classifier""\n+  top: ""loss1a/classifier""\n   param {\n     lr_mult: 1\n     decay_mult: 1\n@@ -930,7 +930,7 @@\n     decay_mult: 0\n   }\n   inner_product_param {\n-    num_output: 1000\n+    num_output: 2\n     weight_filler {\n       type: ""xavier""\n       std: 0.0009765625\n@@ -945,7 +945,7 @@\n layer {\n   name: ""loss1/loss""\n   type: ""SoftmaxWithLoss""\n-  bottom: ""loss1/classifier""\n+  bottom: ""loss1a/classifier""\n   bottom: ""label""\n   top: ""loss1/loss""\n   loss_weight: 0.3\n@@ -954,7 +954,7 @@\n layer {\n   name: ""loss1/top-1""\n   type: ""Accuracy""\n-  bottom: ""loss1/classifier""\n+  bottom: ""loss1a/classifier""\n   bottom: ""label""\n   top: ""loss1/accuracy""\n   include { stage: ""val"" }\n@@ -962,7 +962,7 @@\n layer {\n   name: ""loss1/top-5""\n   type: ""Accuracy""\n-  bottom: ""loss1/classifier""\n+  bottom: ""loss1a/classifier""\n   bottom: ""label""\n   top: ""loss1/accuracy-top5""\n   include { stage: ""val"" }\n@@ -1705,10 +1705,10 @@\n   exclude { stage: ""deploy"" }\n }\n layer {\n-  name: ""loss2/classifier""\n+  name: ""loss2a/classifier""\n   type: ""InnerProduct""\n   bottom: ""loss2/fc""\n-  top: ""loss2/classifier""\n+  top: ""loss2a/classifier""\n   param {\n     lr_mult: 1\n     decay_mult: 1\n@@ -1718,7 +1718,7 @@\n     decay_mult: 0\n   }\n   inner_product_param {\n-    num_output: 1000\n+    num_output: 2\n     weight_filler {\n       type: ""xavier""\n       std: 0.0009765625\n@@ -1733,7 +1733,7 @@\n layer {\n   name: ""loss2/loss""\n   type: ""SoftmaxWithLoss""\n-  bottom: ""loss2/classifier""\n+  bottom: ""loss2a/classifier""\n   bottom: ""label""\n   top: ""loss2/loss""\n   loss_weight: 0.3\n@@ -1742,7 +1742,7 @@\n layer {\n   name: ""loss2/top-1""\n   type: ""Accuracy""\n-  bottom: ""loss2/classifier""\n+  bottom: ""loss2a/classifier""\n   bottom: ""label""\n   top: ""loss2/accuracy""\n   include { stage: ""val"" }\n@@ -1750,7 +1750,7 @@\n layer {\n   name: ""loss2/top-5""\n   type: ""Accuracy""\n-  bottom: ""loss2/classifier""\n+  bottom: ""loss2a/classifier""\n   bottom: ""label""\n   top: ""loss2/accuracy-top5""\n   include { stage: ""val"" }\n@@ -2435,10 +2435,10 @@\n   }\n }\n layer {\n-  name: ""loss3/classifier""\n+  name: ""loss3a/classifier""\n   type: ""InnerProduct""\n   bottom: ""pool5/7x7_s1""\n-  top: ""loss3/classifier""\n+  top: ""loss3a/classifier""\n   param {\n     lr_mult: 1\n     decay_mult: 1\n@@ -2448,7 +2448,7 @@\n     decay_mult: 0\n   }\n   inner_product_param {\n-    num_output: 1000\n+    num_output: 2\n     weight_filler {\n       type: ""xavier""\n     }\n@@ -2461,7 +2461,7 @@\n layer {\n   name: ""loss3/loss""\n   type: ""SoftmaxWithLoss""\n-  bottom: ""loss3/classifier""\n+  bottom: ""loss3a/classifier""\n   bottom: ""label""\n   top: ""loss""\n   loss_weight: 1\n@@ -2470,7 +2470,7 @@\n layer {\n   name: ""loss3/top-1""\n   type: ""Accuracy""\n-  bottom: ""loss3/classifier""\n+  bottom: ""loss3a/classifier""\n   bottom: ""label""\n   top: ""accuracy""\n   include { stage: ""val"" }\n@@ -2478,7 +2478,7 @@\n layer {\n   name: ""loss3/top-5""\n   type: ""Accuracy""\n-  bottom: ""loss3/classifier""\n+  bottom: ""loss3a/classifier""\n   bottom: ""label""\n   top: ""accuracy-top5""\n   include { stage: ""val"" }\n@@ -2489,7 +2489,7 @@\n layer {\n   name: ""softmax""\n   type: ""Softmax""\n-  bottom: ""loss3/classifier""\n+  bottom: ""loss3a/classifier""\n   top: ""softmax""\n   include { stage: ""deploy"" }\n }\n```\n\nI\xe2\x80\x99ve put the complete file in [src/googlenet-customized.prototxt](src/googlenet-customized.prototxt).\n\n> Q: ""What about changes to the prototext definitions of these networks?\n> We changed the fully connected layer name(s), and the number of categories.\n> What else could, or should be changed, and in what circumstances?""\n\nGreat question, and it\'s something I\'m wondering, too.  For example, I know that we can\n[""fix"" certain layers](https://github.com/BVLC/caffe/wiki/Fine-Tuning-or-Training-Certain-Layers-Exclusively)\nso the weights don\'t change.  Doing other things involves understanding how the layers work,\nwhich is beyond this guide, and also beyond its author at present!\n\nLike we did with fine tuning AlexNet, we also reduce the learning rate by\n10% from `0.01` to `0.001`.\n\n> Q: ""What other changes would make sense when fine tuning these networks?\n> What about different numbers of epochs, batch sizes, solver types (Adam, AdaDelta, AdaGrad, etc),\n> learning rates, policies (Exponential Decay, Inverse Decay, Sigmoid Decay, etc),\n> step sizes, and gamma values?""\n\nGreat question, and one that I wonder about as well.  I only have a vague understanding of these\nand it\xe2\x80\x99s likely that there are improvements we can make if you know how to alter these\nvalues when training.  This is something that needs better documentation.\n\nBecause GoogLeNet has a more complicated architecture than AlexNet, fine tuning it requires\nmore time.  On my laptop, it takes 10 minutes to retrain GoogLeNet with our dataset,\nachieving 100% accuracy and a loss of 0.0070:\n\n![Model Attempt 3](images/model-attempt3.png?raw=true ""Model Attempt 3"")\n\nJust as we saw with the fine tuned version of AlexNet, our modified GoogLeNet\nperforms amazing well--the best so far:\n\n![Model Attempt 3 Classify 1](images/model-attempt3-classify1.png?raw=true ""Model Attempt 3 Classify 1"")\n\n![Model Attempt 3 Classify 2](images/model-attempt3-classify2.png?raw=true ""Model Attempt 3 Classify 2"")\n\n![Model Attempt 3 Classify 3](images/model-attempt3-classify3.png?raw=true ""Model Attempt 3 Classify 3"")\n\n## Using our Model\n\nWith our network trained and tested, it\xe2\x80\x99s time to download and use it.  Each of the models\nwe trained in DIGITS has a **Download Model** button, as well as a way to select different\nsnapshots within our training run (e.g., `Epoch #30`):\n\n![Trained Models](images/trained-models.png?raw=true ""Trained Models"")\n\nClicking **Download Model** downloads a `tar.gz` archive containing the following files:\n\n```\ndeploy.prototxt\nmean.binaryproto\nsolver.prototxt\ninfo.json\noriginal.prototxt\nlabels.txt\nsnapshot_iter_90.caffemodel\ntrain_val.prototxt\n```\n\nThere\xe2\x80\x99s a [nice description](https://github.com/BVLC/caffe/wiki/Using-a-Trained-Network:-Deploy) in\nthe Caffe documentation about how to use the model we just built.  It says:\n\n> A network is defined by its design (.prototxt), and its weights (.caffemodel). As a network is\n> being trained, the current state of that network\'s weights are stored in a .caffemodel. With both\n> of these we can move from the train/test phase into the production phase.\n>\n> In its current state, the design of the network is not designed for deployment. Before we can\n> release our network as a product, we often need to alter it in a few ways:\n>\n> 1. Remove the data layer that was used for training, as for in the case of classification we are no longer providing labels for our data.\n> 2. Remove any layer that is dependent upon data labels.\n> 3. Set the network up to accept data.\n> 4. Have the network output the result.\n\nDIGITS has already done the work for us, separating out the different versions of our `prototxt` files.\nThe files we\xe2\x80\x99ll care about when using this network are:\n\n* `deploy.prototxt` - the definition of our network, ready for accepting image input data\n* `mean.binaryproto` - our model will need us to subtract the image mean from each image that it processes, and this is the mean image.\n* `labels.txt` - a list of our labels (`dolphin`, `seahorse`) in case we want to print them vs. just the category number\n* `snapshot_iter_90.caffemodel` - these are the trained weights for our network\n\nWe can use these files in a number of ways to classify new images.  For example, in our\n`CAFFE_ROOT` we can use `build/examples/cpp_classification/classification.bin` to classify one image:\n\n```bash\n$ cd $CAFFE_ROOT/build/examples/cpp_classification\n$ ./classification.bin deploy.prototxt snapshot_iter_90.caffemodel mean.binaryproto labels.txt dolphin1.jpg\n```\n\nThis will spit out a bunch of debug text, followed by the predictions for each of our two categories:\n\n```\n0.9997 - \xe2\x80\x9cdolphin\xe2\x80\x9d\n0.0003 - \xe2\x80\x9cseahorse\xe2\x80\x9d\n```\n\nYou can read the [complete C++ source](https://github.com/BVLC/caffe/tree/master/examples/cpp_classification)\nfor this in the [Caffe examples](https://github.com/BVLC/caffe/tree/master/examples).\n\nFor a classification version that uses the Python interface, DIGITS includes a [nice example](https://github.com/NVIDIA/DIGITS/tree/master/examples/classification).  There\'s also a fairly\n[well documented Python walkthrough](https://github.com/BVLC/caffe/blob/master/examples/00-classification.ipynb) in the Caffe examples.\n\n### Python example\n\nLet\'s write a program that uses our fine-tuned GoogLeNet model to classify the untrained images\nwe have in [data/untrained-samples](data/untrained-samples).  I\'ve cobbled this together based on\nthe examples above, as well as the `caffe` [Python module\'s source](https://github.com/BVLC/caffe/tree/master/python),\nwhich you should prefer to anything I\'m about to say.\n\nA full version of what I\'m going to discuss is available in [src/classify-samples.py](src/classify-samples.py).\nLet\'s begin!\n\nFirst, we\'ll need the [NumPy](http://www.numpy.org/) module.  In a moment we\'ll be using [NumPy](http://www.numpy.org/)\nto work with [`ndarray`s](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html), which Caffe uses a lot.\nIf you haven\'t used them before, as I had not, you\'d do well to begin by reading this\n[Quickstart tutorial](https://docs.scipy.org/doc/numpy-dev/user/quickstart.html).\n\nSecond, we\'ll need to load the `caffe` module from our `CAFFE_ROOT` dir.  If it\'s not already included\nin your Python environment, you can force it to load by adding it manually. Along with it we\'ll\nalso import caffe\'s protobuf module:\n\n```python\nimport numpy as np\n\ncaffe_root = \'/path/to/your/caffe_root\'\nsys.path.insert(0, os.path.join(caffe_root, \'python\'))\nimport caffe\nfrom caffe.proto import caffe_pb2\n```\n\nNext we need to tell Caffe whether to [use the CPU or GPU](https://github.com/BVLC/caffe/blob/61944afd4e948a4e2b4ef553919a886a8a8b8246/python/caffe/_caffe.cpp#L50-L52).\nFor our experiments, the CPU is fine:\n\n```python\ncaffe.set_mode_cpu()\n```\n\nNow we can use `caffe` to load our trained network.  To do so, we\'ll need some of the files we downloaded\nfrom DIGITS, namely:\n\n* `deploy.prototxt` - our ""network file"", the description of the network.\n* `snapshot_iter_90.caffemodel` - our trained ""weights""\n\nWe obviously need to provide the full path, and I\'ll assume that my files are in a dir called `model/`:\n\n```python\nmodel_dir = \'model\'\ndeploy_file = os.path.join(model_dir, \'deploy.prototxt\')\nweights_file = os.path.join(model_dir, \'snapshot_iter_90.caffemodel\')\nnet = caffe.Net(deploy_file, caffe.TEST, weights=weights_file)\n```\n\nThe `caffe.Net()` [constructor](https://github.com/BVLC/caffe/blob/61944afd4e948a4e2b4ef553919a886a8a8b8246/python/caffe/_caffe.cpp#L91-L117)\ntakes a network file, a phase (`caffe.TEST` or `caffe.TRAIN`), as well as an optional weights filename.  When\nwe provide a weights file, the `Net` will automatically load them for us. The `Net` has a number of\n[methods and attributes](https://github.com/BVLC/caffe/blob/master/python/caffe/pycaffe.py) you can use.\n\n**Note:** There is also a [deprecated version of this constructor](https://github.com/BVLC/caffe/blob/61944afd4e948a4e2b4ef553919a886a8a8b8246/python/caffe/_caffe.cpp#L119-L134),\nwhich seems to get used often in sample code on the web. It looks like this, in case you encounter it:\n\n```python\nnet = caffe.Net(str(deploy_file), str(model_file), caffe.TEST)\n```\n\nWe\'re interested in loading images of various sizes into our network for testing. As a result,\nwe\'ll need to *transform* them into a shape that our network can use (i.e., colour, 256x256).\nCaffe provides the [`Transformer` class](https://github.com/BVLC/caffe/blob/61944afd4e948a4e2b4ef553919a886a8a8b8246/python/caffe/io.py#L98)\nfor this purpose.  We\'ll use it to create a transformation appropriate for our images/network:\n\n```python\ntransformer = caffe.io.Transformer({\'data\': net.blobs[\'data\'].data.shape})\n# set_transpose: https://github.com/BVLC/caffe/blob/61944afd4e948a4e2b4ef553919a886a8a8b8246/python/caffe/io.py#L187\ntransformer.set_transpose(\'data\', (2, 0, 1))\n# set_raw_scale: https://github.com/BVLC/caffe/blob/61944afd4e948a4e2b4ef553919a886a8a8b8246/python/caffe/io.py#L221\ntransformer.set_raw_scale(\'data\', 255)\n# set_channel_swap: https://github.com/BVLC/caffe/blob/61944afd4e948a4e2b4ef553919a886a8a8b8246/python/caffe/io.py#L203\ntransformer.set_channel_swap(\'data\', (2, 1, 0))\n```\n\nWe can also use the `mean.binaryproto` file DIGITS gave us to set our transformer\'s mean:\n\n```python\n# This code for setting the mean from https://github.com/NVIDIA/DIGITS/tree/master/examples/classification\nmean_file = os.path.join(model_dir, \'mean.binaryproto\')\nwith open(mean_file, \'rb\') as infile:\n    blob = caffe_pb2.BlobProto()\n    blob.MergeFromString(infile.read())\n    if blob.HasField(\'shape\'):\n        blob_dims = blob.shape\n        assert len(blob_dims) == 4, \'Shape should have 4 dimensions - shape is %s\' % blob.shape\n    elif blob.HasField(\'num\') and blob.HasField(\'channels\') and \\\n            blob.HasField(\'height\') and blob.HasField(\'width\'):\n        blob_dims = (blob.num, blob.channels, blob.height, blob.width)\n    else:\n        raise ValueError(\'blob does not provide shape or 4d dimensions\')\n    pixel = np.reshape(blob.data, blob_dims[1:]).mean(1).mean(1)\n    transformer.set_mean(\'data\', pixel)\n```\n\nIf we had a lot of labels, we might also choose to read in our labels file, which we can use\nlater by looking up the label for a probability using its position (e.g., 0=dolphin, 1=seahorse):\n\n```python\nlabels_file = os.path.join(model_dir, \'labels.txt\')\nlabels = np.loadtxt(labels_file, str, delimiter=\'\\n\')\n``` \n\nNow we\'re ready to classify an image.  We\'ll use [`caffe.io.load_image()`](https://github.com/BVLC/caffe/blob/61944afd4e948a4e2b4ef553919a886a8a8b8246/python/caffe/io.py#L279)\nto read our image file, then use our transformer to reshape it and set it as our network\'s data layer:\n\n```python\n# Load the image from disk using caffe\'s built-in I/O module\nimage = caffe.io.load_image(fullpath)\n# Preprocess the image into the proper format for feeding into the model\nnet.blobs[\'data\'].data[...] = transformer.preprocess(\'data\', image)\n```\n\n> Q: ""How could I use images (i.e., frames) from a camera or video stream instead of files?""\n\nGreat question, here\'s a skeleton to get you started:\n\n```python\nimport cv2\n...\n# Get the shape of our input data layer, so we can resize the image\ninput_shape = net.blobs[\'data\'].data.shape\n...\nwebCamCap = cv2.VideoCapture(0) # could also be a URL, filename\nif webCamCap.isOpened():\n    rval, frame = webCamCap.read()\nelse:\n    rval = False\n\nwhile rval:\n    rval, frame = webCamCap.read()\n    net.blobs[\'data\'].data[...] = transformer.preprocess(\'data\', frame)\n    ...\n\nwebCamCap.release()\n```\n\nBack to our problem, we next need to run the image data through our network and read out\nthe probabilities from our network\'s final `\'softmax\'` layer, which will be in order by label category:\n\n```python\n# Run the image\'s pixel data through the network\nout = net.forward()\n# Extract the probabilities of our two categories from the final layer\nsoftmax_layer = out[\'softmax\']\n# Here we\'re converting to Python types from ndarray floats\ndolphin_prob = softmax_layer.item(0)\nseahorse_prob = softmax_layer.item(1)\n\n# Print the results. I\'m using labels just to show how it\'s done\nlabel = labels[0] if dolphin_prob > seahorse_prob else labels[1]\nfilename = os.path.basename(fullpath)\nprint \'%s is a %s dolphin=%.3f%% seahorse=%.3f%%\' % (filename, label, dolphin_prob*100, seahorse_prob*100)\n```\n\nRunning the full version of this (see [src/classify-samples.py](src/classify-samples.py)) using our\nfine-tuned GoogLeNet network on our [data/untrained-samples](data/untrained-samples) images gives\nme the following output:\n\n```\n[...truncated caffe network output...]\ndolphin1.jpg is a dolphin dolphin=99.968% seahorse=0.032%\ndolphin2.jpg is a dolphin dolphin=99.997% seahorse=0.003%\ndolphin3.jpg is a dolphin dolphin=99.943% seahorse=0.057%\nseahorse1.jpg is a seahorse dolphin=0.365% seahorse=99.635%\nseahorse2.jpg is a seahorse dolphin=0.000% seahorse=100.000%\nseahorse3.jpg is a seahorse dolphin=0.014% seahorse=99.986%\n```\n\nI\'m still trying to learn all the best practices for working with models in code. I wish I had more\nand better documented code examples, APIs, premade modules, etc to show you here. To be honest,\nmost of the code examples I\xe2\x80\x99ve found are terse, and poorly documented--Caffe\xe2\x80\x99s\ndocumentation is spotty, and assumes a lot.\n\nIt seems to me like there\xe2\x80\x99s an opportunity for someone to build higher-level tools on top of the\nCaffe interfaces for beginners and basic workflows like we\'ve done here.  It would be great if\nthere were more simple modules in high-level languages that I could point you at that \xe2\x80\x9cdid the\nright thing\xe2\x80\x9d with our model; someone could/should take this on, and make *using* Caffe\nmodels as easy as DIGITS makes *training* them.  I\xe2\x80\x99d love to have something I could use in node.js,\nfor example.  Ideally one shouldn\xe2\x80\x99t be required to know so much about the internals of the model or Caffe.\nI haven\xe2\x80\x99t used it yet, but [DeepDetect](https://deepdetect.com/) looks interesting on this front,\nand there are likely many other tools I don\xe2\x80\x99t know about.\n\n## Results\n\nAt the beginning we said that our goal was to write a program that used a neural network to\ncorrectly classify all of the images in [data/untrained-samples](data/untrained-samples).\nThese are images of dolphins and seahorses that were never used in the training or validation\ndata:\n\n### Untrained Dolphin Images\n\n![Dolphin 1](data/untrained-samples/dolphin1.jpg?raw=true ""Dolphin 1"")\n![Dolphin 2](data/untrained-samples/dolphin2.jpg?raw=true ""Dolphin 2"")\n![Dolphin 3](data/untrained-samples/dolphin3.jpg?raw=true ""Dolphin 3"")\n\n### Untrained Seahorse Images\n\n![Seahorse 1](data/untrained-samples/seahorse1.jpg?raw=true ""Seahorse 1"")\n![Seahorse 2](data/untrained-samples/seahorse2.jpg?raw=true ""Seahorse 2"")\n![Seahorse 3](data/untrained-samples/seahorse3.jpg?raw=true ""Seahorse 3"")\n\nLet\'s look at how each of our three attempts did with this challenge:\n\n### Model Attempt 1: AlexNet from Scratch (3rd Place)\n\n| Image | Dolphin | Seahorse | Result | \n|-------|---------|----------|--------|\n|[dolphin1.jpg](data/untrained-samples/dolphin1.jpg)| 71.11% | 28.89% | :expressionless: |\n|[dolphin2.jpg](data/untrained-samples/dolphin2.jpg)| 99.2% | 0.8% | :sunglasses: |\n|[dolphin3.jpg](data/untrained-samples/dolphin3.jpg)| 63.3% | 36.7% | :confused: |\n|[seahorse1.jpg](data/untrained-samples/seahorse1.jpg)| 95.04% | 4.96% | :disappointed: |\n|[seahorse2.jpg](data/untrained-samples/seahorse2.jpg)| 56.64% | 43.36 |  :confused: |\n|[seahorse3.jpg](data/untrained-samples/seahorse3.jpg)| 7.06% | 92.94% |  :grin: |\n\n### Model Attempt 2: Fine Tuned AlexNet (2nd Place)\n\n| Image | Dolphin | Seahorse | Result | \n|-------|---------|----------|--------|\n|[dolphin1.jpg](data/untrained-samples/dolphin1.jpg)| 99.1% | 0.09% |  :sunglasses: |\n|[dolphin2.jpg](data/untrained-samples/dolphin2.jpg)| 99.5% | 0.05% |  :sunglasses: |\n|[dolphin3.jpg](data/untrained-samples/dolphin3.jpg)| 91.48% | 8.52% |  :grin: |\n|[seahorse1.jpg](data/untrained-samples/seahorse1.jpg)| 0% | 100% |  :sunglasses: |\n|[seahorse2.jpg](data/untrained-samples/seahorse2.jpg)| 0% | 100% |  :sunglasses: |\n|[seahorse3.jpg](data/untrained-samples/seahorse3.jpg)| 0% | 100% |  :sunglasses: |\n\n### Model Attempt 3: Fine Tuned GoogLeNet (1st Place)\n\n| Image | Dolphin | Seahorse | Result | \n|-------|---------|----------|--------|\n|[dolphin1.jpg](data/untrained-samples/dolphin1.jpg)| 99.86% | 0.14% |  :sunglasses: |\n|[dolphin2.jpg](data/untrained-samples/dolphin2.jpg)| 100% | 0% |  :sunglasses: |\n|[dolphin3.jpg](data/untrained-samples/dolphin3.jpg)| 100% | 0% |  :sunglasses: |\n|[seahorse1.jpg](data/untrained-samples/seahorse1.jpg)| 0.5% | 99.5% |  :sunglasses: |\n|[seahorse2.jpg](data/untrained-samples/seahorse2.jpg)| 0% | 100% |  :sunglasses: |\n|[seahorse3.jpg](data/untrained-samples/seahorse3.jpg)| 0.02% | 99.98% |  :sunglasses: |\n\n## Conclusion\n\nIt\xe2\x80\x99s amazing how well our model works, and what\xe2\x80\x99s possible by fine tuning a pretrained network.\nObviously our dolphin vs. seahorse example is contrived, and the dataset overly limited--we really\ndo want more and better data if we want our network to be robust.  But since our goal was to examine\nthe tools and workflows of neural networks, it\xe2\x80\x99s turned out to be an ideal case, especially since it\ndidn\xe2\x80\x99t require expensive equipment or massive amounts of time.\n\nAbove all I hope that this experience helps to remove the overwhelming fear of getting started.\nDeciding whether or not it\xe2\x80\x99s worth investing time in learning the theories of machine learning and\nneural networks is easier when you\xe2\x80\x99ve been able to see it work in a small way.  Now that you\xe2\x80\x99ve got\na setup and a working approach, you can try doing other sorts of classifications.  You might also look\nat the other types of things you can do with Caffe and DIGITS, for example, finding objects within an\nimage, or doing segmentation.\n\nHave fun with machine learning!\n'"
56,kubeflow/kubeflow,kubeflow,Machine Learning Toolkit for Kubernetes,2017-11-30 18:44:19,2020-06-18 20:04:05,Jsonnet,1434,9027,"b'<img src=""https://www.kubeflow.org/images/logo.svg"" width=""100"">\nKubeflow is a Cloud Native platform for machine learning based on Google\xe2\x80\x99s internal machine learning pipelines.\n\n---\nPlease refer to the official docs at [kubeflow.org](http://kubeflow.org).\n\n\n## Quick Links\n* [Prow test dashboard](https://k8s-testgrid.appspot.com/sig-big-data)\n* [Prow jobs dashboard](https://prow.k8s.io/?repo=kubeflow%2Fkubeflow)\n* [PR Dashboard](https://k8s-gubernator.appspot.com/pr)\n* [Argo UI for E2E tests](http://testing-argo.kubeflow.org)\n\n## Get Involved\nPlease refer to the [Community](https://www.kubeflow.org/docs/about/community/) page.\n\n'"
57,robertmartin8/MachineLearningStocks,robertmartin8,Using python and scikit-learn to make stock predictions,2017-02-12 04:50:44,2020-06-16 08:56:13,Python,250,646,"b'# MachineLearningStocks in python: a starter project and guide\n\n[![forthebadge made-with-python](https://ForTheBadge.com/images/badges/made-with-python.svg)](https://www.python.org/)\n\n[![GitHub license](https://img.shields.io/badge/License-MIT-brightgreen.svg?style=flat-square)](https://github.com/surelyourejoking/MachineLearningStocks/blob/master/LICENSE.txt) (https://github.com/surelyourejoking/MachineLearningStocks/graphs/commit-activity) [![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)\n\nMachineLearningStocks is designed to be an **intuitive** and **highly extensible** template project applying machine learning to making stock predictions. My hope is that this project will help you understand the overall workflow of using machine learning to predict stock movements and also appreciate some of its subtleties. And of course, after following this guide and playing around with the project, you should definitely **make your own improvements** \xe2\x80\x93 if you\'re struggling to think of what to do, at the end of this readme I\'ve included a long list of possiblilities: take your pick.\n\nConcretely, we will be cleaning and preparing a dataset of historical stock prices and fundamentals using `pandas`, after which we will apply a `scikit-learn` classifier to discover the relationship between stock fundamentals (e.g PE ratio, debt/equity, float, etc) and the subsequent annual price change (compared with the an index). We then conduct a simple backtest, before generating predictions on current data.\n\nWhile I would not live trade based off of the predictions from this exact code, I do believe that you can use this project as starting point for a profitable trading system \xe2\x80\x93 I have actually used code based on this project to live trade, with pretty decent results (around 20% returns on backtest and 10-15% on live trading).\n\nThis project has quite a lot of personal significance for me. It was my first proper python project, one of my first real encounters with ML, and the first time I used git. At the start, my code was rife with bad practice and inefficiency: I have since tried to amend most of this, but please be warned that some minor issues may remain (feel free to raise an issue, or fork and submit a PR). Both the project and myself as a programmer have evolved a lot since the first iteration, but there is always room to improve.\n\n*As a disclaimer, this is a purely educational project. Be aware that backtested performance may often be deceptive \xe2\x80\x93 trade at your own risk!*\n\n*MachineLearningStocks predicts which stocks will outperform. But it does not suggest how best to combine them into a portfolio. I have just released [PyPortfolioOpt](https://github.com/robertmartin8/PyPortfolioOpt), a portfolio optimisation library which uses\nclassical efficient frontier techniques (with modern improvements) in order to generate risk-efficient portfolios. Generating optimal allocations from the predicted outperformers might be a great way to improve risk-adjusted returns.*\n\n*This guide has been cross-posted at my academic blog, [reasonabledeviations.com](https://reasonabledeviations.com/)*\n\n## Contents\n\n- [Contents](#contents)\n- [Overview](#overview)\n  - [EDIT as of 24/5/18](#edit-as-of-24518)\n  - [EDIT as of October 2019](#edit-as-of-october-2019)\n- [Quickstart](#quickstart)\n- [Preliminaries](#preliminaries)\n- [Historical data](#historical-data)\n  - [Historical stock fundamentals](#historical-stock-fundamentals)\n  - [Historical price data](#historical-price-data)\n- [Creating the training dataset](#creating-the-training-dataset)\n  - [Preprocessing historical price data](#preprocessing-historical-price-data)\n  - [Features](#features)\n    - [Valuation measures](#valuation-measures)\n    - [Financials](#financials)\n    - [Trading information](#trading-information)\n  - [Parsing](#parsing)\n- [Backtesting](#backtesting)\n- [Current fundamental data](#current-fundamental-data)\n- [Stock prediction](#stock-prediction)\n- [Unit testing](#unit-testing)\n- [Where to go from here](#where-to-go-from-here)\n  - [Data acquisition](#data-acquisition)\n  - [Data preprocessing](#data-preprocessing)\n  - [Machine learning](#machine-learning)\n- [Contributing](#contributing)\n\n## Overview\n\nThe overall workflow to use machine learning to make stocks prediction is as follows:\n\n1. Acquire historical fundamental data \xe2\x80\x93 these are the *features* or *predictors*\n2. Acquire historical stock price data \xe2\x80\x93 this is will make up the dependent variable, or label (what we are trying to predict).\n3. Preprocess data\n4. Use a machine learning model to learn from the data\n5. Backtest the performance of the machine learning model\n6. Acquire current fundamental data\n7. Generate predictions from current fundamental data\n\nThis is a very generalised overview, but in principle this is all you need to build a fundamentals-based ML stock predictor.\n\n### EDIT as of 24/5/18\n\nThis project uses pandas-datareader to download historical price data from Yahoo Finance. However, in the past few weeks this has become extremely inconsistent \xe2\x80\x93 it seems like Yahoo have added some measures to prevent the bulk download of their data. I will try to add a fix, but for now, take note that `download_historical_prices.py` may be deprecated.\n\nAs a temporary solution, I\'ve uploaded `stock_prices.csv` and `sp500_index.csv`, so the rest of the project can still function.\n\n### EDIT as of October 2019\n\nI expect that after so much time there will be many data issues. To that end, I have decided to upload the other CSV files: `keystats.csv` (the output of `parsing_keystats.py`) and `forward_sample.csv` (the output of `current_data.py`).\n\n## Quickstart\n\nIf you want to throw away the instruction manual and play immediately, clone this project, then download and unzip the [data file](https://pythonprogramming.net/data-acquisition-machine-learning/) into the same directory. Then, open an instance of terminal and cd to the project\'s file path, e.g\n\n```bash\ncd Users/User/Desktop/MachineLearningStocks\n```\n\nThen, run the following in terminal:\n\n```bash\npip install -r requirements.txt\npython download_historical_prices.py\npython parsing_keystats.py\npython backtesting.py\npython current_data.py\npytest -v\npython stock_prediction.py\n```\n\nOtherwise, follow the step-by-step guide below.\n\n## Preliminaries\n\nThis project uses python 3.6, and the common data science libraries `pandas` and `scikit-learn`. If you are on python 3.x less than 3.6, you will find some syntax errors wherever f-strings have been used for string formatting. These are fortunately very easy to fix (just rebuild the string using your preferred method), but I do encourage you to upgrade to 3.6 to enjoy the elegance of f-strings. A full list of requirements is included in the `requirements.txt` file. To install all of the requirements at once, run the following code in terminal:\n\n```bash\npip install -r requirements.txt\n```\n\nTo get started, clone this project and unzip it. This folder will become our working directory, so make sure you `cd` your terminal instance into this directory.\n\n## Historical data\n\nData acquisition and preprocessing is probably the hardest part of most machine learning projects. But it is a necessary evil, so it\'s best to not fret and just carry on.\n\nFor this project, we need three datasets:\n\n1. Historical stock fundamentals\n2. Historical stock prices\n3. Historical S&P500 prices\n\nWe need the S&P500 index prices as a benchmark: a 5% stock growth does not mean much if the S&P500 grew 10% in that time period, so all stock returns must be compared to those of the index.\n\n### Historical stock fundamentals\n\nHistorical fundamental data is actually very difficult to find (for free, at least). Although sites like [Quandl](https://www.quandl.com/) do have datasets available, you often have to pay a pretty steep fee.\n\nIt turns out that there is a way to parse this data, for free, from [Yahoo Finance](https://finance.yahoo.com/). I will not go into details, because [Sentdex has done it for us](https://pythonprogramming.net/data-acquisition-machine-learning/). On his page you will be able to find a file called `intraQuarter.zip`, which you should download, unzip, and place in your working directory. Relevant to this project is the subfolder called `_KeyStats`, which contains html files that hold stock fundamentals for all stocks in the S&P500 between 2003 and 2013, sorted by stock. However, at this stage, the data is unusable \xe2\x80\x93 we will have to parse it into a nice csv file before we can do any ML.\n\n### Historical price data\n\nIn the first iteration of the project, I used `pandas-datareader`, an extremely convenient library which can load stock data straight into `pandas`. However, after Yahoo Finance changed their UI, `datareader` no longer worked, so I switched to [Quandl](https://www.quandl.com/), which has free stock price data for a few tickers, and a python API. However, as `pandas-datareader` has been [fixed](https://github.com/ranaroussi/fix-yahoo-finance), we will use that instead.\n\nLikewise, we can easily use `pandas-datareader` to access data for the SPY ticker. Failing that, one could manually download it from [yahoo finance](https://finance.yahoo.com/quote/%5EGSPC/history?p=%5EGSPC), place it into the project directory and rename it `sp500_index.csv`.\n\nThe code for downloading historical price data can be run by entering the following into terminal:\n\n```bash\npython download_historical_prices.py\n```\n\n## Creating the training dataset\n\nOur ultimate goal for the training data is to have a \'snapshot\' of a particular stock\'s fundamentals at a particular time, and the corresponding subsequent annual performance of the stock.\n\nFor example, if our \'snapshot\' consists of all of the fundamental data for AAPL on the date 28/1/2005, then we also need to know the percentage price change of AAPL between 28/1/05 and 28/1/06. Thus our algorithm can learn how the fundamentals impact the annual change in the stock price.\n\nIn fact, this is a slight oversimplification. In fact, what the algorithm will eventually learn is how fundamentals impact the *outperformance of a stock relative to the S&P500 index*. This is why we also need index data.\n\n### Preprocessing historical price data\n\nWhen `pandas-datareader` downloads stock price data, it does not include rows for weekends and public holidays (when the market is closed).\n\nHowever, referring to the example of AAPL above, if our snapshot includes fundamental data for 28/1/05 and we want to see the change in price a year later, we will get the nasty surprise that 28/1/2006 is a Saturday. Does this mean that we have to discard this snapshot?\n\nBy no means \xe2\x80\x93 data is too valuable to callously toss away. As a workaround, I instead decided to \'fill forward\' the missing data, i.e we will assume that the stock price on Saturday 28/1/2006 is equal to the stock price on Friday 27/1/2006.\n\n### Features\n\nBelow is a list of some of the interesting variables that are available on Yahoo Finance.\n\n#### Valuation measures\n\n- \'Market Cap\'\n- Enterprise Value\n- Trailing P/E\n- Forward P/E\n- PEG Ratio\n- Price/Sales\n- Price/Book\n- Enterprise Value/Revenue\n- Enterprise Value/EBITDA\n\n#### Financials\n\n- Profit Margin\n- Operating Margin\n- Return on Assets\n- Return on Equity\n- Revenue\n- Revenue Per Share\n- Quarterly Revenue Growth\n- Gross Profit\n- EBITDA\n- Net Income Avi to Common\n- Diluted EPS\n- Quarterly Earnings Growth\n- Total Cash\n- Total Cash Per Share\n- Total Debt\n- Total Debt/Equity\n- Current Ratio\n- Book Value Per Share\n- Operating Cash Flow\n- Levered Free Cash Flow\n\n#### Trading information\n\n- Beta\n- 50-Day Moving Average\n- 200-Day Moving Average\n- Avg Vol (3 month)\n- Shares Outstanding\n- Float\n- % Held by Insiders\n- % Held by Institutions\n- Shares Short\n- Short Ratio\n- Short % of Float\n- Shares Short (prior month)\n\n### Parsing\n\nHowever, all of this data is locked up in HTML files. Thus, we need to build a parser. In this project, I did the parsing with regex, but please note that generally it is [really not recommended](https://stackoverflow.com/questions/1732348/regex-match-open-tags-except-xhtml-self-contained-tags) to use regex to parse HTML. However, I think regex probably wins out for ease of understanding (this project being educational in nature), and from experience regex works fine in this case.\n\nThis is the exact regex used:\n\n```python\nr\'>\' + re.escape(variable) + r\'.*?(\\-?\\d+\\.*\\d*K?M?B?|N/A[\\\\n|\\s]*|>0|NaN)%?(</td>|</span>)\'\n```\n\nWhile it looks pretty arcane, all it is doing is searching for the first occurence of the feature (e.g ""Market Cap""), then it looks forward until it finds a number immediately followed by a `</td>` or `</span>` (signifying the end of a table entry). The complexity of the expression above accounts for some subtleties in the parsing:\n\n- the numbers could be preceeded by a minus sign\n- Yahoo Finance sometimes uses K, M, and B as abbreviations for thousand, million and billion respectively.\n- some data are given as percentages\n- some datapoints are missing, so instead of a number we have to look for ""N/A"" or ""NaN.\n\nBoth the preprocessing of price data and the parsing of keystats are included in `parsing_keystats.py`. Run the following in your terminal:\n\n```bash\npython parsing_keystats.py\n```\n\nYou should see the file `keystats.csv` appear in your working directory. Now that we have the training data ready, we are ready to actually do some machine learning.\n\n## Backtesting\n\nBacktesting is arguably the most important part of any quantitative strategy: you must have some way of testing the performance of your algorithm before you live trade it.\n\nDespite its importance, I originally did not want to include backtesting code in this repository. The reasons were as follows:\n\n- Backtesting is messy and empirical. The code is not very pleasant to use, and in practice requires a lot of manual interaction.\n- Backtesting is very difficult to get right, and if you do it wrong, you will be deceiving yourself with high returns.\n- Developing and working with your backtest is probably the best way to learn about machine learning and stocks \xe2\x80\x93 you\'ll see what works, what doesn\'t, and what you don\'t understand.\n\nNevertheless, because of the importance of backtesting, I decided that I can\'t really call this a \'template machine learning stocks project\' without backtesting. Thus, I have included a simplistic backtesting script. Please note that there is a fatal flaw with this backtesting implementation that will result in *much* higher backtesting returns. It is quite a subtle point, but I will let you figure that out :)\n\nRun the following in terminal:\n\n```bash\npython backtesting.py\n```\n\nYou should get something like this:\n\n```txt\nClassifier performance\n======================\nAccuracy score:  0.81\nPrecision score:  0.75\n\nStock prediction performance report\n===================================\nTotal Trades: 177\nAverage return for stock predictions:  37.8 %\nAverage market return in the same period:  9.2%\nCompared to the index, our strategy earns  28.6 percentage points more\n```\n\nAgain, the performance looks too good to be true and almost certainly is.\n\n## Current fundamental data\n\nNow that we have trained and backtested a model on our data, we would like to generate actual predictions on current data.\n\nAs always, we can scrape the data from good old Yahoo Finance. My method is to literally just download the statistics page for each stock (here is the [page](https://finance.yahoo.com/quote/AAPL/key-statistics?p=AAPL) for Apple), then to parse it using regex as before.\n\nIn fact, the regex should be almost identical, but because Yahoo has changed their UI a couple of times, there are some minor differences. This part of the projet has to be fixed whenever yahoo finance changes their UI, so if you can\'t get the project to work, the problem is most likely here.\n\nRun the following in terminal:\n\n```bash\npython current_data.py\n```\n\nThe script will then begin downloading the HTML into the `forward/` folder within your working directory, before parsing this data and outputting the file `forward_sample.csv`. You might see a few miscellaneous errors for certain tickers (e.g \'Exceeded 30 redirects.\'), but this is to be expected.\n\n## Stock prediction\n\nNow that we have the training data and the current data, we can finally generate actual predictions. This part of the project is very simple: the only thing you have to decide is the value of the `OUTPERFORMANCE` parameter (the percentage by which a stock has to beat the S&P500 to be considered a \'buy\'). I have set it to 10 by default, but it can easily be modified by changing the variable at the top of the file. Go ahead and run the script:\n\n```bash\npython stock_prediction.py\n```\n\nYou should get something like this:\n\n```txt\n21 stocks predicted to outperform the S&P500 by more than 10%:\nNOC FL SWK NFX LH NSC SCHL KSU DDS GWW AIZ ORLY R SFLY SHW GME DLX DIS AMP BBBY APD\n```\n\n## Unit testing\n\nI have included a number of unit tests (in the `tests/` folder) which serve to check that things are working properly. However, due to the nature of the some of this projects functionality (downloading big datasets), you will have to run all the code once before running the tests. Otherwise, the tests themselves would have to download huge datasets (which I don\'t think is optimal).\n\nI thus recommend that you run the tests after you have run all the other scripts (except, perhaps, `stock_prediction.py`).\n\nTo run the tests, simply enter the following into a terminal instance in the project directory:\n\n```bash\npytest -v\n```\n\nPlease note that it is not considered best practice to include an `__init__.py` file in the `tests/` directory (see [here](https://docs.pytest.org/en/latest/goodpractices.html) for more), but I have done it anyway because it is uncomplicated and functional.\n\n## Where to go from here\n\nI have stated that this project is extensible, so here are some ideas to get you started and possibly increase returns (no promises).\n\n### Data acquisition\n\nMy personal belief is that better quality data is THE factor that will ultimately determine your performance. Here are some ideas:\n\n- Explore the other subfolders in Sentdex\'s `intraQuarter.zip`.\n- Parse the annual reports that all companies submit to the SEC (have a look at the [Edgar Database](https://www.sec.gov/edgar/searchedgar/companysearch.html))\n- Try to find websites from which you can scrape fundamental data (this has been my solution).\n- Ditch US stocks and go global \xe2\x80\x93 perhaps better results may be found in markets that are less-liquid. It\'d be interesting to see whether the predictive power of features vary based on geography.\n- Buy Quandl data, or experiment with alternative data.\n\n### Data preprocessing\n\n- Build a more robust parser using BeautifulSoup\n- In this project, I have just ignored any rows with missing data, but this reduces the size of the dataset considerably. Are there any ways you can fill in some of this data?\n  - hint: if the PE ratio is missing but you know the stock price and the earnings/share...\n  - hint 2: how different is Apple\'s book value in March to its book value in June?\n- Some form of feature engineering\n  - e.g, calculate [Graham\'s number](https://www.investopedia.com/terms/g/graham-number.asp) and use it as a feature\n  - some of the features are probably redundant. Why not remove them to speed up training?\n- Speed up the construction of `keystats.csv`.\n  - hint: don\'t keep appending to one growing dataframe! Split it into chunks\n\n### Machine learning\n\nAltering the machine learning stuff is probably the easiest and most fun to do.\n\n- The most important thing if you\'re serious about results is to find the problem with the current backtesting setup and fix it. This will likely be quite a sobering experience, but if your backtest is done right, it should mean that any observed outperformance on your test set can be traded on (again, do so at your own discretion).\n- Try a different classifier \xe2\x80\x93 there is plenty of research that advocates the use of SVMs, for example. Don\'t forget that other classifiers may require feature scaling etc.\n- Hyperparameter tuning: use gridsearch to find the optimal hyperparameters for your classifier. But make sure you don\'t overfit!\n- Make it *deep* \xe2\x80\x93 experiment with neural networks (an easy way to start is with `sklearn.neural_network`).\n- Change the classification problem into a regression one: will we achieve better results if we try to predict the stock *return* rather than whether it outperformed?\n- Run the prediction multiple times (perhaps using different hyperparameters?) and select the *k* most common stocks to invest in. This is especially important if the algorithm is not deterministic (as is the case for Random Forest)\n- Experiment with different values of the `outperformance` parameter.\n- Should we really be trying to predict raw returns? What happens if a stock achieves a 20% return but does so by being highly volatile?\n- Try to plot the importance of different features to \'see what the machine sees\'.\n\n## Contributing\n\nFeel free to fork, play around, and submit PRs. I would be very grateful for any bug fixes or more unit tests.\n\nThis project was originally based on Sentdex\'s excellent [machine learning tutorial](https://www.youtube.com/playlist?list=PLQVvvaa0QuDd0flgGphKCej-9jp-QdzZ3), but it has since evolved far beyond that and the code is almost completely different. The complete series is also on [his website](https://pythonprogramming.net/machine-learning-python-sklearn-intro/).\n\n---\n\nFor more content like this, check out my academic blog at [reasonabledeviations.com/](https://reasonabledeviations.com).\n'"
58,luispedro/BuildingMachineLearningSystemsWithPython,luispedro,Source Code for the book Building Machine Learning Systems with Python,2013-09-25 07:10:26,2020-06-06 02:13:23,Python,1464,2089,b'Building Machine Learning Systems with Python\n=============================================\n\nSource Code for the book Building Machine Learning Systems with Python by [Luis\nPedro Coelho](http://luispedro.org) and [Willi Richert](http://twotoreal.com).\n\nThe book was published in 2013 (second edition in 2015) by Packt Publishing and\nis available [from their\nwebsite](http://www.packtpub.com/building-machine-learning-systems-with-python/book).\n\nThe code in the repository corresponds to the second edition. Code for the\nfirst edition is available in [first\\_edition\nbranch](https://github.com/luispedro/BuildingMachineLearningSystemsWithPython/tree/first_edition).\n\n'
59,13o-bbr-bbq/machine_learning_security,13o-bbr-bbq,Source code about machine learning and security.,2017-05-01 20:33:43,2020-06-18 04:08:41,Python,455,1329,"b'# Machine Learning and Security\nSource codes about machine learning and security.\n\n## Line up.\n * [Cyber security and Machine Learning course](https://github.com/13o-bbr-bbq/machine_learning_security/tree/master/Security_and_MachineLearning)  \n The elementary training course of Machine learning for security engineer.  \n * [Vulnerabilties of Machine Learning](https://github.com/13o-bbr-bbq/machine_learning_security/blob/master/Vulnerabilities_of_ML/)  \n Summary of Machine Learning vulnerability.  \n * [Analytics](https://github.com/13o-bbr-bbq/machine_learning_security/tree/master/Analytics)  \n Analyzing packet capture data using k-means.  \n * [CNN_test](https://github.com/13o-bbr-bbq/machine_learning_security/tree/master/CNN_test)  \n Generate adversarial example against CNN.  \n * [Deep Exploit](https://github.com/13o-bbr-bbq/machine_learning_security/tree/master/DeepExploit)  \n Fully automatic penetration test tool using Machine Learning.  \n Deep Exploit was presented at **[Black Hat USA 2018 Arsenal](https://www.blackhat.com/us-18/arsenal/schedule/index.html#deep-exploit-11908)** , **[Black Hat EURO 2018 Arsenal](https://www.blackhat.com/eu-18/arsenal/schedule/index.html#deep-exploit-fully-automatic-penetration-test-tool-using-machine-learning-13320)** and **[DEF CON 26! AI Village](https://aivillage.org/posts/accepted-talks/)**.  \n* [GyoiThon](https://github.com/gyoisamurai/GyoiThon)  \n Next generation penetration test tool.  \n GyoiThon was presented at **[Black Hat ASIA 2018 Arsenal](https://www.blackhat.com/asia-18/arsenal/schedule/index.html#gyoithon-9651)** , **[Black Hat ASIA 2019 Arsenal](https://www.blackhat.com/asia-19/arsenal/schedule/index.html#gyoithon-penetration-testing-using-machine-learning-14359)** and **[DEF CON 26! Demo Labs](https://www.defcon.org/html/defcon-26/dc-26-demolabs.html)**.  \n * [DeepGenerator](https://github.com/13o-bbr-bbq/machine_learning_security/tree/master/Generator)  \n Fully automatically generate numerous injection codes for web application assessment using Genetic Algorithm and Generative Adversarial Networks.  \n * [Recommender](https://github.com/13o-bbr-bbq/machine_learning_security/tree/master/Recommender)  \n Recommend optimal injection code for detecting web app vulnerabilities.\n * [SAIVS (Spider Artificial Intelligence Vulnerability Scanner)](https://github.com/13o-bbr-bbq/machine_learning_security/tree/master/Saivs)  \n SAIVS is an artificial intelligence to find vulnerabilities in Web applications.  \n SAIVS was presented at **[Black Hat ASIA 2016 Arsenal](http://www.blackhat.com/asia-16/arsenal.html#saivs-spider-artificial-intelligence-vulnerability-scanner)**.  \n\n## Contact us\n\nIsao Takaesu  \ntakaesu235@gmail.com  \n[https://twitter.com/bbr_bbq](https://twitter.com/bbr_bbq)\n'"
60,masinoa/machine_learning,masinoa,Python coded examples and documentation of machine learning algorithms.,2012-06-12 19:17:17,2020-06-11 14:00:40,Python,368,592,"b'machine_learning\n================\n\nThis repo contains a collection of IPython notebooks detailing various machine learning algorithims. In general, the mathematics follows that presented by Dr. Andrew Ng\'s Machine Learning course taught at Stanford University (materials available from [ITunes U] (http://www.apple.com/education/itunes-u/), Stanford Machine Learning), Dr. Tom Mitchell\'s course at Carnegie Mellon (materials avialable [here](http://www.cs.cmu.edu/~tom/10701_sp11/)), and Christopher M. Bishop\'s ""Pattern Recognition And Machine Learning"". Unless otherwise noted, the Python code is orginal and any errors or ommissions should be attribued to me and not the aforemention authors.\n\nEach ipynb provides a list of the pertinent reading material. It is suggested that the material be read in the order provided.\n\nIf you do not have IPython installed or Notebook configured (why not?) the src directory has .py versions of the notebook files and some of the PDF output files are in this repository\'s Downloads section. However, they are not always as updated as the ipynb files.\n\nPython Version 2.7.2\nIPython Version 0.13\n\n\n'"
61,krishnakumarsekar/awesome-quantum-machine-learning,krishnakumarsekar,"Here you can get all the Quantum Machine learning Basics, Algorithms ,Study Materials ,Projects and the descriptions of the projects around the web",2017-04-26 11:03:50,2020-06-18 19:46:13,HTML,423,1427,"b'# Awesome Quantum Machine Learning [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)\n\nA curated list of awesome quantum machine learning algorithms,study materials,libraries and software (by language).\n\n[![Main Architecture](https://github.com/krishnakumarsekar/awesome-quantum-machine-learning/blob/master/Quantum%20Machine%20complete%20Architecture.png)](https://arxiv.org/pdf/1611.09347.pdf)\n\n[![Quantum Kernel](https://github.com/krishnakumarsekar/awesome-quantum-machine-learning/blob/master/Qantum%20Kernel%20Structure.jpg)](https://www.dwavesys.com/tutorials/background-reading-series/quantum-computing-primer)\n\n[![In Depth Physics Comparison](https://github.com/krishnakumarsekar/awesome-quantum-machine-learning/blob/master/CompareDifferentConcepts.jpg)](https://patents.google.com/patent/US20060091375)\n\n\n## Table of Contents\n\n<!-- MarkdownTOC depth=4 -->\n\n- [INTRODUCTION](#introduction)\n    - [Why Quantum Machine Learning?](#introduction-why-quantum-machine-learning)\n- [BASICS](#basics)\n    - [What is Quantum Mechanics?](#basics-what-quantum-mechanics)\n    - [What is Quantum Computing?](#basics-what-quantum-computing)\n    - [What is Topological Quantum Computing?](#basics-what-topological-quantum-computing)\n    - [Quantum Computing vs Classical Computing](#basics-quantum-classical-vs) \n- [QUANTUM COMPUTING](#quantumcomputing)\n    - [Atom Structure](#quantumcomputing-atom-structure)\n    - [Photon wave](#quantumcomputing-photon-wave)\n    - [Electron Fluctuation or spin](#quantumcomputing-elecfluctuation-spin)\n    - [States](#quantumcomputing-states)\n    - [SuperPosition](#quantumcomputing-superposition)\n    - [SuperPosition specific for machine learning(Quantum Walks)](#quantumcomputing-superpostion-machinelearning)\n    - [Classical Bit](#quantumcomputing-classicalbit)\n    - [Quantum Bit or Qubit or Qbit](#quantumcomputing-qubit)\n    - [Basic Gates in Quantum Computing](#quantumcomputing-basicgates)\n    - [Quantum Diode](#quantumcomputing-diode)\n    - [Quantum Transistor](#quantumcomputing-transistor)\n    - [Quantum Processor](#quantumcomputing-processor)\n    - [Quantum Registery QRAM](#quantumcomputing-qram) \n    - [Quantum Entanglement](#quantumcomputing-entanglement)\n- [QUANTUM COMPUTING MACHINE LEARNING BRIDGE](#qcmlbridge)\n    - [Complex Numbers](#qcmlbridge-complexNumbers)\n    - [Tensors](#qcmlbridge-tensors)\n    - [Tensors Network](#qcmlbridge-tensors-network)             \n    - [Oracle](#qcmlbridge-oracle)\n    - [Hadamard transform](#qcmlbridge-hadamard)\n    - [Hilbert Space](#qcmlbridge-hilbert)\n    - [eigenvalues and eigenvectors](#qcmlbridge-eigen)\n    - [Schr\xc2\xa8odinger Operators](#qcmlbridge-schrodinger)\n    - [Quantum lambda calculus](#qcmlbridge-lamda)\n    - [Quantum Amplitute Phase](#qcmlbridge-amp-phase)\n    - [Qubits Encode and Decode](#qcmlbridge-encode-decode)\n    - [convert classical bit to qubit](#qcmlbridge-classical-qubit)\n    - [Quantum Dirac and Kets](#qcmlbridge-dirac-ket)\n    - [Quantum Complexity](#qcmlbridge-complexity)\n    - [Arbitrary State Generation](#qcmlbridge-arbitarystategeneration)\n- [QUANTUM ALGORITHMS](#quantumalgorithms)\n    - [Quantum Fourier Transform](#quantumalgorithms-fourier)\n    - [Variational-Quantum-Eigensolver](#quantumalgorithms-quantumeigensolver)\n    - [Grovers Algorithm](#quantumalgorithms-grover)\n    - [Shor\'s algorithm](#quantumalgorithms-shors)\n    - [Hamiltonian Oracle Model](#quantumalgorithms-hamiltonian)\n    - [Bernstein-Vazirani Algorithm](#quantumalgorithms-Bernsteinvazirani)\n    - [Simon\xe2\x80\x99s Algorithm](#quantumalgorithms-simons)\n    - [Deutsch-Jozsa Algorithm](#quantumalgorithms-deutschjozsa)\n    - [Gradient Descent](#quantumalgorithms-gradient-descent)                 \n    - [Phase Estimation](#quantumalgorithms-phase-estimation)\n    - [Haar Tansform](#quantumalgorithms-haar)\n    - [Quantum Ridgelet Transform](#quantumalgorithms-ridgelet)\n    - [Quantum NP Problem](#quantumalgorithms-npproblem)\n- [QUANTUM MACHINE LEARNING ALGORITHMS](#quantumalgorithmsml)\n    - [Quantum K-Nearest Neighbour](#quantumalgorithmsml-qknn)\n    - [Quantum K-Means](#quantumalgorithmsml-kmeans)\n    - [Quantum Fuzzy C-Means](#quantumalgorithmsml-qfcm)\n    - [Quantum Support Vector Machine](#quantumalgorithmsml-svm)\n    - [Quantum Genetic Algorithm](#quantumalgorithmsml-genetic)\n    - [Quantum Hidden Morkov Models](#quantumalgorithmsml-hmm)\n    - [Quantum state classification with Bayesian methods](#quantumalgorithmsml-bayesian)\n    - [Quantum Ant Colony Optimization](#quantumalgorithmsml-antcolony)\n    - [Quantum Cellular Automata](#quantumalgorithmsml-caautomata)\n    - [Quantum Classification using Principle Component Analysis](#quantumalgorithmsml-pca)\n    - [Quantum Inspired Evolutionary Algorithm](#quantumalgorithmsml-evolutionary)\n    - [Quantum Approximate Optimization Algorithm](#quantumalgorithmsml-qaoa)\n    - [Quantum Elephant Herding Optimization](#quantumalgorithmsml-qeho)\n    - [Quantum-behaved Particle Swarm Optimization](#quantumalgorithmsml-qpso)\n    - [Quantum Annealing Expectation-Maximization](#quantumalgorithmsml-qaem)\n- [QAUNTUM NEURAL NETWORK](#qnn)\n    - [Quantum perceptrons](#qnn-perceptron)\n    - [Qurons](#qnn-qurons)\n    - [Quantum Auto Encoder](#qnn-autoencoder)\n    - [Quantum Annealing](#qnn-annealing)\n    - [Photonic Implementation of Quantum Neural Network](#qnn-photonicqnn)\n    - [Quantum Feed Forward Neural Network](#qnn-feedforward)\n    - [Quantum Boltzman Neural Network](#qnn-boltzman)\n    - [Quantum Neural Net Weight Storage](#qnn-weightstorage)\n    - [Quantum Upside Down Neural Net](#qnn-upsidedown)\n    - [Quantum Hamiltonian Neural Net](#qnn-hamiltoniannet)\n    - [QANN](#qnn-qann)\n    - [QPN](#qnn-qpn)\n    - [SAL](#qnn-sal)\n    - [Quantum Hamiltonian Learning](#qnn-hamiltonianlearning)\n    - [Compressed Quantum Hamiltonian Learning](#qnn-compressedhamiltonianlearning)\n- [QAUNTUM STATISTICAL DATA ANALYSIS](#quantumstatistics)\n\t- [Quantum Probability Theory](#quantumstatistics-probabilitytheory)\n    - [Kolmogorovian Theory](#quantumstatistics-kolmogorovian)\n    - [Quantum Measurement Problem](#quantumstatistics-measurementproblem)\n    - [Intuitionistic Logic](#quantumstatistics-intuitionistic)\n    - [Heyting Algebra](#quantumstatistics-heytingalgebra)\n    - [Quantum Filtering](#quantumstatistics-quantumfiltering)\n    - [Paradoxes](#quantumstatistics-paradoxes)                                                               \n    - [Quantum Stochastic Process](#quantumstatistics-stochasticprocess)\n    - [Double Negation](#quantumstatistics-doublenegation)\n    - [Quantum Stochastic Calculus](#quantumstatistics-stochasticcalculus)\n    - [Hamiltonian Calculus](#quantumstatistics-hamiltoniancalculus)\n    - [Quantum Ito\'s Formula](#quantumstatistics-itosformula)\n    - [Quantum Stochastic Differential Equations(QSDE)](#quantumstatistics-qsde)\n    - [Quantum Stochastic Integration](#quantumstatistics-stochasticintegration)\n    - [It\xc5\x8d Integral](#quantumstatistics-it\xc5\x8dintegral)\n    - [Quasiprobability Distributions](#quantumstatistics-quasiprobabilitydistributions)\n    - [Quantum Wiener Processes](#quantumstatistics-quantumwienerprocesses)\n    - [Quantum Statistical Ensemble](#quantumstatistics-statisticalensemble)\n   \t- [Quantum Density Operator or Density Matrix](#quantumstatistics-densityoperator)\n    - [Gibbs Canonical Ensemble](#quantumstatistics-gibbscanonicalensemble)\n    - [Quantum Mean](#quantumstatistics-mean)\n    - [Quantum Variance](#quantumstatistics-variance)\n    - [Envariance](#quantumstatistics-envariance)\n    - [Polynomial Optimization](#quantumstatistics-polynomialoptimization)\n    - [Quadratic Unconstrained Binary Optimization](#quantumstatistics-qubo)\n    - [Quantum Gradient Descent](#quantumstatistics-quantumgradientdescent)\n    - [Quantum Based Newton\'s Method for Constrained Optimization](#quantumstatistics-newtonmethodconstrainedoptimization)\n    - [Quantum Based Newton\'s Method for UnConstrained Optimization](#quantumstatistics-newtonmethodunconstrainedoptimization)\n    - [Quantum Ensemble](#quantumstatistics-quantumensemble)\n    - [Quantum Topology](#quantumstatistics-quantumtopology)\n    - [Quantum Topological Data Analysis](#quantumstatistics-quantumtopologicaldataanalysis)\n    - [Quantum Bayesian Hypothesis](#quantumstatistics-quantumbayesianhypothesis)\n    - [Quantum Statistical Decision Theory](#quantumstatistics-quantumstatisticaldecisiontheory)\n    - [Quantum Minimax Theorem](#quantumstatistics-quantumminimaxtheorem)\n    - [Quantum Hunt-Stein Theorem](#quantumstatistics-quantumhuntsteintheorem)\n    - [Quantum Locally Asymptotic Normality](#quantumstatistics-quantumlocalasymptoticnormality)\n    - [Quantum Ising Model](#quantumstatistics-isingmodel)\n    - [Quantum Metropolis Sampling](#quantumstatistics-metropolissampling)\n    - [Quantum Monte Carlo Approximation](#quantumstatistics-montecarloapproximation)\n    - [Quantum Bootstrapping](#quantumstatistics-bootstrapping)\n    - [Quantum Bootstrap Aggregation](#quantumstatistics-bootstrapaggregation)\n    - [Quantum Decision Tree Classifier](#quantumstatistics-decisiontreeclassifier)\n    - [Quantum Outlier Detection](#quantumstatistics-outlierdetection)\n    - [Cholesky-Decomposition for Quantum Chemistry](#quantumstatistics-choleskydecomposition)\n    - [Quantum Statistical Inference](#quantumstatistics-quantumstatisticalinference)\n    - [Asymptotic Quantum Statistical Inference](#quantumstatistics-quantumstatisticalinferenceasymptotic)\n    - [Quantum Gaussian Mixture Modal](#quantumstatistics-qgmm)\n    - [Quantum t-design](#quantumstatistics-quantumtdesign)\n    - [Quantum Central Limit Theorem](#quantumstatistics-quantumcentrallimittheorem)\n    - [Quantum Hypothesis Testing](#quantumstatistics-quantumhypothesistesting)\n    - [Quantum Chi-squared and Goodness of Fit Testing](#quantumstatistics-quantumchisquared)\n   \t- [Quantum Estimation Theory](#quantumstatistics-quantumestimationtheory)\n    - [Quantum Way of Linear Regression](#quantumstatistics-quantumlinearregression)\n    - [Asymptotic Properties of Quantum](#quantumstatistics-quantumasymptoticproperties)\n    - [Outlier Detection in Quantum Concepts](#quantumstatistics-quantumoutlier)\n- [QAUNTUM ARTIFICIAL INTELLIGENCE](#quantumai)\n\t- [Heuristic Quantum Mechanics](#quantumai-heuristicmechanics)\n    - [Consistent Quantum Reasoning](#quantumai-quantumreasoning)\n    - [Quantum Reinforcement Learning](#quantumai-reinforcementlearning)\n- [QAUNTUM COMPUTER VISION](#quantumcv)\n- [QUANTUM PROGRAMMING LANGUAGES , TOOLs and SOFTWARES](#qpl)\n    - [ALL](#qpl-all)\n- [QUANTUM ALGORITHMS SOURCE CODES , GITHUBS](#quantumsourcecode)\n- [QUANTUM HOT TOPICS](#quantumhottopics)\n    - [Quantum Cognition](#quantumhottopics-cognition)\n    - [Quantum Camera](#quantumhottopics-camera)\n    - [Quantum Mathematics](#quantumhottopics-mathematics)\n    - [Quantum Information Processing](#quantumhottopics-informationprocessing)\n    - [Quantum Image Processing](#quantumhottopics-imageprocessing)\n    - [Quantum Cryptography](#quantumhottopics-cryptography)\n    - [Quantum Elastic Search](#quantumhottopics-elasticsearch)\n    - [Quantum DNA Computing](#quantumhottopics-dna)\n    - [Adiabetic Quantum Computing](#quantumhottopics-adiabetic)\n    - [Topological Big Data Anlytics using Quantum](#quantumhottopics-topologicalbigdata)\n    - [Hamiltonian Time Based Quantum Computing](#quantumhottopics-hamiltoniancomputing)\n    - [Deep Quantum Learning](#quantumhottopics-deepquantumlearning)\n    - [Quantum Tunneling](#quantumhottopics-tunneling)\n    - [Quantum Entanglment](#quantumhottopics-entanglment)\n   \t- [Quantum Eigen Spectrum](#quantumhottopics-eigenspectrum)\n    - [Quantum Dots](#quantumhottopics-dots)\n    - [Quantum elctro dynamics](#quantumhottopics-electrodynamics)\n    - [Quantum teleportation](#quantumhottopics-teleportation)\n    - [Quantum Supremacy](#quantumhottopics-supremacy)\n    - [Quantum Zeno Effect](#quantumhottopics-zenoeffect)\n    - [Quantum Cohomology](#quantumhottopics-cohomology)\n    - [Quantum Chromodynamics](#quantumhottopics-chromodynamics)\n    - [Quantum Darwinism](#quantumhottopics-darwinism)\n    - [Quantum Coherence](#quantumhottopics-coherence)\n    - [Quantum Decoherence](#quantumhottopics-decoherence) \n    - [Topological Quantum Computing](#quantumhottopics-topologicalcomputing)\n    - [Topological Quantum Field Theory](#quantumhottopics-topologicalfieldtheory)\n    - [Quantum Knots](#quantumhottopics-knots)\n    - [Topological Entanglment](#quantumhottopics-topologicalentanglment)\n    - [Boson Sampling](#quantumhottopics-bosonsampling)\n    - [Quantum Convolutional Code](#quantumhottopics-convolutionalcode)\n    - [Stabilizer Code](#quantumhottopics-stabilizercode)\n    - [Quantum Chaos](#quantumhottopics-chaos)\n    - [Quantum Game Theory](#quantumhottopics-quantumgametheory)\n    - [Quantum Channel](#quantumhottopics-quantumchannel)\n    - [Tensor Space Theory](#quantumhottopics-tensorspacetheory)\n    - [Quantum Leap](#quantumhottopics-quantumleap)\n    - [Quantum Mechanics for Time Travel](#quantumhottopics-quantumtimetravel)\n    - [Quantum Secured Block Chain](#quantumhottopics-quantumblockchain)\n    - [Quantum Internet](#quantumhottopics-quantuminternet)\n    - [Quantum Optical Network](#quantumhottopics-quantumopticalnetwork)\n    - [Quantum Interference](#quantumhottopics-quantuminterference)\n    - [Quantum Optical Network](#quantumhottopics-quantumopticalnetwork)\n    - [Quantum Operating System](#quantumhottopics-quantumoperatingsystem)\n    - [Electron Fractionalization](#quantumhottopics-electronfractionalization)\n   \t- [Flip-Flop Quantum Computer](#quantumhottopics-flipflopquantumcomputer)\n    - [Quantum Information with Gaussian States](#quantumhottopics-quantuminformationgaussianstates)\n    - [Quantum Anomaly Detection](#quantumhottopics-quantumanomalydetection)\n   \t- [Distributed Secure Quantum Machine Learning](#quantumhottopics-distributedsecureqml)\n    - [Decentralized Quantum Machine Learning](#quantumhottopics-decentralizedqml)\n    - [Artificial Agents for Quantum Designs](#quantumhottopics-artificialagents)\n    - [Light Based Quantum Chips for AI Training](#quantumhottopics-quantumlightchipsai)\n- [QUANTUM STATE PREPARATION ALGORITHM FOR MACHINE LEARNING](#quantumstatepreparationalgorithm)\n    - [Pure Quantum State](#quantumstatepreparationalgorithm-purequantumstate)\n    - [Product State](#quantumstatepreparationalgorithm-productstate)\n    - [Matrix Product State](#quantumstatepreparationalgorithm-matrixproductstate)\n    - [Greenberger\xe2\x80\x93Horne\xe2\x80\x93Zeilinger State](#quantumstatepreparationalgorithm-Greenberger)\n    - [W state](#quantumstatepreparationalgorithm-wstate)\n    - [AKLT model](#quantumstatepreparationalgorithm-akltmodel)\n    - [Majumdar\xe2\x80\x93Ghosh Model](#quantumstatepreparationalgorithm-majumdarmodel)\n    - [Multistate Landau\xe2\x80\x93Zener Models](#quantumstatepreparationalgorithm-Landauzenermodels)\n    - [Projected entangled-pair States](#quantumstatepreparationalgorithm-peps)\n    - [Infinite Projected entangled-pair States](#quantumstatepreparationalgorithm-ipeps)\n    - [Corner Transfer Matrix Method](#quantumstatepreparationalgorithm-cornertransfermatrix)\n    - [Tensor-entanglement Renormalization](#quantumstatepreparationalgorithm-tensorentanglerenormaization)\n    - [Tree Tensor Network for Supervised Learning](#quantumstatepreparationalgorithm-treetensornetwork)\n- [QUANTUM MACHINE LEARNING VS DEEP LEARNING](#qmlvsdl)\n- [QUANTUM MEETUPS](#quantummeetups)\n- [QUANTUM GOOGLE GROUPS](#quantumgroups)\n- [QUANTUM BASED COMPANIES](#quantumcompanies)\n- [QUANTUM LINKEDLIN](#quantumlinkedlin)\n- [QUANTUM BASED DEGREES](#quantumdegrees)\n- [CONSOLIDATED QUANTUM ML BOOKS](#quantumconsolidatedbooks)\n- [CONSOLIDATED QUANTUM ML VIDEOS](#quantumconsolidatedvideos)\n- [CONSOLIDATED QUANTUM ML Reserach Papers](#quantumconsolidatedresearchpapers)\n- [CONSOLIDATED QUANTUM ML Reserach Scientist](#quantumconsolidatedresearchscientist)\n- [RECENT QUANTUM UPDATES FORUM ,PAGES AND NEWSLETTER](#quantumforumsnewsletter)\n                                                                   \n\n<!-- /MarkdownTOC -->\n\n<a name=""introduction""></a>\n## INTRODUCTION\n\n<a name=""introduction-why-quantum-machine-learning""></a>\n#### Why Quantum Machine Learning?\n                 \n##### Machine Learning(ML) is just a term in recent days but the work effort start from 18th century.\n\n##### What is  Machine Learning ? , In Simple word the answer is making the computer or application to learn themselves . So its totally related with computing fields like computer science and IT ? ,The answer is not true . ML is a common platform which is mingled in all the aspects of the life from agriculture to mechanics . Computing is a key component to use ML easily and effectively . To be more clear ,Who is the mother of ML ?, As no option Mathematics is the mother of ML . The world tremendous invention complex numbers given birth to this field . Applying mathematics to the real life problem always gives a solution . From Neural Network to the complex DNA is running under some specific mathematical formulas and theorems.\n\n##### As computing technology growing faster and faster mathematics entered into this field and makes the solution via computing to the real world . In the computing technology timeline once a certain achievements reached peoples interested to use advanced mathematical ideas such as complex numbers ,eigen etc and its the kick start for the ML field such as Artificial Neural Network ,DNA Computing etc.\n\n##### Now the main question, why this field is getting boomed now a days ? , From the business perspective , 8-10 Years before during the kick start time for ML ,the big barrier is to merge mathematics into computing field . people knows well in computing has no idea on mathematics and research mathematician has no idea on what is computing . The education as well as the Job Opportunities is like that in that time . Even if a person tried to study both then the business value for making a product be not good.\n\n##### Then the top product companies like Google ,IBM ,Microsoft decided to form a team with mathematician ,a physician and a computer science person to come up with various ideas in this field . Success of this team made some wonderful products and they started by providing cloud services using this product . Now we are in this [stage](https://cloud.google.com/vision/).\n\n##### So what\'s next ? , As mathematics reached the level of time travel concepts but the computing is still running under classical mechanics . the companies understood, the computing field must have a change from classical to quantum, and they started working on the big Quantum computing field, and the market named this field as Quantum Information Science .The kick start is from Google and IBM with the Quantum Computing processor (D-Wave) for making Quantum Neural Network .The field of Quantum Computer Science and Quantum Information Science will do a big change in AI in the next 10 years. Waiting to see that........... .([google](https://research.google.com/pubs/QuantumAI.html), [ibm](http://research.ibm.com/ibm-q/)).\n\n##### References\n     \n* [D-Wave](https://www.dwavesys.com/quantum-computing) - Owner of a quantum processor\n* [Google](https://research.google.com/pubs/QuantumAI.html) - Quantum AI Lab\n* [IBM](http://research.ibm.com/ibm-q/) - Quantum Computer Lab\n* [Quora](https://www.quora.com/Is-quantum-computing-the-future-of-AI) - Question Regarding future of quantum AI\n* [NASA](https://ti.arc.nasa.gov/tech/dash/physics/quail/) - NASA Quantum Works\n* [Youtube](https://www.youtube.com/watch?v=CMdHDHEuOUE) - Google Video of a Quantum Processor\n* [external-link](http://www.huffingtonpost.com/2013/07/29/quantum-computers-ai-artificial-intelligence-studies_n_3664011.html) - MIT Review\n* [microsoft new product](https://www.microsoft.com/en-us/quantum) - Newly Launched Microsoft Quantum Language and Development Kit\n* [microsoft](https://www.microsoft.com/en-us/research/project/language-integrated-quantum-operations-liqui/) - Microsoft Quantum Related Works\n* [Google2](https://research.googleblog.com/2009/12/machine-learning-with-quantum.html) - Google Quantum Machine Learning Blog\n* [BBC](http://www.bbc.co.uk/programmes/p052800h) - About Google Quantum Supremacy,IBM Quantum Computer and Microsoft Q\n* [Google Quantum Supremacy](https://www.youtube.com/watch?v=-ZNEzzDcllU) - Latest 2019 Google Quantum Supremacy Achievement\n* [IBM Quantum Supremacy](https://www.ibm.com/blogs/research/2019/10/on-quantum-supremacy/) - IBM Talk on Quantum Supremacy as a Primer\n* [VICE on the fight](https://www.vice.com/en_in/article/vb5jxd/why-ibm-thinks-google-hasnt-achieved-quantum-supremacy) - IBM Message on Google Quantum Supremacy\n* [IBM Zurich Quantum Safe Cryptography](https://www.zurich.ibm.com/securityprivacy/quantumsafecryptography.html) - An interesting startup to replace all our Certificate Authority Via Cloud and IBM Q\n\n<a name=""basics""></a>\n## BASICS\n\n<a name=""basics-what-quantum-mechanics""></a>\n#### What is Quantum Mechanics?\n                 \n##### In a single line study of an electron moved out of the atom then its classical mechanic ,vibrates inside the atom its quantum mechanics\n\n* [WIKIPEDIA](https://en.wikipedia.org/wiki/Quantum_mechanics) - Basic History and outline\n* [LIVESCIENCE](http://www.livescience.com/33816-quantum-mechanics-explanation.html). - A survey\n* [YOUTUBE](https://www.youtube.com/watch?v=7u_UQG1La1o) - Simple Animation Video Explanining Great.\n\n<a name=""basics-what-quantum-computing""></a>\n#### What is Quantum Computing?                 \n                 \n##### A way of parallel execution of multiple processess in a same time using qubit ,It reduces the computation time and size of the processor probably in neuro size \n\n* [WIKIPEDIA](https://en.wikipedia.org/wiki/Quantum_computing) - Basic History and outline\n* [WEBOPEDIA](http://www.webopedia.com/TERM/Q/quantum_computing.html). - A survey\n* [YOUTUBE](https://www.youtube.com/watch?v=g_IaVepNDT4) - Simple Animation Video Explanining Great.\n\n<a name=""basics-quantum-classical-vs""></a>\n#### Quantum Computing vs Classical Computing\n                 \n* [LINK](http://www.thphys.nuim.ie/staff/joost/TQM/QvC.html) - Basic outline\n\n                                                \n<a name=""quantumcomputing""></a>\n## Quantum Computing\n\n<a name=""quantumcomputing-atom-structure""></a>\n#### Atom Structure\n                 \n##### one line : Electron Orbiting around the nucleous in an eliptical format\n \n* [YOUTUBE](https://www.youtube.com/watch?v=g_IaVepNDT4) - A nice animation video about the basic atom structure                   \n\n[![atom](https://media.giphy.com/media/Tc1NorMBJTBXG/giphy.gif)](https://en.wikipedia.org/wiki/Atom)\n                 \n<a name=""quantumcomputing-photon-wave""></a>\n#### Photon Wave\n                 \n##### one line : Light nornmally called as wave transmitted as photons as similar as atoms in solid particles\n                 \n* [YOUTUBE](https://www.youtube.com/watch?v=fwXQjRBLwsQ) - A nice animation video about the basic photon 1                  \n* [YOUTUBE](https://www.youtube.com/watch?v=KKr91v7yLcM) - A nice animation video about the basic photon 2\n                 \n[![Photon wave](https://www.wired.com/images_blogs/wiredscience/2013/07/photon1.jpg)](https://en.wikipedia.org/wiki/Photon)\n                 \n<a name=""quantumcomputing-elecfluctuation-spin""></a>\n#### Electron Fluctuation or spin\n                 \n##### one line : When a laser light collide with solid particles the electrons of the atom will get spin between the orbitary layers of the atom\n\n[![Spin](https://github.com/krishnakumarsekar/awesome-quantum-machine-learning/blob/master/spinWave.gif)](https://en.wikipedia.org/wiki/Spin_(physics))\n                 \n* [YOUTUBE](https://www.youtube.com/watch?v=J3xLuZNKhlY) - A nice animation video about the basic Electron Spin 1                  \n* [YOUTUBE](https://www.youtube.com/watch?v=3k5IWlVdMbo) - A nice animation video about the basic Electron Spin 2\n* [YOUTUBE](https://www.youtube.com/watch?v=jvvkomcmyuo) - A nice animation video about the basic Electron Spin 3\n                 \n<a name=""quantumcomputing-states""></a>\n#### States\n                 \n##### one line : Put a point on the spinning electron ,if the point is in the top then state 1 and its in bottom state 0 \n\n[![States](https://3c1703fe8d.site.internapcdn.net/newman/gfx/news/hires/2016/adeeplookint.jpg)](https://en.wikipedia.org/wiki/Quantum_state)\n                 \n* [YOUTUBE](https://www.youtube.com/watch?v=sICXOwOwS4E) - A nice animation video about the Quantum States\n                 \n<a name=""quantumcomputing-superposition""></a>\n#### SuperPosition\n                 \n##### two line : During the spin of the electron the point may be in the middle of upper and lower position, So an effective decision needs to take on the point location either 0 or 1 . Better option to analyse it along with other electrons using probability and is called superposition\n\n[![SuperPosition](http://www.users.csbsju.edu/~frioux/superposition.GIF)](https://en.wikipedia.org/wiki/Quantum_superposition)\n                 \n* [YOUTUBE](https://www.youtube.com/watch?v=hkmoZ8e5Qn0) - A nice animation video about the Quantum Superposition\n\n<a name=""quantumcomputing-superpostion-machinelearning""></a>\n#### SuperPosition specific for machine learning(Quantum Walks)\n                 \n##### one line : As due to computational complexity ,quantum computing only consider superposition between limited electrons ,In case to merge more than one set quantum walk be the idea\n\n[![SuperPosition specific for machine learning](https://github.com/krishnakumarsekar/awesome-quantum-machine-learning/blob/master/Galtonboard4.theora.gif)](https://en.wikipedia.org/wiki/Quantum_walk)\n                 \n* [YOUTUBE](https://www.youtube.com/watch?v=86QsYPxoBow) - A nice video about the Quantum Walks\n                                                                   \n<a name=""quantumcomputing-classicalbit""></a>\n#### Classical Bits\n                 \n##### one line : If electron moved from one one atom to other ,from ground state to excited state a bit value 1 is used else bit value 0 used\n\n[![Classical Bits](https://github.com/krishnakumarsekar/awesome-quantum-machine-learning/blob/master/InverseSpinHall.gif)](https://en.wikipedia.org/wiki/Bit)\n                                                                   \n<a name=""quantumcomputing-qubit""></a>\n#### Qubit\n                 \n##### one line : The superposition value of states of a set of electrons is Qubit \n\n[![Qubit](http://qoqms.phys.strath.ac.uk/figures/qubit.png)](https://en.wikipedia.org/wiki/Qubit)\n                                                                   \n* [YOUTUBE](https://www.youtube.com/watch?v=zNzzGgr2mhk) - A nice video about the Quantum Bits 1\n* [YOUTUBE](https://www.youtube.com/watch?v=F8U1d2Hqark&t=179s) - A nice video about the Bits and Qubits 2\n                                                                   \n<a name=""quantumcomputing-basicgates""></a>\n#### Basic Gates in Quantum Computing\n                 \n##### one line : As like NOT, OR and AND , Basic Gates like NOT, Hadamard gate , SWAP, Phase shift etc can be made with quantum gates \n\n[![Basic Gates in Quantum Computing](http://www.mdpi.com/entropy/entropy-16-05290/article_deploy/html/images/entropy-16-05290f1-1024.png)](https://en.wikipedia.org/wiki/Quantum_gate)\n                                                                   \n* [YOUTUBE](https://www.youtube.com/watch?v=2Qsh_w2kq9Y) - A nice video about the Quantum Gates\n                                                                   \n<a name=""quantumcomputing-diode""></a>\n#### Quantum Diode\n                 \n##### one line : Quantum Diodes using a different idea from normal diode, A bunch of laser photons trigger the electron to spin and the quantum magnetic flux will capture the information  \n\n[![Diodes in Quantum Computing1](https://www.ifw-dresden.de/userfiles/groups/iin_folder/research/photonics/picture_laser_iin.jpg)](http://onlinelibrary.wiley.com/doi/10.1002/adma.201200537/abstract)\n[![Diodes in Quantum Computing2](https://www.photonics.com/images/Web/Articles/2016/7/13/LED_Blue.jpg)](https://www.nature.com/articles/ncomms12978)\n[![Diodes in Quantum Computing3](https://3c1703fe8d.site.internapcdn.net/newman/gfx/news/hires/2013/nanoscaleeng.jpg)](https://phys.org/news/2013-10-nanoscale-boosts-quantum-dot-emitting.html)\n\n                                                                   \n* [YOUTUBE](https://www.youtube.com/watch?v=doyK1olswX4) - A nice video about the Quantum Diode\n                                                                   \n<a name=""quantumcomputing-transistor""></a>\n#### Quantum Transistors\n                 \n##### one line : A transistor default have Source ,drain and gate ,Here source is photon wave ,drain is flux and gate is classical to quantum bits \n\n[![Quantum Transistors1](https://images.sciencedaily.com/2010/05/100514075106_1_900x600.jpg)](http://www.mpq.mpg.de/4987844/qip)\n[![Quantum Transistors2](http://www.mpq.mpg.de/5016851/standard-1412932044.png)](https://en.wikipedia.org/wiki/Magnetic_flux_quantum)\n\n                                                                                                                                    \n* [QUORA](https://www.quora.com/What-is-the-equivalent-of-the-transistor-in-a-quantum-computer) -Discussion about the Quantum Transistor\n* [YOUTUBE](https://www.youtube.com/watch?v=ZTxR2n2mvjc) - Well Explained\n                                                                   \n<a name=""quantumcomputing-processor""></a>\n#### Quantum Processor\n                 \n##### one line : A nano integration circuit performing the quantum gates operation sorrounded by cooling units to reduce the tremendous amount of heat \n\n[![Quantum Processor1](https://www.dwavesys.com/sites/default/files/cooling-082015%20copy.png)](https://www.dwavesys.com/tutorials/background-reading-series/introduction-d-wave-quantum-hardware#h2-0)\n[![Quantum Processor2](https://www.photonics.com/images/Web/Articles/2014/6/5/Quantum_Circuit.png)](https://quantumexperience.ng.bluemix.net/qstage/?cm_mc_uid=36641337812614766932472&cm_mc_sid_50200000=1493295650#/user-guide)\n[![Quantum Processor3](https://universe-review.ca/I13-13-superconductive.jpg)](https://www.cbinsights.com/blog/quantum-computing-corporations-list/)\n                                                                                                                                    \n* [YOUTUBE](https://www.youtube.com/watch?v=CMdHDHEuOUE) - Well Explained\n                                                                   \n<a name=""quantumcomputing-qram""></a>\n#### Quantum Registery QRAM\n                 \n##### one line : Comapring the normal ram ,its ultrafast and very small in size ,the address location can be access using qubits superposition value ,for a very large memory set coherent superposition(address of address) be used\n\n[![QRAM1](https://ai2-s2-public.s3.amazonaws.com/figures/2016-11-08/94d487c6ef4d0fa5594eff352aac19e2bfd47ffa/2-Figure1-1.png)](https://arxiv.org/pdf/0708.1879.pdf)\n[![QRAM2](https://github.com/krishnakumarsekar/awesome-quantum-machine-learning/blob/master/QRAM.png)](https://www.researchgate.net/publication/51394884_Quantum_Random_Access_Memory)\n                                                                   \n* [PDF](https://arxiv.org/pdf/0807.4994.pdf) - very Well Explained\n\n\n<a name=""qcmlbridge""></a>\n## QUANTUM COMPUTING MACHINE LEARNING BRIDGE\n                                                                   \n\n<a name=""qcmlbridge-complexNumbers""></a>\n#### Complex Numbers\n                 \n##### one line : Normally Waves Interference is in n dimensional structure , to find a polynomial equation n order curves ,better option is complex number \n\n[![Complex Numbers1](http://www2.clarku.edu/~djoyce/complex/powers.gif)](https://en.wikipedia.org/wiki/Complex_number)\n[![Complex Numbers2](http://theoryofeverything.org/MyToE/wp-content/uploads/2014/12/outChaos2.png)](https://www.mathsisfun.com/numbers/complex-numbers.html)\n[![Complex Numbers3](http://www.mathwarehouse.com/algebra/complex-number/images/graphs/diagram-complex-plane.png)](https://en.wikipedia.org/wiki/Complex_number)\n                                                                                                                                    \n* [YOUTUBE](https://www.youtube.com/watch?v=T647CGsuOVU) - Wonderful Series very super Explained                                                                  \n\n<a name=""qcmlbridge-tensors""></a>\n#### Tensors\n                 \n##### one line : Vectors have a direction in 2D vector space ,If on a n dimensional vector space ,vectors direction can be specify with the tensor ,The best solution to find the superposition of a n vector electrons spin space is representing vectors as tensors and doing tensor calculus\n\n[![Tensors1](https://i.stack.imgur.com/5QsMD.png)](https://en.wikipedia.org/wiki/Tensor)\n[![Tensors2](https://pbs.twimg.com/media/CK-LzV7VAAAdIC3.jpg)](https://www.quantiki.org/wiki/tensor-product)\n[![Tensors3](https://inspirehep.net/record/1082123/files/Fig1.png)](https://en.wikipedia.org/wiki/Tensor_product)\n[![Tensors4](https://inspirehep.net/record/1237922/files/fig1.png)](https://en.wikipedia.org/wiki/Tensor_product_of_Hilbert_spaces)\n                                                                                                                                    \n* [YOUTUBE](https://www.youtube.com/watch?v=f5liqUk0ZTw) - Wonderful super Explained tensors basics\n* [YOUTUBE](https://www.youtube.com/watch?v=xzG6c96PsLs) - Quantum tensors basics                                                                  \n                                                                   \n<a name=""qcmlbridge-tensors-network""></a>\n#### Tensors Network\n                 \n##### one line : As like connecting multiple vectors ,multple tensors form a network ,solving such a network reduce the complexity of processing qubits\n\n[![Tensors Network1](http://www.cse.unsw.edu.au/~billw/cs9444/tensor-stuff/tensor-intro-0418.gif)](https://arxiv.org/pdf/1306.2164.pdf)\n[![Tensors Network2](http://www.quantuminfo.physik.rwth-aachen.de/global/show_picture.asp?id=aaaaaaaaaaiejix)](https://en.wikipedia.org/wiki/Tensor_network_theory)\n[![Tensors Network3](https://inspirehep.net/record/1242488/files/gSymTN.png)](https://www2.warwick.ac.uk/fac/sci/physics/current/postgraduate/pglist/phrfbk/presentations/leeds14.pdf)\n                                                                                                                                    \n* [YOUTUBE](https://www.youtube.com/watch?v=bD-CWgbsCeI&list=PLgKuh-lKre10UQnP7gBCFoKgq5KWIA7el) - Tensors Network Some ideas specifically for quantum algorithms\n                                                                   \n\n<a name=""quantumalgorithmsml""></a>\n## QUANTUM MACHINE LEARNING ALGORITHMS\n                                                                   \n\n<a name=""quantumalgorithmsml-qknn""></a>\n#### Quantum K-Nearest Neighbour\n                 \n##### info : Here the centroid(euclidean distance) can be detected using the swap gates test between two states of the qubit , As KNN is regerssive loss can be tally using the average \n                                                                                                                                    \n* [PDF1 from Microsoft](https://www.microsoft.com/en-us/research/publication/quantum-nearest-neighbor-algorithms-for-machine-learning/) - Theory Explanation\n* [PDF2](https://arxiv.org/pdf/1409.3097.pdf) - A Good Material to understand the basics\n* [Matlab](https://github.com/krishnakumarsekar/) - Yet to come soon\n* [Python](https://github.com/krishnakumarsekar/) - Yet to come soon\n                                                                   \n<a name=""quantumalgorithmsml-kmeans""></a>\n#### Quantum K-Means\n                 \n##### info : Two Approaches possible ,1. FFT and iFFT to make an oracle and calculate the means of superposition 2. Adiobtic Hamiltonian generation and solve the hamiltonian to determine the cluster \n                                                                                                                                    \n* [PDF1](https://pdfs.semanticscholar.org/6d77/54d33958b4a41d57ec99558eb28ae88f9884.pdf) - Applying Quantum Kmeans on Images in a nice way\n* [PDF2](http://www.machinelearning.org/proceedings/icml2007/papers/518.pdf) - Theory\n* [PDF3](https://arxiv.org/pdf/1307.0411.pdf) - Explaining well the K-means clustering using hamiltonian \n* [Matlab](https://github.com/krishnakumarsekar/) - Yet to come soon\n* [Python](https://github.com/krishnakumarsekar/) - Yet to come soon\n                                                                   \n<a name=""quantumalgorithmsml-qfcm""></a>\n#### Quantum Fuzzy C-Means\n                 \n##### info : As similar to kmeans fcm also using the oracle dialect ,but instead of means,here oracle optimization followed by a rotation gate is giving a good result\n                                                                                                                                    \n* [PDF1](https://pdfs.semanticscholar.org/6d77/54d33958b4a41d57ec99558eb28ae88f9884.pdf) - Theory\n* [Matlab](https://github.com/krishnakumarsekar/) - Yet to come soon\n* [Python](https://github.com/krishnakumarsekar/) - Yet to come soon\n                                                                   \n<a name=""quantumalgorithmsml-svm""></a>\n#### Quantum Support Vector Machine\n                 \n##### info : A little different from above as here kernel preparation is via classical and the whole training be in oracles and oracle will do the classification, As SVM is linear ,An optimal Error(Optimum of the Least Squares Dual Formulation) Based regression is needed to improve the performance\n                                                                                                                                    \n* [PDF1](https://arxiv.org/pdf/1307.0471.pdf) - Nice Explanation but little hard to understand :)\n* [PDF2](http://www.scirp.org/journal/PaperInformation.aspx?paperID=72542) - Nice Application of QSVM\n* [Matlab](https://github.com/krishnakumarsekar/) - Yet to come soon\n* [Python](https://github.com/krishnakumarsekar/) - Yet to come soon\n                                                                   \n<a name=""quantumalgorithmsml-genetic""></a>\n#### Quantum Genetic Algorithm\n                 \n##### info : One of the best algorithm suited for Quantum Field ,Here the chromosomes act as qubit vectors ,the crossover part carrying by an evaluation and the mutation part carrying by the rotation of gates\n  \n[![Flow Chart](https://www.hindawi.com/journals/mpe/2013/730749.fig.001.jpg)]()                                                                   \n\n* [PDF1](https://www.hindawi.com/journals/mpe/2013/730749/) - Very Beautiful Article , well explained and superp                                                                 \n* [PDF2](https://arxiv.org/pdf/1202.2026.pdf) - A big theory :)\n* [PDF3](http://ccis2k.org/iajit/PDF/vol.9,no.3/2107-6.pdf) - Super Comparison\n* [Matlab](http://www.codelooker.com/id/155/717734.html) - Simulation\n* [Python1](https://github.com/ResearchCodesHub/QuantumGeneticAlgorithms/) - Simulation\n* [Python2](https://github.com/krishnakumarsekar/) - Yet to come\n                                                                   \n<a name=""quantumalgorithmsml-hmm""></a>\n#### Quantum Hidden Morkov Models\n                 \n##### info : As HMM is already state based ,Here the quantum states acts as normal for the markov chain and the shift between states is using quantum operation based on probability distribution \n  \n[![Flow Chart](https://github.com/krishnakumarsekar/awesome-quantum-machine-learning/blob/master/quantum%20HMM.png)]()                                                                   \n\n* [PDF1](https://arxiv.org/pdf/1503.08760.pdf) - Nice idea and explanation                                                              \n* [PDF2](https://arxiv.org/pdf/1207.4304.pdf) - Nice but a different concept little\n* [Matlab](https://github.com/krishnakumarsekar/) - Yet to come\n* [Python1](https://github.com/krishnakumarsekar/) - Yet to come\n* [Python2](https://github.com/krishnakumarsekar/) - Yet to come\n                                                                   \n<a name=""quantumalgorithmsml-bayesian""></a>\n#### Quantum state classification with Bayesian methods\n                 \n##### info : Quantum Bayesian Network having the same states concept using quantum states,But here the states classification to make the training data as reusable is based on the density of the states(Interference) \n  \n[![Bayesian Network Sample1](https://image.slidesharecdn.com/sweden-150720134538-lva1-app6892/95/quantumlike-bayesian-networks-using-feynmans-path-diagram-rules-13-638.jpg?cb=1437400046)]()                                                                   \n[![Bayesian Network Sample2](https://image.slidesharecdn.com/sml-150512222733-lva1-app6891/95/quantum-models-for-decision-and-cognition-83-638.jpg?cb=1431469807)]()                                                                   \n[![Bayesian Network Sample3](http://ars.els-cdn.com/content/image/1-s2.0-S1568494614004499-fx1.jpg)]()                                                                   \n                                                                   \n* [PDF1](https://arxiv.org/pdf/1204.1550.pdf) - Good Theory                                                              \n* [PDF2](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4726808/) - Good Explanation\n* [Matlab](https://github.com/krishnakumarsekar/) - Yet to come\n* [Python1](https://github.com/krishnakumarsekar/) - Yet to come\n* [Python2](https://github.com/krishnakumarsekar/) - Yet to come\n                                                                   \n<a name=""quantumalgorithmsml-antcolony""></a>\n#### Quantum Ant Colony Optimization\n                 \n##### info : A good algorithm to process multi dimensional equations, ACO is best suited for Sales man issue , QACO is best suited for Sales man in three or more dimension, Here the quantum rotation circuit is doing the peromene update and qubits based colony communicating all around the colony in complex space\n  \n[![Ant Colony Optimization 1](https://agatakycia.files.wordpress.com/2013/06/minimalpathmodule1.jpg)]()                                                                   \n                                                                   \n* [PDF1](http://ac.els-cdn.com/S2212667812001359/1-s2.0-S2212667812001359-main.pdf?_tid=42e0cd66-2f4a-11e7-920f-00000aacb361&acdnat=1493738345_8f536599e404c7588811ddd49c484688) - Good Concept                                                              \n* [PDF2](http://www.sersc.org/journals/IJMUE/vol10_no11_2015/19.pdf) - Good Application\n* [Matlab](https://github.com/krishnakumarsekar/) - Yet to come\n* [Python1](https://github.com/krishnakumarsekar/) - Yet to come\n* [Python2](https://github.com/krishnakumarsekar/) - Yet to come\n                                                                   \n<a name=""quantumalgorithmsml-caautomata""></a>\n#### Quantum Cellular Automata\n                 \n##### info : One of the very complex algorithm with various types specifically used for polynomial equations and to design the optimistic gates for a problem, Here the lattice is formed using the quatum states and time calculation is based on the change of the state between two qubits ,Best suited for nano electronics\n  \n[![Quantum Cellular Automata](https://github.com/krishnakumarsekar/awesome-quantum-machine-learning/blob/master/ta2-color_orig%20b.jpg)]()                                                                   \n                                                                   \n* [Wikipedia](https://en.wikipedia.org/wiki/Quantum_cellular_automaton) - Basic                                                              \n* [PDF1](https://arxiv.org/pdf/0808.0679.pdf) - Just to get the keywords\n* [PDF2](http://ieee-hpec.org/2013/index_htm_files/7-Improved-Eigensolver-Baldwin-2867489.pdf) - Nice Explanation and an easily understandable application                                                                   \n* [Matlab](https://github.com/krishnakumarsekar/) - Yet to come\n* [Python1](https://github.com/krishnakumarsekar/) - Yet to come\n* [Python2](https://github.com/krishnakumarsekar/) - Yet to come\n                                                                   \n                                                                   \n<a name=""qnn""></a>\n## QAUNTUM NEURAL NETWORK\n                                                                   \n[![QNN 1](https://silky.github.io/images/transition-to-quantum-nn.png)](https://silky.github.io/posts/2016-12-11-quantum-neural-networks.html)\n\n##### one line : Its really one of the hardest topic , To understand easily ,Normal Neural Network is doing parallel procss ,QNN is doing parallel of parallel processess ,In theory combination of various activation functions is possible in QNN ,In Normal NN more than one activation function reduce the performance and increase the complexity\n\n<a name=""qnn-perceptron""></a>\n#### Quantum perceptrons\n                 \n##### info : Perceptron(layer) is the basic unit in Neural Network ,The quantum version of perceptron must satisfy both linear and non linear problems , Quantum Concepts is combination of linear(calculus of superposition) and nonlinear(State approximation using probability) ,To make a perceptron in quantum world ,Transformation(activation function) of non linearity to certain limit is needed ,which is carrying by phase estimation algorithm\n  \n[![Quantum Perceptron 1](https://image.slidesharecdn.com/quantumcomputing-150122163158-conversion-gate01/95/quantum-computing-31-638.jpg?cb=1421944504)](https://en.wikipedia.org/wiki/Activation_function)                                                                   \n[![Quantum Perceptron 2](https://www.nature.com/article-assets/npg/srep/2014/140107/srep03589/images/m685/srep03589-f2.jpg)](https://en.wikipedia.org/wiki/Quantum_phase_estimation_algorithm)                                                                   \n[![Quantum Perceptron 3](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS3I5VAXUuU60tWeE9vKV-n59AbupbCcVWxPRCOPaM1i1zT03QsrQ)]()\n[![Quantum Perceptron 4](https://www.omicsonline.org/articles-images/0976-4860-5-128-g001.gif)](https://www.omicsonline.org/open-access/quantum-neural-network-based-parts-of-speech-tagger-for-hindi-0976-4860-5-137-152.pdf.php?aid=35658) \n[![Quantum Perceptron 5](https://3c1703fe8d.site.internapcdn.net/newman/csz/news/800/2015/neuralqubits.jpg)](https://www.researchgate.net/publication/231178445_Quantum_Learning_and_Quantum_Perceptrons) \n\n* [PDF1](https://arxiv.org/pdf/quant-ph/0201144.pdf) - Good Theory                                                              \n* [PDF2](http://axon.cs.byu.edu/papers/ricks.nips03.pdf/) - Good Explanation\n* [Matlab](https://github.com/krishnakumarsekar/) - Yet to come\n* [Python1](https://github.com/krishnakumarsekar/) - Yet to come\n* [Python2](https://github.com/krishnakumarsekar/) - Yet to come\n                                                        \n<a name=""quantumstatistics""></a>\n## QAUNTUM STATISTICAL DATA ANALYSIS\n                                                                   \n[![quantumstatistics1](https://image.slidesharecdn.com/slide2014rims1031public-141101055906-conversion-gate02/95/quantum-minimax-theorem-in-statistical-decision-theory-rims2014-29-638.jpg?cb=1414822200)](https://www.slideshare.net/tanafuyu/slide-2014-rims1031public)\n[![quantumstatistics2](https://image.slidesharecdn.com/slide2014rims1031public-141101055906-conversion-gate02/95/quantum-minimax-theorem-in-statistical-decision-theory-rims2014-36-638.jpg?cb=1414822200)](https://www.slideshare.net/tanafuyu/slide-2014-rims1031public)\n[![quantumstatistics3](https://image.slidesharecdn.com/slide2014rims1031public-141101055906-conversion-gate02/95/quantum-minimax-theorem-in-statistical-decision-theory-rims2014-10-638.jpg?cb=1414822200)](https://www.slideshare.net/tanafuyu/slide-2014-rims1031public)\n[![quantumstatistics4](https://github.com/krishnakumarsekar/awesome-quantum-machine-learning/blob/master/download.png?raw=true)](https://arxiv.org/pdf/0802.1296.pdf)\n[![quantumstatistics5](https://image.slidesharecdn.com/guelph200609-090408123316-phpapp02/95/quantum-dynamics-as-generalized-conditional-probabilities-2-728.jpg?cb=1239194048)](https://www.slideshare.net/mleifer/quantum-dynamics-as-generalized-conditional-probabilities)\n[![quantumstatistics6]( https://image.slidesharecdn.com/guelph200609-090408123316-phpapp02/95/quantum-dynamics-as-generalized-conditional-probabilities-4-728.jpg?cb=1239194048)](https://www.slideshare.net/mleifer/conditional-density-operators-in-quantum-information)                                                                                                               \n\n##### one line : An under research concept ,It can be seen in multiple ways, one best way if you want to apply n derivative for a problem in current classical theory its difficult to compute as its serialization problem instead if you do parallelization of differentiation you must estimate via probability the value in all flows ,Quantum Probability Helps to achieve this ,as the loss calculation is very less . the other way comparatively booming is Quantum Bayesianism, its a solution to solve most of the uncertainity problem in statistics to combine time and space in highly advanced physical research \n\n                                                                   \n<a name=""qpl""></a>\n## QUANTUM PROGRAMMING LANGUAGES , TOOLs and SOFTWARES\n                                                                   \n\n<a name=""qpl-all""></a>\n#### All\n                 \n##### info : All Programming languages ,softwares and tools in alphabetical order \n                                                                                                                                    \n* [Software](https://www.quantiki.org/wiki/list-qc-simulators) - Nice content of all\n* [Python library](http://qutip.org/) - A python library\n* [Matlab based python library](https://pypi.python.org/pypi/qit) - Matlab Python Library\n* [Quantum Tensor Network Github](https://github.com/emstoudenmire/TNML) - Tensor Network\n* [Bayesforge](http://bayesforge.com/) - A Beautiful Amazon Web Service Enabled Framework for Quantum Alogorithms and Data Analytics\n* [Rigetti](https://github.com/rigetticomputing) - A best tools repository to use quantum computer in real time\n* [Rigetti Forest](http://www.rigetti.com/index.php/forest) - An API to connect Quantum Computer\n* [quil/pyQuil](http://pyquil.readthedocs.io/en/latest/overview.html) - A quantum instruction language to use forest framework\n* [Grove](https://github.com/rigetticomputing/grove) - Grove is a repository to showcase quantum Fourier transform, phase estimation, the quantum approximate optimization algorithm, and others developed using Forest\n* [QISKit](https://github.com/QISKit) - A IBM Kit to access quantum computer and mainly for quantum circuits\n* [IBM Bluemix Simulator](https://quantumexperience.ng.bluemix.net/qx/editor) - A Bluemix Simulator for Quantum Circuits\n* [Microsoft Quantum Development Kit](https://marketplace.visualstudio.com/items?itemName=quantum.DevKit) - Microsoft Visual Studio Enbaled Kit for Quantum Circuit Creation\n* [Microsoft ""Q#""](https://docs.microsoft.com/en-us/quantum/quantum-WriteAQuantumProgram?view=qsharp-preview) - Microsoft Q Sharp a new Programming Language for Quantum Circuit Creation\n* [qiskit api python](https://github.com/QISKit/qiskit-api-py) - An API to connect IBM Quantum Computer ,With the generated token its easy to connect ,but very limited utils ,Lot of new utils will come soon \n* [Cyclops Tensor Framework](http://solomon2.web.engr.illinois.edu/ctf/) - A framework to do tensor network simulations\n* [Python ToolKit for chemistry and physics Quantum Algorithm simulations](https://github.com/qmlcode/qml) - A New Started Project for simulating molecule and solids\n* [Bayesian Based Quatum Projects Repository](https://github.com/artiste-qb-net) - A nice repository and the kickstarter of bayesforge\n* [Google Fermion Products](https://github.com/quantumlib) - A newly launched product specifivally for chemistry simulation\n* [Tree Tensor Networks](https://github.com/dingliu0305/Tree-Tensor-Networks-in-Machine-Learning) - Interesting Tensor Network in Incubator\n* [Deep Tensor Neural Network](https://github.com/atomistic-machine-learning/dtnn) - Some useful information about Tensor Neural Network in Incubator\n* [Generative Tensorial Networks](http://gtn.ai/) - A startup to apply machine learning via tensor network for drug discovery\n* [Google Bristlecone](https://research.googleblog.com/2018/03/a-preview-of-bristlecone-googles-new.html) - A new Quantum Processor from Google , Aimed for Future Hardwares with full fledged AI support\n* [XANADU](https://www.xanadu.ai/) - A Light based Quantum Hardware(chips supports) and Software Company Started in Preparation Stage.  Soon will be in market\n* [fathom computing](https://www.fathomcomputing.com/) -  A new concept to train the ai in a processor using light and quantum based concepts. soon products will be launch\n* [Alibaba Quantum Computing Cloud Service](https://www.alibabacloud.com/press-room/alibaba-cloud-and-cas-launch-one-of-the-worlds-most) -  Cloud Service to access 11 Bit Quantum Computing Processor\n* [Atomistic Machine Learning Project](https://github.com/atomistic-machine-learning) - Seems something Interesting with Deep Tensor Network for Quantum Chemistry Applications\n* [circQ and Google Works](https://ai.google/research/teams/applied-science/quantum/) - Google Top Efforts on Tools\n* [IBM Safe Cryptography on Cloud](https://www.sdxcentral.com/articles/news/ibm-drives-quantum-safe-cryptography-into-its-public-cloud/2019/08/) - IBM Started and Developing a Quantm Safe Cryptography to replace all our Certificate Authority via Cloud\n* [Google Tensor Network Open Source](https://ai.googleblog.com/2019/06/introducing-tensornetwork-open-source.html) - Google Started the Most Scientist Preferred Way To Use a Quantum Computer Circuit. Tensor Flow Which Makes Easy to Design the Network and Will Leave the Work Effect Of Gates, Processor Preparation and also going to tell the beauty of Maths\n* [Google Tensor Network Github](https://github.com/google/TensorNetwork) - Github Project of Google Tensor Network\n* [Quantum Tensorflow](https://github.com/krishnakumarsekar/) - Yet to come soon\n* [Quantum Spark](https://github.com/krishnakumarsekar/) - Yet to come soon\n* [Quatum Map Reduce](https://github.com/krishnakumarsekar/) - Yet to come soon\n* [Quantum Database](https://github.com/krishnakumarsekar/) - Yet to come soon\n* [Quantum Server](https://github.com/krishnakumarsekar/) - Yet to come soon\n* [Quantum Data Analytics](https://github.com/krishnakumarsekar/) - Yet to come soon\n                                                                   \n\n<a name=""quantumhottopics""></a>\n## QUANTUM HOT TOPICS\n                                                                   \n\n<a name=""quantumhottopics-deepquantumlearning""></a>\n#### Deep Quantum Learning\n                                                                   \n##### why and what is deep learning?\n###### In one line , If you know deep learning you can get a good job :) ,Even a different platform undergraduated and graduated person done a master specialization in deep learning can work in this big sector :), Practically speaking machine learning (vector mathematics) , deep learning (vector space(Graphics) mathematics) and big data are the terms created by big companies to make a trend in the market ,but in science and research there is no word such that , Now a days if you ask a junior person working in this big companies ,what is deep learning ,you will get some reply as ""doing linear regression with stochastic gradient for a unsupervised data using Convolutional Neural Network :)"" ,They knows the words clearly and knows how to do programming using that on a bunch of ""relative data"" , If you ask them about the FCM , SVM and HMM etc algorithms ,they will simply say these are olden days algorithms , deep learning replaced all :),  But actually they dont know from the birth to the till level and the effectiveness of algorithms and mathematics ,How many mathematical theorems in vector, spaces , tensors etc solved to find this ""hiding the complexity technology"", They did not played with real non relative data like medical images, astro images , geology images etc , finding a relation and features is really complex and looping over n number of images to do pattern matching is a giant work , Now a days the items mentioned as deep learning (= multiple hidden artifical neural network) is not suitable for that\n\n##### why quantum deep learning or deep quantum learning?\n###### In the mid of Artificial Neural Network Research people realised at the maximum extreme only certain mathematical operations possible to do with ANN and the aim of this ANN is to achieve parallel execution of many mathematical operations , In artificial Intelligence ,the world intelligence stands for mathematics ,how effective if a probem can be solvable is based on the mathematics logic applying on the problem , more the logic will give more performance(more intelligent), This goal open the gate for quantum artificial neural network, On applying the ideas behind the deep learning to quantum mechanics environment, its possible to apply complex mathematical equations to n number of non relational data to find more features and can improve the performance\n                                                                   \n<a name=""qmlvsdl""></a>\n## Quantum Machine Learning vs Deep Learning\n                                                                                    \n##### Its fun to discuss about this , In recent days most of the employees from Product Based Companies Like google,microsoft etc using the word deep learning ,What actually Deep Learning ? and is it a new inventions ? how to learn this ? Is it replacing machine learning ? these question come to the mind of junior research scholars and mid level employees\n                 \n##### The one answer to all questions is deep learning = parallel ""for"" loops ,No more than that ,Its an effective way of executing multiple tasks repeatly and to reduce the computation cost, But it introduce a big cap between mathematics and computerscience , How ?  \n\n##### All classical algorithms based on serial processing ,Its depends on the feedback of the first loop ,On applying a serial classical algorithm in multiple clusters wont give a good result ,but some light weight parallel classical algorithms(Deep learning) doing the job in multiple clusters and its not suitable for complex problems, What is the solution for then? \n\n##### As in the title Quantum Machine Learning ,The advantage behind is deep learning is doing the batch processing simply on the data ,but quantum machine learning designed to do batch processing as per the algorithm\n\n##### The product companies realised this one and they started migrating to quantum machine learning and executing the classical algorithms on quantum concept gives better result than deep learning algorithms on classical computer and the target to merge both to give very wonderful result \n\n##### References\n     \n* [Quora](https://www.quora.com/How-will-quantum-computing-revolutionize-deep-learning) - Good Discussion\n* [Quora](https://www.quora.com/Will-quantum-computing-change-machine-learning) - The Bridge Discussion\n* [Pdf](http://www.scottaaronson.com/papers/qml.pdf) - Nice Discussion\n* [Google](https://venturebeat.com/2015/11/11/google-researcher-quantum-computers-arent-perfect-for-deep-learning/) - Google Research Discussion\n* [Microsoft](http://www.physics.usyd.edu.au/quantum/Coogee2015/Presentations/Svore.pdf) - Microsoft plan to merge both\n* [IBM](https://www.rtinsights.com/ibm-quantum-computing-with-machine-learning-in-cloud/) - IBM plan to merge both\n* [IBM Project](https://www.ibm.com/blogs/research/2017/03/quantum-algorithm-classifies-9500-handwritten-numbers/) - IBM Project idea\n* [MIT and Google](https://www.technologyreview.com/s/544421/googles-quantum-dream-machine/) - Solutions for all questions\n                                                                   \n\n<a name=""quantummeetups""></a>\n## QUANTUM MEETUPS\n\n* [Meetup 1](https://www.meetup.com/Quantum-Physics-Drinks/) - Quantum Physics\n* [Meetup 2](https://www.meetup.com/London-Quantum-Computing-Meetup/) - Quantum Computing London\n* [Meetup 3](https://www.meetup.com/New-York-Quantum-Computing-Meetup/) - Quantum Computing New York\n* [Meetup 4](https://www.meetup.com/Quantum-Computing-and-Big-Data/events/238749477/) - Quantum Computing Canada\n* [Meetup 5](https://www.meetup.com/Austin-Quantum-Computing-Artificial-Intelligence-Meetup/) - Quantum Artificial Intelligence Texas\n* [Meetup 6](https://www.meetup.com/The-NY-Quantum-Theory-Group/) - Genarl Quantum Mechanics , Mathematics New York\n* [Meetup 7](https://www.meetup.com/Quantum-Computers/) - Quantum Computing Mountain View California\n* [Meetup 8](https://www.meetup.com/nyhackr/) - Statistical Analysis New York\n* [Meetup 9](https://www.meetup.com/Quantum-Physics-Meetup-Group/) - Quantum Mechanics London UK\n* [Meetup 10](https://www.meetup.com/Quantum-Physics-Drinks/) - Quantum Physics Sydney Australia\n* [Meetup 11](https://www.meetup.com/Berkeley-Quantum-Physics-Spirituality-Meetup/) - Quantum Physics Berkeley CA\n* [Meetup 12](https://www.meetup.com/QuantumX-Quantum-Computing-Meetup/) - Quantum Computing London UK\n* [Meetup 13](https://www.meetup.com/Carmichael-Quantum-Christians/) - Quantum Mechanics Carmichael CA\n* [Meetup 14](https://www.meetup.com/Relativity-Exploration-of-Portland/) - Maths and Science Group Portland\n* [Meetup 15](https://www.meetup.com/Quantum-Physics-Discussion-Group/) - Quantum Physics Santa Monica, CA\n* [Meetup 16](https://www.meetup.com/Quantum-Vibrational-Healing/) - Quantum Mechanics London\n* [Meetup 17](https://www.meetup.com/London-Quantum-Computing-Meetup/) - Quantum Computing London\n* [Meetup 18](https://www.meetup.com/quantum-metaphysics/) - Quantum Meta Physics ,Kansas City , Missouri ,US\n* [Meetup 19](https://www.meetup.com/Quantum-Content/) - Quantum Mechanics and Physics ,Boston ,Massachusetts ,US\n* [Meetup 20](https://www.meetup.com/Quantum-Organization/) - Quantum Physics and Mechanics ,San Francisco ,California\n* [Meetup 21](https://www.meetup.com/Theoretical-Quantum-Mechanics/) - Quantum Mechanics ,Langhorne, Pennsylvania\n* [Meetup 22](https://www.meetup.com/Portland-Science-Meetup/) - Quantum Mechanics ,Portland\n\n                                                                   \n<a name=""quantumdegrees""></a>\n## QUANTUM BASED DEGREES\n\n##### Plenty of courses around the world and many Universities Launching it day by day ,Instead of covering only Quantum ML , Covering all Quantum Related topics gives more idea in the order below\n                                                                   \n#### Available Courses\n\n###### Quantum Mechanics for Science and Engineers\n\n* Online\n                                                                   \n\t* [Standford university](http://online.stanford.edu/course/qmse01-quantum-mechanics-scientists-and-engineers) - Nice Preparatory Course\n\t* [edx](https://courses.edx.org/courses/course-v1:GeorgetownX+PHYX-008-01x+1T2017/info) - Quantum Mechanics for Everyone\n    * [NPTEL 1](http://nptel.ac.in/courses/115104096/) - Nice Series of Courses to understand basics and backbone of quantum mechanics\n    * [NPTEL 2](http://nptel.ac.in/courses/115102023/)\n    * [NPTEL 3](http://nptel.ac.in/courses/115106066/)\n    * [NPTEL 4](http://nptel.ac.in/courses/115108074/)\n   \t* [NPTEL 5](http://nptel.ac.in/courses/115101010/)\n                                                                   \n* Class Based Course\n                                                                   \n\t* UK\n\n\t\t* [Bristol](http://www.bristol.ac.uk/maths/study/undergraduate/units1617/levelh6units/quantum-mechanics-math35500/)\n                                                                   \n\t* Australia\n                                                                   \n\t\t* [Australian National University](http://programsandcourses.anu.edu.au/course/PHYS2013)\n                                                                   \n\t* Europe\n                                                                   \n\t\t* [Maxs Planks University](http://programsandcourses.anu.edu.au/course/PHYS2013)\n                                                                   \n###### Quantum Physics\n                                                                   \n* Online\n\n\t* [MIT](https://ocw.mit.edu/courses/physics/8-04-quantum-physics-i-spring-2013/lecture-videos/) - Super Explanation and well basics\n    * [NPTEL](http://nptel.ac.in/courses/122106034/) - Nice Series of Courses to understand basics and backbone of quantum Physics\n\n* Class Based Course\n                                                                   \n\t* Europe\n\n\t\t* [University of Copenhagen](http://www.nbi.ku.dk/english/research/quantum-physics/)\n                                                                   \n###### Quantum Chemistry\n\n* Online\n\n    * [NPTEL 1](http://nptel.ac.in/courses/104108057/) - Nice Series of Courses to understand basics and backbone of quantum Chemistry\n    * [NPTEL 2](http://nptel.ac.in/courses/104106083/) - \n\n* Class Based Course\n                                                                   \n\t* Europe\n\n\t\t* [UGent Belgium](http://www.quantum.ugent.be/)\n                                                                   \n###### Quantum Computing\n\n* Online\n\n\t* [MIT](https://ocw.mit.edu/courses/mathematics/18-435j-quantum-computation-fall-2003/index.htm) - Super Explanation and well basics\n\t* [edx](https://www.edx.org/course/quantum-mechanics-quantum-computation-uc-berkeleyx-cs-191x) - Nice Explanation\n    * [NPTEL](http://nptel.ac.in/courses/104104082/) - Nice Series of Courses to understand basics and backbone of quantum Computing\n\n* Class Based Course\n                                                                   \n\t* Canada\n                                                                   \n\t\t* [uwaterloo](https://uwaterloo.ca/institute-for-quantum-computing/)\n\n\t* Singapore\n                                                                   \n\t\t* [National University Singapore](http://www.quantumlah.org/)\n\n\t* USA\n                                                                   \n\t\t* [Berkley](http://www.quantumlah.org/)\n                                                        \n    * China\n        \n        * [Baidu](https://medium.com/@Synced/baidu-launches-institute-of-quantum-computing-899454cbe1c5)\n                                                                                                                                                                                                         \n###### Quantum Technology\n\n* Class Based Course\n                                                                   \n\t* Canada\n                                                                   \n\t\t* [uwaterloo](https://uwaterloo.ca/institute-for-quantum-computing/)\n\n\t* Singapore\n                                                                   \n\t\t* [National University Singapore](http://www.quantumlah.org/)\n\n\t* Europe\n                                                                   \n\t\t* [Munich](http://www.munich-quantum-center.de/index.php?id=1)\n                                                        \n    * Russia\n        \n        * [Skoltech](http://crei.skoltech.ru/cpqm)\n                                                                   \n                                                                   \n###### Quantum Information Science\n\n* External Links\n\n\t* [quantwiki](https://www.quantiki.org/wiki/courses-quantum-information-science)\n                                                                   \n* Online\n\n\t* [MIT](https://ocw.mit.edu/courses/media-arts-and-sciences/mas-865j-quantum-information-science-spring-2006/) - Super Explanation and well basics\n\t* [edx](https://www.edx.org/course/quantum-information-science-ii-mitx-8-371x) - Nice Explanation\n    * [NPTEL](http://nptel.ac.in/courses/115101092/) - Nice Series of Courses to understand basics and backbone of quantum information and computing\n\n* Class Based Course\n                                                                   \n\t* USA\n                                                                   \n\t\t* [MIT](http://qis.mit.edu/)\n\t\t* [Standford University](https://web.stanford.edu/group/yamamotogroup/)\n       \t* [Joint Center for Quantum Information and Computer Science - University of Maryland](http://quics.umd.edu/)\n                                                                   \n\t* Canada\n                                                                   \n\t\t* [Perimeter Institute](https://perimeterinstitute.ca/research/research-areas/quantum-information)\n\n\t* Singapore\n                                                                   \n\t\t* [National University Singapore](http://www.quantumlah.org/)\n\n\t* Europe\n                                                                   \n\t\t* [ULB Belgium](http://quic.ulb.ac.be/teaching)\n        * [IQOQI](https://iqoqi.at/en)\n                                                                   \n                                                                                                                                      \n###### Quantum Electronics\n                                                                   \n* Online\n\n    * [MIT](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-974-fundamentals-of-photonics-quantum-electronics-spring-2006/) - Wonderful Course\n    * [NPTEL](http://nptel.ac.in/courses/115102022/) - Nice Series of Courses to understand basics and backbone of quantum Electronics\n\n* Class Based Course\n                                                                                                                                      \n    * USA\n                                                                   \n\t\t* [Texas](http://www.ece.utexas.edu/research/areas/plasma-quantum-electronics-and-optics)                                                               \n    \n\t* Europe\n                                                                   \n\t\t* [Zurich](http://www.iqe.phys.ethz.ch/utils/contact.html)\n        * [ICFO](http://quantumtech.icfo.eu/)                                                           \n                                                                   \n\t* Asia\n                                                                   \n\t\t* [Tata Institute](http://www.tifr.res.in/~quantro/index.html)\n                                                                   \n###### Quantum Field Theory\n\n* Online\n                                                                   \n\t* [Standford university](https://ocw.mit.edu/courses/physics/8-323-relativistic-quantum-field-theory-i-spring-2008/) - Nice Preparatory Course\n    * [edx](https://www.edx.org/course/effective-field-theory-mitx-8-eftx) - Some QFT Concepts available\n                                                                   \n* Class Based Course\n                                                                   \n\t* UK\n\n\t\t* [Imperial](http://www.imperial.ac.uk/theoretical-physics/postgraduate-study/msc-in-quantum-fields-and-fundamental-forces/)\n                                                                                                                                      \n\t* Europe\n                                                                   \n\t\t* [Vrije](http://www.vub.ac.be/en/study/fiches/56659/quantum-field-theory)\n                                                                 \n###### Quantum Computer Science\n                                                                   \n* Class Based Course\n                                                                   \n\t* USA\n\n\t\t* [Oxford](https://www.cs.ox.ac.uk/teaching/courses/quantum/)\n        * [Joint Center for Quantum Information and Computer Science - University of Maryland](http://quics.umd.edu/)\n                                                                   \n###### Quantum Artificial Intelligence and Machine Learning\n\n* External Links\n\n\t* [Quora 1](https://www.quora.com/Quantum-Computing-vs-Artificial-Intelligence-for-a-PhD)\n    * [Quora 1](https://www.quora.com/Where-can-you-get-a-PhD-in-quantum-machine-learning)\n    * [Artificial Agents Research for Quantum Designs](https://www.uibk.ac.at/newsroom/artificial-agent-designs-quantum-experiments.html.en)\n                                                                   \n###### Quantum Mathematics\n\n* Class Based Course\n                                                                   \n\t* USA\n\n\t\t* [University of Notre ***](http://acms.nd.edu/research/)\n\n\n<a name=""quantumconsolidatedresearchpapers""></a>\n## CONSOLIDATED Quantum Research Papers\n\n* [scirate](https://scirate.com/) - Plenty of Quantum Research Papers Available\n* [Peter Wittek](http://peterwittek.com/book.html) - Famous Researcher for the Quantum Machine Leanrning , Published a book in this topic\n* [Murphy Yuezhen Niu] (https://scholar.google.com/citations?user=0wJPxfkAAAAJ&hl=en) - A good researcher published some nice articles\n\n<a name=""quantumconsolidatedresearchpapers""></a>\n## Recent Quantum Updates forum ,pages and newsletter\n\n* [Quantum-Tech](https://medium.com/quantum-tech) - A Beautiful Newsletter Page Publishing Amazing Links \n* [facebook Quantum Machine Learning](https://www.facebook.com/quantummachinelearning) - Running By me . Not that much good :). You can get some ideas\n* [Linkedlin Quantum Machine Learning](https://www.linkedin.com/groups/8592758) - A nice page running by experts. Can get plenty of ideas\n* [FOSDEM 2019 Quantum Talks](https://fosdem.org/2019/schedule/track/quantum_computing/) - A one day talk in fosdem 2019 with more than 10 research topics,tools and ideas\n* [FOSDEM 2020 Quantum Talks](https://fosdem.org/2020/schedule/track/quantum_computing/) - Live talk in fosdem 2020 with plenty new research topics,tools and ideas\n\n### License\n\n[![License](http://mirrors.creativecommons.org/presskit/buttons/88x31/svg/cc-zero.svg)](https://github.com/krishnakumarsekar/awesome-quantum-machine-learning/blob/master/LICENCE)\n\n### Dedicated Opensources\n\n[![Dedicated Opensources](http://livingintown.com/wp-content/uploads/sites/1112/2015/03/coming-soon-small.jpg)]()\n                                                                  \n* Source code of plenty of Algortihms in Image Processing , Data Mining ,etc in Matlab, Python ,Java and VC++ Scripts\n* Good Explanations of Plenty of algorithms with flow chart etc\n* Comparison Matrix of plenty of algorithms\n* [Is Quantum Machine Learning Will Reveal the Secret Maths behind Astrology?](https://medium.com/@krishnakumar070891/is-quantum-machine-learning-will-reveal-the-secret-maths-behind-astrology-ce69fd71a019)\n* Awesome Machine Learning and Deep Learning Mathematics is [online](https://github.com/krishnakumarsekar/awesome-machine-learning-deep-learning-mathematics)\n* Published Basic Presentation of the series Quantum Machine Learning\n[![PPT Basics](https://image.slidesharecdn.com/quantummachinelearningbasics-170716201841/95/quantum-machine-learning-basics-1-638.jpg?cb=1500236565)](https://docs.google.com/presentation/d/1sqQu3LhX97OIwIEEvDMpzQRh6x52C9XDs1RkbPBM9uM/present)\n[![PPT Basics2](https://image.slidesharecdn.com/quantummachinelearningbasics2fromscratch-171107121417/95/quantum-machine-learningbasics2fromscratch-1-638.jpg?cb=1510057257)](https://docs.google.com/presentation/d/1TBmkOkfeIifT73p2ENtnU75JgzMXqj9sOPws378-DPc/present)\n\n### Contribution\n\n* If you think this page might helpful. Please help for World Education Charity or kids who wants to learn                                                        \n<a href=""https://github.com/krishnakumarsekar/awesome-quantum-machine-learning/blob/master/contribution.md""><img src=""http://comps.canstockphoto.com/can-stock-photo_csp23653568.jpg"" align=""left"" height=""200"" width=""200""></a>\n'"
62,pbharrin/machinelearninginaction,pbharrin,Source Code for the book: Machine Learning in Action published by Manning,2011-05-04 21:27:47,2020-06-18 19:00:46,HTML,1730,2096,"b'Machine Learning in Action \n==========================\n\nThis is the source code to go with ""Machine Learning in Action"" \nby Peter Harrington published by Manning Inc.\nThe official page for this book can be found here: http://manning.com/pharrington/\n\nAll the code examples were working on Python 2.6, there shouldn\'t be any problems with the 2.7.  NumPy will be needed for most examples.  If you have trouble running any of the examples us know on the Forum for this book: http://www.manning-sandbox.com/forum.jspa?forumID=728.  \n\nIf you want to run these on some other version of Python say--3.0 or IronPython, feel free to fork the code.   \n'"
63,xiaqunfeng/machine-learning-yearning,xiaqunfeng,Translation of <Machine Learning Yearning> by Andrew NG,2018-01-10 12:07:01,2020-05-28 00:57:21,,423,1349,"b'# README\n\n**\xe7\x9b\xae  \xe5\xbd\x95**\n\n- [\xe7\xae\x80\xe4\xbb\x8b](#\xe7\xae\x80\xe4\xbb\x8b)\n- [\xe7\x9b\xae\xe7\x9a\x84](#\xe7\x9b\xae\xe7\x9a\x84)\n- [\xe7\xbf\xbb\xe8\xaf\x91\xe7\xab\xa0\xe8\x8a\x82](#\xe7\xbf\xbb\xe8\xaf\x91\xe7\xab\xa0\xe8\x8a\x82)\n- [\xe8\x8b\xb1\xe6\x96\x87\xe5\x8e\x9f\xe6\x96\x87](#\xe8\x8b\xb1\xe6\x96\x87\xe5\x8e\x9f\xe6\x96\x87)\n- [\xe9\x87\x8d\xe8\xa6\x81\xe5\xa3\xb0\xe6\x98\x8e](#\xe9\x87\x8d\xe8\xa6\x81\xe5\xa3\xb0\xe6\x98\x8e!!!)\n\n## \xe7\xae\x80\xe4\xbb\x8b\n\nNG\xe7\x9a\x84\xe6\x89\x8b\xe7\xa8\xbf\xef\xbc\x8c\xe5\x85\xb158\xe7\xab\xa0\xe7\x8e\xb0\xe5\xb7\xb2\xe5\x87\xba\xe5\x85\xa8\xe3\x80\x82\xe6\x88\x91\xe8\xbf\x99\xe9\x87\x8c\xe8\xbe\xb9\xe5\xad\xa6\xe4\xb9\xa0\xe8\xbe\xb9\xe7\xbf\xbb\xe8\xaf\x91\xef\xbc\x8c\xe9\x9a\x8f\xe6\x89\x8b\xe8\xae\xb0\xe5\xbd\x95\xe4\xb9\x8b\xef\xbc\x8c\xe5\x8a\xa0\xe6\xb7\xb1\xe5\xad\xa6\xe4\xb9\xa0\xe5\x8d\xb0\xe8\xb1\xa1\xef\xbc\x8c\xe4\xbb\x85\xe4\xbe\x9b\xe5\xad\xa6\xe4\xb9\xa0\xe4\xba\xa4\xe6\xb5\x81\xe3\x80\x82 \n\n\xe5\xae\x98\xe7\xbd\x91\xef\xbc\x9a[http://www.mlyearning.org/](http://www.mlyearning.org/)\n\n**\xe6\x9b\xb4\xe6\x96\xb0\xe8\xae\xb0\xe5\xbd\x95\xef\xbc\x9a**\n\n- update 2018.02.02\xef\xbc\x9a\xe5\xae\x8c\xe6\x88\x901~14\xe7\xab\xa0\xe7\x9a\x84\xe7\xbf\xbb\xe8\xaf\x91\xef\xbc\x88DONE\xef\xbc\x89\n\n- update 2018.04.25\xef\xbc\x9aNG\xe7\xbb\x88\xe4\xba\x8e\xe5\x87\xba15~19\xe7\xab\xa0\xe7\x9a\x84\xe6\x89\x8b\xe7\xa8\xbf\xe5\x95\xa6\xef\xbc\x8c\xe7\xad\x89\xe7\x9a\x84\xe5\xa5\xbd\xe8\xbe\x9b\xe8\x8b\xa6\xef\xbc\x88DONE\xef\xbc\x89\n\n> Tips\xef\xbc\x9a\xe5\x9c\xa8\xe5\x8e\x9f\xe5\x85\x88\xe7\x9a\x8412\xe7\xab\xa0\xe5\x92\x8c13\xe7\xab\xa0\xe4\xb9\x8b\xe9\x97\xb4\xe6\x96\xb0\xe5\xa2\x9e\xe4\xb8\x80\xe4\xb8\xaa\xe7\xab\xa0\xe8\x8a\x82 `13 Build your first system quickly, then iterate`\xef\xbc\x8c\xe5\x8e\x9f\xe5\x85\x88\xe7\x9a\x84chapter13\xe5\x8f\x98\xe4\xb8\xba14\xef\xbc\x8cchapter14\xe5\x8f\x98\xe4\xb8\xba15\n\n- update 2018.05.02\xef\xbc\x9a\xe6\x89\x8b\xe7\xa8\xbf 20~22 \xe7\xab\xa0\xe5\xb7\xb2\xe5\x87\xba\xef\xbc\x88DONE\xef\xbc\x89\n- update 2018.05.09\xef\xbc\x9a\xe6\x89\x8b\xe7\xa8\xbf 23~27 \xe7\xab\xa0\xe5\xb7\xb2\xe5\x87\xba\xef\xbc\x88DONE\xef\xbc\x89\n- update 2018.05.16\xef\xbc\x9a\xe6\x89\x8b\xe7\xa8\xbf 28~30 \xe7\xab\xa0\xe5\xb7\xb2\xe5\x87\xba\xef\xbc\x88DONE\xef\xbc\x89\n- update 2018.05.23\xef\xbc\x9a\xe6\x89\x8b\xe7\xa8\xbf 31~32 \xe7\xab\xa0\xe5\xb7\xb2\xe5\x87\xba\xef\xbc\x88DONE\xef\xbc\x89\n- update 2018.05.30\xef\xbc\x9a\xe6\x89\x8b\xe7\xa8\xbf 33~35 \xe7\xab\xa0\xe5\xb7\xb2\xe5\x87\xba\xef\xbc\x88DONE\xef\xbc\x89\n- update 2018.06.06\xef\xbc\x9a\xe6\x89\x8b\xe7\xa8\xbf 36~39 \xe7\xab\xa0\xe5\xb7\xb2\xe5\x87\xba\xef\xbc\x88DONE\xef\xbc\x89\n- update 2018.06.13\xef\xbc\x9a\xe6\x89\x8b\xe7\xa8\xbf 40~43 \xe7\xab\xa0\xe5\xb7\xb2\xe5\x87\xba\xef\xbc\x88DONE\xef\xbc\x89\n- update 2018.06.20\xef\xbc\x9a\xe6\x89\x8b\xe7\xa8\xbf 44~46 \xe7\xab\xa0\xe5\xb7\xb2\xe5\x87\xba\xef\xbc\x88DONE\xef\xbc\x89\n- update 2018.06.27\xef\xbc\x9a\xe6\x89\x8b\xe7\xa8\xbf 47~49 \xe7\xab\xa0\xe5\xb7\xb2\xe5\x87\xba\xef\xbc\x88DONE\xef\xbc\x89\n- update 2018.07.04\xef\xbc\x9a\xe6\x89\x8b\xe7\xa8\xbf 50~52 \xe7\xab\xa0\xe5\xb7\xb2\xe5\x87\xba\xef\xbc\x88DONE\xef\xbc\x89\n- update 2018.09.29\xef\xbc\x9a\xe6\x89\x8b\xe7\xa8\xbf 53~58 \xe7\xab\xa0\xe5\xb7\xb2\xe5\x87\xba\xef\xbc\x88DONE\xef\xbc\x89\n\n> \xe4\xb8\x9a\xe4\xbd\x99\xe6\x97\xb6\xe9\x97\xb4\xe7\xbf\xbb\xe8\xaf\x91\xef\xbc\x8c\xe6\xb0\xb4\xe5\xb9\xb3\xe6\x9c\x89\xe9\x99\x90\xef\xbc\x8c\xe5\xa6\x82\xe6\x9c\x89\xe4\xb8\x8d\xe5\xa6\xa5\xe6\x88\x96\xe9\x94\x99\xe8\xaf\xaf\xe4\xb9\x8b\xe5\xa4\x84\xef\xbc\x8c\xe6\xac\xa2\xe8\xbf\x8e\xe4\xb8\x8d\xe5\x90\x9d\xe8\xb5\x90\xe6\x95\x99\xe3\x80\x82\n\n## \xe7\x9b\xae\xe7\x9a\x84\n\n\xe8\xbf\x99\xe6\x9c\xac\xe4\xb9\xa6\xe7\x9a\x84\xe7\x9b\xae\xe7\x9a\x84\xe6\x98\xaf\xe6\x95\x99\xe4\xbd\xa0\xe5\xa6\x82\xe4\xbd\x95\xe5\x81\x9a\xe7\xbb\x84\xe7\xbb\x87\xe4\xb8\x80\xe4\xb8\xaa\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe9\xa1\xb9\xe7\x9b\xae\xe6\x89\x80\xe9\x9c\x80\xe7\x9a\x84\xe5\xa4\xa7\xe9\x87\x8f\xe7\x9a\x84\xe5\x86\xb3\xe5\xae\x9a\xe3\x80\x82 \xe4\xbd\xa0\xe5\xb0\x86\xe5\xad\xa6\xe4\xb9\xa0\xef\xbc\x9a\n\n- \xe5\xa6\x82\xe4\xbd\x95\xe5\xbb\xba\xe7\xab\x8b\xe4\xbd\xa0\xe7\x9a\x84\xe5\xbc\x80\xe5\x8f\x91\xe5\x92\x8c\xe6\xb5\x8b\xe8\xaf\x95\xe9\x9b\x86\n- \xe5\x9f\xba\xe6\x9c\xac\xe9\x94\x99\xe8\xaf\xaf\xe5\x88\x86\xe6\x9e\x90\n- \xe5\xa6\x82\xe4\xbd\x95\xe4\xbd\xbf\xe7\x94\xa8\xe5\x81\x8f\xe5\xb7\xae\xe5\x92\x8c\xe6\x96\xb9\xe5\xb7\xae\xe6\x9d\xa5\xe5\x86\xb3\xe5\xae\x9a\xe8\xaf\xa5\xe5\x81\x9a\xe4\xbb\x80\xe4\xb9\x88\n- \xe5\xad\xa6\xe4\xb9\xa0\xe6\x9b\xb2\xe7\xba\xbf\n- \xe5\xb0\x86\xe5\xad\xa6\xe4\xb9\xa0\xe7\xae\x97\xe6\xb3\x95\xe4\xb8\x8e\xe4\xba\xba\xe7\xb1\xbb\xe6\xb0\xb4\xe5\xb9\xb3\xe7\x9a\x84\xe8\xa1\xa8\xe7\x8e\xb0\xe8\xbf\x9b\xe8\xa1\x8c\xe6\xaf\x94\xe8\xbe\x83\n- \xe8\xb0\x83\xe8\xaf\x95\xe6\x8e\xa8\xe7\x90\x86\xe7\xae\x97\xe6\xb3\x95\n- \xe4\xbb\x80\xe4\xb9\x88\xe6\x97\xb6\xe5\x80\x99\xe5\xba\x94\xe8\xaf\xa5\xe5\x92\x8c\xe4\xb8\x8d\xe5\xba\x94\xe8\xaf\xa5\xe4\xbd\xbf\xe7\x94\xa8\xe7\xab\xaf\xe5\x88\xb0\xe7\xab\xaf\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\n- \xe6\x8c\x89\xe6\xad\xa5\xe8\xbf\x9b\xe8\xa1\x8c\xe9\x94\x99\xe8\xaf\xaf\xe5\x88\x86\xe6\x9e\x90\n\n## \xe7\xbf\xbb\xe8\xaf\x91\xe7\xab\xa0\xe8\x8a\x82\n\n\xe5\x85\xb158\xe4\xb8\xaa\xe7\xab\xa0\xef\xbc\x8c\xe5\x88\x8610\xe5\xb0\x8f\xe8\x8a\x82\xef\xbc\x9a\n\n- Setting up development and test sets\n- Basic Error Analysis\n- Bias and Variance\n- Learning curves\n- Comparing to human-level performance\n- Training and testing on different distributions\n- Debugging inference algorithms\n- End-to-end deep learning\n- Error analysis by parts\n- Conclusion\n\n\xe7\xbf\xbb\xe8\xaf\x91\xe5\x86\x85\xe5\xae\xb9\xe7\xa7\xbb\xe6\xad\xa5gitbooks\xef\xbc\x9a[Machine Learning Yearning](https://xiaqunfeng.gitbooks.io/machine-learning-yearning/content/)\n\n## \xe8\x8b\xb1\xe6\x96\x87\xe5\x8e\x9f\xe6\x96\x87\n\n\xe8\xaf\xa6\xe8\xa7\x81 draft \xe7\x9b\xae\xe5\xbd\x95\xef\xbc\x9a\n\n01-14\xe7\xab\xa0\xef\xbc\x9a[Ng_MLY01-01-14.pdf](draft/Ng_MLY01-01-14.pdf)\n\n15-19\xe7\xab\xa0\xef\xbc\x9a[Ng_MLY02-15-19.pdf](draft/Ng_MLY02-15-19.pdf)\n\n20-22\xe7\xab\xa0\xef\xbc\x9a[Ng_MLY03-20-22.pdf](draft/Ng_MLY03-20-22.pdf)\n\n23-27\xe7\xab\xa0\xef\xbc\x9a[Ng_MLY04-23-27.pdf](draft/Ng_MLY04-23-27.pdf)\n\n28-30\xe7\xab\xa0\xef\xbc\x9a[Ng_MLY05-28-30.pdf](draft/Ng_MLY05-28-30.pdf)\n\n31-32\xe7\xab\xa0\xef\xbc\x9a[Ng_MLY06-31-32.pdf](draft/Ng_MLY06-31-32.pdf)\n\n33-35\xe7\xab\xa0\xef\xbc\x9a[Ng_MLY07-33-35.pdf](draft/Ng_MLY07-33-35.pdf)\n\n36-39\xe7\xab\xa0\xef\xbc\x9a[Ng_MLY08-36-39.pdf](draft/Ng_MLY08-36-39.pdf)\n\n40-43\xe7\xab\xa0\xef\xbc\x9a[Ng_MLY09-40-43.pdf](draft/Ng_MLY09-40-43.pdf)\n\n44-46\xe7\xab\xa0\xef\xbc\x9a[NG_MLY10-44-46.pdf](draft/NG_MLY10-44-46.pdf)\n\n47-49\xe7\xab\xa0\xef\xbc\x9a[NG_MLY11-47-49.pdf](draft/NG_MLY11-47-49.pdf)\n\n50-52\xe7\xab\xa0\xef\xbc\x9a[Ng_MLY12-50-52.pdf](draft/NG_MLY12-50-52.pdf)\n\n53-58\xe7\xab\xa0\xef\xbc\x9a[Ng_MLY13-53-58.pdf](draft/NG_MLY13-53-58.pdf)\n\n## **\xe9\x87\x8d\xe8\xa6\x81\xe5\xa3\xb0\xe6\x98\x8e!!!**\n\n1\xe3\x80\x81\xe5\xb7\xb2\xe6\x8e\x88\xe6\x9d\x83\xe4\xbd\x9c\xe8\x80\x85\xe8\xae\xa4\xe4\xb8\xba\xe6\x88\x91\xe6\x98\xaf\xe6\x9c\x89\xe6\x84\x8f\xe6\x89\xa9\xe6\x95\xa3\xe7\x9a\x84\xef\xbc\x8c\xe7\x89\xb9\xe6\xad\xa4\xe8\xaf\x81\xe6\x98\x8e\xe4\xb8\x8d\xe6\x98\xaf\xef\xbc\x8c\xe4\xbb\xa5\xe4\xb8\x8b\xe6\x98\xaf\xe9\x82\xae\xe4\xbb\xb6\xe6\x88\xaa\xe5\x9b\xbe\xef\xbc\x9a\n\n![mly](mly.jpg)\n\n\xe6\x88\x91\xe4\xb8\x8d\xe5\xa4\xaa\xe7\x9c\x8b\xe9\x82\xae\xe4\xbb\xb6\xef\xbc\x8c\xe5\x9c\xa8\xe6\x88\x91\xe6\x8e\x88\xe6\x9d\x83\xe5\x90\x8c\xe6\x84\x8f\xe4\xb9\x8b\xe5\x89\x8d\xe8\xaf\xa5\xe6\x96\x87\xe7\xab\xa0\xe5\xb0\xb1\xe5\xb7\xb2\xe7\xbb\x8f\xe5\x8f\x91\xe5\x87\xba\xe4\xba\x86\xef\xbc\x8c\xe4\xb9\x9f\xe6\x98\xaf\xe5\x90\x8c\xe4\xba\x8b\xe7\x9c\x8b\xe5\x88\xb0\xe5\x90\x8e\xe5\x8f\x91\xe6\x88\x91\xe6\x89\x8d\xe7\x9f\xa5\xe9\x81\x93\xe7\x9a\x84\xef\xbc\x8c\xe6\x88\x91\xe7\x9c\x8b\xe4\xba\x86\xe6\x9c\xba\xe5\x99\xa8\xe4\xb9\x8b\xe5\xbf\x83\xe7\x9a\x84\xe6\x8a\xa5\xe9\x81\x93\xef\xbc\x8c\xe6\x8e\xaa\xe8\xbe\x9e\xe4\xb8\x8a\xe6\xb2\xa1\xe6\x9c\x89\xe4\xbb\x80\xe4\xb9\x88\xe9\x97\xae\xe9\xa2\x98\xef\xbc\x8c\xe4\xba\x8e\xe6\x98\xaf\xe8\xa1\xa5\xe4\xba\x86\xe5\x90\x8c\xe6\x84\x8f\xef\xbc\x8c\xe4\xbd\x86\xe5\xbc\xba\xe8\xb0\x83\xe4\xba\x86\xe2\x80\x9c\xe7\x94\xa8\xe4\xba\x8e\xe5\xad\xa6\xe4\xb9\xa0\xe4\xba\xa4\xe6\xb5\x81\xe2\x80\x9d\xe3\x80\x82\n\n2\xe3\x80\x81\xe4\xbd\x9c\xe8\x80\x85\xe4\xb8\x80\xe7\x9b\xb4\xe5\xbc\xba\xe8\xb0\x83\xe6\x88\x91\xe7\x9a\x84\xe7\xbf\xbb\xe8\xaf\x91\xe8\x84\xb1\xe7\xa6\xbb\xe4\xba\x86\xe3\x80\x8a\xe8\x91\x97\xe4\xbd\x9c\xe6\x9d\x83\xe6\xb3\x95\xe3\x80\x8b\xe4\xb8\xad\xe5\xaf\xb9\xe4\xba\x8e\xe7\xbf\xbb\xe8\xaf\x91\xe6\x9d\x83\xe6\x89\x80\xe8\xa7\x84\xe5\xae\x9a\xe7\x9a\x84 \xe2\x80\x9c\xe4\xb8\xba\xe5\xad\xa6\xe6\xa0\xa1\xe8\xaf\xbe\xe5\xa0\x82\xe6\x95\x99\xe5\xad\xa6\xe6\x88\x96\xe8\x80\x85\xe7\xa7\x91\xe5\xad\xa6\xe7\xa0\x94\xe7\xa9\xb6\xef\xbc\x8c\xe7\xbf\xbb\xe8\xaf\x91\xe5\xb7\xb2\xe7\xbb\x8f\xe5\x8f\x91\xe8\xa1\xa8\xe7\x9a\x84\xe4\xbd\x9c\xe5\x93\x81\xef\xbc\x8c\xe4\xbe\x9b\xe6\x95\x99\xe5\xad\xa6\xe6\x88\x96\xe8\x80\x85\xe7\xa7\x91\xe7\xa0\x94\xe4\xba\xba\xe5\x91\x98\xe4\xbd\xbf\xe7\x94\xa8\xef\xbc\x8c\xe4\xbd\x86\xe4\xb8\x8d\xe5\xbe\x97\xe5\x87\xba\xe7\x89\x88\xe5\x8f\x91\xe8\xa1\x8c\xe2\x80\x9d \xe7\x9a\x84\xe7\x89\xb9\xe6\xae\x8a\xe8\x8c\x83\xe7\x95\xb4\n\n\xe6\x88\x91\xe5\xaf\xb9\xe6\xad\xa4\xe6\x8f\x90\xe5\x87\xba\xe7\x96\x91\xe6\x83\x91\xef\xbc\x8c\xe8\xae\xa4\xe4\xb8\xba\xe6\xb2\xa1\xe6\x9c\x89\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xba\xe6\x88\x91\xe4\xbb\x8e\xe6\x9c\x80\xe5\xbc\x80\xe5\xa7\x8b\xe5\xb0\xb1\xe6\x98\xaf\xe4\xbb\xa5\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9a\x84\xe7\x9b\xae\xe7\x9a\x84\xe6\x9d\xa5\xe7\xbf\xbb\xe8\xaf\x91\xe7\x9a\x84\xef\xbc\x8c\xe4\xbb\x85\xe4\xbb\x85\xe4\xbd\x9c\xe4\xb8\xba\xe8\x87\xaa\xe5\xb7\xb1\xe7\x9a\x84\xe8\xae\xb0\xe5\xbd\x95\xef\xbc\x8c\xe4\xbb\x8e\xe5\xa7\x8b\xe8\x87\xb3\xe7\xbb\x88\xe5\xb9\xb6\xe6\xb2\xa1\xe6\x9c\x89\xe5\x85\xb6\xe4\xbb\x96\xe5\x95\x86\xe4\xb8\x9a\xe6\x83\xb3\xe6\xb3\x95\xe3\x80\x82\xe6\x89\x80\xe4\xbb\xa5\xe6\x88\x91\xe8\xbf\x99\xe9\x87\x8c\xe7\xac\xa6\xe5\x90\x88\xe4\xbe\x9b\xe5\xad\xa6\xe4\xb9\xa0\xe6\x8e\xa2\xe8\xae\xa8\xe5\x92\x8c\xe7\xa7\x91\xe7\xa0\x94\xe4\xbd\xbf\xe7\x94\xa8\xe7\x9a\x84\xe8\x8c\x83\xe7\x95\xb4\xe3\x80\x82\xe6\x88\x91\xe5\x86\x8d\xe6\xac\xa1\xe5\x90\x91\xe5\x85\xb6\xe5\x92\xa8\xe8\xaf\xa2\xef\xbc\x8c\xe5\x85\xb6\xe5\xb9\xb6\xe6\xb2\xa1\xe6\x9c\x89\xe7\xbb\x99\xe4\xba\x88\xe6\x88\x91\xe8\xa7\xa3\xe9\x87\x8a\xef\xbc\x8c\xe8\x80\x8c\xe6\x98\xaf\xe4\xb8\x80\xe5\x91\xb3\xe5\x9c\xb0\xe5\xbc\xba\xe8\xb0\x83\xe8\xae\xa9\xe6\x88\x91\xe5\x88\xa0\xe9\x99\xa4\xe3\x80\x82\n\n3\xe3\x80\x81\xe4\xbd\x9c\xe8\x80\x85\xe8\xae\xa4\xe4\xb8\xba\xe6\x88\x91\xe6\x98\xaf\xe5\x9c\xa8\xe9\xaa\x97\xe5\x8f\x96star\xe9\x87\x8f\n\n\xe5\x9c\xa8\xe8\xbf\x99\xe9\x87\x8c\xe6\x88\x91\xe4\xb8\x8d\xe5\x90\x8c\xe6\x84\x8f\xe4\xbd\x9c\xe8\x80\x85\xe7\x9a\x84\xe8\xa7\x82\xe7\x82\xb9\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\x8e\xe5\xa7\x8b\xe8\x87\xb3\xe7\xbb\x88\xe4\xbb\x8e\xe6\x9c\xaa\xe4\xb8\xbb\xe5\x8a\xa8\xe5\xae\xa3\xe4\xbc\xa0\xe8\xbf\x87\xef\xbc\x8c\xe5\x9c\xa8\xe6\x9c\xba\xe5\x99\xa8\xe4\xb9\x8b\xe5\xbf\x83\xe6\x8a\xa5\xe9\x81\x93\xe5\x89\x8d\xe5\xb0\xb1\xe5\xb7\xb2\xe7\xbb\x8f\xe6\x9c\x89\xe4\xba\x94\xe7\x99\xbe\xe5\xa4\x9astar\xef\xbc\x88\xe8\xbf\x9c\xe9\xab\x98\xe4\xba\x8e\xe4\xbd\x9c\xe8\x80\x85\xe7\x9b\xae\xe5\x89\x8d\xe7\x9a\x84\xe4\xb8\xa4\xe7\x99\xbe\xe5\xa4\x9a\xef\xbc\x89\xef\xbc\x8c\xe9\x83\xbd\xe6\x98\xaf\xe8\xa2\xab\xe5\x88\xab\xe4\xba\xba\xe8\x87\xaa\xe5\x8f\x91\xe6\x90\x9c\xe7\xb4\xa2\xe5\x85\xb3\xe6\xb3\xa8\xe7\x9a\x84\xef\xbc\x8c\xe6\x88\x91\xe5\x8f\xaa\xe6\x98\xaf\xe9\xbb\x98\xe9\xbb\x98\xe7\x9a\x84\xe5\x9c\xa8\xe5\x81\x9a\xe6\x88\x91\xe6\x9c\x80\xe5\x88\x9d\xe6\x83\xb3\xe8\xa6\x81\xe5\x81\x9a\xe7\x9a\x84\xe4\xba\x8b\xe6\x83\x85\xef\xbc\x9a\xe5\xb0\xb1\xe6\x98\xaf\xe8\x87\xaa\xe5\xb7\xb1\xe5\x9c\xa8\xe9\x98\x85\xe8\xaf\xbb\xe7\x9a\x84\xe5\x90\x8c\xe6\x97\xb6\xe9\xa1\xba\xe4\xbe\xbf\xe7\xbf\xbb\xe8\xaf\x91\xe8\xae\xb0\xe5\xbd\x95\xe4\xb8\x8b\xe6\x9d\xa5\xef\xbc\x8c\xe6\x96\xb9\xe4\xbe\xbf\xe5\x86\x8d\xe6\xac\xa1\xe6\xb8\xa9\xe4\xb9\xa0\xef\xbc\x8c\xe4\xbb\xa5\xe4\xbe\xbf\xe6\x9b\xb4\xe5\xa5\xbd\xe7\x9a\x84\xe7\x90\x86\xe8\xa7\xa3\xe6\x96\x87\xe7\xab\xa0\xe4\xb8\xad\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9\xe3\x80\x82\xe4\xb8\x8a\xe4\xbc\xa0\xe5\x88\xb0github\xe5\x85\xb6\xe4\xb8\x80\xe6\x98\xaf\xe6\x96\xb9\xe4\xbe\xbf\xe7\xae\xa1\xe7\x90\x86\xef\xbc\x8c\xe5\x85\xb6\xe4\xba\x8c\xe6\x98\xaf\xe8\x83\xbd\xe9\xa1\xba\xe4\xbe\xbf\xe5\x92\x8c\xe5\xa4\xa7\xe5\xae\xb6\xe4\xb8\x80\xe8\xb5\xb7\xe5\xad\xa6\xe4\xb9\xa0\xe4\xba\xa4\xe6\xb5\x81\xef\xbc\x8c\xe5\x85\xb1\xe5\x90\x8c\xe8\xbf\x9b\xe6\xad\xa5\xe3\x80\x82\n\n4\xe3\x80\x81\xe8\x99\xbd\xe7\x84\xb6\xe6\x88\x91\xe5\xbc\x80\xe6\xba\x90\xe7\x9a\x84\xe6\xaf\x94\xe8\xbe\x83\xe6\x97\xa9\xef\xbc\x8c\xe5\x8f\x88\xe5\x9b\xa0\xe4\xb8\xba\xe4\xbb\x85\xe9\x99\x90\xe4\xba\x8e\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9b\xae\xe7\x9a\x84\xef\xbc\x8c\xe5\x86\x8d\xe5\x8a\xa0\xe4\xb8\x8a\xe5\xb7\xa5\xe4\xbd\x9c\xe6\xaf\x94\xe8\xbe\x83\xe5\xbf\x99\xef\xbc\x8c\xe7\xac\xac\xe4\xb8\x80\xe6\xac\xa1\xe5\xbc\x84\xe8\xbf\x99\xe4\xb8\xaa\xef\xbc\x8c\xe6\xb2\xa1\xe6\x9c\x89\xe7\x94\xb3\xe8\xaf\xb7\xe5\xae\x8c\xe6\x95\xb4\xe7\x89\x88\xe6\x9d\x83\xe8\xbf\x99\xe4\xb8\xaa\xe6\x84\x8f\xe8\xaf\x86\xef\xbc\x8c\xe5\x9c\xa8\xe8\xbf\x99\xe4\xb8\x80\xe7\x82\xb9\xe4\xb8\x8a\xe6\xaf\x94\xe4\xb8\x8d\xe4\xb8\x8a\xe5\xbc\x80\xe6\xba\x90\xe4\xb8\x80\xe4\xb8\xaa\xe6\x9c\x88\xe4\xb8\x8d\xe5\x88\xb0\xe7\x9a\x84\xe5\xb7\xb2\xe6\x8e\x88\xe6\x9d\x83\xe4\xbd\x9c\xe8\x80\x85\xe3\x80\x82\xe6\x88\x91\xe5\xb7\xb2\xe7\xbb\x8f\xe5\x90\x91NG\xe6\x8f\x90\xe4\xba\xa4\xe4\xba\x86\xe4\xbb\x85\xe4\xbe\x9b\xe5\xad\xa6\xe4\xb9\xa0\xe4\xba\xa4\xe6\xb5\x81\xe7\x9a\x84\xe6\x8e\x88\xe6\x9d\x83\xe7\x94\xb3\xe8\xaf\xb7\xef\xbc\x8c\xe7\xad\x89\xe5\xbe\x85\xe6\x8e\x88\xe6\x9d\x83\xe4\xb9\x8b\xef\xbc\x8c\xe6\x9a\x82\xe4\xb8\x94\xe5\x85\x88\xe5\x9c\xa8github\xe4\xb8\x8a\xe7\xa7\xbb\xe9\x99\xa4\xe7\xbf\xbb\xe8\xaf\x91\xe5\x86\x85\xe5\xae\xb9\xef\xbc\x8c\xe7\xbb\x99\xe5\x90\x84\xe4\xbd\x8d\xe5\xb0\x8f\xe4\xbc\x99\xe4\xbc\xb4\xe5\xad\xa6\xe4\xb9\xa0\xe4\xb8\x8a\xe5\xb8\xa6\xe6\x9d\xa5\xe7\x9a\x84\xe4\xb8\x8d\xe4\xbe\xbf\xef\xbc\x8c\xe6\x95\xac\xe8\xaf\xb7\xe8\xb0\x85\xe8\xa7\xa3\xe3\x80\x82'"
64,JWarmenhoven/Coursera-Machine-Learning,JWarmenhoven,Coursera Machine Learning - Python code,2015-12-15 18:50:37,2020-06-16 08:10:04,Jupyter Notebook,533,791,"b""# Coursera Machine Learning \n<IMG src='https://coursera.s3.amazonaws.com/topics/ml/large-icon.png?auto=format&dpr=1&h=256&w=256&fit=fill&bg=FFF' width=25% height=25%><P>\nThis repository contains python implementations of certain exercises from the course by Andrew Ng.<P>\n\nFor a number of assignments in the course you are instructed to create complete, stand-alone Octave/MATLAB implementations of certain algorithms (Linear and Logistic Regression for example). The rest of the assignments depend on additional code provided by the course authors. For most of the code in this repository I have instead used existing Python implementations like Scikit-learn.<P>\n\n<A href='http://nbviewer.ipython.org/github/JWarmenhoven/Machine-Learning/blob/master/notebooks/Programming%20Exercise%201%20-%20Linear%20Regression.ipynb'>Exercise 1 - Linear Regression</A><BR>\n<A href='http://nbviewer.ipython.org/github/JWarmenhoven/Machine-Learning/blob/master/notebooks/Programming%20Exercise%202%20-%20Logistic%20Regression.ipynb'>Exercise 2 - Logistic Regression</A><BR>\n<A href='http://nbviewer.ipython.org/github/JWarmenhoven/Machine-Learning/blob/master/notebooks/Programming%20Exercise%203%20-%20Multi-class%20Classification%20and%20Neural%20Networks.ipynb'>Exercise 3 - Multi-class Classification and Neural Networks</A><BR>\n<A href='http://nbviewer.ipython.org/github/JWarmenhoven/Machine-Learning/blob/master/notebooks/Programming%20Exercise%204%20-%20Neural%20Networks%20Learning.ipynb'>Exercise 4 - Neural Networks Learning</A><BR>\n<A href='http://nbviewer.jupyter.org/github/JWarmenhoven/Machine-Learning/blob/master/notebooks/Programming%20Exercise%205%20-%20Regularized%20Linear%20Regression%20and%20Bias%20v.s.%20Variance.ipynb'>Exercise 5 - Regularized Linear Regression and Bias v.s. Variance</A><BR>\n<A href='http://nbviewer.jupyter.org/github/JWarmenhoven/Machine-Learning/blob/master/notebooks/Programming%20Exercise%206%20-%20Support%20Vector%20Machines.ipynb'>Exercise 6 - Support Vector Machines</A><BR>\n<A href='http://nbviewer.jupyter.org/github/JWarmenhoven/Machine-Learning/blob/master/notebooks/Programming%20Exercise%207%20-%20K-means%20Clustering%20and%20Principal%20Component%20Analysis.ipynb'>Exercise 7 - K-means Clustering and Principal Component Analysis</A><BR>\n<A href='http://nbviewer.jupyter.org/github/JWarmenhoven/Machine-Learning/blob/master/notebooks/Programming%20Exercise%208%20-%20Anomaly%20Detection%20and%20Recommender%20Systems.ipynb'>Exercise 8 - Anomaly Detection and Recommender Systems</A><BR>\n\n##### References:\nhttps://www.coursera.org/learn/machine-learning/home/welcome\n"""
65,pennyliang/MachineLearning-C---code,pennyliang,using c++ code to show the example of machine learning,2012-02-28 15:13:53,2020-05-26 01:39:23,C++,236,458,"b'hello,pennyliang\nhello,Deep learning\nhello,I come here again,2017-12-14\n'"
66,Azure-Samples/Azure-MachineLearning-DataScience,Azure-Samples,,2014-10-07 21:55:19,2020-06-03 00:56:43,HTML,345,373,"b'# Azure-MachineLearning-DataScience\n\n> **NOTE** This content is no longer maintained. Visit the [Azure Machine Learning Notebook](https://github.com/Azure/MachineLearningNotebooks) project for sample Jupyter notebooks for ML and deep learning with Azure Machine Learning.\n\nThis repository contains walkthroughs, templates and documentation related to Machine Learning & Data Science services and platforms on Azure. Services and platforms include Data Science Virtual Machine, Azure ML, HDInsight, Microsoft R Server, SQL-Server, Azure Data Lake etc. It also hosts materials related to Team Data Science Process (TDSP, https:aka.ms/tdsp)\n\nThere are also materials from tutorials we have delivered at various conferences including KDD, Strata etc., using the above services and platforms.\n\nFor walkthroughs and templates, the primary documentation is on Microsoft documentation sites, with links back to this GitHub repository for the templates and code etc.\n\n\n## NOTE:\nAny screenshots of [RStudio](https://www.rstudio.com/) are from the Open Source Edition.\n'"
67,learnml/machine-learning-specialization,learnml,,2015-11-16 22:33:39,2020-05-12 05:13:00,Jupyter Notebook,560,564,"b'# Machine Learning Specialization\n\n## Datasets\n### Course 1\n**amazon_baby**\n* https://s3.amazonaws.com/static.dato.com/files/coursera/course-1/amazon_baby.gl.zip\n\n**home_data**\n* https://s3.amazonaws.com/static.dato.com/files/coursera/course-1/home_data.gl.zip\n\n**image_test_data**\n* https://s3.amazonaws.com/static.dato.com/files/coursera/course-1/image_test_data.gl.zip\n\n**image_train_data**\n* https://s3.amazonaws.com/static.dato.com/files/coursera/course-1/image_train_data.gl.zip\n\n**people_wiki.gl**\n* https://s3.amazonaws.com/static.dato.com/files/coursera/course-1/people_wiki.gl.zip\n\n**song_data**\n* https://s3.amazonaws.com/static.dato.com/files/coursera/course-1/song_data.gl.zip\n\n<br/>\n#### Course 2\n* https://s3.amazonaws.com/static.dato.com/files/coursera/course-2/kc_house_data.gl.zip\n\n### References\n\nMore information on the Amazon data set may be found [here](http://jmcauley.ucsd.edu/data/amazon/) as well as in the following paper.\n\n```\nInferring networks of substitutable and complementary products\nJ. McAuley, R. Pandey, J. Leskovec\nKnowledge Discovery and Data Mining, 2015\n```\n'"
68,JerryKurata/MachineLearningWithPython,JerryKurata,Starter files for Pluralsight course: Understanding Machine Learning with Python,2016-04-24 21:20:10,2020-06-09 16:48:10,Jupyter Notebook,311,208,"b'# MachineLearningWithPython\nStarter files for Pluralsight course: Understanding Machine Learning with Python\n\n\n## Edit history\nJan 05, 2019 - Updated references to deprecated functions in Pima-Prediction-with-reload.ipynb\n'"
69,src-d/awesome-machine-learning-on-source-code,src-d,Cool links & research papers related to Machine Learning applied to source code (MLonCode),2017-06-20 13:35:45,2020-06-18 20:56:29,,716,4822,"b'# Awesome Machine Learning On Source Code [![Awesome Machine Learning On Source Code](badges/awesome.svg)](https://github.com/src-d/awesome-machine-learning-on-source-code) [![CI Status](https://travis-ci.org/src-d/awesome-machine-learning-on-source-code.svg)](https://travis-ci.org/src-d/awesome-machine-learning-on-source-code)\n\n![Awesome Machine Learning On Source Code](img/awesome-machine-learning-artwork.png)\n\nA curated list of awesome research papers, datasets and software projects devoted to machine learning _and_ source code. [#MLonCode](https://twitter.com/hashtag/MLonCode)\n\n## Contents\n\n- [Digests](#digests)\n- [Conferences](#conferences)\n- [Competitions](#competitions)\n- [Papers](#papers)\n  - [Program Synthesis and Induction](#program-synthesis-and-induction)\n  - [Source Code Analysis and Language modeling](#source-code-analysis-and-language-modeling)\n  - [Neural Network Architectures and Algorithms](#neural-network-architectures-and-algorithms)\n  - [Embeddings in Software Engineering](#embeddings-in-software-engineering)\n  - [Program Translation](#program-translation)\n  - [Code Suggestion and Completion](#code-suggestion-and-completion)\n  - [Program Repair and Bug Detection](#program-repair-and-bug-detection)\n  - [APIs and Code Mining](#apis-and-code-mining)\n  - [Code Optimization](#code-optimization)\n  - [Topic Modeling](#topic-modeling)\n  - [Sentiment Analysis](#sentiment-analysis)\n  - [Code Summarization](#code-summarization)\n  - [Clone Detection](#clone-detection)\n  - [Differentiable Interpreters](#differentiable-interpreters)\n  - [Related research](#related-research)<details><summary>(links require ""Related research"" spoiler to be open)</summary>\n    - [AST Differencing](#ast-differencing)\n    - [Binary Data Modeling](#binary-data-modeling)\n    - [Soft Clustering Using T-mixture Models](#soft-clustering-using-t-mixture-models)\n    - [Natural Language Parsing and Comprehension](#natural-language-parsing-and-comprehension)\n      </details>\n- [Posts](#posts)\n- [Talks](#talks)\n- [Software](#software)\n  - [Machine Learning](#machine-learning)\n  - [Utilities](#utilities)\n- [Datasets](#datasets)\n- [Credits](#credits)\n- [Contributions](#contributions)\n- [License](#license)\n\n## Digests\n\n- [Learning from ""Big Code""](http://learnbigcode.github.io) - Techniques, challenges, tools, datasets on ""Big Code"".\n- [A Survey of Machine Learning for Big Code and Naturalness](https://ml4code.github.io/) - Survey and literature review on Machine Learning on Source Code.\n\n## Conferences\n\n- <img src=""badges/origin-academia-blue.svg"" alt=""origin-academia"" align=""top""> [ACM International Conference on Software Engineering, ICSE](https://www.icse2018.org/)\n- <img src=""badges/origin-academia-blue.svg"" alt=""origin-academia"" align=""top""> [ACM International Conference on Automated Software Engineering, ASE](https://2019.aseconf.org)\n- <img src=""badges/origin-academia-blue.svg"" alt=""origin-academia"" align=""top""> [ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (FSE)](https://conf.researchr.org/home/fse-2018)\n- <img src=""badges/origin-academia-blue.svg"" alt=""origin-academia"" align=""top""> [2018 IEEE 25th International Conference on Software Analysis, Evolution, and Reengineering (SANER)](https://www.conference-publishing.com/list.php?Event=SANER18MAIN)\n- <img src=""badges/origin-academia-blue.svg"" alt=""origin-academia"" align=""top""> [Machine Learning for Programming](https://ml4p.org/)\n- <img src=""badges/origin-academia-blue.svg"" alt=""origin-academia"" align=""top""> [Workshop on NLP for Software Engineering](https://nl4se.github.io/)\n- <img src=""badges/origin-industry-green.svg"" alt=""origin-industry"" align=""top""> [SysML](http://www.sysml.cc/)\n  - [Talks](https://www.youtube.com/channel/UChutDKIa-AYyAmbT45s991g/)\n- <img src=""badges/origin-academia-blue.svg"" alt=""origin-academia"" align=""top""> [Mining Software Repositories](http://www.msrconf.org/)\n- <img src=""badges/origin-industry-green.svg"" alt=""origin-industry"" align=""top""> [AIFORSE](https://aiforse.org/)\n- <img src=""badges/origin-industry-green.svg"" alt=""origin-industry"" align=""top""> [source{d} tech talks](https://blog.sourced.tech/post/ml_talks_moscow/)\n  - [Talks](https://www.youtube.com/playlist?list=PL5Ld68ole7j3iQFUSB3fR9122dHCUWXsy)\n- <img src=""badges/origin-academia-blue.svg"" alt=""origin-academia"" align=""top""> [NIPS Neural Abstract Machines and Program Induction workshop](https://uclmr.github.io/nampi/)\n  - [Talks](https://www.youtube.com/playlist?list=PLzTDea_cM27LVPSTdK9RypSyqBHZWPywt)\n- <img src=""badges/origin-academia-blue.svg"" alt=""origin-academia"" align=""top""> [CamAIML](https://www.microsoft.com/en-us/research/event/artificial-intelligence-and-machine-learning-in-cambridge-2017/)\n  - [Learning to Code: Machine Learning for Program Induction](https://www.youtube.com/watch?v=vzDuVhFMB9Q) - Alexander Gaunt.\n- <img src=""badges/origin-academia-blue.svg"" alt=""origin-academia"" align=""top""> [MASES 2018](https://mases18.github.io/)\n\n## Competitions\n\n- [CodRep](https://github.com/KTH/CodRep-competition) - competition on automatic program repair: given a source line, find the insertion point.\n\n## Papers\n\n#### Program Synthesis and Induction\n\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=""top""> [Program Synthesis and Semantic Parsing with Learned Code Idioms](https://arxiv.org/abs/1906.10816v2) - Richard Shin, Miltiadis Allamanis, Marc Brockschmidt, Oleksandr Polozov, 2019.\n- <img src=""badges/16-pages-gray.svg"" alt=""16-pages"" align=""top""> [Synthetic Datasets for Neural Program Synthesis](https://openreview.net/forum?id=ryeOSnAqYm) - Richard Shin, Neel Kant, Kavi Gupta, Chris Bender, Brandon Trabucco, Rishabh Singh, Dawn Song, ICLR 2019.\n- <img src=""badges/15-pages-gray.svg"" alt=""15-pages"" align=""top""> [Execution-Guided Neural Program Synthesis](https://openreview.net/forum?id=H1gfOiAqYm) - Xinyun Chen, Chang Liu, Dawn Song, ICLR 2019.\n- <img src=""badges/8-pages-gray.svg"" alt=""8-pages"" align=""top""> [DeepFuzz: Automatic Generation of Syntax Valid C Programs for Fuzz Testing](https://faculty.ist.psu.edu/wu/papers/DeepFuzz.pdf) - Xiao Liu, Xiaoting Li, Rupesh Prajapati, Dinghao Wu, AAAI 2019.\n- <img src=""badges/12-pages-beginner-brightgreen.svg"" alt=""12-pages-beginner"" align=""top""> [NL2Bash: A Corpus and Semantic Parser for Natural Language Interface to the Linux Operating System](https://arxiv.org/abs/1802.08979v2) - Xi Victoria Lin, Chenglong Wang, Luke Zettlemoyer, Michael D. Ernst, LREC 2018.\n- <img src=""badges/18-pages-gray.svg"" alt=""18-pages"" align=""top""> [Recent Advances in Neural Program Synthesis](https://arxiv.org/abs/1802.02353v1) - Neel Kant, 2018.\n- <img src=""badges/16-pages-gray.svg"" alt=""16-pages"" align=""top""> [Neural Sketch Learning for Conditional Program Generation](https://arxiv.org/abs/1703.05698) - Vijayaraghavan Murali, Letao Qi, Swarat Chaudhuri, Chris Jermaine, ICLR 2018.\n- <img src=""badges/11-pages-gray.svg"" alt=""11-pages"" align=""top""> [Neural Program Search: Solving Programming Tasks from Description and Examples](https://arxiv.org/abs/1802.04335v1) - Illia Polosukhin, Alexander Skidanov, ICLR 2018.\n- <img src=""badges/16-pages-gray.svg"" alt=""16-pages"" align=""top""> [Neural Program Synthesis with Priority Queue Training](https://arxiv.org/abs/1801.03526v1) - Daniel A. Abolafia, Mohammad Norouzi, Quoc V. Le, 2018.\n- <img src=""badges/31-pages-gray.svg"" alt=""31-pages"" align=""top""> [Towards Synthesizing Complex Programs from Input-Output Examples](https://arxiv.org/abs/1706.01284v3) - Xinyun Chen, Chang Liu, Dawn Song, ICLR 2018.\n- <img src=""badges/8-pages-gray.svg"" alt=""8-pages"" align=""top""> [Glass-Box Program Synthesis: A Machine Learning Approach](https://arxiv.org/abs/1709.08669v1) - Konstantina Christakopoulou, Adam Tauman Kalai, AAAI 2018.\n- <img src=""badges/14-pages-beginner-brightgreen.svg"" alt=""14-pages"" align=""top""> [Synthesizing Benchmarks for Predictive Modeling](https://chriscummins.cc/pub/2017-cgo.pdf) - Chris Cummins, Pavlos Petoumenos, Zheng Wang, Hugh Leather, CGO 2017\n- <img src=""badges/17-pages-beginner-brightgreen.svg"" alt=""17-pages-beginner"" align=""top""> [Program Synthesis for Character Level Language Modeling](https://files.sri.inf.ethz.ch/website/papers/charmodel-iclr2017.pdf) - Pavol Bielik, Veselin Raychev, Martin Vechev, ICLR 2017.\n- <img src=""badges/13-pages-beginner-brightgreen.svg"" alt=""13-pages-beginner"" align=""top""> [SQLNet: Generating Structured Queries From Natural Language Without Reinforcement Learning](https://arxiv.org/abs/1711.04436v1) - Xiaojun Xu, Chang Liu, Dawn Song, 2017.\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=""top""> [Learning to Select Examples for Program Synthesis](https://arxiv.org/abs/1711.03243v1) - Yewen Pu, Zachery Miranda, Armando Solar-Lezama, Leslie Pack Kaelbling, 2017.\n- <img src=""badges/10-pages-gray.svg"" alt=""10-pages"" align=""top""> [Neural Program Meta-Induction](https://arxiv.org/abs/1710.04157v1) - Jacob Devlin, Rudy Bunel, Rishabh Singh, Matthew Hausknecht, Pushmeet Kohli, NIPS 2017.\n- <img src=""badges/14-pages-beginner-brightgreen.svg"" alt=""14-pages-beginner"" align=""top""> [Learning to Infer Graphics Programs from Hand-Drawn Images](https://arxiv.org/abs/1707.09627v4) - Kevin Ellis, Daniel Ritchie, Armando Solar-Lezama, Joshua B. Tenenbaum, 2017.\n- <img src=""badges/10-pages-gray.svg"" alt=""10-pages"" align=""top""> [Neural Attribute Machines for Program Generation](https://arxiv.org/abs/1705.09231v2) - Matthew Amodio, Swarat Chaudhuri, Thomas Reps, 2017.\n- <img src=""badges/11-pages-beginner-brightgreen.svg"" alt=""11-pages-beginner"" align=""top""> [Abstract Syntax Networks for Code Generation and Semantic Parsing](https://arxiv.org/abs/1704.07535v1) - Maxim Rabinovich, Mitchell Stern, Dan Klein, ACL 2017.\n- <img src=""badges/20-pages-gray.svg"" alt=""20-pages"" align=""top""> [Making Neural Programming Architectures Generalize via Recursion](https://arxiv.org/pdf/1704.06611v1.pdf) - Jonathon Cai, Richard Shin, Dawn Song, ICLR 2017.\n- <img src=""badges/14-pages-gray.svg"" alt=""14-pages"" align=""top""> [A Syntactic Neural Model for General-Purpose Code Generation](https://arxiv.org/abs/1704.01696v1) - Pengcheng Yin, Graham Neubig, ACL 2017.\n- <img src=""badges/12-pages-beginner-brightgreen.svg"" alt=""12-pages-beginner"" align=""top""> [Program Synthesis from Natural Language Using Recurrent Neural Networks](https://homes.cs.washington.edu/~mernst/pubs/nl-command-tr170301.pdf) - Xi Victoria Lin, Chenglong Wang, Deric Pang, Kevin Vu, Luke Zettlemoyer, Michael Ernst, 2017.\n- <img src=""badges/18-pages-beginner-brightgreen.svg"" alt=""18-pages-beginner"" align=""top""> [RobustFill: Neural Program Learning under Noisy I/O](https://arxiv.org/abs/1703.07469v1) - Jacob Devlin, Jonathan Uesato, Surya Bhupatiraju, Rishabh Singh, Abdel-rahman Mohamed, Pushmeet Kohli, ICML 2017.\n- <img src=""badges/11-pages-gray.svg"" alt=""11-pages"" align=""top""> [Lifelong Perceptual Programming By Example](https://openreview.net/pdf?id=HJStZKqel) - Gaunt, Alexander L., Marc Brockschmidt, Nate Kushman, and Daniel Tarlow, 2017.\n- <img src=""badges/7-pages-gray.svg"" alt=""7-pages"" align=""top""> [Neural Programming by Example](https://arxiv.org/abs/1703.04990v1) - Chengxun Shu, Hongyu Zhang, AAAI 2017.\n- <img src=""badges/21-pages-gray.svg"" alt=""21-pages"" align=""top""> [DeepCoder: Learning to Write Programs](https://arxiv.org/abs/1611.01989) - Balog Matej, Alexander L. Gaunt, Marc Brockschmidt, Sebastian Nowozin, and Daniel Tarlow, ICLR 2017.\n- <img src=""badges/10-pages-gray.svg"" alt=""10-pages"" align=""top""> [A Differentiable Approach to Inductive Logic Programming](https://pdfs.semanticscholar.org/9698/409fc1603d28b6d51c38261f6243837c8bdd.pdf) - Yang Fan, Zhilin Yang, and William W. Cohen, 2017.\n- <img src=""badges/12-pages-beginner-brightgreen.svg"" alt=""12-pages-beginner"" align=""top""> [Latent Attention For If-Then Program Synthesis](https://arxiv.org/abs/1611.01867v1) - Xinyun Chen, Chang Liu, Richard Shin, Dawn Song, Mingcheng Chen, NIPS 2016.\n- <img src=""badges/11-pages-gray.svg"" alt=""11-pages"" align=""top"" id=""card2code""> [Latent Predictor Networks for Code Generation](https://arxiv.org/abs/1603.06744) - Wang Ling, Edward Grefenstette, Karl Moritz Hermann, Tom\xc3\xa1\xc5\xa1 Ko\xc4\x8disk\xc3\xbd, Andrew Senior, Fumin Wang, Phil Blunsom, ACL 2016.\n- <img src=""badges/6-pages-gray.svg"" alt=""6-pages"" align=""top""> [Neural Symbolic Machines: Learning Semantic Parsers on Freebase with Weak Supervision (Short Version)](https://arxiv.org/abs/1612.01197) - Liang Chen, Jonathan Berant, Quoc Le, Kenneth D. Forbus, and Ni Lao, NIPS 2016.\n- <img src=""badges/5-pages-gray.svg"" alt=""5-pages"" align=""top""> [Programs as Black-Box Explanations](https://arxiv.org/abs/1611.07579) - Singh, Sameer, Marco Tulio Ribeiro, and Carlos Guestrin, NIPS 2016.\n- <img src=""badges/15-pages-gray.svg"" alt=""15-pages"" align=""top""> [Search-Based Generalization and Refinement of Code Templates](http://soft.vub.ac.be/Publications/2016/vub-soft-tr-16-06.pdf) - Tim Molderez, Coen De Roover, SSBSE 2016.\n- <img src=""badges/14-pages-gray.svg"" alt=""14-pages"" align=""top""> [Structured Generative Models of Natural Source Code](https://arxiv.org/abs/1401.0514) - Chris J. Maddison, Daniel Tarlow, ICML 2014.\n\n#### Source Code Analysis and Language modeling\n\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=""top""> [Modeling Vocabulary for Big Code Machine Learning](https://arxiv.org/abs/1904.01873v1) - Hlib Babii, Andrea Janes, Romain Robbes, 2019.\n- <img src=""badges/24-pages-gray.svg"" alt=""24-pages"" align=""top""> [Generative Code Modeling with Graphs](https://openreview.net/forum?id=Bke4KsA5FX) - Marc Brockschmidt, Miltiadis Allamanis, Alexander L. Gaunt, Oleksandr Polozov, ICLR 2019.\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=""top""> [NL2Type: Inferring JavaScript Function Types from Natural Language Information](http://software-lab.org/publications/icse2019_NL2Type.pdf) - Rabee Sohail Malik, Jibesh Patra, Michael Pradel, ICSE 2019.\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=""top""> [A Novel Neural Source Code Representation based on Abstract Syntax Tree](http://xuwang.tech/paper/astnn_icse2019.pdf) - Jian Zhang, Xu Wang, Hongyu Zhang, Hailong Sun, Kaixuan Wang, Xudong Liu, ICSE 2019.\n- <img src=""badges/11-pages-gray.svg"" alt=""11-pages"" align=""top""> [Deep Learning Type Inference](http://vhellendoorn.github.io/PDF/fse2018-j2t.pdf) - Vincent J. Hellendoorn, Christian Bird, Earl T. Barr and Miltiadis Allamanis, FSE 2018. [Code](https://github.com/DeepTyper/DeepTyper).\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=""top""> [Tree2Tree Neural Translation Model for Learning Source Code Changes](https://arxiv.org/pdf/1810.00314.pdf) - Saikat Chakraborty, Miltiadis Allamanis, Baishakhi Ray, 2018.\n- <img src=""badges/11-pages-gray.svg"" alt=""11-pages"" align=""top""> [code2seq: Generating Sequences from Structured Representations of Code](https://arxiv.org/abs/1808.01400) - Uri Alon, Omer Levy, Eran Yahav, 2018.\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=""top""> [Syntax and Sensibility: Using language models to detect and correct syntax errors](http://softwareprocess.es/pubs/santos2018SANER-syntax.pdf) - Eddie Antonio Santos, Joshua Charles Campbell, Dhvani Patel, Abram Hindle, and Jos\xc3\xa9 Nelson Amaral, SANER 2018.\n- <img src=""badges/25-pages-gray.svg"" alt=""25-pages"" align=""top""> [code2vec: Learning Distributed Representations of Code](https://arxiv.org/abs/1803.09473v2) - Uri Alon, Meital Zilberstein, Omer Levy, Eran Yahav, 2018.\n- <img src=""badges/16-pages-gray.svg"" alt=""16-pages"" align=""top""> [Learning to Represent Programs with Graphs](https://arxiv.org/abs/1711.00740v1) - Miltiadis Allamanis, Marc Brockschmidt, Mahmoud Khademi, ICLR 2018.\n- <img src=""badges/36-pages-gray.svg"" alt=""36-pages"" align=""top""> [A Survey of Machine Learning for Big Code and Naturalness](https://arxiv.org/abs/1709.06182v1) - Miltiadis Allamanis, Earl T. Barr, Premkumar Devanbu, Charles Sutton, 2017.\n- <img src=""badges/36-pages-gray.svg"" alt=""36-pages"" align=""top""> [Are Deep Neural Networks the Best Choice for Modeling Source Code?](http://web.cs.ucdavis.edu/~devanbu/isDLgood.pdf) - Vincent J. Hellendoorn, Premkumar Devanbu, FSE 2017.\n- <img src=""badges/4-pages-gray.svg"" alt=""4-pages"" align=""top""> [A deep language model for software code](https://arxiv.org/abs/1608.02715v1) - Hoa Khanh Dam, Truyen Tran, Trang Pham, 2016.\n- <img src=""badges/8-pages-gray.svg"" alt=""8-pages"" align=""top""> [Convolutional Neural Networks over Tree Structures for Programming Language Processing](https://arxiv.org/abs/1409.5718) - Lili Mou, Ge Li, Lu Zhang, Tao Wang, Zhi Jin, AAAI-16. [Code](https://github.com/crestonbunch/tbcnn).\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=""top""> [Suggesting Accurate Method and Class Names](http://homepages.inf.ed.ac.uk/csutton/publications/accurate-method-and-class.pdf) - Miltiadis Allamanis, Earl T. Barr, Christian Bird, Charles Sutton, FSE 2015.\n- <img src=""badges/10-pages-gray.svg"" alt=""10-pages"" align=""top""> [Mining Source Code Repositories at Massive Scale using Language Modeling](http://homepages.inf.ed.ac.uk/csutton/publications/msr2013.pdf) - Miltiadis Allamanis, Charles Sutton, MSR 2013.\n\n#### Neural Network Architectures and Algorithms\n\n- <img src=""badges/19-pages-gray.svg"" alt=""19-pages"" align=""top""> [Learning Compositional Neural Programs with Recursive Tree Search and Planning](https://arxiv.org/abs/1905.12941v1) - Thomas Pierrot, Guillaume Ligner, Scott Reed, Olivier Sigaud, Nicolas Perrin, Alexandre Laterre, David Kas, Karim Beguir, Nando de Freitas, 2019.\n- <img src=""badges/11-pages-gray.svg"" alt=""11-pages"" align=""top""> [From Programs to Interpretable Deep Models and Back](https://link.springer.com/content/pdf/10.1007%2F978-3-319-96145-3_2.pdf) - Eran Yahav, ICCAV 2018.\n- <img src=""badges/13-pages-gray.svg"" alt=""13-pages"" align=""top""> [Neural Code Comprehension: A Learnable Representation of Code Semantics](https://arxiv.org/abs/1806.07336) - Tal Ben-Nun, Alice Shoshana Jakobovits, Torsten Hoefler, NIPS 2018.\n- <img src=""badges/16-pages-gray.svg"" alt=""16-pages"" align=""top""> [A General Path-Based Representation for Predicting Program Properties](https://arxiv.org/abs/1803.09544) - Uri Alon, Meital Zilberstein, Omer Levy, Eran Yahav, PLDI 2018.\n- <img src=""badges/4-pages-gray.svg"" alt=""4-pages"" align=""top""> [Cross-Language Learning for Program Classification using Bilateral Tree-Based Convolutional Neural Networks](https://arxiv.org/abs/1710.06159v2) - Nghi D. Q. Bui, Lingxiao Jiang, Yijun Yu, AAAI 2018.\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=""top""> [Bilateral Dependency Neural Networks for Cross-Language Algorithm Classification](https://bdqnghi.github.io/files/SANER_2019_bilateral_dependency.pdf) - Nghi D. Q. Bui, Yijun Yu, Lingxiao Jiang, SANER 2018.\n- <img src=""badges/17-pages-gray.svg"" alt=""17-pages"" align=""top""> [Syntax-Directed Variational Autoencoder for Structured Data](https://openreview.net/pdf?id=SyqShMZRb) - Hanjun Dai, Yingtao Tian, Bo Dai, Steven Skiena, Le Song, ICLR 2018.\n- <img src=""badges/19-pages-gray.svg"" alt=""19-pages"" align=""top""> [Divide and Conquer with Neural Networks](https://arxiv.org/abs/1611.02401) - Nowak, Alex, and Joan Bruna, ICLR 2018.\n- <img src=""badges/13-pages-gray.svg"" alt=""13-pages"" align=""top""> [Hierarchical multiscale recurrent neural networks](https://arxiv.org/abs/1609.01704) - Chung Junyoung, Sungjin Ahn, and Yoshua Bengio, ICLR 2017.\n- <img src=""badges/10-pages-gray.svg"" alt=""10-pages"" align=""top""> [Learning Efficient Algorithms with Hierarchical Attentive Memory](https://arxiv.org/abs/1602.03218) - Andrychowicz, Marcin, and Karol Kurach, 2016.\n- <img src=""badges/6-pages-gray.svg"" alt=""6-pages"" align=""top""> [Learning Operations on a Stack with Neural Turing Machines](https://arxiv.org/abs/1612.00827) - Deleu, Tristan, and Joseph Dureau, NIPS 2016.\n- <img src=""badges/5-pages-gray.svg"" alt=""5-pages"" align=""top""> [Probabilistic Neural Programs](https://arxiv.org/abs/1612.00712) - Murray, Kenton W., and Jayant Krishnamurthy, NIPS 2016.\n- <img src=""badges/13-pages-gray.svg"" alt=""13-pages"" align=""top""> [Neural Programmer-Interpreters](https://arxiv.org/abs/1511.06279) - Reed, Scott, and Nando de Freitas, ICLR 2016.\n- <img src=""badges/9-pages-gray.svg"" alt=""9-pages"" align=""top""> [Neural GPUs Learn Algorithms](https://arxiv.org/abs/1511.08228) - Kaiser, \xc5\x81ukasz, and Ilya Sutskever, ICLR 2016.\n- <img src=""badges/17-pages-gray.svg"" alt=""17-pages"" align=""top""> [Neural Random-Access Machines](https://arxiv.org/abs/1511.06392v3) - Karol Kurach, Marcin Andrychowicz, Ilya Sutskever, ERCIM News 2016.\n- <img src=""badges/18-pages-gray.svg"" alt=""18-pages"" align=""top""> [Neural Programmer: Inducing Latent Programs with Gradient Descent](https://arxiv.org/abs/1511.04834) - Neelakantan, Arvind, Quoc V. Le, and Ilya Sutskever, ICLR 2015.\n- <img src=""badges/25-pages-gray.svg"" alt=""25-pages"" align=""top""> [Learning to Execute](https://arxiv.org/abs/1410.4615v3) - Wojciech Zaremba, Ilya Sutskever, 2015.\n- <img src=""badges/10-pages-gray.svg"" alt=""10-pages"" align=""top""> [Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets](https://arxiv.org/abs/1503.01007) - Joulin, Armand, and Tomas Mikolov, NIPS 2015.\n- <img src=""badges/26-pages-gray.svg"" alt=""26-pages"" align=""top""> [Neural Turing Machines](https://arxiv.org/abs/1410.5401) - Graves, Alex, Greg Wayne, and Ivo Danihelka, 2014.\n- <img src=""badges/15-pages-gray.svg"" alt=""15-pages"" align=""top""> [From Machine Learning to Machine Reasoning](https://arxiv.org/abs/1102.1808) - Bottou Leon, Journal of Machine Learning 2011.\n\n#### Embeddings in Software Engineering\n\n- <img src=""badges/8-pages-gray.svg"" alt=""8-pages"" align=""top""> [A Literature Study of Embeddings on Source Code](https://arxiv.org/abs/1904.03061) - Zimin Chen and Martin Monperrus, 2019.\n- <img src=""badges/3-pages-gray.svg"" alt=""3-pages"" align=""top""> [AST-Based Deep Learning for Detecting Malicious PowerShell](https://arxiv.org/pdf/1810.09230.pdf) - Gili Rusak, Abdullah Al-Dujaili, Una-May O\'Reilly, 2018.\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=""top""> [Deep Code Search](https://dl.acm.org/citation.cfm?id=3180167) - Xiaodong Gu, Hongyu Zhang, Sunghun Kim, ICSE 2018.\n- <img src=""badges/4-pages-gray.svg"" alt=""4-pages"" align=""top""> [Word Embeddings for the Software Engineering Domain](https://github.com/vefstathiou/SO_word2vec/blob/master/MSR18-w2v.pdf) - Vasiliki Efstathiou, Christos Chatzilenas, Diomidis Spinellis, MSR 2018.\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=top> [\n  Code Vectors: Understanding Programs Through Embedded Abstracted Symbolic Traces](https://arxiv.org/abs/1803.06686) - Jordan Henkel, Shuvendu K. Lahiri, Ben Liblit, Thomas Reps, FSE 2018.\n- <img src=""badges/10-pages-gray.svg"" alt=""10-pages"" align=""top""> [Document Distance Estimation via Code Graph Embedding](https://www.researchgate.net/publication/320074701_Document_Distance_Estimation_via_Code_Graph_Embedding) - Zeqi Lin, Junfeng Zhao, Yanzhen Zou, Bing Xie, Internetware 2017.\n- <img src=""badges/3-pages-gray.svg"" alt=""3-pages"" align=""top""> [Combining Word2Vec with revised vector space model for better code retrieval](https://www.researchgate.net/publication/318123700_Combining_Word2Vec_with_Revised_Vector_Space_Model_for_Better_Code_Retrieval) - Thanh Van Nguyen, Anh Tuan Nguyen, Hung Dang Phan, Trong Duc Nguyen, Tien N. Nguyen, ICSE 2017.\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=""top""> [From word embeddings to document similarities for improved information retrieval in software engineering](https://www.researchgate.net/publication/296526040_From_Word_Embeddings_To_Document_Similarities_for_Improved_Information_Retrieval_in_Software_Engineering) - Xin Ye, Hui Shen, Xiao Ma, Razvan Bunescu, Chang Liu, ICSE 2016.\n- <img src=""badges/3-pages-gray.svg"" alt=""3-pages"" align=""top""> [Mapping API Elements for Code Migration with Vector Representation](https://dl.acm.org/citation.cfm?id=2892661) - Trong Duc Nguyen, Anh Tuan Nguyen, Tien N. Nguyen, ICSE 2016.\n\n#### Program Translation\n\n- <img src=""badges/18-pages-gray.svg"" alt=""18-pages"" align=""top""> [Towards Neural Decompilation](https://arxiv.org/abs/1905.08325v1) - Omer Katz, Yuval Olshaker, Yoav Goldberg, Eran Yahav, 2019.\n- <img src=""badges/14-pages-gray.svg"" alt=""14-pages"" align=""top""> [Tree-to-tree Neural Networks for Program Translation](https://arxiv.org/abs/1802.03691v1) - Xinyun Chen, Chang Liu, Dawn Song, ICLR 2018.\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=""top""> [Code Attention: Translating Code to Comments by Exploiting Domain Features](https://arxiv.org/abs/1709.07642v2) - Wenhao Zheng, Hong-Yu Zhou, Ming Li, Jianxin Wu, 2017.\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=""top""> [Automatically Generating Commit Messages from Diffs using Neural Machine Translation](https://arxiv.org/abs/1708.09492v1) - Siyuan Jiang, Ameer Armaly, Collin McMillan, ASE 2017.\n- <img src=""badges/5-pages-gray.svg"" alt=""5-pages"" align=""top""> [A Parallel Corpus of Python Functions and Documentation Strings for Automated Code Documentation and Code Generation](https://arxiv.org/abs/1707.02275v1) - Antonio Valerio Miceli Barone, Rico Sennrich, ICNLP 2017.\n- <img src=""badges/6-pages-gray.svg"" alt=""6-pages"" align=""top""> [A Neural Architecture for Generating Natural Language Descriptions from Source Code Changes](https://arxiv.org/abs/1704.04856v1) - Pablo Loyola, Edison Marrese-Taylor, Yutaka Matsuo, ACL 2017.\n\n#### Code Suggestion and Completion\n\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=""top""> [Aroma: Code Recommendation via Structural Code Search](https://arxiv.org/abs/1812.01158) - Sifei Luan, Di Yang, Koushik Sen and Satish Chandra, 2019.\n- <img src=""badges/9-pages-gray.svg"" alt=""9-pages"" align=""top""> [Intelligent Code Reviews Using Deep Learning](https://www.kdd.org/kdd2018/files/deep-learning-day/DLDay18_paper_40.pdf) - Anshul Gupta, Neel Sundaresan, KDD DL Day 2018.\n- <img src=""badges/8-pages-gray.svg"" alt=""8-pages"" align=""top""> [Code Completion with Neural Attention and Pointer Networks](https://arxiv.org/abs/1711.09573v1) - Jian Li, Yue Wang, Irwin King, Michael R. Lyu, 2017.\n- <img src=""badges/11-pages-gray.svg"" alt=""11-pages"" align=""top""> [Learning Python Code Suggestion with a Sparse Pointer Network](https://arxiv.org/abs/1611.08307) - Avishkar Bhoopchand, Tim Rockt\xc3\xa4schel, Earl Barr, Sebastian Riedel, 2016.\n- <img src=""badges/10-pages-gray.svg"" alt=""10-pages"" align=""top""> [Code Completion with Statistical Language Models](http://www.cs.technion.ac.il/~yahave/papers/pldi14-statistical.pdf) - Veselin Raychev, Martin Vechev, Eran Yahav, PLDI 2014.\n\n#### Program Repair and Bug Detection\n\n- <img src=""badges/10-pages-gray.svg"" alt=""10-pages"" align=""top""> [SampleFix: Learning to Correct Programs by Sampling Diverse Fixes](https://arxiv.org/abs/1906.10502) - Hossein Hajipour, Apratim Bhattacharya, Mario Fritz, 2019.\n- <img src=""badges/15-pages-gray.svg"" alt=""15-pages"" align=""top""> [Maximal Divergence Sequential Autoencoder for Binary Software Vulnerability Detection](https://openreview.net/forum?id=ByloIiCqYQ) - Tue Le, Tuan Nguyen, Trung Le, Dinh Phung, Paul Montague, Olivier De Vel, Lizhen Qu, ICLR 2019.\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=""top""> [Neural Program Repair by Jointly Learning to Localize and Repair](https://openreview.net/forum?id=ByloJ20qtm) - Marko Vasic, Aditya Kanade, Petros Maniatis, David Bieber, Rishabh Singh, ICLR 2019.\n- <img src=""badges/11-pages-beginner-brightgreen.svg"" alt=""11-pages"" align=""top""> [Compiler Fuzzing through Deep Learning](https://chriscummins.cc/pub/2018-issta.pdf) - Chris Cummins, Pavlos Petoumenos, Alastair Murray, Hugh Leather, ISSTA 2018\n- <img src=""badges/10-pages-gray.svg"" alt=""10-pages"" align=""top""> [Automatically assessing vulnerabilities discovered by compositional analysis](https://dl.acm.org/citation.cfm?id=3243130) - Saahil Ognawala, Ricardo Nales Amato, Alexander Pretschner and Pooja Kulkarni, MASES 2018.\n- <img src=""badges/6-pages-gray.svg"" alt=""6-pages"" align=""top""> [An Empirical Investigation into Learning Bug-Fixing Patches in the Wild via Neural Machine Translation](http://www.cs.wm.edu/~denys/pubs/ASE%2718-Learning-Bug-Fixes-NMT.pdf) - Michele Tufano, Cody Watson, Gabriele Bavota, Massimiliano Di Penta, Martin White, Denys Poshyvanyk, ASE 2018.\n- <img src=""badges/23-pages-gray.svg"" alt=""23-pages"" align=""top""> [DeepBugs: A Learning Approach to Name-based Bug Detection](https://arxiv.org/pdf/1805.11683.pdf) - Michael Pradel, Koushik Sen, 2018.\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=""top""> [Learning How to Mutate Source Code from Bug-Fixes](https://arxiv.org/abs/1812.10772) - Michele Tufano, Cody Watson, Gabriele Bavota, Massimiliano Di Penta, Martin White, Denys Poshyvanyk, 2018.\n- <img src=""badges/10-pages-gray.svg"" alt=""10-pages"" align=""top""> [A deep tree-based model for software defect prediction](https://arxiv.org/abs/1802.00921) - HK Dam, T Pham, SW Ng, [T Tran](https://truyentran.github.io), J Grundy, A Ghose, T Kim, CJ Kim, 2018.\n- <img src=""badges/7-pages-gray.svg"" alt=""7-pages"" align=""top""> [Automated Vulnerability Detection in Source Code Using Deep Representation Learning](https://arxiv.org/abs/1807.04320) - Rebecca L. Russell, Louis Kim, Lei H. Hamilton, Tomo Lazovich, Jacob A. Harer, Onur Ozdemir, Paul M. Ellingwood, Marc W. McConley, 2018.\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=""top""> [Shaping Program Repair Space with Existing Patches and Similar Code](https://xiongyingfei.github.io/papers/ISSTA18a.pdf) - Jiajun Jiang, Yingfei Xiong, Hongyu Zhang, Qing Gao, Xiangqun Chen, 2018. ([code](https://github.com/xgdsmileboy/SimFix)).\n- <img src=""badges/15-pages-gray.svg"" alt=""15-pages"" align=""top""> [Learning to Repair Software Vulnerabilities with Generative Adversarial Networks](https://arxiv.org/abs/1805.07475) - Jacob A. Harer, Onur Ozdemir, Tomo Lazovich, Christopher P. Reale, Rebecca L. Russell, Louis Y. Kim, Peter Chin, 2018.\n- <img src=""badges/11-pages-gray.svg"" alt=""11-pages"" align=""top""> [Dynamic Neural Program Embedding for Program Repair](https://arxiv.org/abs/1711.07163v2) - Ke Wang, Rishabh Singh, Zhendong Su, ICLR 2018.\n- <img src=""badges/8-pages-gray.svg"" alt=""8-pages"" align=""top""> [Estimating defectiveness of source code: A predictive model using GitHub content](https://arxiv.org/abs/1803.07764) - Ritu Kapur, Balwinder Sodhi, 2018\n- <img src=""badges/8-pages-gray.svg"" alt=""8-pages"" align=""top""> [Automated software vulnerability detection with machine learning](https://arxiv.org/abs/1803.04497) - Jacob A. Harer, Louis Y. Kim, Rebecca L. Russell, Onur Ozdemir, Leonard R. Kosta, Akshay Rangamani, Lei H. Hamilton, Gabriel I. Centeno, Jonathan R. Key, Paul M. Ellingwood, Marc W. McConley, Jeffrey M. Opper, Peter Chin, Tomo Lazovich, IWSPA 2018.\n- <img src=""badges/34-pages-gray.svg"" alt=""34-pages"" align=""top""> [Learning a Static Analyzer from Data](https://arxiv.org/abs/1611.01752) - Pavol Bielik, Veselin Raychev, Martin Vechev, CAV 2017. [video](https://www.youtube.com/watch?v=bkieI3jLxVY).\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=""top""> [To Type or Not to Type: Quantifying Detectable Bugs in JavaScript](http://earlbarr.com/publications/typestudy.pdf) - Zheng Gao, Christian Bird, Earl Barr, ICSE 2017.\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=""top""> [Sorting and Transforming Program Repair Ingredients via Deep Learning Code Similarities](https://arxiv.org/abs/1707.04742) - Martin White, Michele Tufano, Mat\xc3\xadas Mart\xc3\xadnez, Martin Monperrus, Denys Poshyvanyk, 2017.\n- <img src=""badges/11-pages-gray.svg"" alt=""11-pages"" align=""top""> [Semantic Code Repair using Neuro-Symbolic Transformation Networks](https://arxiv.org/abs/1710.11054v1) - Jacob Devlin, Jonathan Uesato, Rishabh Singh, Pushmeet Kohli, 2017.\n- <img src=""badges/6-pages-gray.svg"" alt=""6-pages"" align=""top""> [Automated Identification of Security Issues from Commit Messages and Bug Reports](http://asankhaya.github.io/pdf/automated-identification-of-security-issues-from-commit-messages-and-bug-reports.pdf) - Yaqin Zhou and Asankhaya Sharma, FSE 2017.\n- <img src=""badges/31-pages-gray.svg"" alt=""31-pages"" align=""top""> [SmartPaste: Learning to Adapt Source Code](https://arxiv.org/abs/1705.07867) - Miltiadis Allamanis, Marc Brockschmidt, 2017.\n- <img src=""badges/7-pages-gray.svg"" alt=""7-pages"" align=""top""> [End-to-End Prediction of Buffer Overruns from Raw Source Code via Neural Memory Networks](https://arxiv.org/abs/1703.02458v1) - Min-je Choi, Sehun Jeong, Hakjoo Oh, Jaegul Choo, IJCAI 2017.\n- <img src=""badges/11-pages-gray.svg"" alt=""11-pages"" align=""top""> [Tailored Mutants Fit Bugs Better](https://arxiv.org/abs/1611.02516) - Miltiadis Allamanis, Earl T. Barr, Ren\xc3\xa9 Just, Charles Sutton, 2016.\n\n#### APIs and Code Mining\n\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=""top""> [SAR: Learning Cross-Language API Mappings with Little Knowledge](https://bdqnghi.github.io/files/FSE_2019.pdf) - Nghi D. Q. Bui, Yijun Yu, Lingxiao Jiang, FSE 2019.\n- <img src=""badges/4-pages-gray.svg"" alt=""4-pages"" align=""top""> [Hierarchical Learning of Cross-Language Mappings through Distributed Vector Representations for Code](https://arxiv.org/abs/1803.04715) - Nghi D. Q. Bui, Lingxiao Jiang, ICSE 2018.\n- <img src=""badges/7-pages-gray.svg"" alt=""7-pages"" align=""top""> [DeepAM: Migrate APIs with Multi-modal Sequence to Sequence Learning](https://arxiv.org/abs/1704.07734v1) - Xiaodong Gu, Hongyu Zhang, Dongmei Zhang, Sunghun Kim, IJCAI 2017.\n- <img src=""badges/9-pages-gray.svg"" alt=""9-pages"" align=""top""> [Mining Change Histories for Unknown Systematic Edits](http://soft.vub.ac.be/Publications/2017/vub-soft-tr-17-04.pdf) - Tim Molderez, Reinout Stevens, Coen De Roover, MSR 2017.\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=""top""> [Deep API Learning](https://arxiv.org/abs/1605.08535v3) - Xiaodong Gu, Hongyu Zhang, Dongmei Zhang, Sunghun Kim, FSE 2016.\n- <img src=""badges/11-pages-gray.svg"" alt=""11-pages"" align=""top""> [Exploring API Embedding for API Usages and Applications](http://home.eng.iastate.edu/~trong/projects/jv2cs/) - Nguyen, Nguyen, Phan and Nguyen, Journal of Systems and Software 2017.\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=""top""> [API usage pattern recommendation for software development](http://www.sciencedirect.com/science/article/pii/S0164121216301200) - Haoran Niu, Iman Keivanloo, Ying Zou, 2017.\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=""top""> [Parameter-Free Probabilistic API Mining across GitHub](http://homepages.inf.ed.ac.uk/csutton/publications/fse2016.pdf) - Jaroslav Fowkes, Charles Sutton, FSE 2016.\n- <img src=""badges/10-pages-gray.svg"" alt=""10-pages"" align=""top""> [A Subsequence Interleaving Model for Sequential Pattern Mining](http://homepages.inf.ed.ac.uk/csutton/publications/kdd2016-subsequence-interleaving.pdf) - Jaroslav Fowkes, Charles Sutton, KDD 2016.\n- <img src=""badges/4-pages-gray.svg"" alt=""4-pages"" align=""top""> [Lean GHTorrent: GitHub data on demand](https://bvasiles.github.io/papers/lean-ghtorrent.pdf) - Georgios Gousios, Bogdan Vasilescu, Alexander Serebrenik, Andy Zaidman, MSR 2014.\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=""top""> [Mining idioms from source code](http://homepages.inf.ed.ac.uk/csutton/publications/idioms.pdf) - Miltiadis Allamanis, Charles Sutton, FSE 2014.\n- <img src=""badges/4-pages-gray.svg"" alt=""4-pages"" align=""top""> [The GHTorent Dataset and Tool Suite](http://www.gousios.gr/pub/ghtorrent-dataset-toolsuite.pdf) - Georgios Gousios, MSR 2013.\n\n#### Code Optimization\n\n- <img src=""badges/27-pages-gray.svg"" alt=""27-pages"" align=""top""> [The Case for Learned Index Structures](https://arxiv.org/abs/1712.01208v2) - Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, Neoklis Polyzotis, SIGMOD 2018.\n- <img src=""badges/14-pages-gray.svg"" alt=""14-pages"" align=""top""> [End-to-end Deep Learning of Optimization Heuristics](https://chriscummins.cc/pub/2017-pact.pdf) - Chris Cummins, Pavlos Petoumenos, Zheng Wang, Hugh Leather, PACT 2017\n- <img src=""badges/14-pages-gray.svg"" alt=""14-pages"" align=""top""> [Learning to superoptimize programs](https://arxiv.org/abs/1611.01787v3) - Rudy Bunel, Alban Desmaison, M. Pawan Kumar, Philip H.S. Torr, Pushmeet Kohlim ICLR 2017.\n- <img src=""badges/18-pages-gray.svg"" alt=""18-pages"" align=""top""> [Neural Nets Can Learn Function Type Signatures From Binaries](https://www.usenix.org/system/files/conference/usenixsecurity17/sec17-chua.pdf) - Zheng Leong Chua, Shiqi Shen, Prateek Saxena, and Zhenkai Liang, USENIX Security Symposium 2017.\n- <img src=""badges/25-pages-gray.svg"" alt=""25-pages"" align=""top""> [Adaptive Neural Compilation](https://arxiv.org/abs/1605.07969v2) - Rudy Bunel, Alban Desmaison, Pushmeet Kohli, Philip H.S. Torr, M. Pawan Kumar, NIPS 2016.\n- <img src=""badges/10-pages-gray.svg"" alt=""10-pages"" align=""top""> [Learning to Superoptimize Programs - Workshop Version](https://arxiv.org/abs/1612.01094) - Bunel, Rudy, Alban Desmaison, M. Pawan Kumar, Philip H. S. Torr, and Pushmeet Kohli, NIPS 2016.\n\n#### Topic Modeling\n\n- <img src=""badges/9-pages-gray.svg"" alt=""9-pages"" align=""top""> [A Language-Agnostic Model for Semantic Source Code Labeling](https://dl.acm.org/citation.cfm?id=3243132) - Ben Gelman, Bryan Hoyle, Jessica Moore, Joshua Saxe and David Slater, MASES 2018.\n- <img src=""badges/11-pages-gray.svg"" alt=""11-pages"" align=""top""> [Topic modeling of public repositories at scale using names in source code](https://arxiv.org/abs/1704.00135) - Vadim Markovtsev, Eiso Kant, 2017.\n- <img src=""badges/4-pages-gray.svg"" alt=""4-pages"" align=""top""> [Why, When, and What: Analyzing Stack Overflow Questions by Topic, Type, and Code](http://homepages.inf.ed.ac.uk/csutton/publications/msrCh2013.pdf) - Miltiadis Allamanis, Charles Sutton, MSR 2013.\n- <img src=""badges/30-pages-gray.svg"" alt=""30-pages"" align=""top""> [Semantic clustering: Identifying topics in source code](http://scg.unibe.ch/archive/drafts/Kuhn06bSemanticClustering.pdf) - Adrian Kuhn, St\xc3\xa9phane Ducasse, Tudor Girba, Information & Software Technology 2007.\n\n#### Sentiment Analysis\n\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=""top""> [A Benchmark Study on Sentiment Analysis for Software Engineering Research](https://arxiv.org/abs/1803.06525) - Nicole Novielli, Daniela Girardi, Filippo Lanubile, MSR 2018.\n- <img src=""badges/11-pages-gray.svg"" alt=""11-pages"" align=""top""> [Sentiment Analysis for Software Engineering: How Far Can We Go?](http://www.inf.usi.ch/phd/lin/downloads/Lin2018a.pdf) - Bin Lin, Fiorella Zampetti, Gabriele Bavota, Massimiliano Di Penta, Michele Lanza, Rocco Oliveto, ICSE 2018.\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=""top""> [Leveraging Automated Sentiment Analysis in Software Engineering](http://cs.uno.edu/~zibran/resources/MyPapers/SentiStrengthSE_2017.pdf) - Md Rakibul Islam, Minhaz F. Zibran, MSR 2017.\n- <img src=""badges/27-pages-gray.svg"" alt=""27-pages"" align=""top""> [Sentiment Polarity Detection for Software Development](https://arxiv.org/pdf/1709.02984.pdf) - Fabio Calefato, Filippo Lanubile, Federico Maiorano, Nicole Novielli, Empirical Software Engineering 2017.\n- <img src=""badges/6-pages-gray.svg"" alt=""6-pages"" align=""top""> [SentiCR: A Customized Sentiment Analysis Tool for Code Review Interactions](https://drive.google.com/file/d/0Byog0ILN8S1haGxpT3hvSzZxdms/view) - Toufique Ahmed, Amiangshu Bosu, Anindya Iqbal, Shahram Rahimi, ASE 2017.\n\n#### Code Summarization\n\n- <img src=""badges/7-pages-gray.svg"" alt=""7-pages"" align=""top""> [Summarizing Source Code with Transferred API Knowledge](https://xin-xia.github.io/publication/ijcai18.pdf) - Xing Hu, Ge Li, Xin Xia, David Lo, Shuai Lu, Zhi Jin, IJCAI 2018.\n- <img src=""badges/11-pages-gray.svg"" alt=""11-pages"" align=""top""> [Deep Code Comment Generation](https://xin-xia.github.io/publication/icpc182.pdf) - Xing Hu, Ge Li, Xin Xia, David Lo, Zhi Jin, ICPC 2018.\n- <img src=""badges/6-pages-gray.svg"" alt=""6-pages"" align=""top""> [A Neural Framework for Retrieval and Summarization of Source Code](https://dl.acm.org/citation.cfm?id=3240471) - Qingying Chen, Minghui Zhou, ASE 2018.\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=""top""> [Improving Automatic Source Code Summarization via Deep Reinforcement Learning](https://arxiv.org/abs/1811.07234) - Yao Wan, Zhou Zhao, Min Yang, Guandong Xu, Haochao Ying, Jian Wu and Philip S. Yu, ASE 2018.\n- <img src=""badges/11-pages-gray.svg"" alt=""11-pages"" align=""top""> [A Convolutional Attention Network for Extreme Summarization of Source Code](https://arxiv.org/abs/1602.03001) - Miltiadis Allamanis, Hao Peng, Charles Sutton, ICML 2016.\n- <img src=""badges/4-pages-gray.svg"" alt=""4-pages"" align=""top""> [TASSAL: Autofolding for Source Code Summarization](http://homepages.inf.ed.ac.uk/csutton/publications/icse2016-demo.pdf) - Jaroslav Fowkes, Pankajan Chanthirasegaran, Razvan Ranca, Miltiadis Allamanis, Mirella Lapata, Charles Sutton, ICSE 2016.\n- <img src=""badges/11-pages-gray.svg"" alt=""11-pages"" align=""top""> [Summarizing Source Code using a Neural Attention Model](https://github.com/sriniiyer/codenn/blob/master/summarizing_source_code.pdf) - Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, Luke Zettlemoyer, ACL 2016.\n- <img src=""badges/13-pages-gray.svg"" alt=""13-pages"" align=""top""> [Automatic Generation of Pull Request Descriptions](https://arxiv.org/abs/1909.06987) - Zhongxin Liu, Xin Xia, Christoph Treude, David Lo, Shanping Li, ASE 2019.\n\n#### Clone Detection\n\n- <img src=""badges/10-pages-gray.svg"" alt=""10-pages"" align=""top""> [Learning-Based Recursive Aggregation of Abstract Syntax Trees for Code Clone Detection](https://pvs.ifi.uni-heidelberg.de/fileadmin/papers/2019/Buech-Andrzejak-SANER2019.pdf) - Lutz B\xc3\xbcch and Artur Andrzejak, SANER 2019.\n- <img src=""badges/10-pages-gray.svg"" alt=""10-pages"" align=""top""> [A Deep Learning Approach to Program Similarity](https://dl.acm.org/citation.cfm?id=3243131) - Niccol\xc3\xb2 Marastoni, Roberto Giacobazzi and Mila Dalla Preda, MASES 2018.\n- <img src=""badges/6-pages-gray.svg"" alt=""6-pages"" align=""top""> [Recurrent Neural Network for Code Clone Detection](https://seim-conf.org/media/materials/2018/proceedings/SEIM-2018_Short_Papers.pdf#page=48) - Arseny Zorin and Vladimir Itsykson, SEIM 2018.\n- <img src=""badges/8-pages-gray.svg"" alt=""8-pages"" align=""top""> [The Adverse Effects of Code Duplication in Machine Learning Models of Code](https://arxiv.org/abs/1812.06469) - Miltiadis Allamanis, 2018.\n- <img src=""badges/28-pages-gray.svg"" alt=""28-pages"" align=""top""> [D\xc3\xa9j\xc3\xa0Vu: a map of code duplicates on GitHub](http://janvitek.org/pubs/oopsla17b.pdf) - Cristina V. Lopes, Petr Maj, Pedro Martins, Vaibhav Saini, Di Yang, Jakub Zitny, Hitesh Sajnani, Jan Vitek, Programming Languages OOPSLA 2017.\n- <img src=""badges/11-pages-gray.svg"" alt=""11-pages"" align=""top""> [Some from Here, Some from There: Cross-project Code Reuse in GitHub](http://web.cs.ucdavis.edu/~filkov/papers/clones.pdf) - Mohammad Gharehyazie, Baishakhi Ray, Vladimir Filkov, MSR 2017.\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=""top""> [Deep Learning Code Fragments for Code Clone Detection](http://www.cs.wm.edu/~denys/pubs/ASE%2716-DeepLearningClones.pdf) - Martin White, Michele Tufano, Christopher Vendome, and Denys Poshyvanyk, ASE 2016.\n- <img src=""badges/11-pages-gray.svg"" alt=""11-pages"" align=""top""> [A study of repetitiveness of code changes in software evolution](https://lib.dr.iastate.edu/cgi/viewcontent.cgi?referer=https://scholar.google.com/&httpsredir=1&article=1016&context=cs_conf) - HA Nguyen, AT Nguyen, TT Nguyen, TN Nguyen, H Rajan, ASE 2013.\n\n#### Differentiable Interpreters\n\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=""top""> [DDRprog: A CLEVR Differentiable Dynamic Reasoning Programmer](https://arxiv.org/abs/1803.11361v1) - Joseph Suarez, Justin Johnson, Fei-Fei Li, 2018.\n- <img src=""badges/16-pages-gray.svg"" alt=""16-pages"" align=""top""> [Improving the Universality and Learnability of Neural Programmer-Interpreters with Combinator Abstraction](https://arxiv.org/abs/1802.02696v1) - Da Xiao, Jo-Yu Liao, Xingyuan Yuan, ICLR 2018.\n- <img src=""badges/10-pages-gray.svg"" alt=""10-pages"" align=""top""> [Differentiable Programs with Neural Libraries](https://arxiv.org/abs/1611.02109v2) - Alexander L. Gaunt, Marc Brockschmidt, Nate Kushman, Daniel Tarlow, ICML 2017.\n- <img src=""badges/15-pages-gray.svg"" alt=""15-pages"" align=""top""> [Differentiable Functional Program Interpreters](https://arxiv.org/abs/1611.01988v2) - John K. Feser, Marc Brockschmidt, Alexander L. Gaunt, Daniel Tarlow, 2017.\n- <img src=""badges/18-pages-gray.svg"" alt=""18-pages"" align=""top""> [Programming with a Differentiable Forth Interpreter](https://arxiv.org/abs/1605.06640) - Bo\xc5\xa1njak, Matko, Tim Rockt\xc3\xa4schel, Jason Naradowsky, and Sebastian Riedel, ICML 2017.\n- <img src=""badges/15-pages-gray.svg"" alt=""15-pages"" align=""top""> [Neural Functional Programming](https://arxiv.org/abs/1611.01988v1) - Feser John K., Marc Brockschmidt, Alexander L. Gaunt, and Daniel Tarlow, ICLR 2017.\n- <img src=""badges/7-pages-gray.svg"" alt=""7-pages"" align=""top""> [TerpreT: A Probabilistic Programming Language for Program Induction](https://arxiv.org/abs/1612.00817) - Gaunt, Alexander L., Marc Brockschmidt, Rishabh Singh, Nate Kushman, Pushmeet Kohli, Jonathan Taylor, and Daniel Tarlow, NIPS 2016.\n\n<a name=""related-research""></a>\n\n<details>\n<summary>Related research</summary>\n\n#### AST Differencing\n\n- <img src=""badges/12-pages-gray.svg"" alt=""12-pages"" align=""top""> [ClDiff: Generating Concise Linked Code Differences](https://chenbihuan.github.io/paper/ase18-huang-cldiff.pdf) - Kaifeng Huang, Bihuan Chen, Xin Peng, Daihong Zhou, Ying Wang, Yang Liu, Wenyun Zhao, ASE 2018. [Code](https://github.com/FudanSELab/CLDIFF).\n- <img src=""badges/11-pages-gray.svg"" alt=""11-pages"" align=""top""> [Generating Accurate and Compact Edit Scripts Using Tree Differencing](http://www.xifiggam.eu/wp-content/uploads/2018/08/GeneratingAccurateandCompactEditScriptsusingTreeDifferencing.pdf) - Veit Frick, Thomas Grassauer, Fabian Beck, Martin Pinzger, ICSME 2018.\n- <img src=""badges/11-pages-gray.svg"" alt=""11-pages"" align=""top""> [Fine-grained and Accurate Source Code Differencing](https://hal.archives-ouvertes.fr/hal-01054552/document) - Jean-R\xc3\xa9my Falleri, Flor\xc3\xa9al Morandat, Xavier Blanc, Matias Martinez, Martin Monperrus, ASE 2014.\n\n#### Binary Data Modeling\n\n- [Clustering Binary Data with Bernoulli Mixture Models](https://nsgrantham.com/documents/clustering-binary-data.pdf) - Neal S. Grantham.\n- [A Family of Blockwise One-Factor Distributions for Modelling High-Dimensional Binary Data](https://arxiv.org/pdf/1511.01343.pdf) - Matthieu Marbac and Mohammed Sedki, Computational Statistics & Data Analysis 2017.\n- [BayesBinMix: an R Package for Model Based Clustering of Multivariate Binary Data](https://arxiv.org/pdf/1609.06960.pdf) - Panagiotis Papastamoulis and Magnus Rattray, R Journal 2016.\n\n#### Soft Clustering Using T-mixture Models\n\n- [Robust mixture modelling using the t distribution](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.218.7334&rep=rep1&type=pdf) - D. Peel and G. J. McLachlan, Statistics and Computing 2000.\n- [Robust mixture modeling using the skew t distribution](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1030.9865&rep=rep1&type=pdf) - Tsung I. Lin, Jack C. Lee and Wan J. Hsieh, Statistics and Computing 2010.\n\n#### Natural Language Parsing and Comprehension\n\n- <img src=""badges/11-pages-gray.svg"" alt=""11-pages"" align=""top""> [A Fast Unified Model for Parsing and Sentence Understanding](https://arxiv.org/abs/1603.06021) - Samuel R. Bowman, Jon Gauthier, Abhinav Rastogi, Raghav Gupta, Christopher D. Manning, Christopher Potts, ACL 2016.\n\n</details>\n\n## Posts\n\n- [Semantic Code Search](https://towardsdatascience.com/semantic-code-search-3cd6d244a39c)\n- [Learning from Source Code](https://www.microsoft.com/en-us/research/blog/learning-source-code/)\n- [Training a Model to Summarize Github Issues](https://towardsdatascience.com/how-to-create-data-products-that-are-magical-using-sequence-to-sequence-models-703f86a231f8)\n- [Sequence Intent Classification Using Hierarchical Attention Networks](https://www.microsoft.com/developerblog/2018/03/06/sequence-intent-classification/)\n- [Syntax-Directed Variational Autoencoder for Structured Data](https://mlatgt.blog/2018/02/08/syntax-directed-variational-autoencoder-for-structured-data/)\n- [Weighted MinHash on GPU helps to find duplicate GitHub repositories.](https://blog.sourced.tech//post/minhashcuda/)\n- [Source Code Identifier Embeddings](https://blog.sourced.tech/post/id2vec/)\n- [Using recurrent neural networks to predict next tokens in the java solutions](https://codeforces.com/blog/entry/52327)\n- [The half-life of code & the ship of Theseus](https://erikbern.com/2016/12/05/the-half-life-of-code.html)\n- [The eigenvector of ""Why we moved from language X to language Y""](https://erikbern.com/2017/03/15/the-eigenvector-of-why-we-moved-from-language-x-to-language-y.html)\n- [Analyzing Github, How Developers Change Programming Languages Over Time](https://blog.sourced.tech/post/language_migrations/)\n- [Topic Modeling of GitHub Repositories](https://blog.sourced.tech//post/github_topic_modeling/)\n- [Aroma: Using machine learning for code recommendation](https://ai.facebook.com/blog/aroma-ml-for-code-recommendation/)\n\n## Talks\n\n- [Machine Learning on Source Code](http://vmarkovtsev.github.io/pydays-2018-vienna/)\n- [Similarity of GitHub Repositories by Source Code Identifiers](http://vmarkovtsev.github.io/techtalks-2017-moscow/)\n- [Using deep RNN to model source code](http://vmarkovtsev.github.io/re-work-2016-london/)\n- [Source code abstracts classification using CNN (1)](http://vmarkovtsev.github.io/re-work-2016-berlin/)\n- [Source code abstracts classification using CNN (2)](http://vmarkovtsev.github.io/data-natives-2016/)\n- [Source code abstracts classification using CNN (3)](http://vmarkovtsev.github.io/slush-2016/)\n- [Embedding the GitHub contribution graph](https://egorbu.github.io/techtalks-2017-moscow)\n- [Measuring code sentiment in a Git repository](http://vmarkovtsev.github.io/gophercon-2018-moscow/)\n\n## Software\n\n#### Machine Learning\n\n- [Differentiable Neural Computer (DNC)](https://github.com/deepmind/dnc) - TensorFlow implementation of the Differentiable Neural Computer.\n- [sourced.ml](https://github.com/src-d/ml) - Abstracts feature extraction from source code syntax trees and working with ML models.\n- [vecino](https://github.com/src-d/vecino) - Finds similar Git repositories.\n- [apollo](https://github.com/src-d/apollo) - Source code deduplication as scale, research.\n- [gemini](https://github.com/src-d/gemini) - Source code deduplication as scale, production.\n- [enry](https://github.com/src-d/enry) - Insanely fast file based programming language detector.\n- [hercules](https://github.com/src-d/hercules) - Git repository mining framework with batteries on top of go-git.\n- [DeepCS](https://github.com/guxd/deep-code-search) - Keras and Pytorch implementations of DeepCS (Deep Code Search).\n- [Code Neuron](https://github.com/vmarkovtsev/codeneuron) - Recurrent neural network to detect code blocks in natural language text.\n- [Naturalize](https://github.com/mast-group/naturalize) - Language agnostic framework for learning coding conventions from a codebase and then expoiting this information for suggesting better identifier names and formatting changes in the code.\n- [Extreme Source Code Summarization](https://github.com/mast-group/convolutional-attention) - Convolutional attention neural network that learns to summarize source code into a short method name-like summary by just looking at the source code tokens.\n- [Summarizing Source Code using a Neural Attention Model](https://github.com/sriniiyer/codenn) - CODE-NN, uses LSTM networks with attention to produce sentences that describe C# code snippets and SQL queries from StackOverflow. Torch over C#/SQL\n- [Probabilistic API Miner](https://github.com/mast-group/api-mining) - Near parameter-free probabilistic algorithm for mining the most interesting API patterns from a list of API call sequences.\n- [Interesting Sequence Miner](https://github.com/mast-group/sequence-mining) - Novel algorithm that mines the most interesting sequences under a probabilistic model. It is able to efficiently infer interesting sequences directly from the database.\n- [TASSAL](https://github.com/mast-group/tassal) - Tool for the automatic summarization of source code using autofolding. Autofolding automatically creates a summary of a source code file by folding non-essential code and comment blocks.\n- [JNice2Predict](http://www.nice2predict.org/) - Efficient and scalable open-source framework for structured prediction, enabling one to build new statistical engines more quickly.\n- [Clone Digger](http://clonedigger.sourceforge.net/download.html) - clone detection for Python and Java.\n- [Sensibility](https://github.com/naturalness/sensibility) - Uses LSTMs to detect and correct syntax errors in Java source code.\n- [DeepBugs](https://github.com/michaelpradel/DeepBugs) - Framework for learning bug detectors from an existing code corpus.\n- [DeepSim](https://github.com/parasol-aser/deepsim) - a deep learning-based approach to measure code functional similarity.\n- [rnn-autocomplete](https://github.com/ZeRoGerc/rnn-autocomplete) - Neural code autocompletion with RNN (bachelor\'s thesis).\n\n#### Utilities\n\n- [go-git](https://github.com/src-d/go-git) - Highly extensible Git implementation in pure Go which is friendly to data mining.\n- [bblfsh](https://github.com/bblfsh) - Self-hosted server for source code parsing.\n- [engine](https://github.com/src-d/engine) - Scalable and distributed data retrieval pipeline for source code.\n- [minhashcuda](https://github.com/src-d/minhashcuda) - Weighted MinHash implementation on CUDA to efficiently find duplicates.\n- [kmcuda](https://github.com/src-d/kmcuda) - k-means on CUDA to cluster and to search for nearest neighbors in dense space.\n- [wmd-relax](https://github.com/src-d/wmd-relax) - Python package which finds nearest neighbors at Word Mover\'s Distance.\n- [Tregex, Tsurgeon and Semgrex](https://nlp.stanford.edu/software/tregex.shtml) - Tregex is a utility for matching patterns in trees, based on tree relationships and regular expression matches on nodes (the name is short for ""tree regular expressions"").\n- [source{d} models](https://github.com/src-d/models) - Machine Learning models for MLonCode trained using the source{d} stack.\n\n#### Datasets\n\n- [Neural-Code-Search-Evaluation-Dataset](https://github.com/facebookresearch/Neural-Code-Search-Evaluation-Dataset) - dataset contains links to 4.7M methods from 24k+ repositories with 287 StackOverflow questions and code snippet answers.\n- [CodeSearchNet](https://github.com/github/CodeSearchNet) -  collection of datasets and benchmarks for code retrieval using natural language. Contains 2M pairs of (`comment`, `code`).\n- [Public Git Archive](https://github.com/src-d/datasets/tree/master/PublicGitArchive) - 6 TB of Git repositories from GitHub.\n- [StackOverflow Question-Code Dataset](https://github.com/LittleYUYU/StackOverflow-Question-Code-Dataset) - ~148K Python and ~120K SQL question-code pairs mined from StackOverflow.\n- [GitHub Issue Titles and Descriptions for NLP Analysis](https://www.kaggle.com/davidshinn/github-issues/) - ~8 million GitHub issue titles and descriptions from 2017.\n- [GitHub repositories - languages distribution](https://data.world/source-d/github-repositories-languages-distribution) - Programming languages distribution in 14,000,000 repositories on GitHub (October 2016).\n- [452M commits on GitHub](https://data.world/vmarkovtsev/452-m-commits-on-github) - \xe2\x89\x88 452M commits\' metadata from 16M repositories on GitHub (October 2016).\n- [GitHub readme files](https://data.world/vmarkovtsev/github-readme-files) - Readme files of all GitHub repositories (16M) (October 2016).\n- [from language X to Y](https://data.world/vmarkovtsev/from-language-x-to-y) - Cache file Erik Bernhardsson collected for his awesome blog post.\n- [GitHub word2vec 120k](https://data.world/vmarkovtsev/github-word-2-vec-120-k) - Sequences of identifiers extracted from top starred 120,000 GitHub repositories.\n- [GitHub Source Code Names](https://data.world/vmarkovtsev/github-source-code-names) - Names in source code extracted from 13M GitHub repositories, not people.\n- [GitHub duplicate repositories](https://data.world/vmarkovtsev/github-duplicate-repositories) - GitHub repositories not marked as forks but very similar to each other.\n- [GitHub lng keyword frequencies](https://data.world/vmarkovtsev/github-lng-keyword-frequencies) - Programming language keyword frequency extracted from 16M GitHub repositories.\n- [GitHub Java Corpus](http://groups.inf.ed.ac.uk/cup/javaGithub/) - GitHub Java corpus is a set of Java projects collected from GitHub that we have used in a number of our publications. The corpus consists of 14,785 projects and 352,312,696 LOC.\n- [150k Python Dataset](https://www.sri.inf.ethz.ch/py150) - Dataset consisting of 150,000 Python ASTs.\n- [150k JavaScript Dataset](https://www.sri.inf.ethz.ch/js150) - Dataset consisting of 150,000 JavaScript files and their parsed ASTs.\n- [card2code](https://github.com/deepmind/card2code) - This dataset contains the language to code datasets described in the paper [Latent Predictor Networks for Code Generation](#card2code).\n- [NL2Bash](https://github.com/TellinaTool/nl2bash) - This dataset contains a set of ~10,000 bash one-liners collected from websites such as StackOverflow and their English descriptions written by Bash programmers, as described in the [paper](https://arxiv.org/abs/1802.08979).\n- [GitHub JavaScript Dump October 2016](https://archive.org/details/javascript-sources-oct2016.sqlite3) - Dataset consisting of 494,352 syntactically-valid JavaScript files obtained from the top ~10000 starred JavaScript repositories on GitHub, with licenses, and parsed ASTs.\n- [BigCloneBench](https://jeffsvajlenko.weebly.com/bigcloneeval.html) - Clone detection benchmark of 8 million function clone pairs in the IJaDataset.\n\n## Credits\n\n- A lot of references and articles were taken from [mast-group](https://mast-group.github.io/).\n- Inspired by [Awesome Machine Learning](https://github.com/josephmisiti/awesome-machine-learning).\n\n## Contributions\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md). TL;DR: create a [pull request](https://github.com/src-d/awesome-machine-learning-on-source-code/pulls) which is [signed off](https://github.com/src-d/awesome-machine-learning-on-source-code/blob/master/CONTRIBUTING.md#certificate-of-origin).\n\n## License\n\n[![License: CC BY-SA 4.0](badges/License-CC-BY--SA-4.0-lightgrey.svg)](https://creativecommons.org/licenses/by-sa/4.0/)\n'"
70,ssusnic/Machine-Learning-Flappy-Bird,ssusnic,Machine Learning for Flappy Bird using Neural Network and Genetic Algorithm,2017-08-10 15:14:19,2020-06-18 12:58:32,JavaScript,358,1481,"b'# Machine Learning for Flappy Bird using Neural Network and Genetic Algorithm\n\nHere is the source code for a HTML5 project that implements a machine learning algorithm in the Flappy Bird video game using neural networks and a genetic algorithm. The program teaches a little bird how to flap optimally in order to fly safely through barriers as long as possible.\n\nThe complete tutorial with much more details and demo you can find here:  \n[http://www.askforgametask.com/tutorial/machine-learning-algorithm-flappy-bird](http://www.askforgametask.com/tutorial/machine-learning-algorithm-flappy-bird)\n\nHere you can also watch a short video with a simple presentation of the algorithm:  \n[https://www.youtube.com/watch?v=aeWmdojEJf0](https://www.youtube.com/watch?v=aeWmdojEJf0)\n\nAll code is written in HTML5 using [Phaser framework](http://phaser.io/) and [Synaptic Neural Network library](https://synaptic.juancazala.com) for neural network implementation.\n\n![Flappy Bird Screenshot](https://raw.githubusercontent.com/ssusnic/Machine-Learning-Flappy-Bird/master/screenshots/flappy_10.png ""Flappy Bird Screenshot"")\n\n## Neural Network Architecture\n\nTo play the game, each unit (bird) has its own neural network consisted of the next 3 layers:\n1. an input layer with 2 neurons presenting what a bird sees:\n     \n     ```\n     1) horizontal distance between the bird and the closest gap\n     2) height difference between the bird and the closest gap\n     ```\n     \n2. a hidden layer with 6 neurons\n3. an output layer with 1 neuron used to provide an action as follows:\n     \n     ```\n    if output > 0.5 then flap else do nothing\n     ```\n     \n![Flappy Bird Neural Network](https://raw.githubusercontent.com/ssusnic/Machine-Learning-Flappy-Bird/master/screenshots/flappy_06.png ""Flappy Bird Neural Network"")\n\n\nThere is used [Synaptic Neural Network library](https://synaptic.juancazala.com) to implement entire artificial neural network instead of making a new one from the scratch.\n\n## The Main Concept of Machine Learning\n\nThe main concept of machine learning implemented in this program is based on the neuro-evolution form. It uses evolutionary algorithms such as a genetic algorithm to train artificial neural networks. Here are the main steps:\n\n1. create a new population of 10 units (birds) with a **random neural network** \n2. let all units play the game simultaneously by using their own neural networks\n3. for each unit calculate its **fitness** function to measure its quality as:\n\n    ```\n    fitness = total travelled distance - distance to the closest gap\n    ```\n \n    ![Flappy Bird Fitness](https://raw.githubusercontent.com/ssusnic/Machine-Learning-Flappy-Bird/master/screenshots/flappy_08.png ""Flappy Bird Fitness"")\n\n    \n4. when all units are killed, evaluate the current population to the next one using **genetic algorithm operators** (selection, crossover and mutation) as follows:\n\n    ```\n    1. sort the units of the current population in decreasing order by their fitness ranking\n    2. select the top 4 units and mark them as the winners of the current population\n    3. the 4 winners are directly passed on to the next population\n    4. to fill the rest of the next population, create 6 offsprings as follows:\n        - 1 offspring is made by a crossover of two best winners\n        - 3 offsprings are made by a crossover of two random winners\n        - 2 offsprings are direct copy of two random winners\n    5. to add some variations, apply random mutations on each offspring.\n    ```\n    \n5. go back to the step 2\n\n## Implementation\n\n### Requirements\n\nSince the program is written in HTML5 using [Phaser framework](http://phaser.io/) and [Synaptic Neural Network library](https://synaptic.juancazala.com) you need these files:\n\n- **phaser.min.js**\n- **synaptic.min.js**\n\n### gameplay.js \nThe entire game logic is implemented in **gameplay.js** file. It consists of the following classes:\n\n- `App.Main`, the main routine with the following essential functions:\n\t- _preload()_ to preload all assets\n\t- _create()_ to create all objects and initialize a new genetic algorithm object\n\t- _update()_ to run the main loop in which the Flappy Bird game is played by using AI neural networks and the population is evolved by using genetic algorithm\n\t- _drawStatus()_ to display information of all units\n\t\n- `TreeGroup Class`, extended Phaser Group class to represent a moving barrier. This group contains a top and a bottom Tree sprite.\n\n- `Tree Class`, extended Phaser Sprite class to represent a Tree sprite.\n\n- `Bird Class`, extended Phaser Sprite class to represent a Bird sprite.\n\n- `Text Class`, extended Phaser BitmapText class used for drawing text.\n\n### genetic.js \n\nThe genetic algorithm is implemented in **genetic.js** file which consists of the following class:\n\n- `GeneticAlgorithm Class`, the main class to handle all genetic algorithm operations. It needs two parameters: **_max_units_** to set a total number of units in population and **_top_units_** to set a number of top units (winners) used for evolving population. Here are its essential functions:\n\n   - _reset()_ to reset genetic algorithm parameters\n   - _createPopulation()_ to create a new population\n   - _activateBrain()_ to activate the AI neural network of an unit and get its output action according to the inputs\n   - _evolvePopulation()_ to evolve the population by using genetic operators (selection, crossover and mutations)\n   - _selection()_ to select the best units from the current population\n   - _crossOver()_ to perform a single point crossover between two parents\n   - _mutation()_ to perform random mutations on an offspring\n'"
71,Sophia-11/Machine-Learning-Notes,Sophia-11,周志华《机器学习》手推笔记,2019-09-20 05:06:57,2020-06-17 15:55:18,,375,1367,"b'# Machine-Learning-Notes(\xe5\x8a\xa0\xe8\xbd\xbd\xe5\x9b\xbe\xe7\x89\x87\xe8\xbe\x83\xe6\x85\xa2\xef\xbc\x8c\xe8\xaf\xb7\xe8\x80\x90\xe5\xbf\x83\xe7\xad\x89\xe5\xbe\x85,\xe5\x8f\xaa\xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86)\n\xe5\x91\xa8\xe5\xbf\x97\xe5\x8d\x8e\xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe3\x80\x8b\xe6\x89\x8b\xe6\x8e\xa8\xe7\xac\x94\xe8\xae\xb0~\xe6\x8c\x81\xe7\xbb\xad\xe6\x9b\xb4\xe6\x96\xb0\xe4\xb8\xad\n\n## by \xe3\x80\x90\xe8\xae\xa1\xe7\xae\x97\xe6\x9c\xba\xe8\xa7\x86\xe8\xa7\x89\xe8\x81\x94\xe7\x9b\x9f\xe3\x80\x91 \xe7\x8e\x8b\xe5\x8d\x9a\xef\xbc\x88Kings\xef\xbc\x89\xe3\x80\x81Sophia\n\n## \xe6\x89\x8b\xe6\x8e\xa8\xe7\xac\x94\xe8\xae\xb0\xe5\xb7\xb2\xe7\xbb\x8f  150\xe9\xa1\xb5 A4\xe7\xba\xb8\xef\xbc\x8c\xe5\x8f\xaf\xe7\x9b\xb4\xe6\x8e\xa5\xe6\x89\x93\xe5\x8d\xb0 \xef\xbc\x81\xef\xbc\x81\n\n*Last updated: 2020/06/03*   **\xe6\x9b\xb4\xe6\x96\xb0\xe7\xac\xac\xe4\xb8\x89\xe7\x89\x88**\n\n## \xe3\x80\x90\xe8\xae\xa1\xe7\xae\x97\xe6\x9c\xba\xe8\xa7\x86\xe8\xa7\x89\xe8\x81\x94\xe7\x9b\x9f\xe3\x80\x91\xe5\x9b\x9e\xe5\xa4\x8d\xe3\x80\x90\xe8\xa5\xbf\xe7\x93\x9c\xe4\xb9\xa6\xe6\x89\x8b\xe6\x8e\xa8\xe7\xac\x94\xe8\xae\xb0\xe3\x80\x91\xe5\x8d\xb3\xe5\x8f\xaf\xe8\x8e\xb7\xe5\xbe\x97\xe7\x99\xbe\xe5\xba\xa6\xe4\xba\x91pdf\xe4\xb8\x8b\xe8\xbd\xbd\xe9\x93\xbe\xe6\x8e\xa5\n\n#### Update log\n* 2019/09/13 * - \xe6\x9b\xb4\xe6\x96\xb0\xe7\xac\xac\xe4\xb8\x80\xe7\xab\xa0\n* 2019/09/20 * - \xe6\x9b\xb4\xe6\x96\xb0\xe7\xac\xac\xe4\xba\x8c\xe7\xab\xa0\n* 2019/10/03 * - \xe6\x9b\xb4\xe6\x96\xb0\xe7\xac\xac\xe4\xb8\x89\xe7\xab\xa0\n* 2019/11/05 * - \xe6\x9b\xb4\xe6\x96\xb0\xe7\xac\xac\xe5\x9b\x9b\xe7\xab\xa0\n* 2019/11/30 * - \xe6\x9b\xb4\xe6\x96\xb0\xe7\xac\xac\xe4\xba\x94\xe7\xab\xa0  46\xe9\xa1\xb5\n* 2019/12/17 * - \xe6\x9b\xb4\xe6\x96\xb0\xe7\xac\xac\xe5\x85\xad\xe7\xab\xa0  62\xe9\xa1\xb5\n* 2020/01/02 * - \xe6\x9b\xb4\xe6\x96\xb0\xe7\xac\xac\xe4\xb8\x83\xe7\xab\xa0  75\xe9\xa1\xb5\n* 2020/01/28 * - \xe6\x9b\xb4\xe6\x96\xb0\xe7\xac\xac\xe5\x85\xab\xe7\xab\xa0  96\xe9\xa1\xb5 \n* 2020/02/14 * - \xe6\x9b\xb4\xe6\x96\xb0\xe7\xac\xac\xe4\xb9\x9d\xe7\xab\xa0  105\xe9\xa1\xb5\n* 2020/03/27 * - \xe6\x9b\xb4\xe6\x96\xb0\xe7\xac\xac\xe5\x8d\x81\xe7\xab\xa0  116\xe9\xa1\xb5\n* 2020/04/14 * - \xe6\x9b\xb4\xe6\x96\xb0\xe4\xb8\xba\xe7\xac\xac\xe4\xb8\x89\xe7\x89\x88\n* 2020/05/16 * - \xe6\x9b\xb4\xe6\x96\xb0\xe7\xac\xac\xe5\x8d\x81\xe4\xb8\x80\xe7\xab\xa0   129\xe9\xa1\xb5\n* 2020/06/03 * - \xe6\x9b\xb4\xe6\x96\xb0\xe7\xac\xac\xe5\x8d\x81\xe4\xba\x8c\xe7\xab\xa0   150\xe9\xa1\xb5\n\n## Table of Contents\n- [\xe7\xac\xac\xe4\xb8\x80\xe7\xab\xa0\xe7\xbb\xaa\xe8\xae\xba](https://github.com/Sophia-11/Machine-Learning-Notes/)\n- [\xe7\xac\xac\xe4\xba\x8c\xe7\xab\xa0\xe6\xa8\xa1\xe5\x9e\x8b\xe8\xaf\x84\xe4\xbc\xb0\xe4\xb8\x8e\xe9\x80\x89\xe6\x8b\xa9](https://github.com/Sophia-11/Machine-Learning-Notes/)\n- [\xe7\xac\xac\xe4\xb8\x89\xe7\xab\xa0\xe7\xba\xbf\xe6\x80\xa7\xe6\xa8\xa1\xe5\x9e\x8b](https://github.com/Sophia-11/Machine-Learning-Notes/)\n- [\xe7\xac\xac\xe5\x9b\x9b\xe7\xab\xa0\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91](https://github.com/Sophia-11/Machine-Learning-Notes/)\n- [\xe7\xac\xac\xe4\xba\x94\xe7\xab\xa0\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c](https://github.com/Sophia-11/Machine-Learning-Notes/)\n- [\xe7\xac\xac\xe5\x85\xad\xe7\xab\xa0\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba](https://github.com/Sophia-11/Machine-Learning-Notes/)\n- [\xe7\xac\xac\xe4\xb8\x83\xe7\xab\xa0\xe8\xb4\x9d\xe5\x8f\xb6\xe6\x96\xaf\xe5\x88\x86\xe7\xb1\xbb\xe5\x99\xa8](https://github.com/Sophia-11/Machine-Learning-Notes/)\n- [\xe7\xac\xac\xe5\x85\xab\xe7\xab\xa0\xe9\x9b\x86\xe6\x88\x90\xe4\xbf\xa1\xe6\x81\xaf](https://github.com/Sophia-11/Machine-Learning-Notes/)\n- [\xe7\xac\xac\xe4\xb9\x9d\xe7\xab\xa0\xe8\x81\x9a\xe7\xb1\xbb](https://github.com/Sophia-11/Machine-Learning-Notes/)\n- [\xe7\xac\xac\xe5\x8d\x81\xe7\xab\xa0\xe9\x99\x8d\xe7\xbb\xb4\xe4\xb8\x8e\xe5\xba\xa6\xe9\x87\x8f\xe5\xad\xa6\xe4\xb9\xa0](https://github.com/Sophia-11/Machine-Learning-Notes/)\n- [\xe7\xac\xac\xe5\x8d\x81\xe4\xb8\x80\xe7\xab\xa0\xe7\x89\xb9\xe5\xbe\x81\xe9\x80\x89\xe6\x8b\xa9\xe4\xb8\x8e\xe7\xa8\x80\xe7\x96\x8f\xe5\xad\xa6\xe4\xb9\xa0](https://github.com/Sophia-11/Machine-Learning-Notes/)\n- [\xe7\xac\xac\xe5\x8d\x81\xe4\xba\x8c\xe7\xab\xa0\xe8\xae\xa1\xe7\xae\x97\xe5\xad\xa6\xe4\xb9\xa0\xe7\x90\x86\xe8\xae\xba](https://github.com/Sophia-11/Machine-Learning-Notes/)\n- [\xe7\xac\xac\xe5\x8d\x81\xe4\xb8\x89\xe7\xab\xa0\xe5\x8d\x8a\xe7\x9b\x91\xe7\x9d\xa3\xe5\xad\xa6\xe4\xb9\xa0](https://github.com/Sophia-11/Machine-Learning-Notes/)\n- [\xe7\xac\xac\xe5\x8d\x81\xe5\x9b\x9b\xe7\xab\xa0\xe6\xa6\x82\xe7\x8e\x87\xe5\x9b\xbe\xe6\xa8\xa1\xe5\x9e\x8b](https://github.com/Sophia-11/Machine-Learning-Notes/)\n- [\xe7\xac\xac\xe5\x8d\x81\xe4\xba\x94\xe7\xab\xa0\xe8\xa7\x84\xe5\x88\x99\xe5\xad\xa6\xe4\xb9\xa0](https://github.com/Sophia-11/Machine-Learning-Notes/)\n- [\xe7\xac\xac\xe5\x8d\x81\xe5\x85\xad\xe7\xab\xa0\xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0](https://github.com/Sophia-11/Machine-Learning-Notes/)\n\n\n## \xe6\x89\x8b\xe6\x8e\xa8\xe7\xac\x94\xe8\xae\xb0\xe4\xbd\x9c\xe8\x80\x85\xe7\xae\x80\xe4\xbb\x8b--\xe7\x8e\x8b\xe5\x8d\x9aKings\n\xe5\xbe\xae\xe4\xbf\xa1\xe5\x8f\xb7\xef\xbc\x88Kingsplus\xef\xbc\x89\xe5\xa4\x87\xe6\xb3\xa8\xef\xbc\x9a\xe5\x8d\x95\xe4\xbd\x8d/\xe5\xad\xa6\xe6\xa0\xa1+\xe7\xa0\x94\xe7\xa9\xb6\xe6\x96\xb9\xe5\x90\x91 \xef\xbc\x8c\xe5\x88\x86\xe4\xba\xab\xe6\x9c\x80\xe6\x96\xb0\xe7\x9a\x84AI\xe6\x80\x9d\xe7\xbb\xb4\xe5\xaf\xbc\xe5\x9b\xbe\xe5\x92\x8c\xe7\xac\x94\xe8\xae\xb0\n\n985AI\xe5\x8d\x9a\xe5\xa3\xab\xef\xbc\x8cCSDN\xe5\x8d\x9a\xe5\xae\xa2\xe4\xb8\x93\xe5\xae\xb6\n\n\xe5\xb7\xb2\xe8\xbf\x9e\xe8\xbd\xbd\xe7\xb3\xbb\xe5\x88\x97\xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe3\x80\x8b\xe8\xa5\xbf\xe7\x93\x9c\xe4\xb9\xa6\xe6\x89\x8b\xe6\x8e\xa8\xe7\xac\x94\xe8\xae\xb0\n\n\xe5\xb7\xb2\xe5\xae\x8c\xe7\xbb\x93\xe5\xbe\x85\xe6\x9b\xb4\xe7\xac\x94\xe8\xae\xb0\xef\xbc\x9a\xe3\x80\x8a\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0-\xe8\x8a\xb1\xe4\xb9\xa6\xe6\x89\x8b\xe6\x8e\xa8\xe7\xac\x94\xe8\xae\xb0\xe3\x80\x8b\xe3\x80\x81\xe3\x80\x8a\xe6\x97\xa0\xe4\xba\xba\xe9\xa9\xbe\xe9\xa9\xb6\xe6\x89\x8b\xe6\x8e\xa8\xe7\xac\x94\xe8\xae\xb0\xe3\x80\x8b\xe3\x80\x81\xe3\x80\x8aSLAM \xe5\x8d\x81\xe5\x9b\x9b\xe8\xae\xb2\xe3\x80\x8b\n\n| \xe4\xb8\x8b\xe8\xbd\xbd\xe5\x9c\xb0\xe5\x9d\x80 | \xe5\x8d\x9a\xe5\xa3\xab\xe7\xa7\x81\xe4\xba\xba\xe5\xbe\xae\xe4\xbf\xa1 |\n|:-----------:|:-----------:|\n|![](./cvQD.jpg)|![](./Kingsplus.jpg)| \n|\xe3\x80\x90\xe8\xae\xa1\xe7\xae\x97\xe6\x9c\xba\xe8\xa7\x86\xe8\xa7\x89\xe8\x81\x94\xe7\x9b\x9f\xe3\x80\x91\xe5\x9b\x9e\xe5\xa4\x8d\xe3\x80\x90\xe8\xa5\xbf\xe7\x93\x9c\xe4\xb9\xa6\xe6\x89\x8b\xe6\x8e\xa8\xe7\xac\x94\xe8\xae\xb0\xe3\x80\x91\xe5\x8d\xb3\xe5\x8f\xaf\xe8\x8e\xb7\xe5\xbe\x97\xe7\x99\xbe\xe5\xba\xa6\xe4\xba\x91pdf\xe4\xb8\x8b\xe8\xbd\xbd\xe9\x93\xbe\xe6\x8e\xa5|985AI\xe5\x8d\x9a\xe5\xa3\xab\xef\xbc\x8cCSDN\xe5\x8d\x9a\xe5\xae\xa2\xe4\xb8\x93\xe5\xae\xb6|\n\n\n## \xe7\xac\xac\xe4\xb8\x80\xe7\xab\xa0 \xe7\xbb\xaa\xe8\xae\xba\n\n ![image](./ch1/ch01.png)|\n\n\n### \xe6\x95\xb0\xe5\xad\xa6\xe7\xac\xa6\xe5\x8f\xb7\n| 1 | 2 | 3 |4 |\n|:-----------:|:--------:|:---------:|:---------:|\n|![](./ch/0000.jpg)| ![](./ch/0001.jpg)| ![](./ch/0002.jpg)|  ![](./ch/0003.jpg)| \n\n## \xe7\xac\xac\xe4\xba\x8c\xe7\xab\xa0  \xe6\xa8\xa1\xe5\x9e\x8b\xe8\xaf\x84\xe4\xbc\xb0\xe4\xb8\x8e\xe9\x80\x89\xe6\x8b\xa9\n| 1 | 2 | 3 |4 |\n|:-----------:|:--------:|:---------:|:---------:|\n|![](./ch2/%E6%89%AB%E6%8F%8F_%E5%89%AF%E6%9C%AC.jpg)| ![](./ch2/%E6%89%AB%E6%8F%8F0001_%E5%89%AF%E6%9C%AC.jpg)| ![](./ch2/%E6%89%AB%E6%8F%8F0002_%E5%89%AF%E6%9C%AC.jpg)|  ![](./ch2/%E6%89%AB%E6%8F%8F0003_%E5%89%AF%E6%9C%AC.jpg)| \n|![](./ch2/%E6%89%AB%E6%8F%8F0004_%E5%89%AF%E6%9C%AC.jpg)| ![](./ch2/%E6%89%AB%E6%8F%8F0005_%E5%89%AF%E6%9C%AC.jpg)| ![](./ch2/%E6%89%AB%E6%8F%8F0006_%E5%89%AF%E6%9C%AC.jpg)|  ![](./ch2/%E6%89%AB%E6%8F%8F0007_%E5%89%AF%E6%9C%AC.jpg)| \n|![](./ch2/%E6%89%AB%E6%8F%8F0008_%E5%89%AF%E6%9C%AC.jpg)| ![](./ch2/%E6%89%AB%E6%8F%8F0009_%E5%89%AF%E6%9C%AC.jpg)| ![](./ch2/%E6%89%AB%E6%8F%8F0010_%E5%89%AF%E6%9C%AC.jpg)|  ![](./ch2/%E6%89%AB%E6%8F%8F0011_%E5%89%AF%E6%9C%AC.jpg)| \n|![](./ch2/%E6%89%AB%E6%8F%8F0012_%E5%89%AF%E6%9C%AC.jpg)|--by \xe7\x8e\x8b\xe5\x8d\x9aKings||| \n\n\n\n## \xe7\xac\xac\xe4\xb8\x89\xe7\xab\xa0  \xe7\xba\xbf\xe6\x80\xa7\xe6\xa8\xa1\xe5\x9e\x8b\n| 1 | 2 | 3 |4 |\n|:-----------:|:--------:|:---------:|:---------:|\n|![](./ch3/%E6%89%AB%E6%8F%8F0014_%E5%89%AF%E6%9C%AC.jpg)| ![](./ch3/%E6%89%AB%E6%8F%8F0015_%E5%89%AF%E6%9C%AC.jpg)| ![](./ch3/%E6%89%AB%E6%8F%8F0016_%E5%89%AF%E6%9C%AC.jpg)|  ![](./ch3/%E6%89%AB%E6%8F%8F0017_%E5%89%AF%E6%9C%AC.jpg)| \n|![](./ch3/%E6%89%AB%E6%8F%8F0018_%E5%89%AF%E6%9C%AC.jpg)| ![](./ch3/%E6%89%AB%E6%8F%8F0019_%E5%89%AF%E6%9C%AC.jpg)| ![](./ch3/%E6%89%AB%E6%8F%8F0020_%E5%89%AF%E6%9C%AC.jpg)|  ![](./ch3/%E6%89%AB%E6%8F%8F0021_%E5%89%AF%E6%9C%AC.jpg)| \n|![](./ch3/%E6%89%AB%E6%8F%8F0022_%E5%89%AF%E6%9C%AC.jpg)| ![](./ch3/%E6%89%AB%E6%8F%8F0023_%E5%89%AF%E6%9C%AC.jpg)|--by \xe7\x8e\x8b\xe5\x8d\x9aKings| | \n\n\n## \xe7\xac\xac\xe5\x9b\x9b\xe7\xab\xa0   \xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\n| 1 | 2 | 3 |4 |\n|:-----------:|:--------:|:---------:|:---------:|\n|![](./ch4/%E6%89%AB%E6%8F%8F0024_%E5%89%AF%E6%9C%AC.jpg)| ![](./ch4/%E6%89%AB%E6%8F%8F0025_%E5%89%AF%E6%9C%AC.jpg)| ![](./ch4/%E6%89%AB%E6%8F%8F0026_%E5%89%AF%E6%9C%AC.jpg)|  ![](./ch4/%E6%89%AB%E6%8F%8F0027_%E5%89%AF%E6%9C%AC.jpg)| \n|![](./ch4/%E6%89%AB%E6%8F%8F0028_%E5%89%AF%E6%9C%AC.jpg)| ![](./ch4/%E6%89%AB%E6%8F%8F0029_%E5%89%AF%E6%9C%AC.jpg)| ![](./ch4/%E6%89%AB%E6%8F%8F0030_%E5%89%AF%E6%9C%AC.jpg)|  ![](./ch4/%E6%89%AB%E6%8F%8F0031_%E5%89%AF%E6%9C%AC.jpg)| \n|![](./ch4/%E6%89%AB%E6%8F%8F0032_%E5%89%AF%E6%9C%AC.jpg)| ![](./ch4/%E6%89%AB%E6%8F%8F0033_%E5%89%AF%E6%9C%AC.jpg)| ![](./ch4/%E6%89%AB%E6%8F%8F0034_%E5%89%AF%E6%9C%AC.jpg)|  --by \xe7\x8e\x8b\xe5\x8d\x9aKings| \n\n## \xe7\xac\xac\xe4\xba\x94\xe7\xab\xa0   \xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\n| 1 | 2 | 3 |4 |\n|:-----------:|:--------:|:---------:|:---------:|\n|![image](./ch5/%E6%89%AB%E6%8F%8F0035_%E5%89%AF%E6%9C%AC.jpg)|![image](./ch5/%E6%89%AB%E6%8F%8F0036_%E5%89%AF%E6%9C%AC.jpg)|![image](./ch5/%E6%89%AB%E6%8F%8F0037_%E5%89%AF%E6%9C%AC.jpg)|![image](./ch5/%E6%89%AB%E6%8F%8F0038_%E5%89%AF%E6%9C%AC.jpg)|\n![image](./ch5/%E6%89%AB%E6%8F%8F0039_%E5%89%AF%E6%9C%AC.jpg)|![image](./ch5/%E6%89%AB%E6%8F%8F0040_%E5%89%AF%E6%9C%AC.jpg)|![image](./ch5/%E6%89%AB%E6%8F%8F0041_%E5%89%AF%E6%9C%AC.jpg)|![image](./ch5/%E6%89%AB%E6%8F%8F0042_%E5%89%AF%E6%9C%AC.jpg)|\n![image](./ch5/%E6%89%AB%E6%8F%8F0043_%E5%89%AF%E6%9C%AC.jpg)|![image](./ch5/%E6%89%AB%E6%8F%8F0044_%E5%89%AF%E6%9C%AC.jpg)|![image](./ch5/%E6%89%AB%E6%8F%8F0045_%E5%89%AF%E6%9C%AC.jpg)|  --by \xe7\x8e\x8b\xe5\x8d\x9aKings| \n\n\n\n## \xe7\xac\xac\xe5\x85\xad\xe7\xab\xa0   \xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba\n| 1 | 2 | 3 |4 |\n|:-----------:|:--------:|:---------:|:---------:|\n|![image](./ch6/%E6%89%AB%E6%8F%8F_%E5%89%AF%E6%9C%AC.jpg)|![image](./ch6/%E6%89%AB%E6%8F%8F0001_%E5%89%AF%E6%9C%AC.jpg)|![image](./ch6/%E6%89%AB%E6%8F%8F0002_%E5%89%AF%E6%9C%AC.jpg)|![image](./ch6/%E6%89%AB%E6%8F%8F0003_%E5%89%AF%E6%9C%AC.jpg)|\n![image](./ch6/%E6%89%AB%E6%8F%8F0004_%E5%89%AF%E6%9C%AC.jpg)|![image](./ch6/%E6%89%AB%E6%8F%8F0005_%E5%89%AF%E6%9C%AC.jpg)|![image](./ch6/%E6%89%AB%E6%8F%8F0006_%E5%89%AF%E6%9C%AC.jpg)|![image](./ch6/%E6%89%AB%E6%8F%8F0007_%E5%89%AF%E6%9C%AC.jpg)|\n![image](./ch6/%E6%89%AB%E6%8F%8F0008_%E5%89%AF%E6%9C%AC.jpg)|![image](./ch6/%E6%89%AB%E6%8F%8F0009_%E5%89%AF%E6%9C%AC.jpg)|![image](./ch6/%E6%89%AB%E6%8F%8F0010_%E5%89%AF%E6%9C%AC.jpg)|![image](./ch6/%E6%89%AB%E6%8F%8F0011_%E5%89%AF%E6%9C%AC.jpg)|\n![image](./ch6/%E6%89%AB%E6%8F%8F0012_%E5%89%AF%E6%9C%AC.jpg)|![image](./ch6/%E6%89%AB%E6%8F%8F0013_%E5%89%AF%E6%9C%AC.jpg)|![image](./ch6/%E6%89%AB%E6%8F%8F0014_%E5%89%AF%E6%9C%AC.jpg)|![image](./ch6/%E6%89%AB%E6%8F%8F0015_%E5%89%AF%E6%9C%AC.jpg)|\n\n## \xe7\xac\xac\xe4\xb8\x83\xe7\xab\xa0    \xe8\xb4\x9d\xe5\x8f\xb6\xe6\x96\xaf\xe5\x88\x86\xe7\xb1\xbb\xe5\x99\xa8\n![image](./ch7/062.jpg)\n![image](./ch7/063.jpg)\n![image](./ch7/064.jpg)\n![image](./ch7/065.jpg)\n![image](./ch7/066.jpg)\n![image](./ch7/067.jpg)\n![image](./ch7/068.jpg)\n![image](./ch7/069.jpg)\n![image](./ch7/070.jpg)\n![image](./ch7/071.jpg)\n![image](./ch7/072.jpg)\n![image](./ch7/073.jpg)\n![image](./ch7/074.jpg)\n'"
72,rieder91/MachineLearning,rieder91,Exercises for the Stanford/Coursera Machine Learning Class,2012-07-08 14:15:41,2020-06-10 03:17:37,Matlab,197,225,"b'# Machine Learning\n_Coursera, taught by Andrew Ng_\n\n### Done\n * Linear Regression\n * Logistic Regression\n * Multi-class Classification and Neural Networks\n * Neural Network Learning\n * Regularized Linear Regression and Bias/Variance\n * Support Vector Machines\n * K-Means Clustering and PCA\n * Anomaly Detection and Recommender Systems\n\n\n### TODO\n * Nothing\n\n\n### How to contact me\n * via email: thomasrieder _at_ aon _dot_ at\n * via twitter: [My Profile](https://twitter.com/#!/thomasrieder)\n\n\n### Class:\n[Machine Learning](https://class.coursera.org/ml ""Machine Learning"")\n'"
73,awslabs/amazon-sagemaker-examples,awslabs,"Example notebooks that show how to apply machine learning, deep learning and reinforcement learning in Amazon SageMaker",2017-10-23 05:55:22,2020-06-18 19:36:43,Jupyter Notebook,2873,3764,"b'# Amazon SageMaker Examples\n\nThis repository contains example notebooks that show how to apply machine learning and deep learning in [Amazon SageMaker](https://aws.amazon.com/sagemaker)\n\n## Examples\n\n### Introduction to Ground Truth Labeling Jobs\n\nThese examples provide quick walkthroughs to get you up and running with the labeling job workflow for Amazon SageMaker Ground Truth.\n\n- [Bring your own model for sagemaker labeling workflows with active learning](ground_truth_labeling_jobs/bring_your_own_model_for_sagemaker_labeling_workflows_with_active_learning) is an end-to-end example that shows how to bring your custom training, inference logic and active learning to the Amazon SageMaker ecosystem.\n- [From Unlabeled Data to a Deployed Machine Learning Model: A SageMaker Ground Truth Demonstration for Image Classification](ground_truth_labeling_jobs/from_unlabeled_data_to_deployed_machine_learning_model_ground_truth_demo_image_classification) is an end-to-end example that starts with an unlabeled dataset, labels it using the Ground Truth API, analyzes the results, trains an image classification neural net using the annotated dataset, and finally uses the trained model to perform batch and online inference.\n- [Ground Truth Object Detection Tutorial](ground_truth_labeling_jobs/ground_truth_object_detection_tutorial) is a similar end-to-end example but for an object detection task.\n- [Basic Data Analysis of an Image Classification Output Manifest](ground_truth_labeling_jobs/data_analysis_of_ground_truth_image_classification_output) presents charts to visualize the number of annotations for each class, differentiating between human annotations and automatic labels (if your job used auto-labeling). It also displays sample images in each class, and creates a pdf which concisely displays the full results.\n- [Training a Machine Learning Model Using an Output Manifest](ground_truth_labeling_jobs/object_detection_augmented_manifest_training) introduces the concept of an ""augmented manifest"" and demonstrates that the output file of a labeling job can be immediately used as the input file to train a SageMaker machine learning model.\n- [Annotation Consolidation](ground_truth_labeling_jobs/annotation_consolidation) demonstrates Amazon SageMaker Ground Truth annotation consolidation techniques for image classification for a completed labeling job.\n\n\n### Introduction to Applying Machine Learning\n\nThese examples provide a gentle introduction to machine learning concepts as they are applied in practical use cases across a variety of sectors.\n\n- [Targeted Direct Marketing](introduction_to_applying_machine_learning/xgboost_direct_marketing) predicts potential customers that are most likely to convert based on customer and aggregate level metrics, using Amazon SageMaker\'s implementation of [XGBoost](https://github.com/dmlc/xgboost).\n- [Predicting Customer Churn](introduction_to_applying_machine_learning/xgboost_customer_churn) uses customer interaction and service usage data to find those most likely to churn, and then walks through the cost/benefit trade-offs of providing retention incentives.  This uses Amazon SageMaker\'s implementation of [XGBoost](https://github.com/dmlc/xgboost) to create a highly predictive model.\n- [Time-series Forecasting](introduction_to_applying_machine_learning/linear_time_series_forecast) generates a forecast for topline product demand using Amazon SageMaker\'s Linear Learner algorithm.\n- [Cancer Prediction](introduction_to_applying_machine_learning/breast_cancer_prediction) predicts Breast Cancer based on features derived from images, using SageMaker\'s Linear Learner.\n- [Ensembling](introduction_to_applying_machine_learning/ensemble_modeling) predicts income using two Amazon SageMaker models to show the advantages in ensembling.\n- [Video Game Sales](introduction_to_applying_machine_learning/video_game_sales) develops a binary prediction model for the success of video games based on review scores.\n- [MXNet Gluon Recommender System](introduction_to_applying_machine_learning/gluon_recommender_system) uses neural network embeddings for non-linear matrix factorization to predict user movie ratings on Amazon digital reviews.\n- [Fair Linear Learner](introduction_to_applying_machine_learning/fair_linear_learner) is an example of an effective way to create fair linear models with respect to sensitive features.\n- [Population Segmentation of US Census Data using PCA and Kmeans](introduction_to_applying_machine_learning/US-census_population_segmentation_PCA_Kmeans) analyzes US census data and reduces dimensionality using PCA then clusters US counties using KMeans to identify segments of similar counties.\n- [Document Embedding using Object2Vec](introduction_to_applying_machine_learning/object2vec_document_embedding) is an example to embed a large collection of documents in a common low-dimensional space, so that the semantic distances between these documents are preserved.\n- [Traffic violations forecasting using DeepAR](introduction_to_applying_machine_learning/deepar_chicago_traffic_violations) is an example to use daily traffic violation data to predict pattern and seasonality to use Amazon DeepAR alogorithm.\n \n### SageMaker Automatic Model Tuning\n\nThese examples introduce SageMaker\'s hyperparameter tuning functionality which helps deliver the best possible predictions by running a large number of training jobs to determine which hyperparameter values are the most impactful.\n\n- [XGBoost Tuning](hyperparameter_tuning/xgboost_direct_marketing) shows how to use SageMaker hyperparameter tuning to improve your model fits for the [Targeted Direct Marketing](introduction_to_applying_machine_learning/xgboost_direct_marketing) task.\n- [TensorFlow Tuning](hyperparameter_tuning/tensorflow_mnist) shows how to use SageMaker hyperparameter tuning with the pre-built TensorFlow container and MNIST dataset.\n- [MXNet Tuning](hyperparameter_tuning/mxnet_mnist) shows how to use SageMaker hyperparameter tuning with the pre-built MXNet container and MNIST dataset.\n- [Keras BYO Tuning](hyperparameter_tuning/keras_bring_your_own) shows how to use SageMaker hyperparameter tuning with a custom container running a Keras convolutional network on CIFAR-10 data.\n- [R BYO Tuning](hyperparameter_tuning/r_bring_your_own) shows how to use SageMaker hyperparameter tuning with the custom container from the [Bring Your Own R Algorithm](advanced_functionality/r_bring_your_own) example.\n- [Analyzing Results](hyperparameter_tuning/analyze_results) is a shared notebook that can be used after each of the above notebooks to provide analysis on how training jobs with different hyperparameters performed.\n\n### Introduction to Amazon Algorithms\n\nThese examples provide quick walkthroughs to get you up and running with Amazon SageMaker\'s custom developed algorithms.  Most of these algorithms can train on distributed hardware, scale incredibly well, and are faster and cheaper than popular alternatives.\n\n- [k-means](sagemaker-python-sdk/1P_kmeans_highlevel) is our introductory example for Amazon SageMaker.  It walks through the process of clustering MNIST images of handwritten digits using Amazon SageMaker k-means.\n- [Factorization Machines](introduction_to_amazon_algorithms/factorization_machines_mnist) showcases Amazon SageMaker\'s implementation of the algorithm to predict whether a handwritten digit from the MNIST dataset is a 0 or not using a binary classifier.\n- [Latent Dirichlet Allocation (LDA)](introduction_to_amazon_algorithms/lda_topic_modeling) introduces topic modeling using Amazon SageMaker Latent Dirichlet Allocation (LDA) on a synthetic dataset.\n- [Linear Learner](introduction_to_amazon_algorithms/linear_learner_mnist) predicts whether a handwritten digit from the MNIST dataset is a 0 or not using a binary classifier from Amazon SageMaker Linear Learner.\n- [Neural Topic Model (NTM)](introduction_to_amazon_algorithms/ntm_synthetic) uses Amazon SageMaker Neural Topic Model (NTM) to uncover topics in documents from a synthetic data source, where topic distributions are known.\n- [Principal Components Analysis (PCA)](introduction_to_amazon_algorithms/pca_mnist) uses Amazon SageMaker PCA to calculate eigendigits from MNIST.\n- [Seq2Seq](introduction_to_amazon_algorithms/seq2seq_translation_en-de) uses the Amazon SageMaker Seq2Seq algorithm that\'s built on top of [Sockeye](https://github.com/awslabs/sockeye), which is a sequence-to-sequence framework for Neural Machine Translation based on MXNet.  Seq2Seq implements state-of-the-art encoder-decoder architectures which can also be used for tasks like Abstractive Summarization in addition to Machine Translation.  This notebook shows translation from English to German text.\n- [Image Classification](introduction_to_amazon_algorithms/imageclassification_caltech) includes full training and transfer learning examples of Amazon SageMaker\'s Image Classification algorithm.  This uses a ResNet deep convolutional neural network to classify images from the caltech dataset.\n- [XGBoost for regression](introduction_to_amazon_algorithms/xgboost_abalone) predicts the age of abalone ([Abalone dataset](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression.html)) using regression from Amazon SageMaker\'s implementation of [XGBoost](https://github.com/dmlc/xgboost).\n- [XGBoost for multi-class classification](introduction_to_amazon_algorithms/xgboost_mnist) uses Amazon SageMaker\'s implementation of [XGBoost](https://github.com/dmlc/xgboost) to classify handwritten digits from the MNIST dataset as one of the ten digits using a multi-class classifier. Both single machine and distributed use-cases are presented.\n- [DeepAR for time series forecasting](introduction_to_amazon_algorithms/deepar_synthetic) illustrates how to use the Amazon SageMaker DeepAR algorithm for time series forecasting on a synthetically generated data set.\n- [BlazingText Word2Vec](introduction_to_amazon_algorithms/blazingtext_word2vec_text8) generates Word2Vec embeddings from a cleaned text dump of Wikipedia articles using SageMaker\'s fast and scalable BlazingText implementation.\n- [Object Detection](introduction_to_amazon_algorithms/object_detection_pascalvoc_coco) illustrates how to train an object detector using the Amazon SageMaker Object Detection algorithm with different input formats (RecordIO and image).  It uses the Pascal VOC dataset. A third notebook is provided to demonstrate the use of incremental training.\n- [Object detection for bird images](introduction_to_amazon_algorithms/object_detection_birds) demonstrates how to use the Amazon SageMaker Object Detection algorithm with a public dataset of Bird images.\n- [Object2Vec for movie recommendation](introduction_to_amazon_algorithms/object2vec_movie_recommendation) demonstrates how Object2Vec can be used to model data consisting of pairs of singleton tokens using movie recommendation as a running example.\n- [Object2Vec for multi-label classification](introduction_to_amazon_algorithms/object2vec_multilabel_genre_classification) shows how ObjectToVec algorithm can train on data consisting of pairs of sequences and singleton tokens using the setting of genre prediction of movies based on their plot descriptions.\n- [Object2Vec for sentence similarity](introduction_to_amazon_algorithms/object2vec_sentence_similarity) explains how to train Object2Vec using sequence pairs as input using sentence similarity analysis as the application.\n- [IP Insights for suspicious logins](introduction_to_amazon_algorithms/ipinsights_login) shows how to train IP Insights on a login events for a web server to identify suspicious login attempts.\n- [Semantic Segmentation](introduction_to_amazon_algorithms/semantic_segmentation_pascalvoc) shows how to train a semantic segmentation algorithm using the Amazon SageMaker Semantic Segmentation algorithm. It also demonstrates how to host the model and produce segmentaion masks and probability of segmentation.\n\n### Amazon SageMaker RL\n\nThe following provide examples demonstrating different capabilities of Amazon SageMaker RL.\n\n- [Cartpole using Coach](reinforcement_learning/rl_cartpole_coach) demonstrates the simplest usecase of Amazon SageMaker RL using Intel\'s RL Coach.\n- [AWS DeepRacer](reinforcement_learning/rl_deepracer_robomaker_coach_gazebo) demonstrates AWS DeepRacer trainig using RL Coach in the Gazebo environment.\n- [HVAC using EnergyPlus](reinforcement_learning/rl_hvac_coach_energyplus) demonstrates the training of HVAC systems using the EnergyPlus environment.\n- [Knapsack Problem](reinforcement_learning/rl_knapsack_coach_custom) demonstrates how to solve the knapsack problem using a custom environment.\n- [Mountain Car](reinforcement_learning/rl_mountain_car_coach_gymEnv) Mountain car is a classic RL problem. This notebook explains how to solve this using the OpenAI Gym environment.\n- [Distributed Neural Network Compression](reinforcement_learning/rl_network_compression_ray_custom) This notebook explains how to compress ResNets using RL, using a custom environment and the RLLib toolkit.\n- [Turtlebot Tracker](reinforcement_learning/rl_objecttracker_robomaker_coach_gazebo) This notebook demonstrates object tracking using AWS Robomaker and RL Coach in the Gazebo environment.\n- [Portfolio Management](reinforcement_learning/rl_portfolio_management_coach_customEnv) This notebook uses a custom Gym environment to manage multiple financial investments.\n- [Autoscaling](reinforcement_learning/rl_predictive_autoscaling_coach_customEnv) demonstrates how to adjust load depending on demand. This uses RL Coach and a custom environment.\n- [Roboschool](reinforcement_learning/rl_roboschool_ray) is an open source physics simulator that is commonly used to train RL policies for robotic systems. This notebook demonstrates training a few agents using it.\n- [Stable Baselines](reinforcement_learning/rl_roboschool_stable_baselines) In this notebook example, we will make the HalfCheetah agent learn to walk using the stable-baselines, which are a set of improved implementations of Reinforcement Learning (RL) algorithms based on OpenAI Baselines.\n- [Travelling Salesman](reinforcement_learning/rl_traveling_salesman_vehicle_routing_coach) is a classic NP hard problem, which this notebook solves with AWS SageMaker RL.\n- [Tic-tac-toe](reinforcement_learning/rl_tic_tac_toe_coach_customEnv) is a simple implementation of a custom Gym environment to train and deploy an RL agent in Coach that then plays tic-tac-toe interactively in a Jupyter Notebook.\n\n### Scientific Details of Algorithms\n\nThese examples provide more thorough mathematical treatment on a select group of algorithms.\n\n- [Streaming Median](scientific_details_of_algorithms/streaming_median) sequentially introduces concepts used in streaming algorithms, which many SageMaker algorithms rely on to deliver speed and scalability.\n- [Latent Dirichlet Allocation (LDA)](scientific_details_of_algorithms/lda_topic_modeling) dives into Amazon SageMaker\'s spectral decomposition approach to LDA.\n- [Linear Learner features](scientific_details_of_algorithms/linear_learner_class_weights_loss_functions) shows how to use the class weights and loss functions features of the SageMaker Linear Learner algorithm to improve performance on a credit card fraud prediction task\n\n### Amazon SageMaker Debugger\nThese examples provide and introduction to SageMaker Debugger which allows debugging and monitoring capabilities for training of machine learning and deep learning algorithms. Note that although these notebooks focus on a specific framework, the same approach works with all the frameworks that Amazon SageMaker Debugger supports. The notebooks below are listed in the order in which we recommend you review them.\n\n- [Using a built-in rule with TensorFlow](sagemaker-debugger/tensorflow_builtin_rule/)\n- [Using a custom rule with TensorFlow Keras](sagemaker-debugger/tensorflow_keras_custom_rule/)\n- [Interactive tensor analysis in notebook with MXNet](sagemaker-debugger/mnist_tensor_analysis/)\n- [Visualizing Debugging Tensors of MXNet training](sagemaker-debugger/mnist_tensor_plot/)\n- [Real-time analysis in notebook with MXNet](sagemaker-debugger/mxnet_realtime_analysis/)\n- [Using a built in rule with XGBoost](sagemaker-debugger/xgboost_builtin_rules/)\n- [Real-time analysis in notebook with XGBoost](sagemaker-debugger/xgboost_realtime_analysis/)\n- [Using SageMaker Debugger with Managed Spot Training and MXNet](sagemaker-debugger/mxnet_spot_training/)\n- [Reacting to CloudWatch Events from Rules to take an action based on status with TensorFlow](sagemaker-debugger/tensorflow_action_on_rule/)\n- [Using SageMaker Debugger with a custom PyTorch container](sagemaker-debugger/pytorch_custom_container/)\n\n### Advanced Amazon SageMaker Functionality\n\nThese examples that showcase unique functionality available in Amazon SageMaker.  They cover a broad range of topics and will utilize a variety of methods, but aim to provide the user with sufficient insight or inspiration to develop within Amazon SageMaker.\n\n- [Data Distribution Types](advanced_functionality/data_distribution_types) showcases the difference between two methods for sending data from S3 to Amazon SageMaker Training instances.  This has particular implication for scalability and accuracy of distributed training.\n- [Encrypting Your Data](advanced_functionality/handling_kms_encrypted_data) shows how to use Server Side KMS encrypted data with Amazon SageMaker training. The IAM role used for S3 access needs to have permissions to encrypt and decrypt data with the KMS key.\n- [Using Parquet Data](advanced_functionality/parquet_to_recordio_protobuf) shows how to bring [Parquet](https://parquet.apache.org/) data sitting in S3 into an Amazon SageMaker Notebook and convert it into the recordIO-protobuf format that many SageMaker algorithms consume.\n- [Connecting to Redshift](advanced_functionality/working_with_redshift_data) demonstrates how to copy data from Redshift to S3 and vice-versa without leaving Amazon SageMaker Notebooks.\n- [Bring Your Own XGBoost Model](advanced_functionality/xgboost_bring_your_own_model) shows how to use Amazon SageMaker Algorithms containers to bring a pre-trained model to a realtime hosted endpoint without ever needing to think about REST APIs.\n- [Bring Your Own k-means Model](advanced_functionality/kmeans_bring_your_own_model) shows how to take a model that\'s been fit elsewhere and use Amazon SageMaker Algorithms containers to host it.\n- [Bring Your Own R Algorithm](advanced_functionality/r_bring_your_own) shows how to bring your own algorithm container to Amazon SageMaker using the R language.\n- [Installing the R Kernel](advanced_functionality/install_r_kernel) shows how to install the R kernel into an Amazon SageMaker Notebook Instance.\n- [Bring Your Own scikit Algorithm](advanced_functionality/scikit_bring_your_own) provides a detailed walkthrough on how to package a scikit learn algorithm for training and production-ready hosting.\n- [Bring Your Own MXNet Model](advanced_functionality/mxnet_mnist_byom) shows how to bring a model trained anywhere using MXNet into Amazon SageMaker.\n- [Bring Your Own TensorFlow Model](advanced_functionality/tensorflow_iris_byom) shows how to bring a model trained anywhere using TensorFlow into Amazon SageMaker.\n- [Inference Pipeline with SparkML and XGBoost](advanced_functionality/inference_pipeline_sparkml_xgboost_abalone) shows how to deploy an Inference Pipeline with SparkML for data pre-processing and XGBoost for training on the Abalone dataset. The pre-processing code is written once and used between training and inference.\n- [Inference Pipeline with SparkML and BlazingText](advanced_functionality/inference_pipeline_sparkml_blazingtext_dbpedia) shows how to deploy an Inference Pipeline with SparkML for data pre-processing and BlazingText for training on the DBPedia dataset. The pre-processing code is written once and used between training and inference.\n- [Experiment Management Capabilities with Search](advanced_functionality/search) shows how to organize Training Jobs into projects, and track relationships between Models, Endpoints, and Training Jobs.\n- [Host Multiple Models with Your Own Algorithm](advanced_functionality/multi_model_bring_your_own) shows how to deploy multiple models to a realtime hosted endpoint with your own custom algorithm.\n- [Host Multiple Models with XGBoost](advanced_functionality/multi_model_xgboost_home_value) shows how to deploy multiple models to a realtime hosted endpoint using a multi-model enabled XGBoost container.\n- [Host Multiple Models with SKLearn](advanced_functionality/multi_model_sklearn_home_value) shows how to deploy multiple models to a realtime hosted endpoint using a multi-model enabled SKLearn container.\n\n### Amazon SageMaker Neo Compilation Jobs\n\nThese examples provide you an introduction to how to use Neo to optimizes deep learning model\n\n- [GluonCV SSD Mobilenet](sagemaker_neo_compilation_jobs/gluoncv_ssd_mobilenet) shows how to train gluoncv ssd mobilenet and use Amazon Sagemaker Neo to compile and optimize the trained model.\n- [Image Classification](sagemaker_neo_compilation_jobs/imageclassification_caltech) Adapts form [image classification](introduction_to_amazon_algorithms/imageclassification_caltech) including Neo API and comparsion between the baseline\n- [MNIST with MXNet](sagemaker_neo_compilation_jobs/mxnet_mnist) Adapts form [mxnet mnist](sagemaker-python-sdk/mxnet_mnist) including Neo API and comparsion between the baseline\n- [Deploying pre-trained PyTorch vision models](sagemaker_neo_compilation_jobs/pytorch_torchvision) shows how to use Amazon SageMaker Neo to compile and optimize pre-trained PyTorch models from TorchVision.\n- [Distributed TensorFlow](sagemaker_neo_compilation_jobs/tensorflow_distributed_mnist) Adapts form [tensorflow mnist](sagemaker-python-sdk/tensorflow_distributed_mnist) including Neo API and comparsion between the baseline\n- [Predicting Customer Churn](sagemaker_neo_compilation_jobs/xgboost_customer_churn) Adapts form [xgboost customer churn](introduction_to_applying_machine_learning/xgboost_customer_churn) including Neo API and comparsion between the baseline\n\n### Amazon SageMaker Procesing\n\nThese examples show you how to use SageMaker Processing jobs to run data processing workloads.\n\n- [Scikit-Learn Data Processing and Model Evaluation](sagemaker_processing/scikit_learn_data_processing_and_model_evaluation) shows how to use SageMaker Processing and the Scikit-Learn container to run data preprocessing and model evaluation workloads.\n- [Feature transformation with Amazon SageMaker Processing and SparkML](sagemaker_processing/feature_transformation_with_sagemaker_processing) shows how to use SageMaker Processing to run data processing workloads using SparkML prior to training.\n- [Feature transformation with Amazon SageMaker Processing and Dask](sagemaker_processing/feature_transformation_with_sagemaker_processing_dask) shows how to use SageMaker Processing to transform data using Dask distributed clusters\n\n### Amazon SageMaker Pre-Built Framework Containers and the Python SDK\n\n#### Pre-Built Deep Learning Framework Containers\n\nThese examples show you how to train and host in pre-built deep learning framework containers using the SageMaker Python SDK.\n\n- [Chainer CIFAR-10](sagemaker-python-sdk/chainer_cifar10) trains a VGG image classification network on CIFAR-10 using Chainer (both single machine and multi-machine versions are included)\n- [Chainer MNIST](sagemaker-python-sdk/chainer_mnist) trains a basic neural network on MNIST using Chainer (shows how to use local mode)\n- [Chainer sentiment analysis](sagemaker-python-sdk/chainer_sentiment_analysis) trains a LSTM network with embeddings to predict text sentiment using Chainer\n- [IRIS with Scikit-learn](sagemaker-python-sdk/scikit_learn_iris) trains a Scikit-learn classifier on IRIS data\n- [MNIST with MXNet Gluon](sagemaker-python-sdk/mxnet_gluon_mnist) trains a basic neural network on the MNIST handwritten digit dataset using MXNet Gluon\n- [MNIST with MXNet](sagemaker-python-sdk/mxnet_mnist) trains a basic neural network on the MNIST handwritten digit data using MXNet\'s symbolic syntax\n- [Sentiment Analysis with MXNet Gluon](sagemaker-python-sdk/mxnet_gluon_sentiment) trains a text classifier using embeddings with MXNet Gluon\n- [TensorFlow training and serving](sagemaker-python-sdk/tensorflow_script_mode_training_and_serving) trains a basic neural network on MNIST\n- [TensorFlow with Horovod](sagemaker-python-sdk/tensorflow_script_mode_horovod) trains on MNIST using Horovod for distributed training\n- [TensorFlow using shell commands](sagemaker-python-sdk/tensorflow_script_mode_using_shell_commands) shows how to use a shell script for the container\'s entry point\n\n#### Pre-Built Machine Learning Framework Containers\n\nThese examples show you how to build Machine Learning models with frameworks like Apache Spark or Scikit-learn using SageMaker Python SDK.\n\n- [Inference with SparkML Serving](sagemaker-python-sdk/sparkml_serving_emr_mleap_abalone) shows how to build an ML model with Apache Spark using Amazon EMR on Abalone dataset and deploy in SageMaker with SageMaker SparkML Serving.\n- [Pipeline Inference with Scikit-learn and LinearLearner](sagemaker-python-sdk/scikit_learn_inference_pipeline) builds a ML pipeline using Scikit-learn preprocessing and LinearLearner algorithm in single endpoint\n### Using Amazon SageMaker with Apache Spark\n\nThese examples show how to use Amazon SageMaker for model training, hosting, and inference through Apache Spark using [SageMaker Spark](https://github.com/aws/sagemaker-spark). SageMaker Spark allows you to interleave Spark Pipeline stages with Pipeline stages that interact with Amazon SageMaker.\n\n- [MNIST with SageMaker PySpark](sagemaker-spark/pyspark_mnist)\n\n### AWS Marketplace\n\n#### Create algorithms/model packages for listing in AWS Marketplace for machine learning.\n\nThis example shows you how to package a model-package/algorithm for listing in AWS Marketplace for machine learning.\n\n- [Creating Algorithm and Model Package - Listing on AWS Marketplace](aws_marketplace/creating_marketplace_products) provides a detailed walkthrough on how to package a scikit learn algorithm to create SageMaker Algorithm and SageMaker Model Package entities that can be used with the enhanced SageMaker Train/Transform/Hosting/Tuning APIs and listed on AWS Marketplace.\n\n#### Use algorithms and model packages from AWS Marketplace for machine learning.\n\nThese examples show you how to use model-packages and algorithms from AWS Marketplace for machine learning.\n\n- [Using Algorithms](aws_marketplace/using_algorithms)\n\t- [Using Algorithm From AWS Marketplace](aws_marketplace/using_algorithms/amazon_demo_product) provides a detailed walkthrough on how to use Algorithm with the enhanced SageMaker Train/Transform/Hosting/Tuning APIs by choosing a canonical product listed on AWS Marketplace.\n\t- [Using AutoML algorithm](aws_marketplace/using_algorithms/automl) provides a detailed walkthrough on how to use AutoML algorithm from AWS Marketplace.\n\n- [Using Model Packages](aws_marketplace/using_model_packages)\n\t- [Using Model Packages From AWS Marketplace](aws_marketplace/using_model_packages/generic_sample_notebook) is a generic notebook which provides sample code snippets you can modify and use for performing inference on Model Packages from AWS Marketplace, using Amazon SageMaker.\n\t- [Using Amazon Demo product From AWS Marketplace](aws_marketplace/using_model_packages/amazon_demo_product) provides a detailed walkthrough on how to use Model Package entities with the enhanced SageMaker Transform/Hosting APIs by choosing a canonical product listed on AWS Marketplace.\n\t- [Using models for extracting vehicle metadata](aws_marketplace/using_model_packages/auto_insurance) provides a detailed walkthrough on how to use pre-trained models from AWS Marketplace for extracting metadata for a sample use-case of auto-insurance claim processing.\n\t- [Using models for identifying non-compliance at a workplace](aws_marketplace/using_model_packages/improving_industrial_workplace_safety) provides a detailed walkthrough on how to use pre-trained models from AWS Marketplace for extracting metadata for a sample use-case of generating summary reports for identifying non-compliance at a construction/industrial workplace.\n\t- [Extracting insights from your credit card statements](aws_marketplace/using_model_packages/financial_transaction_processing) provides a detailed walkthrough on how to use pre-trained models from AWS Marketplace for efficiently processing financial transaction logs.\n\n\n\n### Under Development\n\nThese Amazon SageMaker examples fully illustrate a concept, but may require some additional configuration on the users part to complete.\n\n## FAQ\n\n*What do I need in order to get started?*\n\n- The quickest setup to run example notebooks includes:\n  - An [AWS account](http://docs.aws.amazon.com/sagemaker/latest/dg/gs-account.html)\n  - Proper [IAM User and Role](http://docs.aws.amazon.com/sagemaker/latest/dg/authentication-and-access-control.html) setup\n  - An [Amazon SageMaker Notebook Instance](http://docs.aws.amazon.com/sagemaker/latest/dg/gs-setup-working-env.html)\n  - An [S3 bucket](http://docs.aws.amazon.com/sagemaker/latest/dg/gs-config-permissions.html)\n\n*Will these examples work outside of Amazon SageMaker Notebook Instances?*\n\n- Although most examples utilize key Amazon SageMaker functionality like distributed, managed training or real-time hosted endpoints, these notebooks can be run outside of Amazon SageMaker Notebook Instances with minimal modification (updating IAM role definition and installing the necessary libraries).\n\n*How do I contribute my own example notebook?*\n\n- Although we\'re extremely excited to receive contributions from the community, we\'re still working on the best mechanism to take in examples from external sources.  Please bear with us in the short-term if pull requests take longer than expected or are closed.\n'"
74,DeqianBai/Hands-on-Machine-Learning,DeqianBai,A series of Jupyter notebooks with Chinese comment that walk you through the fundamentals of Machine Learning and Deep Learning in python using Scikit-Learn and TensorFlow.,2018-10-18 06:40:16,2020-06-18 01:28:42,Jupyter Notebook,382,1209,b'# Hands-on-Machine-Learning\n\n\n### \xe7\x9b\xae\xe7\x9a\x84\n\n\xe8\xbf\x99\xe4\xbb\xbd\xe7\xac\x94\xe8\xae\xb0\xe6\x97\xa8\xe5\x9c\xa8\xe5\xb8\xae\xe5\x8a\xa9\xe4\xb8\xad\xe6\x96\x87\xe5\xad\xa6\xe4\xb9\xa0\xe8\x80\x85\xe4\xbb\xa5\xe4\xb8\x80\xe7\xa7\x8d**\xe8\xbe\x83\xe5\xbf\xab\xe8\xbe\x83\xe7\xb3\xbb\xe7\xbb\x9f\xe7\x9a\x84\xe6\x96\xb9\xe5\xbc\x8f\xe5\x85\xa5\xe9\x97\xa8\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0**\xef\xbc\x8c\n\n\xe6\x98\xaf\xe5\x9c\xa8\xe5\xad\xa6\xe4\xb9\xa0[Hands-on Machine Learning with Scikit-Learn and TensorFlow](http://shop.oreilly.com/product/0636920052289.do)\xe8\xbf\x99\xe6\x9c\xac\xe4\xb9\xa6\xe7\x9a\x84\n\xe6\x97\xb6\xe5\x80\x99\xe5\x81\x9a\xe7\x9a\x84\xe4\xb8\xaa\xe4\xba\xba\xe7\xac\x94\xe8\xae\xb0:\n\n[![book](http://akamaicovers.oreilly.com/images/0636920052289/cat.gif)](http://shop.oreilly.com/product/0636920052289.do)\n\n### \xe6\xad\xa4\xe9\xa1\xb9\xe7\x9b\xae\xe7\x9a\x84\xe5\x8f\xaf\xe5\x8f\x96\xe4\xb9\x8b\xe5\xa4\x84\n- \xe5\x8e\x9f\xe4\xb9\xa6\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81\xe7\xa4\xba\xe4\xbe\x8b\xe9\x83\xa8\xe5\x88\x86**\xe5\x8f\xaa\xe6\x9c\x89\xe4\xbb\xa3\xe7\xa0\x81\xe6\xb2\xa1\xe6\x9c\x89\xe6\x96\x87\xe5\xad\x97\xe6\xb3\xa8\xe9\x87\x8a**\xef\xbc\x8c\xe7\xba\xb8\xe8\xb4\xa8\xe4\xb9\xa6\xe4\xb8\x8a\xe6\x9c\x89\xe6\x96\x87\xe5\xad\x97\xe8\xa7\xa3\xe9\x87\x8a\xe4\xbd\x86\xe4\xb8\x8d\xe5\x88\xa9\xe4\xba\x8e\xe6\x93\x8d\xe4\xbd\x9c\xef\xbc\x8c\xe8\xbf\x99\xe4\xb8\xaa\xe9\xa1\xb9\xe7\x9b\xae\xe5\xb0\x86\xe5\x85\xb6\xe5\x90\x88\xe4\xba\x8c\xe4\xb8\xba\xe4\xb8\x80\xef\xbc\x8c\n\xe5\xad\xa6\xe4\xb9\xa0\xe8\x80\x85\xe8\xbf\x99\xe5\x8f\xaa\xe9\x9c\x80\xe8\xa6\x81\xe6\x89\x93\xe5\xbc\x80Jupyter notebook\xe5\x8d\xb3\xe5\x8f\xaf\xef\xbc\x8c\xe6\x97\xa0\xe9\x9c\x80\xe9\xa2\x91\xe7\xb9\x81\xe7\xbf\xbb\xe9\x98\x85\xe7\xba\xb8\xe8\xb4\xa8\xe4\xb9\xa6\xe7\xb1\x8d\xe6\x88\x96\xe6\x9f\xa5\xe7\x9c\x8bPDF\xe6\x96\x87\xe6\xa1\xa3\n- \xe5\xbd\xa2\xe5\xbc\x8f\xe5\x92\x8c\xe5\x90\xb4\xe5\xa4\xa7\xe5\xa4\xa7Deep learning.ai\xe8\xaf\xbe\xe7\xa8\x8b\xe4\xbd\x9c\xe4\xb8\x9a\xe7\x9a\x84\xe5\xbd\xa2\xe5\xbc\x8f\xe4\xb8\x80\xe6\xa0\xb7\xef\xbc\x8c**\xe4\xb8\x80\xe6\xae\xb5\xe6\x96\x87\xe5\xad\x97\xe8\xa7\xa3\xe9\x87\x8a\xef\xbc\x8c\xe4\xb8\x80\xe6\xae\xb5\xe4\xbb\xa3\xe7\xa0\x81\xe6\x93\x8d\xe4\xbd\x9c**\xef\xbc\x8c\xe6\x96\xb9\xe4\xbe\xbf\xe5\xbf\xab\xe9\x80\x9f\xe7\x90\x86\xe8\xa7\xa3\xe5\x8e\x9f\xe7\x90\x86\xe5\xb9\xb6\xe8\xbf\x9b\xe8\xa1\x8c\xe5\xae\x9e\xe8\xb7\xb5\xe6\x93\x8d\xe4\xbd\x9c\n- \xe4\xb8\xad\xe6\x96\x87\xe6\xb3\xa8\xe9\x87\x8a\xef\xbc\x8c\xe6\x96\xb9\xe4\xbe\xbf\xe4\xb8\xad\xe6\x96\x87\xe5\xad\xa6\xe4\xb9\xa0\xe8\x80\x85\xe8\xbe\x83\xe5\xbf\xab\xe8\xbe\x83\xe7\xb3\xbb\xe7\xbb\x9f\xe7\x9a\x84\xe5\x85\xa5\xe9\x97\xa8\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\n\n### \xe8\xaf\xb4\xe6\x98\x8e\n\n- \xe5\x85\xa8\xe4\xb9\xa6\xe5\x88\x86\xe4\xb8\xba Part I \xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0(8 \xe7\xab\xa0) \xe5\x92\x8c Part II \xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0(8 \xe7\xab\xa0) \xe4\xb8\xa4\xe5\xa4\xa7\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x8cPart II \xe6\x9c\x80\xe5\x90\x8e\xe4\xb8\x80\xe7\xab\xa0\xe6\x98\xaf\xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0\n- \xe7\xbb\xaa\xe8\xae\xba\xe9\x83\xa8\xe5\x88\x86\xe5\x92\x8c\xe7\xac\xac\xe4\xb8\x80\xe7\xab\xa0\xe5\xa4\xa7\xe5\xae\xb6\xe7\x9b\xb4\xe6\x8e\xa5\xe7\x9c\x8b\xe5\x8e\x9f\xe4\xb9\xa6\xe5\xb0\xb1\xe5\xa5\xbd\xe4\xba\x86\xef\xbc\x8c\xe8\xbf\x99\xe4\xb8\xaa\xe9\xa1\xb9\xe7\x9b\xae\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81\xe7\xa4\xba\xe4\xbe\x8b\xe6\x98\xaf\xe4\xbb\x8e\xe7\xac\xac\xe4\xba\x8c\xe7\xab\xa0\xe5\xbc\x80\xe5\xa7\x8b\xe7\x9a\x84\n- \xe6\xad\xa4\xe9\xa1\xb9\xe7\x9b\xae\xe9\x80\x82\xe7\x94\xa8\xe4\xba\x8e**\xe8\x8b\xb1\xe8\xaf\xad\xe4\xb8\x8d\xe6\x98\xaf\xe9\x82\xa3\xe4\xb9\x88\xe5\xa5\xbd\xef\xbc\x8c\xe8\x80\x8c\xe4\xb8\x94\xe6\x97\xb6\xe9\x97\xb4\xe5\x8f\x88\xe4\xb8\x8d\xe6\x80\x8e\xe4\xb9\x88\xe5\x85\x85\xe8\xa3\x95\xef\xbc\x8c\xe5\x8f\x88\xe6\x83\xb3\xe8\xa6\x81\xe5\xbf\xab\xe9\x80\x9f\xe5\x85\xa5\xe9\x97\xa8\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9a\x84\xe8\xaf\xbb\xe8\x80\x85**\xef\xbc\x8c\xe5\xa4\xa7\xe7\xa5\x9e\xe5\xb0\xb1\xe4\xb8\x8d\xe8\xa6\x81\xe5\x9c\xa8\xe8\xbf\x99\xe9\x87\x8c\xe8\x80\xbd\xe8\xaf\xaf\xe6\x97\xb6\xe9\x97\xb4\xef\xbc\x8c\n\xe5\xbd\x93\xe7\x84\xb6\xe4\xbd\xa0\xe5\xa6\x82\xe6\x9e\x9c\xe6\x83\xb3\xe8\xa6\x81\xe5\xae\x8c\xe5\x96\x84\xe4\xb8\x80\xe4\xb8\x8b\xe8\x87\xaa\xe5\xb7\xb1\xe7\x9a\x84\xe7\x9f\xa5\xe8\xaf\x86\xe4\xbd\x93\xe7\xb3\xbb\xef\xbc\x8c\xe7\xbc\x95\xe6\xb8\x85\xe4\xb8\x80\xe4\xba\x9b\xe6\xa6\x82\xe5\xbf\xb5\xe4\xb9\x8b\xe9\x97\xb4\xe7\x9a\x84\xe5\x85\xb3\xe7\xb3\xbb\xef\xbc\x8c\xe8\xbf\x99\xe6\x9c\xac\xe4\xb9\xa6\xe8\xbf\x98\xe6\x98\xaf\xe5\xbe\x88\xe4\xb8\x8d\xe9\x94\x99\xe7\x9a\x84\xe9\x80\x89\xe6\x8b\xa9\n\n### \xe5\xbb\xba\xe8\xae\xae\n- **\xe5\x85\xb3\xe4\xba\x8e\xe6\x97\xb6\xe9\x97\xb4**\xef\xbc\x8c\xe8\xbf\x99\xe6\x9c\xac\xe4\xb9\xa6\xe6\x98\xaf\xe4\xb8\x80\xe4\xbd\x8d\xe7\xbe\x8e\xe5\x9b\xbd\xe6\x95\xb0\xe6\x8d\xae\xe7\xa7\x91\xe5\xad\xa6\xe5\xae\xb6\xe5\x90\x91\xe6\x88\x91\xe6\x8e\xa8\xe8\x8d\x90\xe7\x9a\x84\xef\xbc\x8c\xe4\xbb\x96\xe4\xbb\x8e\xe5\xa4\xb4\xe5\x88\xb0\xe5\xb0\xbe\xe5\x81\x9a\xe5\xae\x8c\xe4\xba\x86\xe6\x95\xb4\xe6\x9c\xac\xe4\xb9\xa6\xe7\x9a\x84\xe6\x89\x80\xe6\x9c\x89\xe7\xa4\xba\xe4\xbe\x8b\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x8c\xe5\xa4\xa7\xe6\xa6\x82\xe7\x94\xa8\xe4\xba\x8680\xe4\xb8\xaa\xe5\xb0\x8f\xe6\x97\xb6\xe5\xb7\xa6\xe5\x8f\xb3\xef\xbc\x8c\xe4\xbb\xa5\xe6\xad\xa4\xe4\xbd\x9c\xe4\xb8\xba\xe5\x8f\x82\xe8\x80\x83\xef\xbc\x8c\xe5\xa4\xa7\xe5\xae\xb6\xe8\x87\xaa\xe8\xa1\x8c\xe5\xae\x89\xe6\x8e\x92\xe8\x87\xaa\xe5\xb7\xb1\xe7\x9a\x84\xe8\xbf\x9b\xe5\xba\xa6\n- **\xe5\x85\xb3\xe4\xba\x8e\xe4\xb9\xa0\xe9\xa2\x98**\xef\xbc\x8c\xe6\xaf\x8f\xe4\xb8\x80\xe7\xab\xa0\xe5\x90\x8e\xe9\x9d\xa2\xe9\x83\xbd\xe6\x8f\x90\xe4\xbe\x9b\xe4\xba\x86\xe7\x9b\xb8\xe5\xba\x94\xe7\x9a\x84\xe7\xbb\x83\xe4\xb9\xa0\xe9\xa2\x98\xef\xbc\x8c\xe6\x97\xa2\xe6\x9c\x89\xe7\xae\x80\xe8\xbf\xb0\xe7\xb1\xbb\xe7\x9a\x84\xe9\x97\xae\xe7\xad\x94\xe9\xa2\x98\xef\xbc\x8c\xe4\xb9\x9f\xe6\x9c\x89\xe4\xbb\xbb\xe5\x8a\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81\xe6\x93\x8d\xe4\xbd\x9c\xe9\xa2\x98\xef\xbc\x8c\xe9\x99\x84\xe5\xbd\x95\xe9\x87\x8c\xe9\x9d\xa2\xe9\x83\xbd\xe6\x9c\x89\xe5\x8f\x82\xe8\x80\x83\xe7\xad\x94\xe6\xa1\x88\xef\xbc\x8c\xe5\xbb\xba\xe8\xae\xae\xe6\x9c\x89\xe6\x97\xb6\xe9\x97\xb4\xe7\x9a\x84\xe9\x83\xbd\xe5\xad\xa6\xe4\xb9\xa0\xe4\xb8\x80\xe4\xb8\x8b\xef\xbc\x8c\xe5\xaf\xb9\xe4\xba\x8e\xe6\x8e\x8c\xe6\x8f\xa1\xe7\x9f\xa5\xe8\xaf\x86\xef\xbc\x8c\xe5\xba\x94\xe5\xaf\xb9\xe9\x9d\xa2\xe8\xaf\x95\xef\xbc\x8c\xe5\xbe\x88\xe6\x9c\x89\xe5\xb8\xae\xe5\x8a\xa9\xe3\x80\x82\xe7\xae\x80\xe8\xbf\xb0\xe5\x9e\x8b\xe7\x9a\x84\xe8\xaf\xbe\xe5\x90\x8e\xe4\xb9\xa0\xe9\xa2\x98\xe9\x83\xbd\xe4\xbb\xa5\xe7\xab\xa0\xe8\x8a\x82\xe4\xb8\xba\xe5\x8d\x95\xe4\xbd\x8d\xe7\xbf\xbb\xe8\xaf\x91\xe6\x88\x90\xe4\xb8\xad\xe6\x96\x87\xe6\x94\xbe\xe5\x9c\xa8[\xe6\x88\x91\xe7\x9a\x84\xe7\xae\x80\xe4\xb9\xa6](https://www.jianshu.com/u/8f6436eabaac)\xe4\xb8\x8a\xe4\xba\x86\xe6\xac\xa2\xe8\xbf\x8e\xe6\x9f\xa5\xe9\x98\x85[Hands-on machine learning with scikit-learn and tensorflow](https://www.jianshu.com/nb/29757286)\n\n### \xe6\x94\xb6\xe8\x8e\xb7\n\n- \xe5\x9c\xa8\xe7\x9f\xa5\xe8\xaf\x86\xe7\x82\xb9\xe5\xb9\xbf\xe5\xba\xa6\xe4\xb8\x8a\xe6\x89\xab\xe6\xb8\x85\xe4\xb8\x80\xe7\xb3\xbb\xe5\x88\x97\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\x92\x8c\xe6\xb7\xb1\xe5\xba\xa6\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9a\x84\xe6\xa6\x82\xe5\xbf\xb5\xef\xbc\x8c\xe5\xbe\xaa\xe5\xba\x8f\xe6\xb8\x90\xe8\xbf\x9b\xef\xbc\x8c\xe6\x98\x93\xe4\xba\x8e\xe6\x8e\xa5\xe5\x8f\x97\n- \xe7\xac\xac\xe4\xba\x8c\xe7\xab\xa0\xe4\xbd\xbf\xe7\x94\xa8Scikit-Learn \xe5\x85\xa8\xe7\xa8\x8b\xe8\xb7\x9f\xe8\xb8\xaa\xe4\xb8\x80\xe4\xb8\xaa\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe9\xa1\xb9\xe7\x9b\xae\xe7\x9a\x84\xe4\xbe\x8b\xe5\xad\x90\xef\xbc\x8c\xe9\x9d\x9e\xe5\xb8\xb8\xe6\x9c\x89\xe5\xb8\xae\xe5\x8a\xa9\n- \xe6\x8e\xa2\xe7\xb4\xa2\xe5\x90\x84\xe7\xa7\x8d\xe8\xae\xad\xe7\xbb\x83\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x8c\xe5\x8c\x85\xe6\x8b\xac\xef\xbc\x9a\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba\xe3\x80\x81\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe3\x80\x81\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\xe4\xbb\xa5\xe5\x8f\x8a\xe9\x9b\x86\xe6\x88\x90\xe6\x96\xb9\xe6\xb3\x95\n- \xe4\xbd\xbf\xe7\x94\xa8TensorFlow\xe5\xba\x93\xe6\x9e\x84\xe5\xbb\xba\xe5\x92\x8c\xe8\xae\xad\xe7\xbb\x83\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xef\xbc\x8c\xe6\xb7\xb1\xe5\x85\xa5\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe6\x9e\xb6\xe6\x9e\x84\xef\xbc\x8c\xe5\x8c\x85\xe6\x8b\xac\xe5\x8d\xb7\xe7\xa7\xaf\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe3\x80\x81\xe5\xbe\xaa\xe7\x8e\xaf\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe5\x92\x8c\xe6\xb7\xb1\xe5\xba\xa6\xe5\xbc\xba\xe5\x8c\x96\xe5\xad\xa6\xe4\xb9\xa0\n- \xe7\x9f\xa5\xe8\xaf\x86\xe4\xbd\x93\xe7\xb3\xbb\xe9\x9d\x9e\xe5\xb8\xb8\xe7\xb3\xbb\xe7\xbb\x9f\xef\xbc\x8c \xe5\xa6\x82\xe6\x9e\x9c\xe4\xbd\xa0\xe8\x83\xbd\xe5\xa4\x9f\xe4\xbb\x8e\xe7\xbb\xaa\xe8\xae\xba\xe9\x83\xa8\xe5\x88\x86\xe4\xb8\x80\xe7\x9b\xb4\xe7\x9c\x8b\xe5\x88\xb0\xe9\x99\x84\xe5\xbd\x95\xe9\x83\xa8\xe5\x88\x86\xe5\xb9\xb6\xe5\x81\x9a\xe5\xae\x8c\xe8\xbf\x99\xe4\xb8\x8a\xe9\x9d\xa2\xe7\x9a\x84\xe7\xa4\xba\xe4\xbe\x8b\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x8c\xe4\xbd\xa0\xe7\x9a\x84\xe7\x90\x86\xe8\xae\xba\xe5\x9f\xba\xe7\xa1\x80\xe4\xb8\x80\xe5\xae\x9a\xe4\xbc\x9a\xe6\x89\x8e\xe5\xae\x9e\xe7\x9a\x84\xe4\xb8\x8d\xe8\xa6\x81\xe4\xb8\x8d\xe8\xa6\x81\xe7\x9a\x84\n\n\n\n### \xe6\x84\x9f\xe8\xb0\xa2\n- \xe6\x84\x9f\xe8\xb0\xa2[Aurelien Geron](https://github.com/ageron)\xef\xbc\x8c\xe8\xbf\x99\xe6\x98\xaf\xe4\xb8\x80\xe6\x9c\xac\xe9\x9d\x9e\xe5\xb8\xb8\xe4\xbc\x98\xe7\xa7\x80\xe7\x9a\x84\xe6\x95\x99\xe6\x9d\x90\n[Hands-on Machine Learning with Scikit-Learn and TensorFlow](http://shop.oreilly.com/product/0636920052289.do)\n- \xe6\x84\x9f\xe8\xb0\xa2 Will Koehrsen\xef\xbc\x8c\xe6\x98\xaf\xe4\xbb\x96\xe5\x90\x91\xe6\x88\x91\xe6\x8e\xa8\xe8\x8d\x90\xe4\xba\x86\xe8\xbf\x99\xe6\x9c\xac\xe4\xb9\xa6\n\n### \xe8\x81\x94\xe7\xb3\xbb\xe6\x88\x91\n\xe5\xa6\x82\xe6\x9e\x9c\xe4\xbd\xa0\xe6\x9c\x89\xe4\xbb\xbb\xe4\xbd\x95\xe9\x97\xae\xe9\xa2\x98\xe5\x8f\xaf\xe4\xbb\xa5\xe9\x82\xae\xe4\xbb\xb6\xe8\x81\x94\xe7\xb3\xbb\xe6\x88\x91\n\n\n\nbaideqian@foxmail.com\n\n\n\n'
75,jphall663/awesome-machine-learning-interpretability,jphall663,A curated list of awesome machine learning interpretability resources.,2018-06-21 14:26:51,2020-06-17 19:56:37,,318,1701,"b'# awesome-machine-learning-*interpretability* [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)\n\nA curated, but probably biased and incomplete, list of awesome machine learning interpretability resources.\n\nIf you want to contribute to this list (*and please do!*) read over the [contribution guidelines](contributing.md), send a pull request, or contact me [@jpatrickhall](https://twitter.com/jpatrickhall).\n\n**An incomplete, imperfect blueprint for a more human-centered, lower-risk machine learning.** The resources in this repository can be used to do many of these things today. *The resources in this repository should not be considered legal compliance advice.*\n![alt-text](https://github.com/h2oai/mli-resources/blob/master/blueprint.png)\n</br>Image credit: H2O.ai Machine Learning Interpretability team, https://github.com/h2oai/mli-resources.\n\n\n## Table of Contents\n\n* [Comprehensive Software Examples and Tutorials](https://github.com/jphall663/awesome-machine-learning-interpretability#comprehensive-software-examples-and-tutorials)\n* Explainability- or Fairness-Enhancing Software Packages\n  * [Browser](https://github.com/jphall663/awesome-machine-learning-interpretability#browser)\n  * [Python](https://github.com/jphall663/awesome-machine-learning-interpretability#python)\n  * [R](https://github.com/jphall663/awesome-machine-learning-interpretability#r)\n* [Free Books](https://github.com/jphall663/awesome-machine-learning-interpretability#free-books)\n* [Other Interpretability and Fairness Resources and Lists](https://github.com/jphall663/awesome-machine-learning-interpretability#other-interpretability-and-fairness-resources-and-lists)\n* [Review and General Papers](https://github.com/jphall663/awesome-machine-learning-interpretability#review-and-general-papers)\n* [Teaching Resources](https://github.com/jphall663/awesome-machine-learning-interpretability#teaching-resources)\n* Interpretable (""Whitebox"") or Fair Modeling Packages\n  * [C/C++](https://github.com/jphall663/awesome-machine-learning-interpretability#cc)\n  * [Python](https://github.com/jphall663/awesome-machine-learning-interpretability#python-1)\n  * [R](https://github.com/jphall663/awesome-machine-learning-interpretability#r-1)\n\n## Comprehensive Software Examples and Tutorials\n\n* [Getting a Window into your Black Box Model](http://projects.rajivshah.com/inter/ReasonCode_NFL.html)\n* [IML](https://mybinder.org/v2/gh/christophM/iml/master?filepath=./notebooks/tutorial-intro.ipynb)\n* [Interpretable Machine Learning with Python](https://github.com/jphall663/interpretable_machine_learning_with_python)\n* [Interpreting Machine Learning Models with the iml Package](http://uc-r.github.io/iml-pkg)\n* [Interpretable Machine Learning using Counterfactuals](https://docs.seldon.io/projects/alibi/en/v0.2.0/examples/cf_mnist.html)\n* [Machine Learning Explainability by Kaggle Learn](https://www.kaggle.com/learn/machine-learning-explainability)\n* [Model Interpretability with DALEX](http://uc-r.github.io/dalex)\n* Model Interpretation series by Dipanjan (DJ) Sarkar:\n  * [The Importance of Human Interpretable Machine Learning](https://towardsdatascience.com/human-interpretable-machine-learning-part-1-the-need-and-importance-of-model-interpretation-2ed758f5f476)\n  * [Model Interpretation Strategies](https://towardsdatascience.com/explainable-artificial-intelligence-part-2-model-interpretation-strategies-75d4afa6b739)\n  * [Hands-on Machine Learning Model Interpretation](https://towardsdatascience.com/explainable-artificial-intelligence-part-3-hands-on-machine-learning-model-interpretation-e8ebe5afc608)\n  * [Interpreting Deep Learning Models for Computer Vision](https://towardsdatascience.com/explainable-artificial-intelligence-part-3-hands-on-machine-learning-model-interpretation-e8ebe5afc608)\n* [Partial Dependence Plots in R](https://journal.r-project.org/archive/2017/RJ-2017-016/)\n* [Saliency Maps for Deep Learning](https://medium.com/@thelastalias/saliency-maps-for-deep-learning-part-1-vanilla-gradient-1d0665de3284)\n* [Visualizing ML Models with LIME](http://uc-r.github.io/lime)\n* [Visualizing and debugging deep convolutional networks](https://rohitghosh.github.io/2018/01/05/visualising-debugging-deep-neural-networks/)\n* [What does a CNN see?](https://colab.research.google.com/drive/1xM6UZ9OdpGDnHBljZ0RglHV_kBrZ4e-9)\n\n## Explainability- or Fairness-Enhancing Software Packages\n\n### Browser\n\n* [manifold](https://github.com/uber/manifold)\n* [TensorBoard Projector](http://projector.tensorflow.org)\n* [What-if Tool](https://pair-code.github.io/what-if-tool/index.html#about)\n\n### Python\n\n* [acd](https://github.com/csinva/hierarchical_dnn_interpretations)\n* [aequitas](https://github.com/dssg/aequitas)\n* [AI Fairness 360](http://aif360.mybluemix.net)\n* [AI Explainability 360](https://github.com/IBM/AIX360)\n* [ALEPython](https://github.com/blent-ai/ALEPython)\n* [allennlp](https://github.com/allenai/allennlp)\n* [algofairness](https://github.com/algofairness)\n* [Alibi](https://github.com/SeldonIO/alibi)\n* [anchor](https://github.com/marcotcr/anchor)\n* [BlackBoxAuditing](https://github.com/algofairness/BlackBoxAuditing)\n* [casme](https://github.com/kondiz/casme)\n* [captum](https://github.com/pytorch/captum)\n* [causalml](https://github.com/uber/causalml)\n* [ContrastiveExplanation (Foil Trees)](https://github.com/MarcelRobeer/ContrastiveExplanation)\n* [DeepExplain](https://github.com/marcoancona/DeepExplain)\n* [deeplift](https://github.com/kundajelab/deeplift)\n* [deepvis](https://github.com/yosinski/deep-visualization-toolbox)\n* [DiCE](https://github.com/microsoft/DiCE)\n* [DoWhy](https://github.com/microsoft/dowhy)\n* [eli5](https://github.com/TeamHG-Memex/eli5)\n* [fairml](https://github.com/adebayoj/fairml)\n* [fairness-comparison](https://github.com/algofairness/fairness-comparison)\n* [fairness_measures_code](https://github.com/megantosh/fairness_measures_code)\n* [foolbox](https://github.com/bethgelab/foolbox)\n* [Grad-CAM](https://github.com/topics/grad-cam) (GitHub topic)\n* [iNNvestigate neural nets](https://github.com/albermax/innvestigate)\n* [Integrated-Gradients](https://github.com/ankurtaly/Integrated-Gradients)\n* [interpret_with_rules](https://github.com/clips/interpret_with_rules)\n* [Keras-vis](https://github.com/raghakot/keras-vis)\n* [keract](https://github.com/philipperemy/keract/)\n* [lofo-importance](https://github.com/aerdem4/lofo-importance)\n* [L2X](https://github.com/Jianbo-Lab/L2X)\n* [lime](https://github.com/marcotcr/lime)\n* [lrp_toolbox](https://github.com/sebastian-lapuschkin/lrp_toolbox)\n* [microsoft/interpret](https://github.com/Microsoft/interpret)\n* [MLextend](http://rasbt.github.io/mlxtend/)\n* [ml-fairness-gym](https://github.com/google/ml-fairness-gym)\n* [OptBinning](https://github.com/guillermo-navas-palencia/optbinning)\n* [PDPbox](https://github.com/SauceCat/PDPbox)\n* [pyBreakDown](https://github.com/MI2DataLab/pyBreakDown)\n* [PyCEbox](https://github.com/AustinRochford/PyCEbox)\n* [pymc3](https://github.com/pymc-devs/pymc3)\n* [rationale](https://github.com/taolei87/rcnn/tree/master/code/rationale)\n* [robustness](https://github.com/MadryLab/robustness)\n* [RISE](https://github.com/eclique/RISE) \n* [SALib](https://github.com/SALib/SALib)\n* [shap](https://github.com/slundberg/shap)\n* [Skater](https://github.com/datascienceinc/Skater)\n* [tensorfow/cleverhans](https://github.com/tensorflow/cleverhans)\n* [tensorflow/lucid](https://github.com/tensorflow/lucid)\n* [tensorflow/model-analysis](https://github.com/tensorflow/model-analysis)\n* [tensorflow/privacy](https://github.com/tensorflow/privacy)\n* [tensorflow/tcav](https://github.com/tensorflow/tcav)\n* [tensorfuzz](https://github.com/brain-research/tensorfuzz)\n* [TensorWatch](https://github.com/microsoft/tensorwatch)\n* [TextFooler](https://github.com/jind11/TextFooler)\n* [tf-explain](https://github.com/sicara/tf-explain)\n* [Themis](https://github.com/LASER-UMASS/Themis)\n* [themis-ml](https://github.com/cosmicBboy/themis-ml)\n* [treeinterpreter](https://github.com/andosa/treeinterpreter)\n* [woe](https://github.com/boredbird/woe)\n* [xai](https://github.com/EthicalML/xai)\n* [yellowbrick](https://github.com/DistrictDataLabs/yellowbrick)\n\n### R\n\n* [ALEPlot](https://cran.r-project.org/web/packages/ALEPlot/index.html)\n* [breakDown](https://pbiecek.github.io/breakDown/index.html)\n* [DrWhyAI](https://github.com/ModelOriented/DrWhy)\n* [DALEX](https://github.com/pbiecek/DALEX)\n* [DALEXtra](https://cran.r-project.org/web/packages/DALEXtra/index.html)\n* [EloML](https://github.com/ModelOriented/EloML)\n* [ExplainPrediction](https://github.com/rmarko/ExplainPrediction)\n* [fastshap](https://github.com/bgreenwell/fastshap)\n* [featureImportance](https://github.com/giuseppec/featureImportance)\n* [forestmodel](https://cran.r-project.org/web/packages/forestmodel/index.html)\n* [fscaret](https://cran.r-project.org/web/packages/fscaret/)\n* [ICEbox](https://cran.r-project.org/web/packages/ICEbox/index.html)\n* [iml](https://github.com/christophM/iml)\n* [lightgbmExplainer](https://github.com/lantanacamara/lightgbmExplainer)\n* [lime](https://github.com/thomasp85/lime)\n* [live](https://cran.r-project.org/web/packages/live/index.html)\n* [mcr](https://github.com/aaronjfisher/mcr)\n* [modelDown](https://cran.r-project.org/web/packages/modelDown/index.html)\n* [modelOriented](https://github.com/ModelOriented)\n* [modelStudio](https://github.com/ModelOriented/modelStudio)\n* [pdp](https://bgreenwell.github.io/pdp/index.html)\n* [shapFlex](https://github.com/nredell/shapFlex)\n* [shapleyR](https://github.com/redichh/ShapleyR)\n* [shapper](https://cran.r-project.org/web/packages/shapper/index.html)\n* [smbinning](https://cran.r-project.org/web/packages/smbinning/index.html)\n* [vip](https://github.com/koalaverse/vip)\n* [xgboostExplainer](https://github.com/AppliedDataSciencePartners/xgboostExplainer)\n\n## Free Books\n\n* [An Introduction to Machine Learning Interpretability](https://www.h2o.ai/oreilly-mli-booklet-2019/)\n* [Fairness and Machine Learning](http://fairmlbook.org/)\n* [Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/)\n\n\n## Other Interpretability and Fairness Resources and Lists\n\n* [8 Principles of Responsible ML](https://ethical.institute/principles.html)\n* [ACM FAT* 2019 Youtube Playlist](https://www.youtube.com/playlist?list=PLXA0IWa3BpHk7fE8IH6wXNEfAZyr3A5Yb)\n* [AI Ethics Guidelines Global Inventory](https://algorithmwatch.org/en/project/ai-ethics-guidelines-global-inventory/)\n* [AI Incident Database](http://aiid.partnershiponai.org/)\n* [AllenNLP Interpret: A Framework for Explaining Predictions of NLP Models](http://sameersingh.org/files/papers/allennlp-interpret-demo-emnlp19.pdf)\n* [Awesome interpretable machine learning](https://github.com/lopusz/awesome-interpretable-machine-learning) ;)\n* [Awesome machine learning operations](https://github.com/EthicalML/awesome-machine-learning-operations)\n* [Awful AI](https://github.com/daviddao/awful-ai)\n* [algoaware](https://www.algoaware.eu/)\n* [BIML Interactive Machine Learning Risk Framework](https://berryvilleiml.com/interactive/)\n* [Beyond Explainability: A Practical Guide to Managing Risk in Machine Learning Models](https://go.immuta.com/beyond-explainability-white-paper)\n* [Consultation on the OPC\xe2\x80\x99s Proposals for ensuring appropriate regulation of artificial intelligence](https://www.priv.gc.ca/en/about-the-opc/what-we-do/consultations/consultation-ai/pos_ai_202001/)\n* [criticalML](https://github.com/rockita/criticalML)\n* [Debugging Machine Learning Models (ICLR workshop proceedings)](https://debug-ml-iclr2019.github.io/)\n* [Deep Insights into Explainability and Interpretability of Machine Learning Algorithms and Applications to Risk Management](https://ww2.amstat.org/meetings/jsm/2019/onlineprogram/AbstractDetails.cfm?abstractid=303053)\n* [Distill](https://distill.pub) \n* [Fairness, Accountability, and Transparency in Machine Learning (FAT/ML) Scholarship](https://www.fatml.org/resources/relevant-scholarship)\n* [General principles for the use of Artificial Intelligence in the financial sector](https://www.dnb.nl/binaries/General%20principles%20for%20the%20use%20of%20Artificial%20Intelligence%20in%20the%20financial%20sector_tcm46-385055.pdf)\n* [Opinion of the German Data Ethics Commission](https://www.bmjv.de/SharedDocs/Downloads/DE/Themen/Fokusthemen/Gutachten_DEK_EN.pdf?__blob=publicationFile&v=2)\n* [Machine Learning Ethics References](https://github.com/radames/Machine-Learning-Ethics-References)\n* [Machine Learning Interpretability Resources](https://github.com/h2oai/mli-resources)\n* [MIT AI Ethics Reading Group](https://mitaiethics.github.io/)\n* [private-ai-resources](https://github.com/OpenMined/private-ai-resources)\n* [Problems with Shapley-value-based explanations as feature importance measures](https://arxiv.org/pdf/2002.11097v1.pdf)\n* [Real-World Model Debugging Strategies](https://medium.com/@jphall_22520/strategies-for-model-debugging-aa822f1097ce)\n* [Sample AI Incident Response Checklist](https://bnh-ai.github.io/resources/)\n* [Singapore Personal Data Protection Commission (PDPC) Model Artificial Intelligence Governance Framework](https://www.pdpc.gov.sg/Resources/Model-AI-Gov)\n* [Ten Questions on AI Risk](https://fpf.org/wp-content/uploads/2020/06/Ten-Questions-on-AI-Risk-FPF.pdf)\n* [Testing and Debugging in Machine Learning](https://developers.google.com/machine-learning/testing-debugging)\n* [Troubleshooting Deep Neural Networks](http://josh-tobin.com/assets/pdf/troubleshooting-deep-neural-networks-01-19.pdf)\n* [Trump Administration Draft Guidance for Regulation of Artificial Intelligence Applications](https://www.whitehouse.gov/wp-content/uploads/2020/01/Draft-OMB-Memo-on-Regulation-of-AI-1-7-19.pdf) \n* [U.K. Information Commissioner\'s Office (ICO) AI Audting Framework (overview series)](https://ico.org.uk/about-the-ico/news-and-events/ai-blog-an-overview-of-the-auditing-framework-for-artificial-intelligence-and-its-core-components/)\n* [U.S FDA Proposed Regulatory Framework for Modifications to Artificial Intelligence/Machine Learning (AI/ML)-Based Software as a Medical Device (SaMD)](https://www.fda.gov/media/122535/download?mod=article_inline)\n* [AI Principles: Recommendations on the Ethical Use of Artificial Intelligence by the Department of Defense](https://media.defense.gov/2019/Oct/31/2002204458/-1/-1/0/DIB_AI_PRINCIPLES_PRIMARY_DOCUMENT.PDF)\n* [Warning Signs: The Future of Privacy and Security in an Age of Machine Learning](https://fpf.org/wp-content/uploads/2019/09/FPF_WarningSigns_Report.pdf)\n* [XAI Resources](https://github.com/pbiecek/xai_resources)\n* [You Created A Machine Learning Application Now Make Sure It\'s Secure](https://www.oreilly.com/ideas/you-created-a-machine-learning-application-now-make-sure-its-secure)\n\n## Review and General Papers\n\n* [50 Years of Test (Un)fairness: Lessons for Machine Learning](https://arxiv.org/pdf/1811.10104.pdf)\n* [A Comparative Study of Fairness-Enhancing Interventions in Machine Learning](https://arxiv.org/pdf/1802.04422.pdf)\n* [A Survey Of Methods For Explaining Black Box Models](https://arxiv.org/pdf/1802.01933.pdf)\n* [A Marauder\xe2\x80\x99s Map of Security and Privacy in Machine Learning](https://arxiv.org/pdf/1811.01134.pdf)\n* [Challenges for Transparency](https://arxiv.org/pdf/1708.01870.pdf)\n* [Closing the AI Accountability Gap](https://arxiv.org/pdf/2001.00973.pdf)\n* [Explaining Explanations: An Overview of Interpretability of Machine Learning](https://arxiv.org/pdf/1806.00069.pdf)\n* [Explanation in Human-AI Systems: A Literature Meta-Review, Synopsis of Key Ideas and Publications, and Bibliography for Explainable AI](https://arxiv.org/abs/1902.01876v1)\n* [Interpretable Machine Learning: Definitions, Methods, and Applications](https://arxiv.org/abs/1901.04592)\n* [Limitations of Interpretable Machine Learning](https://compstat-lmu.github.io/iml_methods_limitations/)\n* [Machine Learning Explainability in Finance](https://www.bankofengland.co.uk/-/media/boe/files/working-paper/2019/machine-learning-explainability-in-finance-an-application-to-default-risk-analysis)\n* [On the Art and Science of Machine Learning Explanations](https://arxiv.org/pdf/1810.02909.pdf)\n* [On the Responsibility of Technologists: A Prologue and Primer](https://algo-stats.info/2018/04/15/on-the-responsibility-of-technologists-a-prologue-and-primer/)\n* [Please Stop Explaining Black Box Models for High-Stakes Decisions](https://arxiv.org/pdf/1811.10154.pdf)\n* [The Mythos of Model Interpretability](https://arxiv.org/pdf/1606.03490.pdf)\n* [Towards A Rigorous Science of Interpretable Machine Learning](https://arxiv.org/pdf/1702.08608.pdf)\n* [Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable Claims](https://arxiv.org/pdf/2004.07213.pdf)\n* [The Security of Machine Learning](https://people.eecs.berkeley.edu/~adj/publications/paper-files/SecML-MLJ2010.pdf)\n* [Techniques for Interpretable Machine Learning](https://arxiv.org/pdf/1808.00033.pdf)\n* [Trends and Trajectories for Explainable, Accountable and Intelligible Systems: An HCI Research Agenda](https://dl.acm.org/citation.cfm?id=3174156)\n\n## Teaching Resources\n\n* [An Introduction to Data Ethics](https://www.scu.edu/ethics/focus-areas/technology-ethics/resources/an-introduction-to-data-ethics/)\n* [Fairness in Machine Learning](https://fairmlclass.github.io/)\n* [Human-Center Machine Learning](http://courses.mpi-sws.org/hcml-ws18/)\n* [Practical Model Interpretability](https://github.com/jphall663/GWU_data_mining/blob/master/10_model_interpretability/10_model_interpretability.md)\n* [Trustworthy Deep Learning](https://berkeley-deep-learning.github.io/cs294-131-s19/)\n\n## Interpretable (""Whitebox"") or Fair Modeling Packages\n\n### C/C++\n\n* [Certifiably Optimal RulE ListS](https://github.com/nlarusstone/corels)\n\n### Python\n\n* [Bayesian Case Model](https://users.cs.duke.edu/~cynthia/code/BCM.zip)\n* [Bayesian Ors-Of-Ands](https://github.com/wangtongada/BOA)\n* [Bayesian Rule List (BRL)](https://users.cs.duke.edu/~cynthia/code/BRL_supplement_code.zip)\n* [Explainable Boosting Machine (EBM)/GA2M](https://github.com/Microsoft/interpret)\n* [fair-classification](https://github.com/mbilalzafar/fair-classification)\n* [Falling Rule List (FRL)](https://users.cs.duke.edu/~cynthia/code/falling_rule_list.zip)\n* H2O-3\n  * [Penalized Generalized Linear Models](http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/modeling.html#h2ogeneralizedlinearestimator)\n  * [Monotonic GBM](http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/modeling.html#h2ogradientboostingestimator)\n  * [Sparse Principal Components (GLRM)](http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/modeling.html#h2ogeneralizedlowrankestimator)\n* [Optimal Sparse Decision Trees](https://github.com/xiyanghu/OSDT)\n* [Monotonic](http://xgboost.readthedocs.io/en/latest/tutorials/monotonic.html) [XGBoost](http://xgboost.readthedocs.io/en/latest/)\n* [Multilayer Logical Perceptron (MLLP)](https://github.com/12wang3/mllp)\n* [pyGAM](https://github.com/dswah/pyGAM)\n* [pySS3](https://github.com/sergioburdisso/pyss3)\n* [Risk-SLIM](https://github.com/ustunb/risk-SLIM)\n* Scikit-learn\n  * [Decision Trees](http://scikit-learn.org/stable/modules/tree.html)\n  * [Generalized Linear Models](http://scikit-learn.org/stable/modules/linear_model.html)\n  * [Sparse Principal Components](http://scikit-learn.org/stable/modules/decomposition.html#sparse-principal-components-analysis-sparsepca-and-minibatchsparsepca)\n* [sklearn-expertsys](https://github.com/tmadl/sklearn-expertsys)\n* [skope-rules](https://github.com/scikit-learn-contrib/skope-rules)\n* [Super-sparse Linear Integer models (SLIMs)](https://github.com/ustunb/slim-python)\n* [tensorflow/lattice](https://github.com/tensorflow/lattice)\n* [This Looks Like That](https://github.com/cfchen-duke/ProtoPNet)\n\n### R\n\n* [arules](https://cran.r-project.org/web/packages/arules/index.html)\n* [Causal SVM](https://github.com/shangtai/githubcausalsvm)\n* [elasticnet](https://cran.r-project.org/web/packages/elasticnet/index.html)\n* [gam](https://cran.r-project.org/web/packages/gam/index.html)\n* [glm2](https://cran.r-project.org/web/packages/glm2/)\n* [glmnet](https://cran.r-project.org/web/packages/glmnet/index.html)\n* H2O-3\n  * [Penalized Generalized Linear Models](http://docs.h2o.ai/h2o/latest-stable/h2o-r/docs/reference/h2o.glm.html)\n  * [Monotonic GBM](http://docs.h2o.ai/h2o/latest-stable/h2o-r/docs/reference/h2o.gbm.html)\n  * [Sparse Principal Components (GLRM)](http://docs.h2o.ai/h2o/latest-stable/h2o-r/docs/reference/h2o.glrm.html)\n* [Monotonic](http://xgboost.readthedocs.io/en/latest/tutorials/monotonic.html) [XGBoost](http://xgboost.readthedocs.io/en/latest/)\n* [quantreg](https://cran.r-project.org/web/packages/quantreg/index.html)\n* [rpart](https://cran.r-project.org/web/packages/rpart/index.html)\n* [RuleFit](http://statweb.stanford.edu/~jhf/R_RuleFit.html)\n* [Scalable Bayesian Rule Lists (SBRL)](https://users.cs.duke.edu/~cynthia/code/sbrl_1.0.tar.gz)\n'"
76,Spandan-Madan/DeepLearningProject,Spandan-Madan,An in-depth machine learning tutorial introducing readers to a whole machine learning pipeline from scratch.,2017-07-12 16:03:24,2020-06-08 07:31:51,HTML,611,4043,"b'![harvard-logo](http://logonoid.com/images/harvard-logo.png)\n# An end to end tutorial of a machine learning pipeline\n\nThis tutorial tries to do what most Most Machine Learning tutorials available online do not. It is not a 30 minute tutorial which teaches you how to ""Train your own neural network"" or ""Learn deep learning in under 30 minutes"". It\'s a full pipeline which you would need to do if you actually work with machine learning - introducing you to all the parts, and all the implementation decisions and details that need to be made. The dataset is not one of the standard sets like MNIST or CIFAR, you will make you very own dataset. Then you will go through a couple conventional machine learning algorithms, before finally getting to deep learning!\n\nIn the fall of 2016, I was a Teaching Fellow (Harvard\'s version of TA) for the graduate class on ""Advanced Topics in Data Science (CS209/109)"" at Harvard University. I was in-charge of designing the class project given to the students, and this tutorial has been built on top of the project I designed for the class.\n\n# UPDATE 24th October 2018\nThe tutorial has now been re-written in PyTorch thanks to Anshul Basia (https://github.com/AnshulBasia)\n\nYou can access the HTML here: https://spandan-madan.github.io/DeepLearningProject/PyTorch_version/Deep_Learning_Project-Pytorch.html\nand the IPython Notebook with the code in PyTorch here:https://github.com/Spandan-Madan/DeepLearningProject/blob/master/PyTorch_version/Deep_Learning_Project-Pytorch.ipynb\n\n\n\n# Citing if you use the work here\nIf you would like to use this work, please cite the work using the doi -\n[![DOI](https://zenodo.org/badge/doi/10.5281/zenodo.830003.svg)](http://dx.doi.org/10.5281/zenodo.830003)\n\n# Reading/Viewing the Tutorial\nTo view the project as an HTML file, visit - https://spandan-madan.github.io/DeepLearningProject/\n\n# The Code\nIf you would like to access to Code, please go through the ipython notebook `Deep_Learning_Project.ipynb`\n\n# SETUP\n\nPython\n- We will be using Python 2.7. Primary reason is that Tensorflow is not compatible with python > 3.5, and some other libraries are not compatible with python 3.\n\nTo make setup easy, we are going to use conda.\n- Please install conda 3 from https://www.continuum.io/downloads\n- The repository has a conda config file which will make setting up super easy. It\'s the file `deeplearningproject_environment.yml`\n- Then create a new conda environment using the command with `conda env create -f deeplearningproject_environment.yml`\n- Now, you can activate the environment with: `source activate deeplearningproject`  \n- `jupyter notebook` \nIf all the isntallations go through, you are good to go! If not, here is a list of packages that need to be installed: `requests imDbPy wget tmdbsimple seaborn sklearn Pillow keras tensorflow h5py gensim nltk stop_words`\n\nPlease install imdbpy using \'pip install imdbpy==6.6\' since earlier versions are broken\n### Setting up conda environment in jupyter notebook\nTo be able to run the environment you just created on a juputer notebook, first check that you have the python package `ipykernel` installed. If you don\'t simply install it using\n\n```bash\npip install ipykernel\n```\n\nNow, add this to your jupyter notebook using the command:\n\n```bash\npython -m ipykernel install --user --name deeplearningproject --display-name ""deeplearningproject""\n```\n\nNeedless to say, remove all single quotes before running commands.\n\nGo to the directory and run jupyter notbeook by ""jupyter notebook"" and open the respective notebook on browser.\nTO install TMDB: pip install tmdbsimple\nUse ""import tmdbsimple as tmdb""\n\n\n### Setting up a docker container with docker-compose\n\n#### Prerequisites\n* Docker https://docs.docker.com/install/\n* docker compose https://docs.docker.com/compose/install/\n\n#### Run docker-compose\nTo work with an isolate environment and be able to run it on many systems without troubles, you can run this docker-compose command:\n```bash\ndocker-compose up\n```\nIt will build `deeplearningproject` image according to Dockerfile. And then run dokcer container via docker-compose. See Docker and docker-compose docs for more informations :\n* https://docs.docker.com/\n* https://docs.docker.com/compose/\n\nThen access notebooks through your web browser at http://localhost:8888\n\nYou should notice that notebooks have been copied from root to notebooks folder to mount them into container via bind volume. Any changes you make, will be saved  on host (notebooks dir).\n\n#### Add packages\nYou can add conda or pip packages to image (and thus, container) by updating `deeplearningproject_environment.yml` file and then run\n```bash\ndocker-compose build\n```\nIt will build a new `deeplearningproject` image with new conda/pip packages installed. Stop your running container (`CTRL-C`) and then `docker-compose up` to rerun a fresh new container.\n\n\n# Known common bugs\nI will keep updating this as issues pop up on this repository.\n\n- One known bug is because Keras 2.0 is not compatible with some Keras 1.2 functionalities. You may run into errors with importing `VGG16`. If so, just update keras using the following command:\n```bash\nsudo pip install git+git://github.com/fchollet/keras.git --upgrade\n```\n\n-OS Error: Too Many Open Files\nRefer to: https://stackoverflow.com/questions/16526783/python-subprocess-too-many-open-files\nor, shut down notebook and execute following the the same terminal\n``bash\nulimit -Sn 10000\n```\n\nAnd restart the jupyter notebook.\n\nHope this repo helps introduce you to a full machine learning pipeline! If you spot an error, please create an issue to help out others using this resource!\n\nTo prevent problems with installation and setting up, this repository comes with a conda environment profile. The only thing you will need is to install the newest version of conda, and use this profile to create a new environment and it will come set up with all the libraries you will need for the tutorial.\n\n'"
77,atinesh-s/Coursera-Machine-Learning-Stanford,atinesh-s,Machine learning-Stanford University,2016-07-02 06:08:23,2020-06-17 12:00:33,Matlab,490,545,"b'# Machine Learning (Coursera)\nThis is my solution to all the programming assignments and quizzes of Machine-Learning (Coursera) taught by Andrew Ng. After completing this course you will get a broad idea of Machine learning algorithms. Try to solve all the assignments by yourself first, but if you get stuck somewhere then feel free to browse the code.\n\n## Contents\n* Lectures Slides\n* Solution to programming assignment\n* Solution to Quizzes\n\n## Certificate\n* [Verified Certificate](https://www.coursera.org/account/accomplishments/certificate/GDDBFB572MUQ)\n\n## References\n[[1] Machine Learning - Stanford University](https://www.coursera.org/learn/machine-learning)\n'"
78,stedy/Machine-Learning-with-R-datasets,stedy,Formatted datasets for Machine Learning With R by Brett Lantz,2014-08-19 22:22:19,2020-06-15 00:51:21,,1017,294,"b'# Data for Machine Learning with R\n[Machine Learning with R](https://www.packtpub.com/big-data-and-business-intelligence/machine-learning-r) by Brett Lantz is a book that provides an introduction to machine learning using R. As far as I can tell, Packt Publishing does not make its datasets\navailable online unless you buy the book and create a [user account](https://www.packtpub.com/books/content/support) which can be a problem if you are checking the book out from the library or borrowing the book from a friend. All of these datasets\nare in the public domain but simply needed some cleaning up and recoding to match the format in the book.\n\n# How to download the data\n1. In your Mac or Linux envirounment, open a terminal and change to the directory where you want your data to be downloaded.\n2. Go to the github page you want to download it\'s data (for example the challenger data in chapter 6: https://github.com/stedy/Machine-Learning-with-R-datasets/blob/master/challenger.csv)\n3. On the right side, you will find a button called ""raw"". Click on it.\n4. Copy the url you will get for the new page (in our example I got https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/challenger.csv)\n5. put the following command in the terminal screen\nwget name_of_url\n\nso in our example it should be like this\n`wget https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/challenger.csv`\n\n\nChapter 1\n---------\n\nNo datasets used\n\nChapter 2\n---------\n\nusedcars.csv could not be found online\n\nChapter 3\n---------\n\nwisc_bc_data.csv from https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/\n\nChapter 4\n---------\n\nsms_spam.csv from http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/\n\nChapter 5\n---------\n\ncredit.csv from https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/\n\nmushrooms.csv from https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/\n\nChapter 6\n---------\nchallenger.csv from https://archive.ics.uci.edu/ml/machine-learning-databases/space-shuttle/\n\ninsurance.csv could not be found online\n\nwhitewines.csv from https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/\n\nChapter 7\n---------\n\nconcrete.csv from https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/compressive/\n\nletterdata.csv from https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/\n\nChapter 8\n---------\n\ngroceries.csv is from [arules](http://cran.r-project.org/web/packages/arules/index.html) package but probably just easier to call `library(arules); data(Groceries)`\n\nChapter 9\n---------\n\nsnsdata.csv could not be found online\n\nChapter 10\n----------\n\nsms_results.csv is likely from the `sms_test_pred` object in Chapter 4 but difficult to be sure.\n\ncredit.csv is likely the same file from Chapter 5.\n\nChapter 11\n----------\n\ncredit.csv from Chapter 5 is reused.\n\nChapter 12\n----------\n\nNo datasets used\n\n\n'"
79,kailashahirwar/cheatsheets-ai,kailashahirwar,Essential Cheat Sheets for deep learning and machine learning researchers https://medium.com/@kailashahirwar/essential-cheat-sheets-for-machine-learning-and-deep-learning-researchers-efb6a8ebd2e5,2017-05-24 12:06:56,2020-06-18 20:24:35,,3232,13344,"b'# AI Cheatsheets\n\nEssential Cheat Sheets for deep learning and machine learning engineers\n\nWebsite: https://aicheatsheets.com\n\n<p align=""center"">\n  <img width=""50%"" height=""auto"" src=""Triplebyte_logo.png"">\n</p>\n<p align=""center"">\nLooking for a new job? Take Triplebyte\xe2\x80\x99s <a href=""https://triplebyte.com/a/ZYAvvEc/d"">quiz</a> and get a job at top companies like Adobe, Dropbox and Instacart!\n</p>\n\n![website-1](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/screenshots/website.png)\n\n![website-2](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/screenshots/website-2.png)\n\n![tensorflow-1](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/screenshots/tensorflow1.png)\n\nMedium Article: https://medium.com/@kailashahirwar/essential-cheat-sheets-for-machine-learning-and-deep-learning-researchers-efb6a8ebd2e5\n\n![medium-article](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/screenshots/medium-article.png)\n\nReddit Thread: https://www.reddit.com/r/Python/comments/cyslju/ai_cheatsheets_now_learn_tensorflow_keras_pytorch/?utm_source=share&utm_medium=web2x\n\n![reddit-post](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/screenshots/reddit-post.png)\n  \n    \n  - [**Tensorflow**](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/PDFs/Tensorflow.pdf)<br>\n  - [**Keras**](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/Keras.jpg)<br>\n  - [**Neural Networks Zoo**](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/Neural%20Networks%20Zoo.png)<br>\n  - [**Numpy**](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/Numpy.png)<br>\n  - [**Scipy**](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/Scipy.png)<br>\n  - [**Pandas-1**](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/Pandas-1.jpg)<br>\n  - [**Pandas-2**](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/Pandas-2.jpg)<br>\n  - [**Pandas-3**](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/Pandas-3.png)<br>\n  - [**Scikit-learn**](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/Scikit%20Learn.png)<br>\n  - [**Matplotlib**](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/Matplotlib.png)<br>\n  - [**Seaborn**](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/seaborn.png)<br>\n  - [**ggplot2-1**](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/ggplot2-1.jpg)<br>\n  - [**ggplot2-2**](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/ggplot2-2.jpg)<br>\n  - [**PySpark**](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/PySpark.jpg)<br>\n  - [**PySpark-RDD**](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/PySpark-RDD.png)<br>\n  - [**PySpark-SQL**](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/PySpark-SQL.png)<br>\n  - [**R Studio(dplyr & tidyr)-1**](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/Data%20Wrangling%20with%20dplyr%20and%20tidyr%20-%20R%20Studio-1.jpg)<br>\n  - [**R Studio(dplyr & tidyr)-2**](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/Data%20Wrangling%20with%20dplyr%20and%20tidyr%20-%20R%20Studio-2.jpg)<br>\n  - [**Neural Network Cells**](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/Neural%20Network%20Cells.png)<br>\n  - [**Neural Network Graphs**](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/Neural%20Network%20Graphs.png)<br>\n  - [**Deep Learning Cheat Sheet**](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/Deep%20Learning%20Cheat%20Sheet-Hacker%20Noon.pdf)<br>\n  - [**Dask1**](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/Dask1.png)\n  - [**Dask2**](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/Dask2.png)\n  - [**Dask3**](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/Dask3.png)\n  - [**Dask4**](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/Dask4.png)\n  - [**All Cheat Sheets(PDF)**](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/All%20Cheat%20Sheets.pdf)<br>\n  \n[**Medium Article**](https://medium.com/@kailashahirwar/essential-cheat-sheets-for-machine-learning-and-deep-learning-researchers-efb6a8ebd2e5)\n  \nLicense\n-----------------\n\n[MIT License](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/LICENSE.md)\n\n[AI Cheatsheets](https://aicheatsheets.com)'"
80,haifengl/smile,haifengl,Statistical Machine Intelligence & Learning Engine,2014-11-20 16:28:12,2020-06-18 19:45:34,Java,982,4789,"b'# Smile\n\n[![Donate](https://img.shields.io/badge/Donate-PayPal-green.svg)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=XKU5BZX7XHPQ6)\n[![Join the chat at https://gitter.im/haifengl/smile](https://badges.gitter.im/haifengl/smile.svg)](https://gitter.im/haifengl/smile?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n[![Maven Central](https://maven-badges.herokuapp.com/maven-central/com.github.haifengl/smile-core/badge.svg)](https://maven-badges.herokuapp.com/maven-central/com.github.haifengl/smile-core)\n\nSmile (Statistical Machine Intelligence and Learning Engine) is\na fast and comprehensive machine learning, NLP, linear algebra,\ngraph, interpolation, and visualization system in Java and Scala.\nWith advanced data structures and algorithms, Smile delivers\nstate-of-art performance. Smile is well documented and please\ncheck out the project [website](http://haifengl.github.io/)\nfor programming guides and more information.\n\nSmile covers every aspect of machine learning, including classification,\nregression, clustering, association rule mining, feature selection,\nmanifold learning, multidimensional scaling, genetic algorithms,\nmissing value imputation, efficient nearest neighbor search, etc.\n\nSmile implements the following major machine learning algorithms:\n\n- **Classification:**\nSupport Vector Machines, Decision Trees, AdaBoost, Gradient Boosting,\nRandom Forest, Logistic Regression, Neural Networks, RBF Networks,\nMaximum Entropy Classifier, KNN, Na\xc3\xafve Bayesian,\nFisher/Linear/Quadratic/Regularized Discriminant Analysis.\n\n- **Regression:**\nSupport Vector Regression, Gaussian Process, Regression Trees,\nGradient Boosting, Random Forest, RBF Networks, OLS, LASSO, ElasticNet,\nRidge Regression.\n\n- **Feature Selection:**\nGenetic Algorithm based Feature Selection, Ensemble Learning based Feature\nSelection, TreeSHAP, Signal Noise ratio, Sum Squares ratio.\n\n- **Clustering:**\nBIRCH, CLARANS, DBSCAN, DENCLUE, Deterministic Annealing, K-Means,\nX-Means, G-Means, Neural Gas, Growing Neural Gas, Hierarchical\nClustering, Sequential Information Bottleneck, Self-Organizing Maps,\nSpectral Clustering, Minimum Entropy Clustering.\n\n- **Association Rule & Frequent Itemset Mining:**\nFP-growth mining algorithm.\n\n- **Manifold Learning:**\nIsoMap, LLE, Laplacian Eigenmap, t-SNE, UMAP, PCA, Kernel PCA,\nProbabilistic PCA, GHA, Random Projection, ICA.\n\n- **Multi-Dimensional Scaling:**\nClassical MDS, Isotonic MDS, Sammon Mapping.\n\n- **Nearest Neighbor Search:**\nBK-Tree, Cover Tree, KD-Tree, SimHash, LSH.\n\n- **Sequence Learning:**\nHidden Markov Model, Conditional Random Field.\n\n- **Natural Language Processing:**\nSentence Splitter and Tokenizer, Bigram Statistical Test, Phrase Extractor,\nKeyword Extractor, Stemmer, POS Tagging, Relevance Ranking\n\nYou can use the libraries through Maven central repository by adding the\nfollowing to your project pom.xml file.\n```\n    <dependency>\n      <groupId>com.github.haifengl</groupId>\n      <artifactId>smile-core</artifactId>\n      <version>2.4.0</version>\n    </dependency>\n```\n\nFor NLP, use the artifactId smile-nlp.\n\nFor Scala API, please use\n```\n    libraryDependencies += ""com.github.haifengl"" %% ""smile-scala"" % ""2.4.0""\n```\n\nFor Kotlin API, add the below into the `dependencies` section\nof Gradle build script.\n```\n    implementation(""com.github.haifengl:smile-kotlin:2.4.0"")\n```\n\nFor Clojure API, add the following dependency to your project or build file:\n```\n    [org.clojars.haifengl/smile ""2.4.0""]\n```\n\nTo enable machine optimized matrix computation, the users should\nmake their machine-optimized libblas3 (CBLAS) and liblapack3 (Fortran)\navailable as shared libraries at runtime. This module employs the highly\nefficient [netlib-java](https://github.com/fommil/netlib-java#netlib-java)\nlibrary.\n\n#### OS X\nApple OS X requires no further setup as it ships with the veclib framework.\n\n#### Linux\nGenerically-tuned ATLAS and OpenBLAS are available with most distributions\nand must be enabled explicitly using the package-manager. For example,\n\n - sudo apt-get install libatlas3-base libopenblas-base\n - sudo update-alternatives --config libblas.so\n - sudo update-alternatives --config libblas.so.3\n - sudo update-alternatives --config liblapack.so\n - sudo update-alternatives --config liblapack.so.3\n\nHowever, these are only generic pre-tuned builds. If you have [Intel MKL]\n(https://software.intel.com/en-us/mkl) installed, you could also create\nsymbolic links from libblas.so.3 and liblapack.so.3 to libmkl_rt.so or\nuse Debian\'s alternatives system.\n\n#### Windows\nThe native_system builds expect to find libblas3.dll and liblapack3.dll\non the %PATH% (or current working directory). Smile prebuilt package\nships [Intel MKL](https://software.intel.com/en-us/mkl), which features\nhighly optimized, threaded, and vectorized math functions that maximize\nperformance on each processor family.\n\n## Shell\nSmile comes with interactive shells for Java, Scala and Kotlin.\nDownload pre-packaged Smile from the\n[releases page](https://github.com/haifengl/smile/releases).\nIn the home directory of Smile, type\n```\n    ./bin/smile\n```\nto enter the Scala shell. You can run any valid Scala expressions\nin the shell. In the simplest case, you can use it as a calculator.\nBesides, all high-level Smile operators are predefined in the shell.\nBy default, the shell uses up to 75% memory. If you need more memory\nto handle large data, use the option `-J-Xmx` or `-XX:MaxRAMPercentage`.\nFor example,\n```\n    ./bin/smile -J-Xmx30G\n```\nYou can also modify the configuration file `./conf/smile.ini` for the\nmemory and other JVM settings.\n\nTo use Java\'s JShell, type\n```\n    ./bin/jshell.sh\n```\nwhich has Smile\'s jars in the classpath. Similarly, run\n```\n    ./bin/kotlin.sh\n```\nto enter Kotlin REPL.\n\n## Model Serialization\nMost models support the Java `Serializable` interface (all classifiers\ndo support `Serializable` interface) so that you can use them in Spark.\nFor reading/writing the models in non-Java code, we suggest [XStream]\n(https://github.com/x-stream/xstream) to serialize the trained models.\nXStream is a simple library to serialize objects to XML and back again.\nXStream is easy to use and doesn\'t require mappings (actually requires\nno modifications to objects). [Protostuff](http://code.google.com/p/protostuff/)\nis a nice alternative that supports forward-backward compatibility\n(schema evolution) and validation. Beyond XML, Protostuff supports many\nother formats such as JSON, YAML, protobuf, etc.\n\n## Visualization\nSmile provides a Swing-based data visualization library SmilePlot,\nwhich provides scatter plot, line plot, staircase plot, bar plot,\nbox plot, histogram, 3D histogram, dendrogram, heatmap, hexmap,\nQQ plot, contour plot, surface, and wireframe.\n\nTo use SmilePlot, add the following to dependencies\n```\n    <dependency>\n      <groupId>com.github.haifengl</groupId>\n      <artifactId>smile-plot</artifactId>\n      <version>2.4.0</version>\n    </dependency>\n```\n\nSmile also support data visualization in declarative approach.\nWith `smile.plot.vega package`, we can create a specification\nthat describes visualizations as mappings from data to properties\nof graphical marks (e.g., points or bars). The specification is\nbased on [Vega-Lite](https://vega.github.io/vega-lite/). The\nVega-Lite compiler automatically produces visualization components\nincluding axes, legends, and scales. It then determines properties\nof these components based on a set of carefully designed rules.\n\n## Gallery\n<table class=""center"" width=""100%"">\n    <tr>\n        <td width=""50%"">\n            <figure>\n                <a href=""http://haifengl.github.io/gallery/smile-demo-kpca.png""><img src=""http://haifengl.github.io/gallery/smile-demo-kpca-small.png"" alt=""Kernel PCA""></a>\n                <figcaption><h2>Kernel PCA</h2></figcaption>\n            </figure>\n        </td>\n        <td width=""50%"">\n            <figure>\n                <a href=""http://haifengl.github.io/gallery/smile-demo-isomap.png""><img src=""http://haifengl.github.io/gallery/smile-demo-isomap-small.png"" alt=""IsoMap""></a>\n                <figcaption><h2>IsoMap</h2></figcaption>\n            </figure>\n        </td>\n    </tr>\n    <tr>\n        <td width=""50%"">\n            <figure>\n                <a href=""http://haifengl.github.io/gallery/smile-demo-mds.png""><img src=""http://haifengl.github.io/gallery/smile-demo-mds-small.png"" alt=""MDS""></a>\n                <figcaption><h2>Multi-Dimensional Scaling</h2></figcaption>\n            </figure>\n        </td>\n        <td width=""50%"">\n            <figure>\n                <a href=""http://haifengl.github.io/gallery/smile-demo-som.png""><img src=""http://haifengl.github.io/gallery/smile-demo-som-small.png"" alt=""SOM""></a>\n                <figcaption><h2>SOM</h2></figcaption>\n            </figure>\n        </td>\n    </tr>\n    <tr>\n        <td width=""50%"">\n            <figure>\n                <a href=""http://haifengl.github.io/gallery/smile-demo-ann.png""><img src=""http://haifengl.github.io/gallery/smile-demo-ann-small.png"" alt=""Neural Network""></a>\n                <figcaption><h2>Neural Network</h2></figcaption>\n            </figure>\n        </td>\n        <td width=""50%"">\n            <figure>\n                <a href=""http://haifengl.github.io/gallery/smile-demo-svm.png""><img src=""http://haifengl.github.io/gallery/smile-demo-svm-small.png"" alt=""SVM""></a>\n                <figcaption><h2>SVM</h2></figcaption>\n            </figure>\n        </td>\n    </tr>\n    <tr>\n        <td width=""50%"">\n            <figure>\n                <a href=""http://haifengl.github.io/gallery/smile-demo-agglomerative-clustering.png""><img src=""http://haifengl.github.io/gallery/smile-demo-agglomerative-clustering-small.png"" alt=""Agglomerative Clustering""></a>\n                <figcaption><h2>Agglomerative Clustering</h2></figcaption>\n            </figure>\n        </td>\n        <td width=""50%"">\n            <figure>\n                <a href=""http://haifengl.github.io/gallery/smile-demo-xmeans.png""><img src=""http://haifengl.github.io/gallery/smile-demo-xmeans-small.png"" alt=""X-Means""></a>\n                <figcaption><h2>X-Means</h2></figcaption>\n            </figure>\n        </td>\n    </tr>\n    <tr>\n        <td width=""50%"">\n            <figure>\n                <a href=""http://haifengl.github.io/gallery/smile-demo-dbscan.png""><img src=""http://haifengl.github.io/gallery/smile-demo-dbscan-small.png"" alt=""DBSCAN""></a>\n                <figcaption><h2>DBSCAN</h2></figcaption>\n            </figure>\n        </td>\n        <td width=""50%"">\n            <figure>\n                <a href=""http://haifengl.github.io/gallery/smile-demo-neural-gas.png""><img src=""http://haifengl.github.io/gallery/smile-demo-neural-gas-small.png"" alt=""Neural Gas""></a>\n                <figcaption><h2>Neural Gas</h2></figcaption>\n            </figure>\n        </td>\n    </tr>\n    <tr>\n        <td width=""50%"">\n            <figure>\n                <a href=""http://haifengl.github.io/gallery/smile-demo-wavelet.png""><img src=""http://haifengl.github.io/gallery/smile-demo-wavelet-small.png"" alt=""Wavelet""></a>\n                <figcaption><h2>Wavelet</h2></figcaption>\n            </figure>\n        </td>\n        <td width=""50%"">\n            <figure>\n                <a href=""http://haifengl.github.io/gallery/smile-demo-mixture.png""><img src=""http://haifengl.github.io/gallery/smile-demo-mixture-small.png"" alt=""Mixture""></a>\n                <figcaption><h2>Exponential Family Mixture</h2></figcaption>\n            </figure>\n        </td>\n    </tr>\n</table>\n\n'"
81,zlotus/notes-LSJU-machine-learning,zlotus,机器学习笔记,2016-06-15 14:56:12,2020-06-12 16:33:47,Jupyter Notebook,397,828,b'# \xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xac\x94\xe8\xae\xb0\n\n## \xe7\xae\x80\xe4\xbb\x8b\n\n**\xe4\xbd\x9c\xe8\x80\x85\xef\xbc\x9a\xe5\xad\x90\xe5\xae\x9e**\n\n\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xac\x94\xe8\xae\xb0\xef\xbc\x8c\xe4\xbd\xbf\xe7\x94\xa8 `jupyter notebook (ipython notebook)` \xe7\xbc\x96\xe5\x86\x99\xe5\xb1\x95\xe7\xa4\xba\xe3\x80\x82\n\n`Github` \xe5\x8a\xa0\xe8\xbd\xbd `.ipynb` \xe7\x9a\x84\xe9\x80\x9f\xe5\xba\xa6\xe8\xbe\x83\xe6\x85\xa2\xef\xbc\x8c\xe5\xbb\xba\xe8\xae\xae\xe5\x9c\xa8 [Nbviewer](http://nbviewer.jupyter.org/github/zlotus/notes-LSJU-machine-learning/blob/master/ReadMe.ipynb?flush_cache=true) \xe4\xb8\xad\xe6\x9f\xa5\xe7\x9c\x8b\xe8\xaf\xa5\xe9\xa1\xb9\xe7\x9b\xae\xe3\x80\x82\n\n----\n\n## \xe7\x9b\xae\xe5\xbd\x95\n\n\xe6\x9d\xa5\xe8\x87\xaa\xe6\x96\xaf\xe5\x9d\xa6\xe7\xa6\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe8\xaf\xbe\xe7\xa8\x8b\xe3\x80\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe3\x80\x8b\xe7\x9a\x84\xe7\xac\x94\xe8\xae\xb0\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe5\x9c\xa8[\xe6\x96\xaf\xe5\x9d\xa6\xe7\xa6\x8f\xe5\xa4\xa7\xe5\xad\xa6\xe5\x85\xac\xe5\xbc\x80\xe8\xaf\xbe\xef\xbc\x9a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe8\xaf\xbe\xe7\xa8\x8b](http://open.163.com/special/opencourse/machinelearning.html)\xe8\xa7\x82\xe7\x9c\x8b\xe3\x80\x82\n\n\xe6\xa0\xb9\xe6\x8d\xae\xe8\xa7\x86\xe9\xa2\x91\xe5\x86\x85\xe5\xae\xb9\xef\xbc\x8c\xe5\xaf\xb9\xe6\xaf\x8f\xe4\xb8\x80\xe8\xae\xb2\xe7\x9a\x84\xe5\x90\x8d\xe7\xa7\xb0\xe5\x8f\xaf\xe8\x83\xbd\xe4\xbc\x9a\xe6\x9c\x89\xe6\x89\x80\xe6\x9b\xb4\xe6\x94\xb9\xef\xbc\x88\xe4\xbb\xa5\xe6\x9b\xb4\xe5\xa5\xbd\xe7\x9a\x84\xe4\xbd\x93\xe7\x8e\xb0\xe5\x90\x84\xe8\xae\xb2\xe7\x9a\x84\xe6\x95\x99\xe5\xad\xa6\xe5\x86\x85\xe5\xae\xb9\xef\xbc\x89\xe3\x80\x82\n\n- \xe3\x80\x90\xe7\xac\xac1\xe8\xae\xb2\xe3\x80\x91 \xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9a\x84\xe5\x8a\xa8\xe6\x9c\xba\xe4\xb8\x8e\xe5\xba\x94\xe7\x94\xa8\xef\xbc\x88\xe4\xb8\xbb\xe8\xa6\x81\xe6\x98\xaf\xe8\xaf\xbe\xe7\xa8\x8b\xe8\xa6\x81\xe6\xb1\x82\xe4\xb8\x8e\xe5\xba\x94\xe7\x94\xa8\xe8\x8c\x83\xe4\xbe\x8b\xef\xbc\x8c\xe6\xb2\xa1\xe6\x9c\x89\xe6\xb6\x89\xe5\x8f\x8a\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\x9a\x84\xe5\x85\xb7\xe4\xbd\x93\xe8\xae\xa1\xe7\xae\x97\xe5\x86\x85\xe5\xae\xb9\xef\xbc\x89\n- \xe3\x80\x90\xe7\xac\xac2\xe8\xae\xb2\xe3\x80\x91 [\xe7\x9b\x91\xe7\x9d\xa3\xe5\xad\xa6\xe4\xb9\xa0\xe5\xba\x94\xe7\x94\xa8-\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92](chapter02.ipynb)\n- \xe3\x80\x90\xe7\xac\xac3\xe8\xae\xb2\xe3\x80\x91 [\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9a\x84\xe6\xa6\x82\xe7\x8e\x87\xe8\xa7\xa3\xe9\x87\x8a\xe3\x80\x81\xe5\xb1\x80\xe9\x83\xa8\xe5\x8a\xa0\xe6\x9d\x83\xe5\x9b\x9e\xe5\xbd\x92\xe3\x80\x81\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92](chapter03.ipynb)\n- \xe3\x80\x90\xe7\xac\xac4\xe8\xae\xb2\xe3\x80\x91 [\xe7\x89\x9b\xe9\xa1\xbf\xe6\xb3\x95\xe3\x80\x81\xe4\xb8\x80\xe8\x88\xac\xe7\xba\xbf\xe6\x80\xa7\xe6\xa8\xa1\xe5\x9e\x8b](chapter04.ipynb)\n- \xe3\x80\x90\xe7\xac\xac5\xe8\xae\xb2\xe3\x80\x91 [\xe7\x94\x9f\xe6\x88\x90\xe5\xad\xa6\xe4\xb9\xa0\xe7\xae\x97\xe6\xb3\x95\xe3\x80\x81\xe9\xab\x98\xe6\x96\xaf\xe5\x88\xa4\xe5\x88\xab\xe5\x88\x86\xe6\x9e\x90\xe3\x80\x81\xe6\x9c\xb4\xe7\xb4\xa0\xe8\xb4\x9d\xe5\x8f\xb6\xe6\x96\xaf\xe7\xae\x97\xe6\xb3\x95](chapter05.ipynb)\n- \xe3\x80\x90\xe7\xac\xac6\xe8\xae\xb2\xe3\x80\x91 [\xe4\xba\x8b\xe4\xbb\xb6\xe6\xa8\xa1\xe5\x9e\x8b\xe3\x80\x81\xe5\x87\xbd\xe6\x95\xb0\xe9\x97\xb4\xe9\x9a\x94\xe4\xb8\x8e\xe5\x87\xa0\xe4\xbd\x95\xe9\x97\xb4\xe9\x9a\x94](chapter06.ipynb)\n- \xe3\x80\x90\xe7\xac\xac7\xe8\xae\xb2\xe3\x80\x91 [\xe6\x9c\x80\xe4\xbc\x98\xe9\x97\xb4\xe9\x9a\x94\xe5\x88\x86\xe7\xb1\xbb\xe5\x99\xa8\xe3\x80\x81\xe6\x8b\x89\xe6\xa0\xbc\xe6\x9c\x97\xe6\x97\xa5\xe5\xaf\xb9\xe5\x81\xb6\xe3\x80\x81\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba](chapter07.ipynb)\n- \xe3\x80\x90\xe7\xac\xac8\xe8\xae\xb2\xe3\x80\x91 [\xe6\xa0\xb8\xe6\x96\xb9\xe6\xb3\x95\xe3\x80\x81\xe5\xba\x8f\xe5\x88\x97\xe6\x9c\x80\xe5\xb0\x8f\xe4\xbc\x98\xe5\x8c\x96\xe7\xae\x97\xe6\xb3\x95](chapter08.ipynb)\n- \xe3\x80\x90\xe7\xac\xac9\xe8\xae\xb2\xe3\x80\x91 [\xe7\xbb\x8f\xe9\xaa\x8c\xe9\xa3\x8e\xe9\x99\xa9\xe6\x9c\x80\xe5\xb0\x8f\xe5\x8c\x96](chapter09.ipynb)\n- \xe3\x80\x90\xe7\xac\xac10\xe8\xae\xb2\xe3\x80\x91 [\xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe7\x89\xb9\xe5\xbe\x81\xe9\x80\x89\xe6\x8b\xa9](chapter10.ipynb)\n- \xe3\x80\x90\xe7\xac\xac11\xe8\xae\xb2\xe3\x80\x91 [\xe8\xb4\x9d\xe5\x8f\xb6\xe6\x96\xaf\xe7\xbb\x9f\xe8\xae\xa1\xe3\x80\x81\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe5\xba\x94\xe7\x94\xa8\xe5\xbb\xba\xe8\xae\xae](chapter11.ipynb)\n- \xe3\x80\x90\xe7\xac\xac12\xe8\xae\xb2\xe3\x80\x91 [$k$-means\xe7\xae\x97\xe6\xb3\x95\xe3\x80\x81\xe9\xab\x98\xe6\x96\xaf\xe6\xb7\xb7\xe5\x90\x88\xe6\xa8\xa1\xe5\x9e\x8b\xe5\x8f\x8a\xe6\x9c\x80\xe5\xa4\xa7\xe6\x9c\x9f\xe6\x9c\x9b\xe7\xae\x97\xe6\xb3\x95](chapter12.ipynb)\n- \xe3\x80\x90\xe7\xac\xac13\xe8\xae\xb2\xe3\x80\x91 [\xe6\x9c\x80\xe5\xa4\xa7\xe6\x9c\x9f\xe6\x9c\x9b\xe7\xae\x97\xe6\xb3\x95\xe5\x8f\x8a\xe5\x85\xb6\xe5\xba\x94\xe7\x94\xa8\xe3\x80\x81\xe5\x9b\xa0\xe5\xad\x90\xe5\x88\x86\xe6\x9e\x90\xe6\xa8\xa1\xe5\x9e\x8b](chapter13.ipynb)\n- \xe3\x80\x90\xe7\xac\xac14\xe8\xae\xb2\xe3\x80\x91 [\xe5\x9b\xa0\xe5\xad\x90\xe5\x88\x86\xe6\x9e\x90\xe7\x9a\x84EM\xe7\xae\x97\xe6\xb3\x95\xe3\x80\x81\xe4\xb8\xbb\xe6\x88\x90\xe5\x88\x86\xe5\x88\x86\xe6\x9e\x90](chapter14.ipynb)\n- \xe3\x80\x90\xe7\xac\xac15\xe8\xae\xb2\xe3\x80\x91 [PCA\xe7\x9a\x84\xe5\xa5\x87\xe5\xbc\x82\xe5\x80\xbc\xe5\x88\x86\xe8\xa7\xa3\xe3\x80\x81\xe7\x8b\xac\xe7\xab\x8b\xe6\x88\x90\xe5\x88\x86\xe5\x88\x86\xe6\x9e\x90](chapter15.ipynb)\n- \xe3\x80\x90\xe7\xac\xac16\xe8\xae\xb2\xe3\x80\x91 [\xe9\xa9\xac\xe5\xb0\x94\xe5\x8f\xaf\xe5\xa4\xab\xe5\x86\xb3\xe7\xad\x96\xe8\xbf\x87\xe7\xa8\x8b](chapter16.ipynb)\n- \xe3\x80\x90\xe7\xac\xac17\xe8\xae\xb2\xe3\x80\x91 [\xe8\xa7\xa3\xe8\xbf\x9e\xe7\xbb\xad\xe7\x8a\xb6\xe6\x80\x81\xe7\x9a\x84MDP](chapter17.ipynb)\n- \xe3\x80\x90\xe7\xac\xac18\xe8\xae\xb2\xe3\x80\x91 [\xe7\xba\xbf\xe6\x80\xa7\xe4\xba\x8c\xe6\xac\xa1\xe8\xb0\x83\xe8\x8a\x82](chapter18.ipynb)\n- \xe3\x80\x90\xe7\xac\xac19\xe8\xae\xb2\xe3\x80\x91 [\xe5\xbe\xae\xe5\x88\x86\xe5\x8a\xa8\xe6\x80\x81\xe8\xa7\x84\xe5\x88\x92\xe5\x8f\x8a\xe7\xba\xbf\xe6\x80\xa7\xe4\xba\x8c\xe6\xac\xa1\xe5\x9e\x8b\xe9\xab\x98\xe6\x96\xaf](chapter19.ipynb)\n- \xe3\x80\x90\xe7\xac\xac20\xe8\xae\xb2\xe3\x80\x91 [\xe7\xad\x96\xe7\x95\xa5\xe6\x90\x9c\xe7\xb4\xa2\xe7\xae\x97\xe6\xb3\x95](chapter20.ipynb)\n\n----\n\n- \xe3\x80\x90\xe5\x8f\x82\xe8\x80\x83\xe7\xac\x94\xe8\xae\xb01\xe3\x80\x91 \xe7\xba\xbf\xe6\x80\xa7\xe4\xbb\xa3\xe6\x95\xb0\xe5\xa4\x8d\xe4\xb9\xa0\xe5\x8f\x8a\xe5\x8f\x82\xe8\x80\x83\n- \xe3\x80\x90\xe5\x8f\x82\xe8\x80\x83\xe7\xac\x94\xe8\xae\xb02\xe3\x80\x91 [\xe6\xa6\x82\xe7\x8e\x87\xe8\xae\xba\xe5\xa4\x8d\xe4\xb9\xa0](sn02.ipynb)\n- \xe3\x80\x90\xe5\x8f\x82\xe8\x80\x83\xe7\xac\x94\xe8\xae\xb03\xe3\x80\x91 MATLAB\xe5\x85\xa5\xe9\x97\xa8\n- \xe3\x80\x90\xe5\x8f\x82\xe8\x80\x83\xe7\xac\x94\xe8\xae\xb04\xe3\x80\x91 \xe5\x87\xb8\xe4\xbc\x98\xe5\x8c\x96\xe6\xa6\x82\xe8\xbf\xb01\n- \xe3\x80\x90\xe5\x8f\x82\xe8\x80\x83\xe7\xac\x94\xe8\xae\xb05\xe3\x80\x91 \xe5\x87\xb8\xe4\xbc\x98\xe5\x8c\x96\xe6\xa6\x82\xe8\xbf\xb02\n- \xe3\x80\x90\xe5\x8f\x82\xe8\x80\x83\xe7\xac\x94\xe8\xae\xb06\xe3\x80\x91 [\xe9\x9a\x90\xe5\xbc\x8f\xe9\xa9\xac\xe5\xb0\x94\xe5\x8f\xaf\xe5\xa4\xab\xe6\xa8\xa1\xe5\x9e\x8b](sn06.ipynb)\n- \xe3\x80\x90\xe5\x8f\x82\xe8\x80\x83\xe7\xac\x94\xe8\xae\xb07\xe3\x80\x91 [\xe5\xa4\x9a\xe5\x85\x83\xe9\xab\x98\xe6\x96\xaf\xe5\x88\x86\xe5\xb8\x83](sn07.ipynb)\n- \xe3\x80\x90\xe5\x8f\x82\xe8\x80\x83\xe7\xac\x94\xe8\xae\xb08\xe3\x80\x91 [\xe6\x9b\xb4\xe5\xa4\x9a\xe5\x85\xb3\xe4\xba\x8e\xe5\xa4\x9a\xe5\x85\x83\xe9\xab\x98\xe6\x96\xaf\xe5\x88\x86\xe5\xb8\x83\xe7\x9a\x84\xe7\x9f\xa5\xe8\xaf\x86](sn08.ipynb)\n- \xe3\x80\x90\xe5\x8f\x82\xe8\x80\x83\xe7\xac\x94\xe8\xae\xb09\xe3\x80\x91 \xe9\xab\x98\xe6\x96\xaf\xe8\xbf\x87\xe7\xa8\x8b\n\n\xe7\xac\x94\xe8\xae\xb0\xe6\xa0\xbc\xe5\xbc\x8f\xe5\x80\x9f\xe9\x89\xb4[Jin Li](https://github.com/lijin-THU/)\xe7\x9a\x84[\xe6\x9c\xba\xe5\x99\xa8\xe5\xad\xa6\xe4\xb9\xa0\xe7\xac\x94\xe8\xae\xb0](https://github.com/lijin-THU/notes-machine-learning)\xe3\x80\x82'
82,WillKoehrsen/machine-learning-project-walkthrough,WillKoehrsen,An implementation of a complete machine learning solution in Python on a real-world dataset. This project is meant to demonstrate how all the steps of a machine learning pipeline come together to solve a problem!,2018-05-12 23:57:18,2020-06-17 21:00:19,Jupyter Notebook,427,678,b'# machine-learning-project-walkthrough \n\nAn implementation of a complete machine learning solution in Python on a real-world dataset. This project is meant to demonstrate \nhow all the steps of a machine learning pipeline come together to solve a problem! \n'
83,RedditSota/state-of-the-art-result-for-machine-learning-problems,RedditSota,"This repository provides state of the art (SoTA) results for all machine learning problems. We do our best to keep this repository up to date.  If you do find a problem's SoTA result is out of date or missing, please raise this as an issue or submit Google form (with this information: research paper name, dataset, metric, source code and year). We will fix it immediately.",2017-11-09 01:21:40,2020-06-18 14:24:00,,1393,8970,"b'# State-of-the-art result for all Machine Learning Problems\n\n### LAST UPDATE: 20th Februray 2019\n\n### NEWS: I am looking for a Collaborator esp who does research in NLP, Computer Vision and Reinforcement learning. If you are not a researcher, but you are willing, contact me. Email me: yxt.stoaml@gmail.com\n\nThis repository provides state-of-the-art (SoTA) results for all machine learning problems. We do our best to keep this repository up to date.  If you do find a problem\'s SoTA result is out of date or missing, please raise this as an issue (with this information: research paper name, dataset, metric, source code and year). We will fix it immediately.\n\nYou can also submit this [Google Form](https://docs.google.com/forms/d/e/1FAIpQLSe_fFZVCeCVRGGgOQIpoQSXY7mZWynsx7g6WxZEVpO5vJioUA/viewform?embedded=true) if you are new to Github.\n\nThis is an attempt to make  one stop for all types of machine learning problems state of the art result. I can not do this alone. I need help from everyone. Please submit the Google form/raise an issue if you find SOTA result for a dataset.  Please share this on Twitter, Facebook, and other social media.\n\n\nThis summary is categorized into:\n\n- [Supervised Learning](https://github.com/RedditSota/state-of-the-art-result-for-machine-learning-problems#supervised-learning)\n    - [Speech](https://github.com/RedditSota/state-of-the-art-result-for-machine-learning-problems#speech)\n    - [Computer Vision](https://github.com/RedditSota/state-of-the-art-result-for-machine-learning-problems#computer-vision)\n    - [NLP](https://github.com/RedditSota/state-of-the-art-result-for-machine-learning-problems#nlp)\n- [Semi-supervised Learning](https://github.com/RedditSota/state-of-the-art-result-for-machine-learning-problems#semi-supervised-learning)\n    - Computer Vision\n- [Unsupervised Learning](https://github.com/RedditSota/state-of-the-art-result-for-machine-learning-problems#unsupervised-learning)\n    - Speech\n    - Computer Vision\n    - [NLP](https://github.com/RedditSota/state-of-the-art-result-for-machine-learning-problems/blob/master/README.md#nlp-1)\n- [Transfer Learning](https://github.com/RedditSota/state-of-the-art-result-for-machine-learning-problems#transfer-learning)\n- [Reinforcement Learning](https://github.com/RedditSota/state-of-the-art-result-for-machine-learning-problems#reinforcement-learning)\n\n## Supervised Learning\n\n\n### NLP\n#### 1. Language Modelling\n\n<table>\n  <tbody>\n    <tr>\n      <th width=""30%"">Research Paper</th>\n      <th align=""center"" width=""20%"">Datasets</th>\n      <th align=""center"" width=""20%"">Metric</th>\n      <th align=""center"" width=""20%"">Source Code</th>\n      <th align=""center"" width=""10%"">Year</th>\n    </tr>  \n    <tr>\n      <td><a href=\'https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf\'> Language Models are Unsupervised Multitask Learners </a></td>\n      <td align=""left""><ul><li> PTB </li><li> WikiText-2 </li></ul></td>\n      <td align=""left""><ul><li> Perplexity: 35.76 </li><li> Perplexity: 18.34 </li></ul></td>\n      <td align=""left""><a href=\'https://github.com/openai/gpt-2\'>Tensorflow </a></td>\n      <td align=""left"">2019</td>   \n    </tr>\n    <tr>\n      <td><a href=\'https://arxiv.org/pdf/1711.03953.pdf\'>BREAKING THE SOFTMAX BOTTLENECK: A HIGH-RANK RNN LANGUAGE MODEL </a></td>\n      <td align=""left""><ul><li> PTB </li><li> WikiText-2 </li></ul></td>\n      <td align=""left""><ul><li> Perplexity: 47.69 </li><li> Perplexity: 40.68 </li></ul></td>\n      <td align=""left""><a href=\'https://github.com/zihangdai/mos\'>Pytorch </a></td>\n      <td align=""left"">2017</td>   \n    </tr>\n    <tr>\n      <td><a href=\'https://arxiv.org/pdf/1709.07432.pdf\'>DYNAMIC EVALUATION OF NEURAL SEQUENCE MODELS </a></td>\n      <td align=""left""><ul><li> PTB </li><li> WikiText-2 </li></ul></td>\n      <td align=""left""><ul><li> Perplexity: 51.1 </li><li> Perplexity: 44.3 </li></ul></td>\n      <td align=""left""><a href=\'https://github.com/benkrause/dynamic-evaluation\'>Pytorch </a></td>\n      <td align=""left"">2017</td>   \n    </tr>\n    <tr>\n      <td><a href=\'https://arxiv.org/pdf/1708.02182.pdf\'>Averaged Stochastic Gradient  Descent <br/> with Weight Dropped LSTM or QRNN </a></td>\n      <td align=""left""><ul><li> PTB </li><li> WikiText-2 </li></ul></td>\n      <td align=""left""><ul><li> Perplexity: 52.8 </li><li> Perplexity: 52.0 </li></ul></td>\n      <td align=""left""><a href=\'https://github.com/salesforce/awd-lstm-lm\'>Pytorch </a></td>\n      <td align=""left"">2017</td>   \n    </tr>\n    <tr>\n      <td><a href=\'https://arxiv.org/pdf/1711.00066.pdf\'>FRATERNAL DROPOUT </a></td>\n      <td align=""left""><ul><li> PTB </li><li> WikiText-2 </li></ul></td>\n      <td align=""left""><ul><li> Perplexity: 56.8 </li><li> Perplexity: 64.1 </li></ul></td>\n      <td align=""left""> <a href=\'https://github.com/kondiz/fraternal-dropout\'> Pytorch </a>  </td>\n      <td align=""left"">2017</td>   \n    </tr>\n        <tr>\n      <td><a href=\'https://arxiv.org/pdf/1703.10722.pdf\'>Factorization tricks for LSTM networks </a></td>\n      <td align=""left"">One Billion Word Benchmark</td>\n      <td align=""left""> Perplexity:  23.36</td>\n      <td align=""left""><a href=\'https://github.com/okuchaiev/f-lm\'>Tensorflow </a></td>\n      <td align=""left"">2017</td>   \n    </tr>\n  </tbody>\n</table>\n\n\n\n\n#### 2. Machine Translation\n\n<table>\n  <tbody>\n    <tr>\n      <th width=""30%"">Research Paper</th>\n      <th align=""center"" width=""20%"">Datasets</th>\n      <th align=""center"" width=""20%"">Metric</th>\n      <th align=""center"" width=""20%"">Source Code</th>\n      <th align=""center"" width=""10%"">Year</th>\n    </tr>\n    <tr>\n      <td><a href=\'https://arxiv.org/pdf/1808.09381v2.pdf\'> Understanding Back-Translation at Scale </a></td>\n      <td align=""left""> <ul><li>WMT 2014 English-to-French </li><li>WMT 2014 English-to-German </li></ul></td>\n      <td align=""left""> <ul><li>  BLEU: 45.6 </li><li>   BLEU: 35.0 </li></ul> </td>\n      <td align=""left""> <ul><li><a href=\'https://github.com/pytorch/fairseq\'>PyTorch</a></li></ul></td>\n      <td align=""left"">2018</td>    \n    </tr>\n    <tr>\n      <td><a href=\'https://arxiv.org/pdf/1711.02132.pdf\'>WEIGHTED TRANSFORMER NETWORK FOR\nMACHINE TRANSLATION</a></td>\n      <td align=""left""> <ul><li>WMT 2014 English-to-French </li><li>WMT 2014 English-to-German </li></ul></td>\n      <td align=""left""> <ul><li>  BLEU: 41.4 </li><li>   BLEU: 28.9 </li></ul> </td>\n      <td align=""left""> <ul><li><a href=\'\'>NOT FOUND</a></li></ul></td>\n      <td align=""left"">2017</td>    \n    </tr>\n    <tr>\n      <td><a href=\'https://arxiv.org/abs/1706.03762\'>Attention Is All You Need</a></td>\n      <td align=""left""> <ul><li>WMT 2014 English-to-French </li><li>WMT 2014 English-to-German </li></ul></td>\n      <td align=""left""> <ul><li>  BLEU: 41.0 </li><li>   BLEU: 28.4 </li></ul> </td>\n      <td align=""left""> <ul><li><a href=\'https://github.com/jadore801120/attention-is-all-you-need-pytorch\'>PyTorch</a> </li><li> <a href=\'https://github.com/tensorflow/tensor2tensor\'>Tensorflow</a></li></ul></td>\n      <td align=""left"">2017</td>    \n    </tr>\n     <tr>\n      <td><a href=\'https://einstein.ai/static/images/pages/research/non-autoregressive-neural-mt.pdf\'>NON-AUTOREGRESSIVE\nNEURAL MACHINE TRANSLATION</a></td>\n      <td align=""left""> <ul><li> WMT16 Ro\xe2\x86\x92En </li></ul></td>\n      <td align=""left""> <ul><li> BLEU: 31.44 </li></ul> </td>\n      <td align=""left""><ul><li><a href=\'https://github.com/salesforce/nonauto-nmt\'>PyTorch</a></ul></li></td>\n      <td align=""left"">2017</td>    \n      </tr>\n          <tr>\n      <td><a href=\'https://arxiv.org/abs/1703.04887\'> Improving Neural Machine Translation with Conditional Sequence Generative Adversarial Nets</a></td>\n      <td align=""left""> <ul><li>NIST02    </li><li>NIST03 </li><li>NIST04 </li><li>NIST05 </li></ul></td>\n      <td align=""left""><li>38.74  </li><li>36.01  </li><li> 37.54 </li><li>33.76 </li></ul </td>\n      <td align=""left""> <ul><li><a href=\'https://github.com/ngohoanhkhoa/GAN-NMT\'>NMTPY</a> </li></ul></td>\n      <td align=""left"">2017</td>    \n    </tr>\n  </tbody>\n</table>  \n\n#### 3. Text Classification\n\n<table>\n  <tbody>\n    <tr>\n      <th width=""30%"">Research Paper</th>\n      <th align=""center"" width=""20%"">Datasets</th>\n      <th align=""center"" width=""20%"">Metric</th>\n      <th align=""center"" width=""20%"">Source Code</th>\n      <th align=""center"" width=""10%"">Year</th>\n    </tr>\n    <tr>\n      <td><a href=\'https://arxiv.org/abs/1705.09207\'> Learning Structured Text Representations </a></td>\n      <td align=""left"">Yelp</td>\n      <td align=""left"">Accuracy: 68.6</td>\n      <td align=""left""> <ul><li><a href=\'https://github.com/nlpyang/structured\'>Tensorflow</a></ul></li></td>\n      <td align=""left"">2017</td>    \n    </tr>\n    <tr>\n      <td><a href=\'https://arxiv.org/pdf/1710.00519.pdf\'>Attentive Convolution</a></td>\n      <td align=""left"">Yelp</td>\n      <td align=""left"">Accuracy: 67.36</td>\n      <td align=""left""> <ul><li><a href=\'https://github.com/yinwenpeng/Attentive_Convolution\'>Theano</a></ul></li></td>\n      <td align=""left"">2017</td>   \n    </tr>\n  </tbody>\n</table>\n\n#### 4. Natural Language Inference \nLeader board: \n\n[Stanford Natural Language Inference (SNLI)](https://nlp.stanford.edu/projects/snli/)\n\n[MultiNLI](https://www.kaggle.com/c/multinli-matched-open-evaluation/leaderboard)\n\n<table>\n  <tbody>\n    <tr>\n      <th width=""30%"">Research Paper</th>\n      <th align=""center"" width=""20%"">Datasets</th>\n      <th align=""center"" width=""20%"">Metric</th>\n      <th align=""center"" width=""20%"">Source Code</th>\n      <th align=""center"" width=""10%"">Year</th>\n    </tr>\n    <tr>\n      <td><a href=\'https://arxiv.org/pdf/1709.04348.pdf\'> NATURAL LANGUAGE INFERENCE OVER INTERACTION SPACE </a></td>\n      <td align=""left"">Stanford Natural Language Inference (SNLI)</td>\n      <td align=""left"">Accuracy: 88.9</td>\n      <td align=""left""><a href=\'https://github.com/YichenGong/Densely-Interactive-Inference-Network\'>Tensorflow</a> </td>\n      <td align=""left"">2017</td>\n  </tr>\n    <tr>\n      <td><a href=https://arxiv.org/pdf/1810.04805.pdf> BERT-LARGE (ensemble) </a></td>\n      <td align=""left"">Multi-Genre Natural Language Inference (MNLI)</td>\n      <td align=""left""><ul><li>Matched accuracy: 86.7</li><li>Mismatched accuracy: 85.9</td>\n      <td align=""left""><ul><li><a href=\'https://github.com/google-research/bert\'>Tensorflow</a></li><li><a href=\'https://github.com/huggingface/pytorch-pretrained-BERT\'>PyTorch</a></li> </td>\n      <td align=""left"">2018</td>\n  </tr>\n  </tbody>\n</table>\n\n\n#### 5. Question Answering\nLeader Board\n\n[SQuAD](https://rajpurkar.github.io/SQuAD-explorer/)\n<table>\n  <tbody>\n    <tr>\n      <th width=""30%"">Research Paper</th>\n      <th align=""center"" width=""20%"">Datasets</th>\n      <th align=""center"" width=""20%"">Metric</th>\n      <th align=""center"" width=""20%"">Source Code</th>\n      <th align=""center"" width=""10%"">Year</th>\n    </tr>\n    <tr>\n      <td><a href=\'https://arxiv.org/pdf/1810.04805.pdf\'> BERT-LARGE (ensemble) </a></td>\n      <td align=""left"">The Stanford Question Answering Dataset</td>\n      <td align=""left""><ul><li> Exact Match: 87.4 </li><li> F1: 93.2 </li></ul></td>\n      <td align=""left""><ul><li><a href=\'https://github.com/google-research/bert\'>Tensorflow</a></li><li><a href=\'https://github.com/huggingface/pytorch-pretrained-BERT\'>PyTorch</a> </td>\n      <td align=""left"">2018</td>    \n  </tr>\n  </tbody>\n</table>\n\n\n#### 6. Named entity recognition\n<table>\n  <tbody>\n    <tr>\n      <th width=""30%"">Research Paper</th>\n      <th align=""center"" width=""20%"">Datasets</th>\n      <th align=""center"" width=""20%"">Metric</th>\n      <th align=""center"" width=""20%"">Source Code</th>\n      <th align=""center"" width=""10%"">Year</th>\n    </tr>\n    <tr>\n      <td><a href=\'https://arxiv.org/pdf/1710.11027.pdf\'>Named Entity Recognition in Twitter using Images and Text </a></td>\n      <td align=""left"">Ritter</td>\n      <td align=""left""><ul><li> F-measure: 0.59 </li></ul></td>\n      <td align=""left""><a href=\'\'>NOT FOUND</a> </td>\n      <td align=""left"">2017</td>    \n  </tr>\n  </tbody>\n</table>\n\n#### 7. Abstractive Summarization\n\nResearch Paper | Datasets  | Metric | Source Code | Year  \n------------ | ------------- | ------------ | ------------- | -------------  \n[Cutting-off redundant repeating generations </br> for neural abstractive summarization](https://aclanthology.info/pdf/E/E17/E17-2047.pdf) | <ul><li>DUC-2004</li><li>Gigaword</li></ul> | <ul><li>DUC-2004</li><ul><li> ROUGE-1: **32.28** </li><li> ROUGE-2: 10.54 </li><li>ROUGE-L: **27.80** </li></ul><li>Gigaword</li><ul><li> ROUGE-1: **36.30** </li><li> ROUGE-2: 17.31 </li><li>ROUGE-L: **33.88** </li></ul></ul> | NOT YET AVAILABLE | 2017\n[Convolutional Sequence to Sequence](https://arxiv.org/pdf/1705.03122.pdf) | <ul><li>DUC-2004</li><li>Gigaword</li></ul> | <ul><li>DUC-2004</li><ul><li> ROUGE-1: 33.44 </li><li> ROUGE-2: **10.84** </li><li>ROUGE-L: 26.90 </li></ul><li>Gigaword</li><ul><li> ROUGE-1: 35.88 </li><li> ROUGE-2: 27.48 </li><li>ROUGE-L: 33.29 </li></ul></ul> | [PyTorch](https://github.com/facebookresearch/fairseq-py) | 2017\n\n\n#### 8. Dependency Parsing\n\nResearch Paper | Datasets  | Metric | Source Code | Year  \n------------ | ------------- | ------------ | ------------- | -------------  \n[Globally Normalized Transition-Based Neural Networks](https://arxiv.org/pdf/1603.06042.pdf) | <ul><li>Final CoNLL \xe2\x80\x9909 dependency parsing </li></ul> | <ul><li> 94.08% UAS accurancy</li> <li>92.15% LAS accurancy</li></ul> | <ul><li>[SyntaxNet](https://github.com/tensorflow/models/tree/master/research/syntaxnet) </li></ul>| <ul><li>2017</li></ul>\n\n\n### Computer Vision\n\n#### 1. Classification\n\n<table>\n  <tbody>\n    <tr>\n      <th width=""30%"">Research Paper</th>\n      <th align=""center"" width=""20%"">Datasets</th>\n      <th align=""center"" width=""20%"">Metric</th>\n      <th align=""center"" width=""20%"">Source Code</th>\n      <th align=""center"" width=""10%"">Year</th>\n    </tr>\n    <tr>\n      <td><a href=\'https://arxiv.org/pdf/1710.09829.pdf\'> Dynamic Routing Between Capsules </a></td>\n      <td align=""left""> <ul><li> MNIST </li></ul> </td>\n      <td align=""left""> <ul><li> Test Error: 0.25\xc2\xb10.005 </li></ul> </td>\n      <td align=""left""> <ul><li>  <a href=\'https://github.com/Sarasra/models/tree/master/research/capsules\'>Official Implementation</a> </li><li> <a href=\'https://github.com/gram-ai/capsule-networks\'>PyTorch</a> </li><li> <a href=\'https://github.com/naturomics/CapsNet-Tensorflow\'>Tensorflow</a> </li><li> <a href=\'https://github.com/XifengGuo/CapsNet-Keras\'>Keras</a> </li><li>  <a href=\'https://github.com/soskek/dynamic_routing_between_capsules\'>Chainer</a> </li> <li>  <a href=\'https://github.com/loretoparisi/CapsNet\'>List of all implementations</a> </li>\n          </ul>  </td>\n      <td align=""left"">2017</td>    \n    </tr>\n    <tr>\n      <td><a href=\'https://arxiv.org/pdf/1102.0183.pdf\'> High-Performance Neural Networks for Visual Object Classification </a></td>\n      <td align=""left""> <ul><li> NORB </li></ul></td>\n      <td align=""left""> <ul><li> Test Error: 2.53 \xc2\xb1 0.40 </li></ul> </td>\n      <td align=""left""> <ul><li><a href=\'\'>NOT FOUND</a></ul></li> </td>\n      <td align=""left"">2011</td>    \n    </tr>\n    <tr>\n      <td><a href=\'https://arxiv.org/pdf/1811.06965.pdf\'>Giant AmoebaNet with GPipe</a></td>\n      <td align=""left""> <ul><li> CIFAR-10 </li> <li> CIFAR-100</li><li> ImageNet-1k</li><li> ...</li></ul></td>\n      <td align=""left""> <ul><li> Test Error: 1.0% </li> <li> Test Error: 8.7% </li><li> Top-1 Error 15.7</li><li> ...</li></ul> </td>\n      <td align=""left""> <ul><li> <a href=\'\'>NOT FOUND</a> </li></ul> </td>\n      <td align=""left"">2018</td>    \n    </tr>\n    <tr>\n      <td><a href=\'https://openreview.net/pdf?id=S1NHaMW0b\'>ShakeDrop regularization </a></td>\n      <td align=""left""> <ul><li> CIFAR-10 </li> <li> CIFAR-100</li></ul></td>\n      <td align=""left""> <ul><li> Test Error: 2.31% </li> <li> Test Error: 12.19% </li></ul> </td>\n      <td align=""left""> <ul><li> <a href=\'\'>NOT FOUND</a> </li></ul> </td>\n      <td align=""left"">2017</td>    \n    </tr>\n    <tr>\n      <td><a href=\'https://arxiv.org/pdf/1611.05431.pdf\'>Aggregated Residual Transformations for Deep Neural Networks </a></td>\n      <td align=""left""> <ul><li>  CIFAR-10  </li></ul></td>\n      <td align=""left""> <ul><li> Test Error: 3.58% </li></ul> </td>\n      <td align=""left""> <ul><li>  <a href=\'https://github.com/facebookresearch/ResNeXt\'>PyTorch</a> </li></ul> </td>\n      <td align=""left"">2017</td>    \n    </tr>\n    <tr>\n      <td><a href=\'https://arxiv.org/abs/1708.04896\'> Random Erasing Data Augmentation </a></td>\n      <td align=""left""> <ul><li> CIFAR-10 </li> <li> CIFAR-100 </li> <li> Fashion-MNIST </li> </ul></td>\n \xc2\xa0 \xc2\xa0 \xc2\xa0<td align=""left""> <ul><li> Test Error: 3.08% </li>\n          <li> Test Error: 17.73% </li>\n          <li> Test Error: 3.65% </li>\n          </ul> </td>\n      <td align=""left""> <a href=\'https://github.com/zhunzhong07/Random-Erasing\'> Pytorch </td>\n      <td align=""left"">2017</td>    \n    </tr>\n    <tr>\n      <td><a href=\'https://arxiv.org/abs/1709.07634\'> EraseReLU: A Simple Way to Ease the Training of Deep Convolution Neural Networks </a></td>\n      <td align=""left""> <ul><li> CIFAR-10 </li> <li> CIFAR-100 </li> </ul></td>\n \xc2\xa0 \xc2\xa0 \xc2\xa0<td align=""left""> <ul><li> Test Error: 3.56% </li>\n          <li> Test Error: 16.53% </li>\n          </ul> </td>\n      <td align=""left""> <a href=\'https://github.com/D-X-Y/EraseReLU\'> Pytorch </td>\n      <td align=""left"">2017</td>    \n    </tr>\n    <tr>\n      <td><a href=\'https://arxiv.org/pdf/1710.09829.pdf\'> Dynamic Routing Between Capsules </a></td>\n      <td align=""left""> <ul><li> MultiMNIST </li></ul></td>\n      <td align=""left""> <ul><li> Test Error: 5% </li></ul> </td>\n      <td align=""left""> <ul><li> <a href=\'https://github.com/gram-ai/capsule-networks\'>PyTorch</a> </li><li> <a href=\'https://github.com/naturomics/CapsNet-Tensorflow\'>Tensorflow</a> </li><li> <a href=\'https://github.com/XifengGuo/CapsNet-Keras\'>Keras</a> </li><li>  <a href=\'https://github.com/soskek/dynamic_routing_between_capsules\'>Chainer</a> </li><li>  <a href=\'https://github.com/loretoparisi/CapsNet\'>List of all implementations</a> </li></ul> </td>\n      <td align=""left"">2017</td>    \n    </tr>\n    <tr>\n      <td><a href=\'https://arxiv.org/pdf/1707.07012.pdf\'>Learning Transferable Architectures for Scalable Image Recognition</a></td>\n      <td align=""left""> <ul><li>   ImageNet-1k  </li></ul></td>\n      <td align=""left""> <ul><li> Top-1 Error:17.3 </li></ul> </td>\n      <td align=""left""> <ul><li>  <a href=\'https://github.com/tensorflow/models/tree/master/research/slim/nets/nasnet\'>Tensorflow</a> </li></ul> </td>\n      <td align=""left"">2017</td>    \n    </tr>\n     <tr>\n      <td><a href=\'https://arxiv.org/pdf/1709.01507.pdf\'>Squeeze-and-Excitation Networks </a></td>\n      <td align=""left""> <ul><li>   ImageNet-1k  </li></ul></td>\n      <td align=""left""> <ul><li> Top-1 Error: 18.68 </li></ul> </td>\n      <td align=""left""> <ul><li>  <a href=\'https://github.com/hujie-frank/SENet\'>CAFFE</a> </li></ul> </td>\n      <td align=""left"">2017</td>    \n    </tr>\n    <tr>\n      <td><a href=\'https://arxiv.org/pdf/1611.05431.pdf\'>Aggregated Residual Transformations for Deep Neural Networks </a></td>\n      <td align=""left""> <ul><li>   ImageNet-1k  </li></ul></td>\n      <td align=""left""> <ul><li> Top-1 Error: 20.4% </li></ul> </td>\n      <td align=""left""> <ul><li>  <a href=\'https://github.com/facebookresearch/ResNeXt\'>Torch</a> </li></ul> </td>\n      <td align=""left"">2016</td>    \n    </tr>\n  </tbody>\n</table>\n\n#### 2. Instance Segmentation\n<table>\n  <tbody>\n    <tr>\n      <th width=""30%"">Research Paper</th>\n      <th align=""center"" width=""20%"">Datasets</th>\n      <th align=""center"" width=""20%"">Metric</th>\n      <th align=""center"" width=""20%"">Source Code</th>\n      <th align=""center"" width=""10%"">Year</th>\n    </tr>\n    <tr>\n      <td><a href=\'https://arxiv.org/pdf/1703.06870.pdf\'>Mask R-CNN</a></td>\n      <td align=""left""> <ul><li> COCO  </li></ul></td>\n      <td align=""left""> <ul><li> Average Precision: 37.1% </li></ul> </td>\n      <td align=""left""> <ul><li>  <a href=\'https://github.com/facebookresearch/Detectron\'>Detectron (Official Version)</a> </li><li>  <a href=\'https://github.com/TuSimple/mx-maskrcnn\'>MXNet</a> </li><li>  <a href=\'https://github.com/matterport/Mask_RCNN\'>Keras</a> </li><li>  <a href=\'https://github.com/CharlesShang/FastMaskRCNN\'>TensorFlow </a> </li></ul> </td>\n      <td align=""left"">2017</td>    \n    </tr>\n  </tbody>\n</table>\n\n#### 3. Visual Question Answering\n<table>\n  <tbody>\n    <tr>\n      <th width=""30%"">Research Paper</th>\n      <th align=""center"" width=""20%"">Datasets</th>\n      <th align=""center"" width=""20%"">Metric</th>\n      <th align=""center"" width=""20%"">Source Code</th>\n      <th align=""center"" width=""10%"">Year</th>\n    </tr>\n    <tr>\n      <td><a href=\'https://arxiv.org/abs/1708.02711\'>Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge</a></td>\n      <td align=""left""> <ul><li> VQA  </li></ul></td>\n      <td align=""left""> <ul><li> Overall score: 69 </li></ul> </td>\n      <td align=""left""> <ul><li>   <a href=\'\'>NOT FOUND</a> </li></ul> </li></ul> </td>\n      <td align=""left"">2017</td>    \n    </tr>\n  </tbody>\n</table>\n\n#### 4. Person Re-identification\n<table>\n  <tbody>\n    <tr>\n      <th width=""30%"">Research Paper</th>\n      <th align=""center"" width=""20%"">Datasets</th>\n      <th align=""center"" width=""20%"">Metric</th>\n      <th align=""center"" width=""20%"">Source Code</th>\n      <th align=""center"" width=""10%"">Year</th>\n    </tr>\n    <tr>\n      <td><a href=\'https://arxiv.org/abs/1708.04896\'> Random Erasing Data Augmentation </a></td>\n      <td align=""left""> <ul><li> <a href=\'http://www.liangzheng.org/Project/project_reid.html\'> Market-1501 </a> </li> <li> <a href=\'https://github.com/zhunzhong07/person-re-ranking\'> CUHK03-new-protocol </a> </li> <li> <a href=\'https://github.com/layumi/DukeMTMC-reID_evaluation\'> DukeMTMC-reID </a> </li> </ul></td>\n \xc2\xa0 \xc2\xa0 \xc2\xa0<td align=""left""> <ul><li> Rank-1: 89.13 mAP:\xc2\xa083.93 </li>\n          <li> Rank-1: 84.02 mAP:\xc2\xa078.28 </li>\n          <li> labeled (Rank-1: 63.93 mAP:\xc2\xa065.05) detected (Rank-1: 64.43 mAP:\xc2\xa064.75) </li>\n          </ul> </td>\n      <td align=""left""> <a href=\'https://github.com/zhunzhong07/Random-Erasing\'> Pytorch </td>\n      <td align=""left"">2017</td>    \n    </tr>\n  </tbody>\n</table>\n\n### Speech\n[Speech SOTA](https://github.com/syhw/wer_are_we)\n#### 1. ASR\n\n<table>\n  <tbody>\n    <tr>\n      <th width=""30%"">Research Paper</th>\n      <th align=""center"" width=""20%"">Datasets</th>\n      <th align=""center"" width=""20%"">Metric</th>\n      <th align=""center"" width=""20%"">Source Code</th>\n      <th align=""center"" width=""10%"">Year</th>\n    </tr>\n    <tr>\n      <td><a href=\'https://arxiv.org/pdf/1708.06073.pdf\'>The Microsoft 2017 Conversational Speech Recognition System</a></td>\n      <td align=""left""> <ul><li> Switchboard Hub5\'00  </li></ul></td>\n      <td align=""left""> <ul><li> WER: 5.1  </li></ul> </td>\n      <td align=""left""> <ul><li>  <a href=\'\'>NOT FOUND</a></li></ul> </td>\n      <td align=""left"">2017</td>    \n    </tr>\n    <tr>\n      <td><a href=\'https://arxiv.org/pdf/1801.00059.pdf\'>The CAPIO 2017 Conversational Speech Recognition System</a></td>\n      <td align=""left""> <ul><li> Switchboard Hub5\'00  </li></ul></td>\n      <td align=""left""> <ul><li> WER: 5.0  </li></ul> </td>\n      <td align=""left""> <ul><li>  <a href=\'\'>NOT FOUND</a></li></ul> </td>\n      <td align=""left"">2017</td>    \n    </tr>\n  </tbody>\n</table>\n\n\n## Semi-supervised Learning\n#### Computer Vision\n<table>\n  <tbody>\n    <tr>\n      <th width=""30%"">Research Paper</th>\n      <th align=""center"" width=""20%"">Datasets</th>\n      <th align=""center"" width=""20%"">Metric</th>\n      <th align=""center"" width=""20%"">Source Code</th>\n      <th align=""center"" width=""10%"">Year</th>\n    </tr>\n    <tr>\n      <td><a href=\'https://arxiv.org/pdf/1507.00677.pdf\'> DISTRIBUTIONAL SMOOTHINGWITH VIRTUAL ADVERSARIAL TRAINING </a></td>\n      <td align=""left""> <ul><li> SVHN </li><li> NORB </li></ul></td>\n      <td align=""left""> <ul><li> Test error: 24.63 </li><li> Test error: 9.88 </li></ul> </td>\n      <td align=""left""> <a href=\'https://github.com/takerum/vat\'>Theano</a></td>\n      <td align=""left"">2016</td>    \n    </tr>\n     <tr>\n      <td><a href=\'https://arxiv.org/pdf/1704.03976.pdf\'> Virtual Adversarial Training:\na Regularization Method for Supervised and\nSemi-supervised Learning </a></td>\n      <td align=""left""> <ul><li> MNIST </li></ul></td>\n      <td align=""left""> <ul><li> Test error: 1.27 </li></ul> </td>\n      <td align=""left""> <ul><li><a href=\'\'>NOT FOUND</a></ul></li> </td>\n      <td align=""left"">2017</td>    \n    </tr>\n    <tr>\n      <td><a href=\'https://arxiv.org/pdf/1706.08249.pdf\'> Few Shot Object Detection </a></td>\n      <td align=""left""> <ul><li> VOC2007 </li><li> VOC2012 </li></ul></td>\n      <td align=""left""> <ul><li> mAP : 41.7 </li><li> mAP : 35.4 </li></ul> </td>\n      <td align=""left""> <ul><li><a href=\'\'>NOT FOUND</a></ul></li> </td>\n      <td align=""left"">2017</td>    \n    </tr>\n    <tr>\n      <td><a href=\'https://arxiv.org/pdf/1701.07717.pdf\'> Unlabeled Samples Generated by GAN\nImprove the Person Re-identification Baseline in vitro </a></td>\n      <td align=""left""> <ul><li> <a href=\'http://www.liangzheng.org/Project/project_reid.html\'> Market-1501 </a> </li> <li> CUHK-03 </li> <li> <a href=\'https://github.com/layumi/DukeMTMC-reID_evaluation\'> DukeMTMC-reID </a> </li> <li> <a href=\'http://www.vision.caltech.edu/visipedia/CUB-200-2011.html\'> CUB-200-2011 </a></li></ul></td>\n \xc2\xa0 \xc2\xa0 \xc2\xa0<td align=""left""> <ul><li> Rank-1: 83.97 mAP:\xc2\xa066.07 </li>\n          <li> Rank-1: 84.6 mAP:\xc2\xa087.4 </li>\n          <li> Rank-1: 67.68 mAP:\xc2\xa047.13 </li>\n \xc2\xa0 \xc2\xa0 \xc2\xa0 \xc2\xa0 \xc2\xa0<li> Test Accuracy: 84.4 </li>\n          </ul> </td>\n      <td align=""left""> <a href=\'https://github.com/layumi/Person-reID_GAN\'> Matconvnet </td>\n      <td align=""left"">2017</td>    \n    </tr>\n      \n  </tbody>\n</table>\n\n## Unsupervised Learning\n\n#### Computer Vision\n##### 1. Generative Model\n<table>\n  <tbody>\n    <tr>\n      <th width=""30%"">Research Paper</th>\n      <th align=""center"" width=""20%"">Datasets</th>\n      <th align=""center"" width=""20%"">Metric</th>\n      <th align=""center"" width=""20%"">Source Code</th>\n      <th align=""center"" width=""10%"">Year</th>\n    </tr>\n    <tr>\n      <td><a href=\'http://research.nvidia.com/sites/default/files/publications/karras2017gan-paper-v2.pdf\'> PROGRESSIVE GROWING OF GANS FOR IMPROVED QUALITY, STABILITY, AND VARIATION </a></td>\n       <td align=""left"">Unsupervised CIFAR 10</td>\n      <td align=""left"">Inception score: 8.80 </td>\n      <td align=""left""> <a href=\'https://github.com/tkarras/progressive_growing_of_gans\'>Theano</a></td>\n      <td align=""left"">2017</td>    \n    </tr>\n  </tbody>\n</table>\n\n### NLP\n\n#### Machine Translation\n\n\n<table>\n  <tbody>\n    <tr>\n      <th width=""30%"">Research Paper</th>\n      <th align=""center"" width=""20%"">Datasets</th>\n      <th align=""center"" width=""20%"">Metric</th>\n      <th align=""center"" width=""20%"">Source Code</th>\n      <th align=""center"" width=""10%"">Year</th>\n       <tr> \n      <td><a href=\'https://arxiv.org/pdf/1711.00043.pdf\'>UNSUPERVISED MACHINE TRANSLATION\nUSING MONOLINGUAL CORPORA ONLY</a></td>\n      <td align=""left""> <ul><li> Multi30k-Task1(en-fr fr-en de-en en-de)  </li></ul></td>\n      <td align=""left""> <ul><li> BLEU:(32.76 32.07 26.26 22.74) </li></ul> </td>\n      <td align=""left""><ul><li><a href=\'\'>NOT FOUND</a></ul></li></td>\n      <td align=""left"">2017</td>    \n    </tr>\n        <tr> \n      <td><a href=\'https://arxiv.org/pdf/1804.09057.pdf\'>Unsupervised Neural Machine Translation with Weight Sharing</a></td>\n      <td align=""left""> <ul><li> WMT14(en-fr fr-en)  </li><li> WMT16 (de-en en-de) </li></ul></td>\n      <td align=""left""> <ul><li> BLEU:(16.97 15.58) </li> <li> BLEU:(14.62 10.86) </li></ul> </td>\n      <td align=""left""><ul><li><a href=\'\'>NOT FOUND</a></ul></li></td>\n      <td align=""left"">2018</td>    \n    </tr>\n     \n\n  </tbody>\n</table>  \n\n## Transfer Learning\n\n<table>\n  <tbody>\n    <tr>\n      <th width=""30%"">Research Paper</th>\n      <th align=""center"" width=""20%"">Datasets</th>\n      <th align=""center"" width=""20%"">Metric</th>\n      <th align=""center"" width=""20%"">Source Code</th>\n      <th align=""center"" width=""10%"">Year</th>\n       <tr> \n      <td><a href=\'https://arxiv.org/pdf/1706.05137.pdf\'>One Model To Learn Them All</a></td>\n      <td align=""left""> <ul><li> WMT EN \xe2\x86\x92 DE </li><li> WMT EN \xe2\x86\x92 FR (BLEU) </li><li> ImageNet (top-5 accuracy) </li></ul></td>\n      <td align=""left""> <ul><li> BLEU: 21.2 </li> <li> BLEU:30.5  </li><li> 86% </li></ul> </td>\n      <td align=""left""><ul><li><a href=\'https://github.com/tensorflow/tensor2tensor\'>Tensorflow</a></ul></li></td>\n      <td align=""left"">2017</td>    \n    </tr>\n      \n\n  </tbody>\n</table>  \n\n\n\n## Reinforcement Learning\n<table>\n  <tbody>\n    <tr>\n      <th width=""30%"">Research Paper</th>\n      <th align=""center"" width=""20%"">Datasets</th>\n      <th align=""center"" width=""20%"">Metric</th>\n      <th align=""center"" width=""20%"">Source Code</th>\n      <th align=""center"" width=""10%"">Year</th>\n       <tr> \n      <td><a href=\'http://www.gwern.net/docs/rl/2017-silver.pdf\'>Mastering the game of Go without human knowledge</a></td>\n      <td align=""left""> the game of Go </td>\n      <td align=""left""> ElO Rating: 5185</td>\n      <td align=""left""><ul><li><a href=https://github.com/gcp/leela-zero>C++</a></ul></li></td>\n      <td align=""left"">2017</td>    \n    </tr>\n      \n\n  </tbody>\n</table>  \n\nEmail: yxt.stoaml@gmail.com\n'"
84,nfmcclure/tensorflow_cookbook,nfmcclure,Code for Tensorflow Machine Learning Cookbook,2016-06-10 13:23:57,2020-06-18 03:17:12,Jupyter Notebook,2381,5590,"b'<img src=""https://github.com/nfmcclure/tensorflow_cookbook/raw/master/images/book_covers.jpg"" data-canonical-src=""https://github.com/nfmcclure/tensorflow_cookbook/raw/master/images/book_covers.jpg"" width=""400"" height=""250"" />\n\n# [TensorFlow Machine Learning Cookbook](https://www.packtpub.com/big-data-and-business-intelligence/tensorflow-machine-learning-cookbook)\n\n## [A Packt Publishing Book](https://www.packtpub.com/big-data-and-business-intelligence/tensorflow-machine-learning-cookbook)\n\n### By Nick McClure\n\n=================\n\nBuild: [![Build Status](https://travis-ci.org/nfmcclure/tensorflow_cookbook.svg?branch=master)](https://travis-ci.org/nfmcclure/tensorflow_cookbook)\n\n=================\n\n\nTable of Contents\n=================\n\n  * [Ch 1: Getting Started with TensorFlow](#ch-1-getting-started-with-tensorflow)\n  * [Ch 2: The TensorFlow Way](#ch-2-the-tensorflow-way)\n  * [Ch 3: Linear Regression](#ch-3-linear-regression)\n  * [Ch 4: Support Vector Machines](#ch-4-support-vector-machines)\n  * [Ch 5: Nearest Neighbor Methods](#ch-5-nearest-neighbor-methods)\n  * [Ch 6: Neural Networks](#ch-6-neural-networks)\n  * [Ch 7: Natural Language Processing](#ch-7-natural-language-processing)\n  * [Ch 8: Convolutional Neural Networks](#ch-8-convolutional-neural-networks)\n  * [Ch 9: Recurrent Neural Networks](#ch-9-recurrent-neural-networks)\n  * [Ch 10: Taking TensorFlow to Production](#ch-10-taking-tensorflow-to-production)\n  * [Ch 11: More with TensorFlow](#ch-11-more-with-tensorflow)\n\n---\n\n## [Ch 1: Getting Started with TensorFlow](01_Introduction#ch-1-getting-started-with-tensorflow)\n<kbd>\n  <a href=""01_Introduction/01_How_TensorFlow_Works#introduction-to-how-tensorflow-graphs-work"">\n    <img src=""01_Introduction/images/01_outline.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""01_Introduction/02_Creating_and_Using_Tensors#creating-and-using-tensors"">\n    <img src=""01_Introduction/images/02_variable.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""01_Introduction/03_Using_Variables_and_Placeholders#variables-and-placeholders"">\n    <img src=""01_Introduction/images/03_placeholder.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""01_Introduction/06_Implementing_Activation_Functions#activation-functions"">\n    <img src=""01_Introduction/images/06_activation_funs1.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""01_Introduction/06_Implementing_Activation_Functions#activation-functions"">\n    <img src=""01_Introduction/images/06_activation_funs2.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n\nThis chapter intends to introduce the main objects and concepts in TensorFlow.  We also introduce how to access the data for the rest of the book and provide additional resources for learning about TensorFlow.\n\n 1. [General Outline of TF Algorithms](01_Introduction/01_How_TensorFlow_Works#introduction-to-how-tensorflow-graphs-work)\n  * Here we introduce TensorFlow and the general outline of how most TensorFlow algorithms work.\n 2. [Creating and Using Tensors](01_Introduction/02_Creating_and_Using_Tensors#creating-and-using-tensors)\n  * How to create and initialize tensors in TensorFlow.  We also depict how these operations appear in Tensorboard.\n 3. [Using Variables and Placeholders](01_Introduction/03_Using_Variables_and_Placeholders#variables-and-placeholders)\n  * How to create and use variables and placeholders in TensorFlow.  We also depict how these operations appear in Tensorboard.\n 4. [Working with Matrices](01_Introduction/04_Working_with_Matrices#working-with-matrices)\n  * Understanding how TensorFlow can work with matrices is crucial to understanding how the algorithms work.\n 5. [Declaring Operations](01_Introduction/05_Declaring_Operations#declaring-operations)\n  * How to use various mathematical operations in TensorFlow.\n 6. [Implementing Activation Functions](01_Introduction/06_Implementing_Activation_Functions#activation-functions)\n  * Activation functions are unique functions that TensorFlow has built in for your use in algorithms.\n 7. [Working with Data Sources](01_Introduction/07_Working_with_Data_Sources#data-source-information)\n  * Here we show how to access all the various required data sources in the book.  There are also links describing the data sources and where they come from.\n 8. [Additional Resources](01_Introduction/08_Additional_Resources#additional-resources)\n  * Mostly official resources and papers.  The papers are TensorFlow papers or Deep Learning resources.\n\n## [Ch 2: The TensorFlow Way](02_TensorFlow_Way#ch-2-the-tensorflow-way)\n<kbd>\n  <a href=""02_TensorFlow_Way/01_Operations_as_a_Computational_Graph#operations-as-a-computational-graph"">\n    <img src=""02_TensorFlow_Way/images/01_Operations_on_a_Graph.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""02_TensorFlow_Way/02_Layering_Nested_Operations#multiple-operations-on-a-computational-graph"">\n    <img src=""02_TensorFlow_Way/images/02_Multiple_Operations.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""02_TensorFlow_Way/03_Working_with_Multiple_Layers#working-with-multiple-layers"">\n    <img src=""02_TensorFlow_Way/images/03_Multiple_Layers.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""02_TensorFlow_Way/04_Implementing_Loss_Functions#implementing-loss-functions"">\n    <img src=""02_TensorFlow_Way/images/04_loss_fun1.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""02_TensorFlow_Way/05_Implementing_Back_Propagation#implementing-back-propagation"">\n    <img src=""02_TensorFlow_Way/images/04_loss_fun2.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""02_TensorFlow_Way/06_Working_with_Batch_and_Stochastic_Training#working-with-batch-and-stochastic-training"">\n    <img src=""02_TensorFlow_Way/images/06_Back_Propagation.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""02_TensorFlow_Way/07_Combining_Everything_Together#combining-everything-together"">\n    <img src=""02_TensorFlow_Way/images/07_Combing_Everything_Together.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""02_TensorFlow_Way/08_Evaluating_Models#evaluating-models"">\n    <img src=""02_TensorFlow_Way/images/08_Evaluating_Models.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n\nAfter we have established the basic objects and methods in TensorFlow, we now want to establish the components that make up TensorFlow algorithms.  We start by introducing computational graphs, and then move to loss functions and back propagation.  We end with creating a simple classifier and then show an example of evaluating regression and classification algorithms.\n\n 1. [One Operation as a Computational Graph](02_TensorFlow_Way/01_Operations_as_a_Computational_Graph#operations-as-a-computational-graph)\n  * We show how to create an operation on a computational graph and how to visualize it using Tensorboard.\n 2. [Layering Nested Operations](02_TensorFlow_Way/02_Layering_Nested_Operations#multiple-operations-on-a-computational-graph)\n  * We show how to create multiple operations on a computational graph and how to visualize them using Tensorboard.\n 3. [Working with Multiple Layers](02_TensorFlow_Way/03_Working_with_Multiple_Layers#working-with-multiple-layers)\n  * Here we extend the usage of the computational graph to create multiple layers and show how they appear in Tensorboard.\n 4. [Implementing Loss Functions](02_TensorFlow_Way/04_Implementing_Loss_Functions#implementing-loss-functions)\n  * In order to train a model, we must be able to evaluate how well it is doing. This is given by loss functions. We plot various loss functions and talk about the benefits and limitations of some.\n 5. [Implementing Back Propagation](02_TensorFlow_Way/05_Implementing_Back_Propagation#implementing-back-propagation)\n  * Here we show how to use loss functions to iterate through data and back propagate errors for regression and classification.\n 6. [Working with Stochastic and Batch Training](02_TensorFlow_Way/06_Working_with_Batch_and_Stochastic_Training#working-with-batch-and-stochastic-training)\n  * TensorFlow makes it easy to use both batch and stochastic training. We show how to implement both and talk about the benefits and limitations of each.\n 7. [Combining Everything Together](02_TensorFlow_Way/07_Combining_Everything_Together#combining-everything-together)\n  * We now combine everything together that we have learned and create a simple classifier.\n 8. [Evaluating Models](02_TensorFlow_Way/08_Evaluating_Models#evaluating-models)\n  * Any model is only as good as it\'s evaluation.  Here we show two examples of (1) evaluating a regression algorithm and (2) a classification algorithm.\n\n## [Ch 3: Linear Regression](03_Linear_Regression#ch-3-linear-regression)\n\n<kbd>\n  <a href=""03_Linear_Regression/01_Using_the_Matrix_Inverse_Method#using-the-matrix-inverse-method"">\n    <img src=""03_Linear_Regression/images/01_Inverse_Matrix_Method.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""03_Linear_Regression/02_Implementing_a_Decomposition_Method#using-the-cholesky-decomposition-method"">\n    <img src=""03_Linear_Regression/images/02_Cholesky_Decomposition.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""03_Linear_Regression/03_TensorFlow_Way_of_Linear_Regression#learning-the-tensorflow-way-of-regression"">\n    <img src=""03_Linear_Regression/images/03_lin_reg_fit.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""03_Linear_Regression/04_Loss_Functions_in_Linear_Regressions#loss-functions-in-linear-regression"">\n    <img src=""03_Linear_Regression/images/04_L1_L2_learningrates.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""03_Linear_Regression/05_Implementing_Deming_Regression#implementing-deming-regression"">\n    <img src=""03_Linear_Regression/images/05_demming_vs_linear_reg.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""03_Linear_Regression/06_Implementing_Lasso_and_Ridge_Regression#implementing-lasso-and-ridge-regression"">\n    <img src=""03_Linear_Regression/images/07_elasticnet_reg_loss.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""03_Linear_Regression/07_Implementing_Elasticnet_Regression#implementing-elasticnet-regression"">\n    <img src=""03_Linear_Regression/images/07_elasticnet_reg_loss.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""03_Linear_Regression/08_Implementing_Logistic_Regression#implementing-logistic-regression"">\n    <img src=""03_Linear_Regression/images/08_logistic_reg_acc.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n\nHere we show how to implement various linear regression techniques in TensorFlow.  The first two sections show how to do standard matrix linear regression solving in TensorFlow.  The remaining six sections depict how to implement various types of regression using computational graphs in TensorFlow.\n\n 1. [Using the Matrix Inverse Method](03_Linear_Regression/01_Using_the_Matrix_Inverse_Method#using-the-matrix-inverse-method)\n  * How to solve a 2D regression with a matrix inverse in TensorFlow.\n 2. [Implementing a Decomposition Method](03_Linear_Regression/02_Implementing_a_Decomposition_Method#using-the-cholesky-decomposition-method)\n  * Solving a 2D linear regression with Cholesky decomposition.\n 3. [Learning the TensorFlow Way of Linear Regression](03_Linear_Regression/03_TensorFlow_Way_of_Linear_Regression#learning-the-tensorflow-way-of-regression)\n  * Linear regression iterating through a computational graph with L2 Loss.\n 4. [Understanding Loss Functions in Linear Regression](03_Linear_Regression/04_Loss_Functions_in_Linear_Regressions#loss-functions-in-linear-regression)\n  * L2 vs L1 loss in linear regression.  We talk about the benefits and limitations of both.\n 5. [Implementing Deming Regression (Total Regression)](03_Linear_Regression/05_Implementing_Deming_Regression#implementing-deming-regression)\n  * Deming (total) regression implemented in TensorFlow by changing the loss function.\n 6. [Implementing Lasso and Ridge Regression](03_Linear_Regression/06_Implementing_Lasso_and_Ridge_Regression#implementing-lasso-and-ridge-regression)\n  * Lasso and Ridge regression are ways of regularizing the coefficients. We implement both of these in TensorFlow via changing the loss functions.\n 7. [Implementing Elastic Net Regression](03_Linear_Regression/07_Implementing_Elasticnet_Regression#implementing-elasticnet-regression)\n  * Elastic net is a regularization technique that combines the L2 and L1 loss for coefficients.  We show how to implement this in TensorFlow.\n 8. [Implementing Logistic Regression](03_Linear_Regression/08_Implementing_Logistic_Regression#implementing-logistic-regression)\n  * We implement logistic regression by the use of an activation function in our computational graph.\n\n## [Ch 4: Support Vector Machines](04_Support_Vector_Machines#ch-4-support-vector-machines)\n\n<kbd>\n  <a href=""04_Support_Vector_Machines/01_Introduction#support-vector-machine-introduction"">\n    <img src=""04_Support_Vector_Machines/images/01_introduction.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""04_Support_Vector_Machines/02_Working_with_Linear_SVMs#working-with-linear-svms"">\n    <img src=""04_Support_Vector_Machines/images/02_linear_svm_output.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""04_Support_Vector_Machines/03_Reduction_to_Linear_Regression#svm-reduction-to-linear-regression"">\n    <img src=""04_Support_Vector_Machines/images/03_svm_regression_output.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""04_Support_Vector_Machines/04_Working_with_Kernels#working-with-kernels"">\n    <img src=""04_Support_Vector_Machines/images/04_linear_svm_gaussian.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""04_Support_Vector_Machines/05_Implementing_Nonlinear_SVMs#implementing-nonlinear-svms"">\n    <img src=""04_Support_Vector_Machines/images/05_non_linear_svms.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""04_Support_Vector_Machines/06_Implementing_Multiclass_SVMs#implementing-multiclass-svms"">\n    <img src=""04_Support_Vector_Machines/images/06_multiclass_svm.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n\nThis chapter shows how to implement various SVM methods with TensorFlow.  We first create a linear SVM and also show how it can be used for regression.  We then introduce kernels (RBF Gaussian kernel) and show how to use it to split up non-linear data. We finish with a multi-dimensional implementation of non-linear SVMs to work with multiple classes.\n\n\n 1. [Introduction](04_Support_Vector_Machines/01_Introduction#support-vector-machine-introduction)\n  * We introduce the concept of SVMs and how we will go about implementing them in the TensorFlow framework.\n 2. [Working with Linear SVMs](04_Support_Vector_Machines/02_Working_with_Linear_SVMs#working-with-linear-svms)\n  * We create a linear SVM to separate I. setosa based on sepal length and pedal width in the Iris data set.\n 3. [Reduction to Linear Regression](04_Support_Vector_Machines/03_Reduction_to_Linear_Regression#svm-reduction-to-linear-regression)\n  * The heart of SVMs is separating classes with a line.  We change tweek the algorithm slightly to perform SVM regression.\n 4. [Working with Kernels in TensorFlow](04_Support_Vector_Machines/04_Working_with_Kernels#working-with-kernels)\n  * In order to extend SVMs into non-linear data, we explain and show how to implement different kernels in TensorFlow.\n 5. [Implementing Non-Linear SVMs](04_Support_Vector_Machines/05_Implementing_Nonlinear_SVMs#implementing-nonlinear-svms)\n  * We use the Gaussian kernel (RBF) to separate non-linear classes.\n 6. [Implementing Multi-class SVMs](04_Support_Vector_Machines/06_Implementing_Multiclass_SVMs#implementing-multiclass-svms)\n  * SVMs are inherently binary predictors.  We show how to extend them in a one-vs-all strategy in TensorFlow.\n\n## [Ch 5: Nearest Neighbor Methods](05_Nearest_Neighbor_Methods#ch-5-nearest-neighbor-methods)\n<kbd>\n  <a href=""05_Nearest_Neighbor_Methods/01_Introduction#nearest-neighbor-methods-introduction"">\n    <img src=""05_Nearest_Neighbor_Methods/images/nearest_neighbor_intro.jpg"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""05_Nearest_Neighbor_Methods/02_Working_with_Nearest_Neighbors#working-with-nearest-neighbors"">\n    <img src=""05_Nearest_Neighbor_Methods/images/02_nn_histogram.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""05_Nearest_Neighbor_Methods/03_Working_with_Text_Distances#working-with-text-distances"">\n    <img src=""05_Nearest_Neighbor_Methods/images/image.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""05_Nearest_Neighbor_Methods/04_Computing_with_Mixed_Distance_Functions#computing-with-mixed-distance-functions"">\n    <img src=""05_Nearest_Neighbor_Methods/images/04_pred_vs_actual.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""05_Nearest_Neighbor_Methods/05_An_Address_Matching_Example#an-address-matching-example"">\n    <img src=""05_Nearest_Neighbor_Methods/images/image.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""05_Nearest_Neighbor_Methods/06_Nearest_Neighbors_for_Image_Recognition#nearest-neighbors-for-image-recognition"">\n    <img src=""05_Nearest_Neighbor_Methods/images/06_nn_image_recognition.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n\nNearest Neighbor methods are a very popular ML algorithm.  We show how to implement k-Nearest Neighbors, weighted k-Nearest Neighbors, and k-Nearest Neighbors with mixed distance functions.  In this chapter we also show how to use the Levenshtein distance (edit distance) in TensorFlow, and use it to calculate the distance between strings. We end this chapter with showing how to use k-Nearest Neighbors for categorical prediction with the MNIST handwritten digit recognition.\n\n 1. [Introduction](05_Nearest_Neighbor_Methods/01_Introduction#nearest-neighbor-methods-introduction)\n  * We introduce the concepts and methods needed for performing k-Nearest Neighbors in TensorFlow.\n 2. [Working with Nearest Neighbors](05_Nearest_Neighbor_Methods/02_Working_with_Nearest_Neighbors#working-with-nearest-neighbors)\n  * We create a nearest neighbor algorithm that tries to predict housing worth (regression).\n 3. [Working with Text Based Distances](05_Nearest_Neighbor_Methods/03_Working_with_Text_Distances#working-with-text-distances)\n  * In order to use a distance function on text, we show how to use edit distances in TensorFlow.\n 4. [Computing Mixing Distance Functions](05_Nearest_Neighbor_Methods/04_Computing_with_Mixed_Distance_Functions#computing-with-mixed-distance-functions)\n  * Here we implement scaling of the distance function by the standard deviation of the input feature for k-Nearest Neighbors.\n 5. [Using Address Matching](05_Nearest_Neighbor_Methods/05_An_Address_Matching_Example#an-address-matching-example)\n  * We use a mixed distance function to match addresses. We use numerical distance for zip codes, and string edit distance for street names. The street names are allowed to have typos.\n 6. [Using Nearest Neighbors for Image Recognition](05_Nearest_Neighbor_Methods/06_Nearest_Neighbors_for_Image_Recognition#nearest-neighbors-for-image-recognition)\n  * The MNIST digit image collection is a great data set for illustration of how to perform k-Nearest Neighbors for an image classification task.\n\n## [Ch 6: Neural Networks](06_Neural_Networks#ch-6-neural-networks)\n\n<kbd>\n  <a href=""06_Neural_Networks/01_Introduction#neural-networks-introduction"">\n    <img src=""06_Neural_Networks/images/image.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""06_Neural_Networks/02_Implementing_an_Operational_Gate#implementing-an-operational-gate"">\n    <img src=""06_Neural_Networks/images/02_operational_gates.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""06_Neural_Networks/03_Working_with_Activation_Functions#working-with-activation-functions"">\n    <img src=""06_Neural_Networks/images/03_activation1.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""06_Neural_Networks/04_Single_Hidden_Layer_Network#implementing-a-one-layer-neural-network"">\n    <img src=""06_Neural_Networks/images/04_nn_layout.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""06_Neural_Networks/05_Implementing_Different_Layers#implementing-different-layers"">\n    <img src=""06_Neural_Networks/images/image.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""06_Neural_Networks/06_Using_Multiple_Layers#using-multiple-layers"">\n    <img src=""06_Neural_Networks/images/06_nn_multiple_layers_loss.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""06_Neural_Networks/07_Improving_Linear_Regression#improving-linear-regression"">\n    <img src=""06_Neural_Networks/images/07_lin_reg_loss.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""06_Neural_Networks/08_Learning_Tic_Tac_Toe#learning-to-play-tic-tac-toe"">\n    <img src=""06_Neural_Networks/images/08_tictactoe_layout.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n\nNeural Networks are very important in machine learning and growing in popularity due to the major breakthroughs in prior unsolved problems.  We must start with introducing \'shallow\' neural networks, which are very powerful and can help us improve our prior ML algorithm results.  We start by introducing the very basic NN unit, the operational gate.  We gradually add more and more to the neural network and end with training a model to play tic-tac-toe.\n\n 1. [Introduction](06_Neural_Networks/01_Introduction#neural-networks-introduction)\n  * We introduce the concept of neural networks and how TensorFlow is built to easily handle these algorithms.\n 2. [Implementing Operational Gates](06_Neural_Networks/02_Implementing_an_Operational_Gate#implementing-an-operational-gate)\n  * We implement an operational gate with one operation. Then we show how to extend this to multiple nested operations.\n 3. [Working with Gates and Activation Functions](06_Neural_Networks/03_Working_with_Activation_Functions#working-with-activation-functions)\n  * Now we have to introduce activation functions on the gates.  We show how different activation functions operate.\n 4. [Implementing a One Layer Neural Network](06_Neural_Networks/04_Single_Hidden_Layer_Network#implementing-a-one-layer-neural-network)\n  * We have all the pieces to start implementing our first neural network.  We do so here with regression on the Iris data set.\n 5. [Implementing Different Layers](06_Neural_Networks/05_Implementing_Different_Layers#implementing-different-layers)\n  * This section introduces the convolution layer and the max-pool layer.  We show how to chain these together in a 1D and 2D example with fully connected layers as well.\n 6. [Using Multi-layer Neural Networks](06_Neural_Networks/06_Using_Multiple_Layers#using-multiple-layers)\n  * Here we show how to functionalize different layers and variables for a cleaner multi-layer neural network.\n 7. [Improving Predictions of Linear Models](06_Neural_Networks/07_Improving_Linear_Regression#improving-linear-regression)\n  * We show how we can improve the convergence of our prior logistic regression with a set of hidden layers.\n 8. [Learning to Play Tic-Tac-Toe](06_Neural_Networks/08_Learning_Tic_Tac_Toe#learning-to-play-tic-tac-toe)\n  * Given a set of tic-tac-toe boards and corresponding optimal moves, we train a neural network classification model to play.  At the end of the script, you can attempt to play against the trained model.\n\n## [Ch 7: Natural Language Processing](07_Natural_Language_Processing#ch-7-natural-language-processing)\n\n<kbd>\n  <a href=""07_Natural_Language_Processing/01_Introduction#natural-language-processing-introduction"">\n    <img src=""07_Natural_Language_Processing/images/image.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""07_Natural_Language_Processing/02_Working_with_Bag_of_Words#working-with-bag-of-words"">\n    <img src=""07_Natural_Language_Processing/images/02_bag_of_words.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""07_Natural_Language_Processing/03_Implementing_tf_idf#implementing-tf-idf"">\n    <img src=""07_Natural_Language_Processing/images/03_tfidf_acc.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""07_Natural_Language_Processing/04_Working_With_Skip_Gram_Embeddings#working-with-skip-gram-embeddings"">\n    <img src=""07_Natural_Language_Processing/images/04_skipgram_model.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""07_Natural_Language_Processing/05_Working_With_CBOW_Embeddings#working-with-cbow-embeddings"">\n    <img src=""07_Natural_Language_Processing/images/05_cbow_model.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""07_Natural_Language_Processing/06_Using_Word2Vec_Embeddings#using-word2vec-embeddings"">\n    <img src=""07_Natural_Language_Processing/images/06_word2vec_loss.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""07_Natural_Language_Processing/07_Sentiment_Analysis_With_Doc2Vec#sentiment-analysis-with-doc2vec"">\n    <img src=""07_Natural_Language_Processing/images/07_sentiment_doc2vec_loss.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n\nNatural Language Processing (NLP) is a way of processing textual information into numerical summaries, features, or models. In this chapter we will motivate and explain how to best deal with text in TensorFlow.  We show how to implement the classic \'Bag-of-Words\' and show that there may be better ways to embed text based on the problem at hand. There are neural network embeddings called Word2Vec (CBOW and Skip-Gram) and Doc2Vec.  We show how to implement all of these in TensorFlow.\n\n 1. [Introduction](07_Natural_Language_Processing/01_Introduction#natural-language-processing-introduction)\n  * We introduce methods for turning text into numerical vectors. We introduce the TensorFlow \'embedding\' feature as well.\n 2. [Working with Bag-of-Words](07_Natural_Language_Processing/02_Working_with_Bag_of_Words#working-with-bag-of-words)\n  * Here we use TensorFlow to do a one-hot-encoding of words called bag-of-words.  We use this method and logistic regression to predict if a text message is spam or ham.\n 3. [Implementing TF-IDF](07_Natural_Language_Processing/03_Implementing_tf_idf#implementing-tf-idf)\n  * We implement Text Frequency - Inverse Document Frequency (TFIDF) with a combination of Sci-kit Learn and TensorFlow. We perform logistic regression on TFIDF vectors to improve on our spam/ham text-message predictions.\n 4. [Working with Skip-Gram](07_Natural_Language_Processing/04_Working_With_Skip_Gram_Embeddings#working-with-skip-gram-embeddings)\n  * Our first implementation of Word2Vec called, ""skip-gram"" on a movie review database.\n 5. [Working with CBOW](07_Natural_Language_Processing/05_Working_With_CBOW_Embeddings#working-with-cbow-embeddings)\n  * Next, we implement a form of Word2Vec called, ""CBOW"" (Continuous Bag of Words) on a movie review database.  We also introduce method to saving and loading word embeddings.\n 6. [Implementing Word2Vec Example](07_Natural_Language_Processing/06_Using_Word2Vec_Embeddings#using-word2vec-embeddings)\n  * In this example, we use the prior saved CBOW word embeddings to improve on our TF-IDF logistic regression of movie review sentiment.\n 7. [Performing Sentiment Analysis with Doc2Vec](07_Natural_Language_Processing/07_Sentiment_Analysis_With_Doc2Vec#sentiment-analysis-with-doc2vec)\n  * Here, we introduce a Doc2Vec method (concatenation of doc and word embeddings) to improve out logistic model of movie review sentiment.\n\n## [Ch 8: Convolutional Neural Networks](08_Convolutional_Neural_Networks#ch-8-convolutional-neural-networks)\n\n<kbd>\n  <a href=""08_Convolutional_Neural_Networks/01_Intro_to_CNN#introduction-to-convolutional-neural-networks"">\n    <img src=""08_Convolutional_Neural_Networks/images/01_intro_cnn.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""08_Convolutional_Neural_Networks/02_Intro_to_CNN_MNIST#introduction-to-cnn-with-mnist"">\n    <img src=""08_Convolutional_Neural_Networks/images/02_cnn1_mnist_output.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""08_Convolutional_Neural_Networks/03_CNN_CIFAR10#cifar-10-cnn"">\n    <img src=""08_Convolutional_Neural_Networks/images/03_cnn2_loss_acc.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""08_Convolutional_Neural_Networks/04_Retraining_Current_Architectures#retraining-fine-tuning-current-cnn-architectures"">\n    <img src=""08_Convolutional_Neural_Networks/images/image.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""08_Convolutional_Neural_Networks/05_Stylenet_NeuralStyle#stylenet--neural-style"">\n    <img src=""08_Convolutional_Neural_Networks/images/05_stylenet_ex.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""08_Convolutional_Neural_Networks/06_Deepdream#deepdream-in-tensorflow"">\n    <img src=""08_Convolutional_Neural_Networks/images/06_deepdream_ex.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n\nConvolutional Neural Networks (CNNs) are ways of getting neural networks to deal with image data. CNN derive their name from the use of a convolutional layer that applies a fixed size filter across a larger image, recognizing a pattern in any part of the image. There are many other tools that they use (max-pooling, dropout, etc...) that we show how to implement with TensorFlow.  We also show how to retrain an existing architecture and take CNNs further with Stylenet and Deep Dream.\n\n 1. [Introduction](08_Convolutional_Neural_Networks/01_Intro_to_CNN#introduction-to-convolutional-neural-networks)\n  * We introduce convolutional neural networks (CNN), and how we can use them in TensorFlow.\n 2. [Implementing a Simple CNN.](08_Convolutional_Neural_Networks/02_Intro_to_CNN_MNIST#introduction-to-cnn-with-mnist)\n  * Here, we show how to create a CNN architecture that performs well on the MNIST digit recognition task.\n 3. [Implementing an Advanced CNN.](08_Convolutional_Neural_Networks/03_CNN_CIFAR10#cifar-10-cnn)\n  * In this example, we show how to replicate an architecture for the CIFAR-10 image recognition task.\n 4. [Retraining an Existing Architecture.](08_Convolutional_Neural_Networks/04_Retraining_Current_Architectures#retraining-fine-tuning-current-cnn-architectures)\n  * We show how to download and setup the CIFAR-10 data for the TensorFlow retraining/fine-tuning tutorial.\n 5. [Using Stylenet/NeuralStyle.](08_Convolutional_Neural_Networks/05_Stylenet_NeuralStyle#stylenet--neural-style)\n  * In this recipe, we show a basic implementation of using Stylenet or Neuralstyle.\n 6. [Implementing Deep Dream.](08_Convolutional_Neural_Networks/06_Deepdream#deepdream-in-tensorflow)\n  * This script shows a line-by-line explanation of TensorFlow\'s deepdream tutorial. Taken from [Deepdream on TensorFlow](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/tutorials/deepdream). Note that the code here is converted to Python 3.\n\n## [Ch 9: Recurrent Neural Networks](09_Recurrent_Neural_Networks#ch-9-recurrent-neural-networks)\n\n<kbd>\n  <a href=""09_Recurrent_Neural_Networks/01_Introduction#introduction-to-rnns-in-tensorflow"">\n    <img src=""09_Recurrent_Neural_Networks/images/01_RNN_Seq2Seq.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""09_Recurrent_Neural_Networks/02_Implementing_RNN_for_Spam_Prediction#implementing-an-rnn-for-spam-prediction"">\n    <img src=""09_Recurrent_Neural_Networks/images/02_RNN_Spam_Acc_Loss.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""09_Recurrent_Neural_Networks/03_Implementing_LSTM#implementing-an-lstm-model"">\n    <img src=""09_Recurrent_Neural_Networks/images/03_LSTM_Loss.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""09_Recurrent_Neural_Networks/04_Stacking_Multiple_LSTM_Layers#stacking-multiple-lstm-layers"">\n    <img src=""09_Recurrent_Neural_Networks/images/04_MultipleRNN_Architecture.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""09_Recurrent_Neural_Networks/05_Creating_A_Sequence_To_Sequence_Model#creating-a-sequence-to-sequence-model-with-tensorflow-seq2seq"">\n    <img src=""09_Recurrent_Neural_Networks/images/05_Seq2Seq_Loss.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""09_Recurrent_Neural_Networks/06_Training_A_Siamese_Similarity_Measure#training-a-siamese-similarity-measure-rnns"">\n    <img src=""09_Recurrent_Neural_Networks/images/06_Similarity_RNN.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n\nRecurrent Neural Networks (RNNs) are very similar to regular neural networks except that they allow \'recurrent\' connections, or loops that depend on the prior states of the network. This allows RNNs to efficiently deal with sequential data, whereas other types of networks cannot. We then motivate the usage of LSTM (Long Short Term Memory) networks as a way of addressing regular RNN problems. Then we show how easy it is to implement these RNN types in TensorFlow.\n\n 1. [Introduction](09_Recurrent_Neural_Networks/01_Introduction#introduction-to-rnns-in-tensorflow)\n  * We introduce Recurrent Neural Networks and how they are able to feed in a sequence and predict either a fixed target (categorical/numerical) or another sequence (sequence to sequence).\n 2. [Implementing an RNN Model for Spam Prediction](09_Recurrent_Neural_Networks/02_Implementing_RNN_for_Spam_Prediction#implementing-an-rnn-for-spam-prediction)\n  * In this example, we create an RNN model to improve on our spam/ham SMS text predictions.\n 3. [Implementing an LSTM Model for Text Generation](09_Recurrent_Neural_Networks/03_Implementing_LSTM#implementing-an-lstm-model)\n  * We show how to implement a LSTM (Long Short Term Memory) RNN for Shakespeare language generation. (Word level vocabulary)\n 4. [Stacking Multiple LSTM Layers](09_Recurrent_Neural_Networks/04_Stacking_Multiple_LSTM_Layers#stacking-multiple-lstm-layers)\n  * We stack multiple LSTM layers to improve on our Shakespeare language generation. (Character level vocabulary)\n 5. [Creating a Sequence to Sequence Translation Model (Seq2Seq)](09_Recurrent_Neural_Networks/05_Creating_A_Sequence_To_Sequence_Model#creating-a-sequence-to-sequence-model-with-tensorflow-seq2seq)\n  * Here, we use TensorFlow\'s sequence-to-sequence models to train an English-German translation model.\n 6. [Training a Siamese Similarity Measure](09_Recurrent_Neural_Networks/06_Training_A_Siamese_Similarity_Measure#training-a-siamese-similarity-measure-rnns)\n  * Here, we implement a Siamese RNN to predict the similarity of addresses and use it for record matching.  Using RNNs for record matching is very versatile, as we do not have a fixed set of target categories and can use the trained model to predict similarities across new addresses.\n\n## [Ch 10: Taking TensorFlow to Production](10_Taking_TensorFlow_to_Production#ch-10-taking-tensorflow-to-production)\n<kbd>\n  <a href=""10_Taking_TensorFlow_to_Production/01_Implementing_Unit_Tests#implementing-unit-tests"">\n    <img src=""10_Taking_TensorFlow_to_Production/images/image.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""10_Taking_TensorFlow_to_Production/02_Using_Multiple_Devices#using-multiple-devices"">\n    <img src=""10_Taking_TensorFlow_to_Production/images/image.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""10_Taking_TensorFlow_to_Production/03_Parallelizing_TensorFlow#parallelizing-tensorflow"">\n    <img src=""10_Taking_TensorFlow_to_Production/images/image.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""10_Taking_TensorFlow_to_Production/04_Production_Tips#production-tips-with-tensorflow"">\n    <img src=""10_Taking_TensorFlow_to_Production/images/image.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""10_Taking_TensorFlow_to_Production/05_Production_Example#a-production-example"">\n    <img src=""10_Taking_TensorFlow_to_Production/images/image.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n\nOf course there is more to TensorFlow than just creating and fitting machine learning models.  Once we have a model that we want to use, we have to move it towards production usage.  This chapter will provide tips and examples of implementing unit tests, using multiple processors, using multiple machines (TensorFlow distributed), and finish with a full production example.\n\n 1. [Implementing Unit Tests](10_Taking_TensorFlow_to_Production/01_Implementing_Unit_Tests#implementing-unit-tests)\n  * We show how to implement different types of unit tests on tensors (placeholders and variables).\n 2. [Using Multiple Executors (Devices)](10_Taking_TensorFlow_to_Production/02_Using_Multiple_Devices#using-multiple-devices)\n  * How to use a machine with multiple devices.  E.g., a machine with a CPU, and one or more GPUs.\n 3. [Parallelizing TensorFlow](10_Taking_TensorFlow_to_Production/03_Parallelizing_TensorFlow#parallelizing-tensorflow)\n  * How to setup and use TensorFlow distributed on multiple machines.\n 4. [Tips for TensorFlow in Production](10_Taking_TensorFlow_to_Production/04_Production_Tips#production-tips-with-tensorflow)\n  * Various tips for developing with TensorFlow\n 5. [An Example of Productionalizing TensorFlow](10_Taking_TensorFlow_to_Production/05_Production_Example#a-production-example)\n  * We show how to do take the RNN model for predicting ham/spam (from Chapter 9, recipe #2) and put it in two production level files: training and evaluation.\n\n## [Ch 11: More with TensorFlow](11_More_with_TensorFlow#ch-11-more-with-tensorflow)\n\n<kbd>\n  <a href=""11_More_with_TensorFlow/01_Visualizing_Computational_Graphs#visualizing-computational-graphs-wtensorboard"">\n    <img src=""11_More_with_TensorFlow/images/01_tensorboard1.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""11_More_with_TensorFlow/02_Working_with_a_Genetic_Algorithm"">\n    <img src=""11_More_with_TensorFlow/images/02_genetic_algorithm.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""11_More_with_TensorFlow/03_Clustering_Using_KMeans#clustering-using-k-means"">\n    <img src=""11_More_with_TensorFlow/images/03_kmeans.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n<kbd>\n  <a href=""11_More_with_TensorFlow/04_Solving_A_System_of_ODEs#solving-a-system-of-odes"">\n    <img src=""11_More_with_TensorFlow/images/04_ode_system.png"" align=""center"" height=""45"" width=""90"">\n  </a>\n</kbd>\n\nTo illustrate how versatile TensorFlow is, we will show additional examples in this chapter. We start with showing how to use the logging/visualizing tool Tensorboard.  Then we illustrate how to do k-means clustering, use a genetic algorithm, and solve a system of ODEs.\n\n 1. [Visualizing Computational Graphs (with Tensorboard)](11_More_with_TensorFlow/01_Visualizing_Computational_Graphs#visualizing-computational-graphs-wtensorboard)\n  * An example of using histograms, scalar summaries, and creating images in Tensorboard.\n 2. [Working with a Genetic Algorithm](11_More_with_TensorFlow/02_Working_with_a_Genetic_Algorithm#working-with-a-genetic-algorithm)\n  * We create a genetic algorithm to optimize an individual (array of 50 numbers) toward the ground truth function.\n 3. [Clustering Using K-means](11_More_with_TensorFlow/03_Clustering_Using_KMeans#clustering-using-k-means)\n  * How to use TensorFlow to do k-means clustering.  We use the Iris data set, set k=3, and use k-means to make predictions.\n 4. [Solving a System of ODEs](11_More_with_TensorFlow/04_Solving_A_System_of_ODEs#solving-a-system-of-odes)\n  * Here, we show how to use TensorFlow to solve a system of ODEs.  The system of concern is the Lotka-Volterra predator-prey system.\n 5. [Using a Random Forest](11_More_with_TensorFlow/05_Using_a_Random_Forest#using-a-random-forest)\n  * We illustrate how to use TensorFlow\'s gradient boosted regression and classification trees.\n 6. [Using TensorFlow with Keras](11_More_with_TensorFlow/06_Using_TensorFlow_with_Keras#using-tensorflow-with-keras)\n  * Here we show how to use the Keras sequential model building for a fully connected neural network and a CNN model with callbacks.'"
85,aws-samples/machine-learning-samples,aws-samples,Sample applications built using AWS' Amazon Machine Learning. ,2015-03-24 23:10:14,2020-06-17 13:58:38,Python,375,810,"b'# Amazon Machine Learning Samples\n\nEach subdirectory contains sample code for using Amazon Machine Learning.\nRefer to the `README.md` file in each sub-directory for details on using\neach sample.\n\n## Targeted Marketing Samples\n\nThese samples show how to use the Amazon Machine Learning API for a\ntargeted marketing application.  This follows the ""banking"" dataset example\ndescribed in the Developer Guide.  There are three versions available:\n\n* [Targeted Marketing with Machine Learning in Java](targeted-marketing-java/)\n* [Targeted Marketing with Machine Learning in Python](targeted-marketing-python/)\n* [Targeted Marketing with Machine Learning in Scala](targeted-marketing-scala/)\n\n\n## Social Media and Amazon Mechanical Turk\n\nThis sample application shows how to use Amazon Mechanical Turk to create a\nlabeled dataset from raw tweets, and then build a machine learning model\nusing the Amazon Machine Learning API that predicts whether or not new\ntweets should be acted upon by customer service.  The sample shows how to\nset up an automated filter using AWS Lambda that monitors tweets on an\nAmazon Kinesis stream and sends notifications whenever the ML Model\npredicts that a new tweet is actionable.  Notifications go to Amazon SNS,\nallowing delivery to email, SMS text messages, or other software services.\n\n* [Machine-Learning based Social Media Filtering (Python & JavaScript)](social-media/)\n\n\n## Mobile Prediction Samples\n\nThese samples show how to use the Amazon Machine Learning API to make\nreal-time predictions from a mobile device.  There are two versions available:\n\n* [Real-time Machine Learning Predictions from iOS](mobile-ios/)\n* [Real-time Machine Learning Predictions from Android](mobile-android/)\n\n\n## K-fold Cross-validation Sample\n\nThis sample shows how to use the Amazon Machine Learning API to evaluate ML models using k-fold cross-validation.\n\n* [K-fold Cross-validation Sample (Python)](k-fold-cross-validation/)\n\n\n## Other tools\n\nA collection of simple scripts to help with common tasks.\n\n* [Machine Learning Tools (python)](ml-tools-python/)\n\n\n## Support\n\nFor assistance with using the Amazon Machine Learning Service, or these samples, please see the [AWS Forums](https://forums.aws.amazon.com/forum.jspa?forumID=194&start=0).\n'"
86,PAIR-code/facets,PAIR-code,Visualizations for machine learning datasets,2017-07-07 14:03:03,2020-06-18 10:24:30,Jupyter Notebook,797,6209,"b'# Introduction\n\nThe facets project contains two visualizations for understanding and analyzing machine learning datasets: Facets Overview and Facets Dive.\n\nThe visualizations are implemented as [Polymer](https://www.polymer-project.org) web components, backed by [Typescript](https://www.typescriptlang.org) code and can be easily embedded into Jupyter notebooks or webpages.\n\nLive demos of the visualizations can be found on the [Facets project description page](https://pair-code.github.io/facets/).\n\n## Facets Overview\n\n![Overview visualization of UCI census data](/img/overview-census.png ""Overview visualization of UCI census data -  Lichman, M. (2013). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml/datasets/Census+Income]. Irvine, CA: University of California, School of Information and Computer Science"")\n\nOverview gives a high-level view of one or more data sets. It produces a visual feature-by-feature statistical analysis, and can also be used to compare statistics across two or more data sets. The tool can process both numeric and string features, including multiple instances of a number or string per feature.\n\nOverview can help uncover issues with datasets, including the following:\n\n* Unexpected feature values\n* Missing feature values for a large number of examples\n* Training/serving skew\n* Training/test/validation set skew\n\nKey aspects of the visualization are outlier detection and distribution comparison across multiple datasets.\nInteresting values (such as a high proportion of missing data, or very different distributions of a feature across multiple datasets) are highlighted in red.\nFeatures can be sorted by values of interest such as the number of missing values or the skew between the different datasets.\n\nThe python code to generate the statistics for visualization can be installed through `pip install facets-overview`.\n\nDetails about Overview usage can be found in its [README](./facets_overview/README.md).\n\n## Facets Dive\n\n![Dive visualization of UCI census data](/img/dive-census.png ""Dive visualization of UCI census data -  Lichman, M. (2013). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml/datasets/Census+Income]. Irvine, CA: University of California, School of Information and Computer Science"")\n\nDive is a tool for interactively exploring up to tens of thousands of multidimensional data points, allowing users to seamlessly switch between a high-level overview and low-level details.\nEach example is a represented as single item in the visualization and the points can be positioned by faceting/bucketing in multiple dimensions by their feature values. Combining smooth animation and zooming with faceting and filtering, Dive makes it easy to spot patterns and outliers in complex data sets.\n\nDetails about Dive usage can be found in its [README](./facets_dive/README.md).\n\n# Setup\n\n## Usage in Google Colabratory/Jupyter Notebooks\n\nUsing Facets in [Google Colabratory](https://colab.research.google.com) and [Jupyter](http://jupyter.org) notebooks can be seen\n[in this notebook](https://colab.research.google.com/github/PAIR-code/facets/blob/master/colab_facets.ipynb). These notebooks work without the need to first download/install this repository.\n\nBoth Facets visualizations make use of HTML imports. So in order to use them, you must first load the appropriate polyfill, through `<script src=""https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js""></script>`, as shown in the demo notebooks in this repo.\n\nNote that for using Facets Overview in a Jupyter notebook, there are two considerations:\n1. In the notebook, you will need to change the path that the Facets Overview python code is loaded from to the correct path given where your notebook kernel is run from.\n2. You must also have the Protocol Buffers python runtime library installed: https://github.com/google/protobuf/tree/master/python. If you used pip or anaconda to install Jupyter, you can use the same tool to install the runtime library.\n\nWhen visualizing a large amount of data in Dive in a Juypter notebook, as is done in the [Dive demo Jupyter notebook](./facets_dive/Dive_demo.ipynb), you will need to start the notebook server with an increased IOPub data rate.\nThis can be done with the command ```jupyter notebook --NotebookApp.iopub_data_rate_limit=10000000```.\n\n## Code Installation\n```\ngit clone https://github.com/PAIR-code/facets\ncd facets\n```\n\n## Building the Visualizations\n\nIf you make code changes to the visualization and would like to rebuild them, follow these directions:\n\n1. Install bazel: https://bazel.build/\n2. Build the visualizations: ```bazel build facets:facets_jupyter``` (run from the facets top-level directory)\n\n## Using the rebuilt Visualizations in a Jupyter notebook\n\nIf you want to use the visualizations you built locally in a Jupyter notebook, follow these directions:\n\n1. Move the resulting vulcanized html file from the build step into the facets-dist directory: ```cp -f bazel-bin/facets/facets-jupyter.html facets-dist/```\n2. Install the visualizations into Jupyter as an nbextension.\n  * If jupyter was installed with pip, you can use ```jupyter nbextension install facets-dist/ ``` if jupyter was installed system-wide or ```jupyter nbextension install facets-dist/ --user``` if installed per-user (run from the facets top-level directory). You do not need to run any follow-up ```jupyter nbextension enable``` command for this extension.\n  * Alternatively, you can manually install the nbextension by finding your jupyter installation\'s ```share/jupyter/nbextensions``` folder and copying the facets-dist directory into it.\n3. In the notebook cell\'s HTML link tag that loads the built facets html, load from ```/nbextensions/facets-dist/facets-jupyter.html```, which is the locally installed facets distribution. from the previous step.\n\n## Known Issues\n\n* The Facets visualizations currently work only in Chrome - [Issue 9](../../issues/9).\n\n**Disclaimer: This is not an official Google product**\n'"
87,EpistasisLab/tpot,EpistasisLab,A Python Automated Machine Learning tool that optimizes machine learning pipelines using genetic programming.,2015-11-03 21:08:40,2020-06-18 20:19:10,Python,1254,7150,"b'Master status: [![Master Build Status - Mac/Linux](https://travis-ci.org/EpistasisLab/tpot.svg?branch=master)](https://travis-ci.org/EpistasisLab/tpot)\n[![Master Build Status - Windows](https://ci.appveyor.com/api/projects/status/b7bmpwpkjhifrm7v/branch/master?svg=true)](https://ci.appveyor.com/project/weixuanfu/tpot?branch=master)\n[![Master Coverage Status](https://coveralls.io/repos/github/EpistasisLab/tpot/badge.svg?branch=master)](https://coveralls.io/github/EpistasisLab/tpot?branch=master)\n\nDevelopment status: [![Development Build Status - Mac/Linux](https://travis-ci.org/EpistasisLab/tpot.svg?branch=development)](https://travis-ci.org/EpistasisLab/tpot/branches)\n[![Development Build Status - Windows](https://ci.appveyor.com/api/projects/status/b7bmpwpkjhifrm7v/branch/development?svg=true)](https://ci.appveyor.com/project/weixuanfu/tpot?branch=development)\n[![Development Coverage Status](https://coveralls.io/repos/github/EpistasisLab/tpot/badge.svg?branch=development)](https://coveralls.io/github/EpistasisLab/tpot?branch=development)\n\nPackage information: [![Python 3.7](https://img.shields.io/badge/python-3.7-blue.svg)](https://www.python.org/downloads/release/python-370/)\n[![License: LGPL v3](https://img.shields.io/badge/license-LGPL%20v3-blue.svg)](http://www.gnu.org/licenses/lgpl-3.0)\n[![PyPI version](https://badge.fury.io/py/TPOT.svg)](https://badge.fury.io/py/TPOT)\n\n<p align=""center"">\n<img src=""https://raw.githubusercontent.com/EpistasisLab/tpot/master/images/tpot-logo.jpg"" width=300 />\n</p>\n\n**TPOT** stands for **T**ree-based **P**ipeline **O**ptimization **T**ool. Consider TPOT your **Data Science Assistant**. TPOT is a Python Automated Machine Learning tool that optimizes machine learning pipelines using genetic programming.\n\n![TPOT Demo](https://github.com/EpistasisLab/tpot/blob/master/images/tpot-demo.gif ""TPOT Demo"")\n\nTPOT will automate the most tedious part of machine learning by intelligently exploring thousands of possible pipelines to find the best one for your data.\n\n![An example Machine Learning pipeline](https://github.com/EpistasisLab/tpot/blob/master/images/tpot-ml-pipeline.png ""An example Machine Learning pipeline"")\n\n<p align=""center""><strong>An example Machine Learning pipeline</strong></p>\n\nOnce TPOT is finished searching (or you get tired of waiting), it provides you with the Python code for the best pipeline it found so you can tinker with the pipeline from there.\n\n![An example TPOT pipeline](https://github.com/EpistasisLab/tpot/blob/master/images/tpot-pipeline-example.png ""An example TPOT pipeline"")\n\nTPOT is built on top of scikit-learn, so all of the code it generates should look familiar... if you\'re familiar with scikit-learn, anyway.\n\n**TPOT is still under active development** and we encourage you to check back on this repository regularly for updates.\n\nFor further information about TPOT, please see the [project documentation](http://epistasislab.github.io/tpot/).\n\n## License\n\nPlease see the [repository license](https://github.com/EpistasisLab/tpot/blob/master/LICENSE) for the licensing and usage information for TPOT.\n\nGenerally, we have licensed TPOT to make it as widely usable as possible.\n\n## Installation\n\nWe maintain the [TPOT installation instructions](http://epistasislab.github.io/tpot/installing/) in the documentation. TPOT requires a working installation of Python.\n\n## Usage\n\nTPOT can be used [on the command line](http://epistasislab.github.io/tpot/using/#tpot-on-the-command-line) or [with Python code](http://epistasislab.github.io/tpot/using/#tpot-with-code).\n\nClick on the corresponding links to find more information on TPOT usage in the documentation.\n\n## Examples\n\n### Classification\n\nBelow is a minimal working example with the the optical recognition of handwritten digits dataset.\n\n```python\nfrom tpot import TPOTClassifier\nfrom sklearn.datasets import load_digits\nfrom sklearn.model_selection import train_test_split\n\ndigits = load_digits()\nX_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target,\n                                                    train_size=0.75, test_size=0.25, random_state=42)\n\ntpot = TPOTClassifier(generations=5, population_size=50, verbosity=2, random_state=42)\ntpot.fit(X_train, y_train)\nprint(tpot.score(X_test, y_test))\ntpot.export(\'tpot_digits_pipeline.py\')\n```\n\nRunning this code should discover a pipeline that achieves about 98% testing accuracy, and the corresponding Python code should be exported to the `tpot_digits_pipeline.py` file and look similar to the following:\n\n```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline, make_union\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom tpot.builtins import StackingEstimator\nfrom tpot.export_utils import set_param_recursive\n\n# NOTE: Make sure that the outcome column is labeled \'target\' in the data file\ntpot_data = pd.read_csv(\'PATH/TO/DATA/FILE\', sep=\'COLUMN_SEPARATOR\', dtype=np.float64)\nfeatures = tpot_data.drop(\'target\', axis=1)\ntraining_features, testing_features, training_target, testing_target = \\\n            train_test_split(features, tpot_data[\'target\'], random_state=42)\n\n# Average CV score on the training set was: 0.9799428471757372\nexported_pipeline = make_pipeline(\n    PolynomialFeatures(degree=2, include_bias=False, interaction_only=False),\n    StackingEstimator(estimator=LogisticRegression(C=0.1, dual=False, penalty=""l1"")),\n    RandomForestClassifier(bootstrap=True, criterion=""entropy"", max_features=0.35000000000000003, min_samples_leaf=20, min_samples_split=19, n_estimators=100)\n)\n# Fix random state for all the steps in exported pipeline\nset_param_recursive(exported_pipeline.steps, \'random_state\', 42)\n\nexported_pipeline.fit(training_features, training_target)\nresults = exported_pipeline.predict(testing_features)\n```\n\n### Regression\n\nSimilarly, TPOT can optimize pipelines for regression problems. Below is a minimal working example with the practice Boston housing prices data set.\n\n```python\nfrom tpot import TPOTRegressor\nfrom sklearn.datasets import load_boston\nfrom sklearn.model_selection import train_test_split\n\nhousing = load_boston()\nX_train, X_test, y_train, y_test = train_test_split(housing.data, housing.target,\n                                                    train_size=0.75, test_size=0.25, random_state=42)\n\ntpot = TPOTRegressor(generations=5, population_size=50, verbosity=2, random_state=42)\ntpot.fit(X_train, y_train)\nprint(tpot.score(X_test, y_test))\ntpot.export(\'tpot_boston_pipeline.py\')\n```\n\nwhich should result in a pipeline that achieves about 12.77 mean squared error (MSE), and the Python code in `tpot_boston_pipeline.py` should look similar to:\n\n```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom tpot.export_utils import set_param_recursive\n\n# NOTE: Make sure that the outcome column is labeled \'target\' in the data file\ntpot_data = pd.read_csv(\'PATH/TO/DATA/FILE\', sep=\'COLUMN_SEPARATOR\', dtype=np.float64)\nfeatures = tpot_data.drop(\'target\', axis=1)\ntraining_features, testing_features, training_target, testing_target = \\\n            train_test_split(features, tpot_data[\'target\'], random_state=42)\n\n# Average CV score on the training set was: -10.812040755234403\nexported_pipeline = make_pipeline(\n    PolynomialFeatures(degree=2, include_bias=False, interaction_only=False),\n    ExtraTreesRegressor(bootstrap=False, max_features=0.5, min_samples_leaf=2, min_samples_split=3, n_estimators=100)\n)\n# Fix random state for all the steps in exported pipeline\nset_param_recursive(exported_pipeline.steps, \'random_state\', 42)\n\nexported_pipeline.fit(training_features, training_target)\nresults = exported_pipeline.predict(testing_features)\n```\n\nCheck the documentation for [more examples and tutorials](http://epistasislab.github.io/tpot/examples/).\n\n## Contributing to TPOT\n\nWe welcome you to [check the existing issues](https://github.com/EpistasisLab/tpot/issues/) for bugs or enhancements to work on. If you have an idea for an extension to TPOT, please [file a new issue](https://github.com/EpistasisLab/tpot/issues/new) so we can discuss it.\n\nBefore submitting any contributions, please review our [contribution guidelines](http://epistasislab.github.io/tpot/contributing/).\n\n## Having problems or have questions about TPOT?\n\nPlease [check the existing open and closed issues](https://github.com/EpistasisLab/tpot/issues?utf8=%E2%9C%93&q=is%3Aissue) to see if your issue has already been attended to. If it hasn\'t, [file a new issue](https://github.com/EpistasisLab/tpot/issues/new) on this repository so we can review your issue.\n\n## Citing TPOT\n\nIf you use TPOT in a scientific publication, please consider citing at least one of the following papers:\n\nTrang T. Le, Weixuan Fu and Jason H. Moore (2020). [Scaling tree-based automated machine learning to biomedical big data with a feature set selector](https://academic.oup.com/bioinformatics/article/36/1/250/5511404). *Bioinformatics*.36(1): 250-256.\n\nBibTeX entry:\n\n```bibtex\n@article{le2020scaling,\n  title={Scaling tree-based automated machine learning to biomedical big data with a feature set selector},\n  author={Le, Trang T and Fu, Weixuan and Moore, Jason H},\n  journal={Bioinformatics},\n  volume={36},\n  number={1},\n  pages={250--256},\n  year={2020},\n  publisher={Oxford University Press}\n}\n```\n\n\nRandal S. Olson, Ryan J. Urbanowicz, Peter C. Andrews, Nicole A. Lavender, La Creis Kidd, and Jason H. Moore (2016). [Automating biomedical data science through tree-based pipeline optimization](http://link.springer.com/chapter/10.1007/978-3-319-31204-0_9). *Applications of Evolutionary Computation*, pages 123-137.\n\nBibTeX entry:\n\n```bibtex\n@inbook{Olson2016EvoBio,\n    author={Olson, Randal S. and Urbanowicz, Ryan J. and Andrews, Peter C. and Lavender, Nicole A. and Kidd, La Creis and Moore, Jason H.},\n    editor={Squillero, Giovanni and Burelli, Paolo},\n    chapter={Automating Biomedical Data Science Through Tree-Based Pipeline Optimization},\n    title={Applications of Evolutionary Computation: 19th European Conference, EvoApplications 2016, Porto, Portugal, March 30 -- April 1, 2016, Proceedings, Part I},\n    year={2016},\n    publisher={Springer International Publishing},\n    pages={123--137},\n    isbn={978-3-319-31204-0},\n    doi={10.1007/978-3-319-31204-0_9},\n    url={http://dx.doi.org/10.1007/978-3-319-31204-0_9}\n}\n```\n\nRandal S. Olson, Nathan Bartley, Ryan J. Urbanowicz, and Jason H. Moore (2016). [Evaluation of a Tree-based Pipeline Optimization Tool for Automating Data Science](http://dl.acm.org/citation.cfm?id=2908918). *Proceedings of GECCO 2016*, pages 485-492.\n\nBibTeX entry:\n\n```bibtex\n@inproceedings{OlsonGECCO2016,\n    author = {Olson, Randal S. and Bartley, Nathan and Urbanowicz, Ryan J. and Moore, Jason H.},\n    title = {Evaluation of a Tree-based Pipeline Optimization Tool for Automating Data Science},\n    booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference 2016},\n    series = {GECCO \'16},\n    year = {2016},\n    isbn = {978-1-4503-4206-3},\n    location = {Denver, Colorado, USA},\n    pages = {485--492},\n    numpages = {8},\n    url = {http://doi.acm.org/10.1145/2908812.2908918},\n    doi = {10.1145/2908812.2908918},\n    acmid = {2908918},\n    publisher = {ACM},\n    address = {New York, NY, USA},\n}\n```\n\nAlternatively, you can cite the repository directly with the following DOI:\n\n[![DOI](https://zenodo.org/badge/20747/rhiever/tpot.svg)](https://zenodo.org/badge/latestdoi/20747/rhiever/tpot)\n\n## Support for TPOT\n\nTPOT was developed in the [Computational Genetics Lab](http://epistasis.org/) at the [University of Pennsylvania](https://www.upenn.edu/) with funding from the [NIH](http://www.nih.gov/) under grant R01 AI117694. We are incredibly grateful for the support of the NIH and the University of Pennsylvania during the development of this project.\n\nThe TPOT logo was designed by Todd Newmuis, who generously donated his time to the project.\n'"
88,cortexlabs/cortex,cortexlabs,Build machine learning APIs,2019-01-24 04:43:14,2020-06-18 21:02:26,Go,415,5309,"b'<!-- Delete on release branches -->\n<img src=\'https://s3-us-west-2.amazonaws.com/cortex-public/logo.png\' height=\'88\'>\n\n# Build machine learning APIs\n\n<br>\n\n<!-- Delete on release branches -->\n<!-- CORTEX_VERSION_README_MINOR -->\n[install](https://docs.cortex.dev/install) \xe2\x80\xa2 [docs](https://docs.cortex.dev) \xe2\x80\xa2 [examples](https://github.com/cortexlabs/cortex/tree/0.17/examples) \xe2\x80\xa2 [we\'re hiring](https://angel.co/cortex-labs-inc/jobs) \xe2\x80\xa2 [chat with us](https://gitter.im/cortexlabs/cortex)<br><br>\n\n<!-- Set header Cache-Control=no-cache on the S3 object metadata (see https://help.github.com/en/articles/about-anonymized-image-urls) -->\n![Demo](https://d1zqebknpdh033.cloudfront.net/demo/gif/v0.13_2.gif)\n\n<br>\n\n## Key features\n\n* **Multi framework:** deploy TensorFlow, PyTorch, scikit-learn, and other models.\n* **Autoscaling:** automatically scale APIs to handle production workloads.\n* **ML instances:** run inference on G4, P2, M5, C5 and other AWS instance types.\n* **Spot instances:** save money with spot instances.\n* **Multi-model APIs:** deploy multiple models in a single API.\n* **Rolling updates:** update deployed APIs with no downtime.\n* **Log streaming:** stream logs from deployed models to your CLI.\n* **Prediction monitoring:** monitor API performance and prediction results.\n\n<br>\n\n## Deploying a model\n\n### Install the CLI\n\n<!-- CORTEX_VERSION_README_MINOR -->\n```bash\n$ bash -c ""$(curl -sS https://raw.githubusercontent.com/cortexlabs/cortex/0.17/get-cli.sh)""\n```\n\n### Implement your predictor\n\n```python\n# predictor.py\n\nclass PythonPredictor:\n    def __init__(self, config):\n        self.model = download_model()\n\n    def predict(self, payload):\n        return self.model.predict(payload[""text""])\n```\n\n### Configure your deployment\n\n```yaml\n# cortex.yaml\n\n- name: sentiment-classifier\n  predictor:\n    type: python\n    path: predictor.py\n  compute:\n    gpu: 1\n    mem: 4G\n```\n\n### Deploy your model\n\n```bash\n$ cortex deploy\n\ncreating sentiment-classifier\n```\n\n### Serve predictions\n\n```bash\n$ curl http://localhost:8888 \\\n    -X POST -H ""Content-Type: application/json"" \\\n    -d \'{""text"": ""serving models locally is cool!""}\'\n\npositive\n```\n\n<br>\n\n## Deploying models at scale\n\n### Spin up a cluster\n\nCortex clusters are designed to be self-hosted on any AWS account:\n\n```bash\n$ cortex cluster up\n\naws region: us-east-1\naws instance type: g4dn.xlarge\nspot instances: yes\nmin instances: 0\nmax instances: 5\n\nyour cluster will cost $0.19 - $2.85 per hour based on cluster size and spot instance pricing/availability\n\n\xef\xbf\xae spinning up your cluster ...\n\nyour cluster is ready!\n```\n\n### Deploy to your cluster with the same code and configuration\n\n```bash\n$ cortex deploy --env aws\n\ncreating sentiment-classifier\n```\n\n### Serve predictions at scale\n\n```bash\n$ curl http://***.amazonaws.com/sentiment-classifier \\\n    -X POST -H ""Content-Type: application/json"" \\\n    -d \'{""text"": ""serving models at scale is really cool!""}\'\n\npositive\n```\n\n### Monitor your deployment\n\n```bash\n$ cortex get sentiment-classifier\n\nstatus   up-to-date   requested   last update   avg request   2XX\nlive     1            1           8s            24ms          12\n\nclass     count\npositive  8\nnegative  4\n```\n\n### How it works\n\nThe CLI sends configuration and code to the cluster every time you run `cortex deploy`. Each model is loaded into a Docker container, along with any Python packages and request handling code. The model is exposed as a web service using a Network Load Balancer (NLB) and FastAPI / TensorFlow Serving / ONNX Runtime (depending on the model type). The containers are orchestrated on Elastic Kubernetes Service (EKS) while logs and metrics are streamed to CloudWatch.\n\nCortex manages its own Kubernetes cluster so that end-to-end functionality like request-based autoscaling, GPU support, and spot instance management can work out of the box without any additional DevOps work.\n\n<br>\n\n## Examples\n\n<!-- CORTEX_VERSION_README_MINOR x3 -->\n* [Image classification](https://github.com/cortexlabs/cortex/tree/0.17/examples/tensorflow/image-classifier): deploy an Inception model to classify images.\n* [Search completion](https://github.com/cortexlabs/cortex/tree/0.17/examples/pytorch/search-completer): deploy Facebook\'s RoBERTa model to complete search terms.\n* [Text generation](https://github.com/cortexlabs/cortex/tree/0.17/examples/pytorch/text-generator): deploy Hugging Face\'s DistilGPT2 model to generate text.\n'"
89,aleju/imgaug,aleju,Image augmentation for machine learning experiments.,2015-07-10 20:31:33,2020-06-18 20:52:44,Python,1792,9298,"b'# imgaug\n\nThis python library helps you with augmenting images for your machine learning projects.\nIt converts a set of input images into a new, much larger set of slightly altered images.\n\n[![Build Status](https://travis-ci.org/aleju/imgaug.svg?branch=master)](https://travis-ci.org/aleju/imgaug)\n[![codecov](https://codecov.io/gh/aleju/imgaug/branch/master/graph/badge.svg)](https://codecov.io/gh/aleju/imgaug)\n[![Codacy Badge](https://api.codacy.com/project/badge/Grade/1370ce38e99e40af842d47a8dd721444)](https://www.codacy.com/app/aleju/imgaug?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=aleju/imgaug&amp;utm_campaign=Badge_Grade)\n\n<table>\n\n<tr>\n<th>&nbsp;</th>\n<th>Image</th>\n<th>Heatmaps</th>\n<th>Seg. Maps</th>\n<th>Keypoints</th>\n<th>Bounding Boxes,<br>Polygons</th>\n</tr>\n\n<!-- Line 1: Original Input -->\n<tr>\n<td><em>Original Input</em></td>\n<td><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/noop_image.jpg?raw=true"" height=""83"" width=""124"" alt=""input images""></td>\n<td><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/noop_heatmap.jpg?raw=true"" height=""83"" width=""124"" alt=""input heatmaps""></td>\n<td><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/noop_segmap.jpg?raw=true"" height=""83"" width=""124"" alt=""input segmentation maps""></td>\n<td><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/noop_kps.jpg?raw=true"" height=""83"" width=""124"" alt=""input keypoints""></td>\n<td><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/noop_bbs.jpg?raw=true"" height=""83"" width=""124"" alt=""input bounding boxes""></td>\n</tr>\n\n<!-- Line 2: Gauss. Noise + Contrast + Sharpen -->\n<tr>\n<td>Gauss. Noise<br>+&nbsp;Contrast<br>+&nbsp;Sharpen</td>\n<td><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/non_geometric_image.jpg?raw=true"" height=""83"" width=""124"" alt=""non geometric augmentations, applied to images""></td>\n<td><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/non_geometric_heatmap.jpg?raw=true"" height=""83"" width=""124"" alt=""non geometric augmentations, applied to heatmaps""></td>\n<td><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/non_geometric_segmap.jpg?raw=true"" height=""83"" width=""124"" alt=""non geometric augmentations, applied to segmentation maps""></td>\n<td><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/non_geometric_kps.jpg?raw=true"" height=""83"" width=""124"" alt=""non geometric augmentations, applied to keypoints""></td>\n<td><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/non_geometric_bbs.jpg?raw=true"" height=""83"" width=""124"" alt=""non geometric augmentations, applied to bounding boxes""></td>\n</tr>\n\n<!-- Line 3: Affine -->\n<tr>\n<td>Affine</td>\n<td><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/affine_image.jpg?raw=true"" height=""83"" width=""124"" alt=""affine augmentations, applied to images""></td>\n<td><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/affine_heatmap.jpg?raw=true"" height=""83"" width=""124"" alt=""affine augmentations, applied to heatmaps""></td>\n<td><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/affine_segmap.jpg?raw=true"" height=""83"" width=""124"" alt=""affine augmentations, applied to segmentation maps""></td>\n<td><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/affine_kps.jpg?raw=true"" height=""83"" width=""124"" alt=""affine augmentations, applied to keypoints""></td>\n<td><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/affine_bbs.jpg?raw=true"" height=""83"" width=""124"" alt=""affine augmentations, applied to bounding boxes""></td>\n</tr>\n\n<!-- Line 4: Crop + Pad -->\n<tr>\n<td>Crop<br>+&nbsp;Pad</td>\n<td><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/cropandpad_image.jpg?raw=true"" height=""83"" width=""124"" alt=""crop and pad augmentations, applied to images""></td>\n<td><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/cropandpad_heatmap.jpg?raw=true"" height=""83"" width=""124"" alt=""crop and pad augmentations, applied to heatmaps""></td>\n<td><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/cropandpad_segmap.jpg?raw=true"" height=""83"" width=""124"" alt=""crop and pad augmentations, applied to segmentation maps""></td>\n<td><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/cropandpad_kps.jpg?raw=true"" height=""83"" width=""124"" alt=""crop and pad augmentations, applied to keypoints""></td>\n<td><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/cropandpad_bbs.jpg?raw=true"" height=""83"" width=""124"" alt=""crop and pad augmentations, applied to bounding boxes""></td>\n</tr>\n\n<!-- Line 5: Fliplr + Perspective -->\n<tr>\n<td>Fliplr<br>+&nbsp;Perspective</td>\n<td><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/fliplr_perspective_image.jpg"" height=""83"" width=""124"" alt=""Horizontal flip and perspective transform augmentations, applied to images""></td>\n<td><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/fliplr_perspective_heatmap.jpg?raw=true"" height=""83"" width=""124"" alt=""Horizontal flip and perspective transform augmentations, applied to heatmaps""></td>\n<td><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/fliplr_perspective_segmap.jpg?raw=true"" height=""83"" width=""124"" alt=""Horizontal flip and perspective transform augmentations, applied to segmentation maps""></td>\n<td><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/fliplr_perspective_kps.jpg?raw=true"" height=""83"" width=""124"" alt=""Horizontal flip and perspective transform augmentations, applied to keypoints""></td>\n<td><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/fliplr_perspective_bbs.jpg?raw=true"" height=""83"" width=""124"" alt=""Horizontal flip and perspective transform augmentations, applied to bounding boxes""></td>\n</tr>\n\n</table>\n\n\n**More (strong) example augmentations of one input image:**\n\n![64 quokkas](https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/examples_grid.jpg?raw=true ""64 quokkas"")\n\n\n## Table of Contents\n\n1. [Features](#features)\n2. [Installation](#installation)\n3. [Documentation](#documentation)\n4. [Recent Changes](#recent_changes)\n5. [Example Images](#example_images)\n6. [Code Examples](#code_examples)\n7. [Citation](#citation)\n\n\n<a name=""features""/>\n\n## Features\n\n* Many augmentation techniques\n  * E.g. affine transformations, perspective transformations, contrast changes, gaussian noise, dropout of regions, hue/saturation changes, cropping/padding, blurring, ...\n  * Optimized for high performance\n  * Easy to apply augmentations only to some images\n  * Easy to apply augmentations in random order\n* Support for\n  * Images (full support for uint8, for other dtypes see [documentation](https://imgaug.readthedocs.io/en/latest/source/dtype_support.html))\n  * Heatmaps (float32), Segmentation Maps (int), Masks (bool)\n    * May be smaller/larger than their corresponding images. *No* extra lines of code needed for e.g. crop.\n  * Keypoints/Landmarks (int/float coordinates)\n  * Bounding Boxes (int/float coordinates)\n  * Polygons (int/float coordinates)\n  * Line Strings (int/float coordinates)\n* Automatic alignment of sampled random values\n  * Example: Rotate image and segmentation map on it by the same value sampled from `uniform(-10\xc2\xb0, 45\xc2\xb0)`. (0 extra lines of code.)\n* Probability distributions as parameters\n  * Example: Rotate images by values sampled from `uniform(-10\xc2\xb0, 45\xc2\xb0)`.\n  * Example: Rotate images by values sampled from `ABS(N(0, 20.0))*(1+B(1.0, 1.0))`"", where `ABS(.)` is the absolute function, `N(.)` the gaussian distribution and `B(.)` the beta distribution.\n* Many helper functions\n  * Example: Draw heatmaps, segmentation maps, keypoints, bounding boxes, ...\n  * Example: Scale segmentation maps, average/max pool of images/maps, pad images to aspect\n    ratios (e.g. to square them)\n  * Example: Convert keypoints to distance maps, extract pixels within bounding boxes from images, clip polygon to the image plane, ...\n* Support for augmentation on multiple CPU cores\n\n\n<a name=""installation""/>\n\n## Installation\n\nThe library supports python 2.7 and 3.4+.\n\n### Installation: Anaconda\n\nTo install the library in anaconda, perform the following commands:\n```bash\nconda config --add channels conda-forge\nconda install imgaug\n```\n\nYou can deinstall the library again via `conda remove imgaug`.\n\n### Installation: pip\n\nThen install imgaug either via pypi (can lag behind the github version):\n```bash\npip install imgaug\n```\n\nor install the latest version directly from github:\n```bash\npip install git+https://github.com/aleju/imgaug.git\n```\n\nFor more details, see the [install guide](https://imgaug.readthedocs.io/en/latest/source/installation.html)\n\nTo deinstall the library, just execute `pip uninstall imgaug`.\n\n\n<a name=""documentation""/>\n\n## Documentation\n\nExample jupyter notebooks:\n  * [Load and Augment an Image](https://nbviewer.jupyter.org/github/aleju/imgaug-doc/blob/master/notebooks/A01%20-%20Load%20and%20Augment%20an%20Image.ipynb)\n  * [Multicore Augmentation](https://nbviewer.jupyter.org/github/aleju/imgaug-doc/blob/master/notebooks/A03%20-%20Multicore%20Augmentation.ipynb)\n  * Augment and work with: [Keypoints/Landmarks](https://nbviewer.jupyter.org/github/aleju/imgaug-doc/blob/master/notebooks/B01%20-%20Augment%20Keypoints.ipynb),\n    [Bounding Boxes](https://nbviewer.jupyter.org/github/aleju/imgaug-doc/blob/master/notebooks/B02%20-%20Augment%20Bounding%20Boxes.ipynb),\n    [Polygons](https://nbviewer.jupyter.org/github/aleju/imgaug-doc/blob/master/notebooks/B03%20-%20Augment%20Polygons.ipynb),\n    [Line Strings](https://nbviewer.jupyter.org/github/aleju/imgaug-doc/blob/master/notebooks/B06%20-%20Augment%20Line%20Strings.ipynb),\n    [Heatmaps](https://nbviewer.jupyter.org/github/aleju/imgaug-doc/blob/master/notebooks/B04%20-%20Augment%20Heatmaps.ipynb),\n    [Segmentation Maps](https://nbviewer.jupyter.org/github/aleju/imgaug-doc/blob/master/notebooks/B05%20-%20Augment%20Segmentation%20Maps.ipynb) \n\nMore notebooks: [imgaug-doc/notebooks](https://github.com/aleju/imgaug-doc/tree/master/notebooks).\n\nExample ReadTheDocs pages:\n* [Quick example code on how to use the library](http://imgaug.readthedocs.io/en/latest/source/examples_basics.html)\n* [Overview of all Augmenters](https://imgaug.readthedocs.io/en/latest/source/overview_of_augmenters.html)\n* [API](http://imgaug.readthedocs.io/en/latest/source/api.html)\n\nMore RTD documentation: [imgaug.readthedocs.io](http://imgaug.readthedocs.io/en/latest/source/examples_basics.html).\n\nAll documentation related files of this project are hosted in the\nrepository [imgaug-doc](https://github.com/aleju/imgaug-doc).\n\n\n<a name=""recent_changes""/>\n\n## Recent Changes\n\n* **0.4.0**: Added new augmenters, changed backend to batchwise augmentation,\n  support for numpy 1.18 and python 3.8.\n* **0.3.0**: Reworked segmentation map augmentation, adapted to numpy 1.17+\n  random number sampling API, several new augmenters.\n* **0.2.9**: Added polygon augmentation, added line string augmentation,\n  simplified augmentation interface.\n* **0.2.8**: Improved performance, dtype support and multicore augmentation.\n\nSee [changelogs/](changelogs/) for more details.\n\n\n<a name=""example_images""/>\n\n## Example Images\n\nThe images below show examples for most augmentation techniques.\n\nValues written in the form `(a, b)` denote a uniform distribution,\ni.e. the value is randomly picked from the interval `[a, b]`.\nLine strings are supported by (almost) all augmenters, but are not explicitly\nvisualized here.\n\n<table>\n\n<tr><td colspan=""5""><strong>meta</strong></td></tr>\n<tr>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/meta.html#identity"">Identity</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/meta.html#channelshuffle"">ChannelShuffle</a></sub></td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n</tr>\n<tr>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/meta/identity.gif"" height=""148"" width=""100"" alt=""Identity""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/meta/channelshuffle.gif"" height=""148"" width=""100"" alt=""ChannelShuffle""></td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n</tr>\n<tr>\n\n</tr>\n<tr>\n<td colspan=""5"">See also: <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/meta.html#sequential"">Sequential</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/meta.html#someof"">SomeOf</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/meta.html#oneof"">OneOf</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/meta.html#sometimes"">Sometimes</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/meta.html#withchannels"">WithChannels</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/meta.html#lambda"">Lambda</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/meta.html#assertlambda"">AssertLambda</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/meta.html#assertshape"">AssertShape</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/meta.html#removecbasbyoutofimagefraction"">RemoveCBAsByOutOfImageFraction</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/meta.html#clipcbastoimageplanes"">ClipCBAsToImagePlanes</a></td>\n</tr>\n<tr><td colspan=""5""><strong>arithmetic</strong></td></tr>\n<tr>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#add"">Add</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#add"">Add</a><br/>(per_channel=True)</sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#additivegaussiannoise"">AdditiveGaussianNoise</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#additivegaussiannoise"">AdditiveGaussianNoise</a><br/>(per_channel=True)</sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#multiply"">Multiply</a></sub></td>\n</tr>\n<tr>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/arithmetic/add.gif"" height=""148"" width=""100"" alt=""Add""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/arithmetic/add_per_channel_true.gif"" height=""148"" width=""100"" alt=""Add per_channel=True""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/arithmetic/additivegaussiannoise.gif"" height=""148"" width=""100"" alt=""AdditiveGaussianNoise""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/arithmetic/additivegaussiannoise_per_channel_true.gif"" height=""148"" width=""100"" alt=""AdditiveGaussianNoise per_channel=True""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/arithmetic/multiply.gif"" height=""148"" width=""100"" alt=""Multiply""></td>\n</tr>\n<tr>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#cutout"">Cutout</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#dropout"">Dropout</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#coarsedropout"">CoarseDropout</a><br/>(p=0.2)</sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#coarsedropout"">CoarseDropout</a><br/>(p=0.2, per_channel=True)</sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#dropout2d"">Dropout2d</a></sub></td>\n</tr>\n<tr>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/arithmetic/cutout.gif"" height=""148"" width=""100"" alt=""Cutout""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/arithmetic/dropout.gif"" height=""148"" width=""100"" alt=""Dropout""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/arithmetic/coarsedropout_p_0_2.gif"" height=""148"" width=""100"" alt=""CoarseDropout p=0.2""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/arithmetic/coarsedropout_p_0_2_per_channel_true.gif"" height=""148"" width=""100"" alt=""CoarseDropout p=0.2, per_channel=True""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/arithmetic/dropout2d.gif"" height=""148"" width=""100"" alt=""Dropout2d""></td>\n</tr>\n<tr>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#saltandpepper"">SaltAndPepper</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#coarsesaltandpepper"">CoarseSaltAndPepper</a><br/>(p=0.2)</sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#invert"">Invert</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#solarize"">Solarize</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#jpegcompression"">JpegCompression</a></sub></td>\n</tr>\n<tr>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/arithmetic/saltandpepper.gif"" height=""148"" width=""100"" alt=""SaltAndPepper""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/arithmetic/coarsesaltandpepper_p_0_2.gif"" height=""148"" width=""100"" alt=""CoarseSaltAndPepper p=0.2""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/arithmetic/invert.gif"" height=""148"" width=""100"" alt=""Invert""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/arithmetic/solarize.gif"" height=""148"" width=""100"" alt=""Solarize""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/arithmetic/jpegcompression.gif"" height=""148"" width=""100"" alt=""JpegCompression""></td>\n</tr>\n<tr>\n\n</tr>\n<tr>\n<td colspan=""5"">See also: <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#addelementwise"">AddElementwise</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#additivelaplacenoise"">AdditiveLaplaceNoise</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#additivepoissonnoise"">AdditivePoissonNoise</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#multiplyelementwise"">MultiplyElementwise</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#totaldropout"">TotalDropout</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#replaceelementwise"">ReplaceElementwise</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#impulsenoise"">ImpulseNoise</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#salt"">Salt</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#pepper"">Pepper</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#coarsesalt"">CoarseSalt</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#coarsepepper"">CoarsePepper</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#solarize"">Solarize</a></td>\n</tr>\n<tr><td colspan=""5""><strong>artistic</strong></td></tr>\n<tr>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/artistic.html#cartoon"">Cartoon</a></sub></td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n</tr>\n<tr>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/artistic/cartoon.gif"" height=""144"" width=""128"" alt=""Cartoon""></td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n</tr>\n<tr><td colspan=""5""><strong>blend</strong></td></tr>\n<tr>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/blend.html#blendalpha"">BlendAlpha</a><br/>with EdgeDetect(1.0)</sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/blend.html#blendalphasimplexnoise"">BlendAlphaSimplexNoise</a><br/>with EdgeDetect(1.0)</sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/blend.html#blendalphafrequencynoise"">BlendAlphaFrequencyNoise</a><br/>with EdgeDetect(1.0)</sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/blend.html#blendalphasomecolors"">BlendAlphaSomeColors</a><br/>with RemoveSaturation(1.0)</sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/blend.html#blendalpharegulargrid"">BlendAlphaRegularGrid</a><br/>with Multiply((0.0, 0.5))</sub></td>\n</tr>\n<tr>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/blend/blendalpha_with_edgedetect_1_0.gif"" height=""148"" width=""100"" alt=""BlendAlpha with EdgeDetect1.0""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/blend/blendalphasimplexnoise_with_edgedetect_1_0.gif"" height=""148"" width=""100"" alt=""BlendAlphaSimplexNoise with EdgeDetect1.0""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/blend/blendalphafrequencynoise_with_edgedetect_1_0.gif"" height=""148"" width=""100"" alt=""BlendAlphaFrequencyNoise with EdgeDetect1.0""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/blend/blendalphasomecolors_with_removesaturation_1_0.gif"" height=""144"" width=""128"" alt=""BlendAlphaSomeColors with RemoveSaturation1.0""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/blend/blendalpharegulargrid_with_multiply_0_0_0_5.gif"" height=""148"" width=""100"" alt=""BlendAlphaRegularGrid with Multiply0.0, 0.5""></td>\n</tr>\n<tr>\n\n</tr>\n<tr>\n<td colspan=""5"">See also: <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/blend.html#blendalphamask"">BlendAlphaMask</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/blend.html#blendalphaelementwise"">BlendAlphaElementwise</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/blend.html#blendalphaverticallineargradient"">BlendAlphaVerticalLinearGradient</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/blend.html#blendalphahorizontallineargradient"">BlendAlphaHorizontalLinearGradient</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/blend.html#blendalphasegmapclassids"">BlendAlphaSegMapClassIds</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/blend.html#blendalphaboundingboxes"">BlendAlphaBoundingBoxes</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/blend.html#blendalphacheckerboard"">BlendAlphaCheckerboard</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blend.html#imgaug.augmenters.blend.SomeColorsMaskGen"">SomeColorsMaskGen</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blend.html#imgaug.augmenters.blend.HorizontalLinearGradientMaskGen"">HorizontalLinearGradientMaskGen</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blend.html#imgaug.augmenters.blend.VerticalLinearGradientMaskGen"">VerticalLinearGradientMaskGen</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blend.html#imgaug.augmenters.blend.RegularGridMaskGen"">RegularGridMaskGen</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blend.html#imgaug.augmenters.blend.CheckerboardMaskGen"">CheckerboardMaskGen</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blend.html#imgaug.augmenters.blend.SegMapClassIdsMaskGen"">SegMapClassIdsMaskGen</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blend.html#imgaug.augmenters.blend.BoundingBoxesMaskGen"">BoundingBoxesMaskGen</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blend.html#imgaug.augmenters.blend.InvertMaskGen"">InvertMaskGen</a></td>\n</tr>\n<tr><td colspan=""5""><strong>blur</strong></td></tr>\n<tr>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/blur.html#gaussianblur"">GaussianBlur</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/blur.html#averageblur"">AverageBlur</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/blur.html#medianblur"">MedianBlur</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/blur.html#bilateralblur"">BilateralBlur</a><br/>(sigma_color=250,<br/>sigma_space=250)</sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/blur.html#motionblur"">MotionBlur</a><br/>(angle=0)</sub></td>\n</tr>\n<tr>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/blur/gaussianblur.gif"" height=""148"" width=""100"" alt=""GaussianBlur""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/blur/averageblur.gif"" height=""148"" width=""100"" alt=""AverageBlur""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/blur/medianblur.gif"" height=""148"" width=""100"" alt=""MedianBlur""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/blur/bilateralblur_sigma_color_250_sigma_space_250.gif"" height=""148"" width=""100"" alt=""BilateralBlur sigma_color=250, sigma_space=250""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/blur/motionblur_angle_0.gif"" height=""148"" width=""100"" alt=""MotionBlur angle=0""></td>\n</tr>\n<tr>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/blur.html#motionblur"">MotionBlur</a><br/>(k=5)</sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/blur.html#meanshiftblur"">MeanShiftBlur</a></sub></td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n</tr>\n<tr>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/blur/motionblur_k_5.gif"" height=""148"" width=""100"" alt=""MotionBlur k=5""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/blur/meanshiftblur.gif"" height=""148"" width=""100"" alt=""MeanShiftBlur""></td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n</tr>\n<tr><td colspan=""5""><strong>collections</strong></td></tr>\n<tr>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/collections.html#randaugment"">RandAugment</a></sub></td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n</tr>\n<tr>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/collections/randaugment.gif"" height=""148"" width=""100"" alt=""RandAugment""></td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n</tr>\n<tr><td colspan=""5""><strong>color</strong></td></tr>\n<tr>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/color.html#multiplyandaddtobrightness"">MultiplyAndAddToBrightness</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/color.html#multiplyhueandsaturation"">MultiplyHueAndSaturation</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/color.html#multiplyhue"">MultiplyHue</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/color.html#multiplysaturation"">MultiplySaturation</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/color.html#addtohueandsaturation"">AddToHueAndSaturation</a></sub></td>\n</tr>\n<tr>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/color/multiplyandaddtobrightness.gif"" height=""148"" width=""100"" alt=""MultiplyAndAddToBrightness""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/color/multiplyhueandsaturation.gif"" height=""148"" width=""100"" alt=""MultiplyHueAndSaturation""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/color/multiplyhue.gif"" height=""148"" width=""100"" alt=""MultiplyHue""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/color/multiplysaturation.gif"" height=""148"" width=""100"" alt=""MultiplySaturation""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/color/addtohueandsaturation.gif"" height=""148"" width=""100"" alt=""AddToHueAndSaturation""></td>\n</tr>\n<tr>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/color.html#grayscale"">Grayscale</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/color.html#removesaturation"">RemoveSaturation</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/color.html#changecolortemperature"">ChangeColorTemperature</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/color.html#kmeanscolorquantization"">KMeansColorQuantization</a><br/>(to_colorspace=RGB)</sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/color.html#uniformcolorquantization"">UniformColorQuantization</a><br/>(to_colorspace=RGB)</sub></td>\n</tr>\n<tr>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/color/grayscale.gif"" height=""148"" width=""100"" alt=""Grayscale""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/color/removesaturation.gif"" height=""148"" width=""100"" alt=""RemoveSaturation""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/color/changecolortemperature.gif"" height=""148"" width=""100"" alt=""ChangeColorTemperature""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/color/kmeanscolorquantization_to_colorspace_rgb.gif"" height=""148"" width=""100"" alt=""KMeansColorQuantization to_colorspace=RGB""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/color/uniformcolorquantization_to_colorspace_rgb.gif"" height=""148"" width=""100"" alt=""UniformColorQuantization to_colorspace=RGB""></td>\n</tr>\n<tr>\n\n</tr>\n<tr>\n<td colspan=""5"">See also: <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/color.html#withcolorspace"">WithColorspace</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/color.html#withbrightnesschannels"">WithBrightnessChannels</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/color.html#multiplybrightness"">MultiplyBrightness</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/color.html#addtobrightness"">AddToBrightness</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/color.html#withhueandsaturation"">WithHueAndSaturation</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/color.html#addtohue"">AddToHue</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/color.html#addtosaturation"">AddToSaturation</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/color.html#changecolorspace"">ChangeColorspace</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/color.html#posterize"">Posterize</a></td>\n</tr>\n<tr><td colspan=""5""><strong>contrast</strong></td></tr>\n<tr>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/contrast.html#gammacontrast"">GammaContrast</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/contrast.html#gammacontrast"">GammaContrast</a><br/>(per_channel=True)</sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/contrast.html#sigmoidcontrast"">SigmoidContrast</a><br/>(cutoff=0.5)</sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/contrast.html#sigmoidcontrast"">SigmoidContrast</a><br/>(gain=10)</sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/contrast.html#logcontrast"">LogContrast</a></sub></td>\n</tr>\n<tr>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/contrast/gammacontrast.gif"" height=""148"" width=""100"" alt=""GammaContrast""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/contrast/gammacontrast_per_channel_true.gif"" height=""148"" width=""100"" alt=""GammaContrast per_channel=True""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/contrast/sigmoidcontrast_cutoff_0_5.gif"" height=""148"" width=""100"" alt=""SigmoidContrast cutoff=0.5""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/contrast/sigmoidcontrast_gain_10.gif"" height=""148"" width=""100"" alt=""SigmoidContrast gain=10""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/contrast/logcontrast.gif"" height=""148"" width=""100"" alt=""LogContrast""></td>\n</tr>\n<tr>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/contrast.html#linearcontrast"">LinearContrast</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/contrast.html#allchannelshistogramequalization"">AllChannels-</a><br/>HistogramEqualization</sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/contrast.html#histogramequalization"">HistogramEqualization</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/contrast.html#allchannelsclahe"">AllChannelsCLAHE</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/contrast.html#clahe"">CLAHE</a></sub></td>\n</tr>\n<tr>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/contrast/linearcontrast.gif"" height=""148"" width=""100"" alt=""LinearContrast""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/contrast/allchannels_histogramequalization.gif"" height=""148"" width=""100"" alt=""AllChannels- HistogramEqualization""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/contrast/histogramequalization.gif"" height=""148"" width=""100"" alt=""HistogramEqualization""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/contrast/allchannelsclahe.gif"" height=""148"" width=""100"" alt=""AllChannelsCLAHE""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/contrast/clahe.gif"" height=""148"" width=""100"" alt=""CLAHE""></td>\n</tr>\n<tr>\n\n</tr>\n<tr>\n<td colspan=""5"">See also: <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/contrast.html#equalize"">Equalize</a></td>\n</tr>\n<tr><td colspan=""5""><strong>convolutional</strong></td></tr>\n<tr>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/convolutional.html#sharpen"">Sharpen</a><br/>(alpha=1)</sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/convolutional.html#emboss"">Emboss</a><br/>(alpha=1)</sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/convolutional.html#edgedetect"">EdgeDetect</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/convolutional.html#directededgedetect"">DirectedEdgeDetect</a><br/>(alpha=1)</sub></td>\n<td>&nbsp;</td>\n</tr>\n<tr>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/convolutional/sharpen_alpha_1.gif"" height=""148"" width=""100"" alt=""Sharpen alpha=1""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/convolutional/emboss_alpha_1.gif"" height=""148"" width=""100"" alt=""Emboss alpha=1""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/convolutional/edgedetect.gif"" height=""148"" width=""100"" alt=""EdgeDetect""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/convolutional/directededgedetect_alpha_1.gif"" height=""148"" width=""100"" alt=""DirectedEdgeDetect alpha=1""></td>\n<td>&nbsp;</td>\n</tr>\n<tr>\n\n</tr>\n<tr>\n<td colspan=""5"">See also: <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/convolutional.html#convolve"">Convolve</a></td>\n</tr>\n<tr>\n<td colspan=""5""><strong>debug</strong></td></tr>\n<tr>\n<td colspan=""5"">See also: <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/debug.html#savedebugimageeverynbatches"">SaveDebugImageEveryNBatches</a></td>\n</tr>\n<tr><td colspan=""5""><strong>edges</strong></td></tr>\n<tr>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/edges.html#canny"">Canny</a></sub></td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n</tr>\n<tr>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/edges/canny.gif"" height=""148"" width=""100"" alt=""Canny""></td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n</tr>\n<tr><td colspan=""5""><strong>flip</strong></td></tr>\n<tr>\n<td colspan=""2""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/flip.html#fliplr"">Fliplr</a></sub></td>\n<td colspan=""2""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/flip.html#flipud"">Flipud</a></sub></td>\n<td>&nbsp;</td>\n</tr>\n<tr>\n<td colspan=""2""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/flip/fliplr.gif"" height=""148"" width=""300"" alt=""Fliplr""></td>\n<td colspan=""2""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/flip/flipud.gif"" height=""148"" width=""300"" alt=""Flipud""></td>\n<td>&nbsp;</td>\n</tr>\n<tr>\n\n</tr>\n<tr>\n<td colspan=""5"">See also: <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/color.html#horizontalflip"">HorizontalFlip</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/color.html#verticalflip"">VerticalFlip</a></td>\n</tr>\n<tr><td colspan=""5""><strong>geometric</strong></td></tr>\n<tr>\n<td colspan=""2""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/geometric.html#affine"">Affine</a></sub></td>\n<td colspan=""2""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/geometric.html#affine"">Affine: Modes</a></sub></td>\n<td>&nbsp;</td>\n</tr>\n<tr>\n<td colspan=""2""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/geometric/affine.gif"" height=""148"" width=""300"" alt=""Affine""></td>\n<td colspan=""2""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/geometric/affine_modes.gif"" height=""148"" width=""300"" alt=""Affine: Modes""></td>\n<td>&nbsp;</td>\n</tr>\n<tr>\n<td colspan=""2""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/geometric.html#affine"">Affine: cval</a></sub></td>\n<td colspan=""2""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/geometric.html#piecewiseaffine"">PiecewiseAffine</a></sub></td>\n<td>&nbsp;</td>\n</tr>\n<tr>\n<td colspan=""2""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/geometric/affine_cval.gif"" height=""148"" width=""300"" alt=""Affine: cval""></td>\n<td colspan=""2""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/geometric/piecewiseaffine.gif"" height=""148"" width=""300"" alt=""PiecewiseAffine""></td>\n<td>&nbsp;</td>\n</tr>\n<tr>\n<td colspan=""2""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/geometric.html#perspectivetransform"">PerspectiveTransform</a></sub></td>\n<td colspan=""2""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/geometric.html#elastictransformation"">ElasticTransformation</a><br/>(sigma=1.0)</sub></td>\n<td>&nbsp;</td>\n</tr>\n<tr>\n<td colspan=""2""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/geometric/perspectivetransform.gif"" height=""148"" width=""300"" alt=""PerspectiveTransform""></td>\n<td colspan=""2""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/geometric/elastictransformation_sigma_1_0.gif"" height=""148"" width=""300"" alt=""ElasticTransformation sigma=1.0""></td>\n<td>&nbsp;</td>\n</tr>\n<tr>\n<td colspan=""2""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/geometric.html#elastictransformation"">ElasticTransformation</a><br/>(sigma=4.0)</sub></td>\n<td colspan=""2""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/geometric.html#rot90"">Rot90</a></sub></td>\n<td>&nbsp;</td>\n</tr>\n<tr>\n<td colspan=""2""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/geometric/elastictransformation_sigma_4_0.gif"" height=""148"" width=""300"" alt=""ElasticTransformation sigma=4.0""></td>\n<td colspan=""2""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/geometric/rot90.gif"" height=""148"" width=""300"" alt=""Rot90""></td>\n<td>&nbsp;</td>\n</tr>\n<tr>\n<td colspan=""2""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/geometric.html#withpolarwarping"">WithPolarWarping</a><br/>+Affine</sub></td>\n<td colspan=""2""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/geometric.html#jigsaw"">Jigsaw</a><br/>(5x5 grid)</sub></td>\n<td>&nbsp;</td>\n</tr>\n<tr>\n<td colspan=""2""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/geometric/withpolarwarping_affine.gif"" height=""148"" width=""300"" alt=""WithPolarWarping +Affine""></td>\n<td colspan=""2""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/geometric/jigsaw_5x5_grid.gif"" height=""148"" width=""300"" alt=""Jigsaw 5x5 grid""></td>\n<td>&nbsp;</td>\n</tr>\n<tr>\n\n</tr>\n<tr>\n<td colspan=""5"">See also: <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/geometric.html#scalex"">ScaleX</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/geometric.html#scaley"">ScaleY</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/geometric.html#translatex"">TranslateX</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/geometric.html#translatey"">TranslateY</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/geometric.html#rotate"">Rotate</a></td>\n</tr>\n<tr><td colspan=""5""><strong>imgcorruptlike</strong></td></tr>\n<tr>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/imgcorruptlike.html#glassblur"">GlassBlur</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/imgcorruptlike.html#defocusblur"">DefocusBlur</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/imgcorruptlike.html#zoomblur"">ZoomBlur</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/imgcorruptlike.html#snow"">Snow</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/imgcorruptlike.html#spatter"">Spatter</a></sub></td>\n</tr>\n<tr>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/imgcorruptlike/glassblur.gif"" height=""148"" width=""100"" alt=""GlassBlur""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/imgcorruptlike/defocusblur.gif"" height=""148"" width=""100"" alt=""DefocusBlur""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/imgcorruptlike/zoomblur.gif"" height=""148"" width=""100"" alt=""ZoomBlur""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/imgcorruptlike/snow.gif"" height=""148"" width=""100"" alt=""Snow""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/imgcorruptlike/spatter.gif"" height=""148"" width=""100"" alt=""Spatter""></td>\n</tr>\n<tr>\n\n</tr>\n<tr>\n<td colspan=""5"">See also: <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/imgcorruptlike.html#gaussiannoise"">GaussianNoise</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/imgcorruptlike.html#shotnoise"">ShotNoise</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/imgcorruptlike.html#impulsenoise"">ImpulseNoise</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/imgcorruptlike.html#specklenoise"">SpeckleNoise</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/imgcorruptlike.html#gaussianblur"">GaussianBlur</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/imgcorruptlike.html#motionblur"">MotionBlur</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/imgcorruptlike.html#fog"">Fog</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/imgcorruptlike.html#frost"">Frost</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/imgcorruptlike.html#contrast"">Contrast</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/imgcorruptlike.html#brightness"">Brightness</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/imgcorruptlike.html#saturate"">Saturate</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/imgcorruptlike.html#jpegcompression"">JpegCompression</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/imgcorruptlike.html#pixelate"">Pixelate</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/imgcorruptlike.html#elastictransform"">ElasticTransform</a></td>\n</tr>\n<tr><td colspan=""5""><strong>pillike</strong></td></tr>\n<tr>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/pillike.html#autocontrast"">Autocontrast</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/pillike.html#enhancecolor"">EnhanceColor</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/pillike.html#enhancesharpness"">EnhanceSharpness</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/pillike.html#filteredgeenhancemore"">FilterEdgeEnhanceMore</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/pillike.html#filtercontour"">FilterContour</a></sub></td>\n</tr>\n<tr>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/pillike/autocontrast.gif"" height=""148"" width=""100"" alt=""Autocontrast""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/pillike/enhancecolor.gif"" height=""148"" width=""100"" alt=""EnhanceColor""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/pillike/enhancesharpness.gif"" height=""148"" width=""100"" alt=""EnhanceSharpness""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/pillike/filteredgeenhancemore.gif"" height=""148"" width=""100"" alt=""FilterEdgeEnhanceMore""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/pillike/filtercontour.gif"" height=""148"" width=""100"" alt=""FilterContour""></td>\n</tr>\n<tr>\n\n</tr>\n<tr>\n<td colspan=""5"">See also: <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/pillike.html#solarize"">Solarize</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/pillike.html#posterize"">Posterize</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/pillike.html#equalize"">Equalize</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/pillike.html#enhancecontrast"">EnhanceContrast</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/pillike.html#enhancebrightness"">EnhanceBrightness</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/pillike.html#filterblur"">FilterBlur</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/pillike.html#filtersmooth"">FilterSmooth</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/pillike.html#filtersmoothmore"">FilterSmoothMore</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/pillike.html#filteredgeenhance"">FilterEdgeEnhance</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/pillike.html#filterfindedges"">FilterFindEdges</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/pillike.html#filteremboss"">FilterEmboss</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/pillike.html#filtersharpen"">FilterSharpen</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/pillike.html#filterdetail"">FilterDetail</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/pillike.html#affine"">Affine</a></td>\n</tr>\n<tr><td colspan=""5""><strong>pooling</strong></td></tr>\n<tr>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/pooling.html#averagepooling"">AveragePooling</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/pooling.html#maxpooling"">MaxPooling</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/pooling.html#minpooling"">MinPooling</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/pooling.html#medianpooling"">MedianPooling</a></sub></td>\n<td>&nbsp;</td>\n</tr>\n<tr>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/pooling/averagepooling.gif"" height=""148"" width=""100"" alt=""AveragePooling""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/pooling/maxpooling.gif"" height=""148"" width=""100"" alt=""MaxPooling""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/pooling/minpooling.gif"" height=""148"" width=""100"" alt=""MinPooling""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/pooling/medianpooling.gif"" height=""148"" width=""100"" alt=""MedianPooling""></td>\n<td>&nbsp;</td>\n</tr>\n<tr><td colspan=""5""><strong>segmentation</strong></td></tr>\n<tr>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/segmentation.html#superpixels"">Superpixels</a><br/>(p_replace=1)</sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/segmentation.html#superpixels"">Superpixels</a><br/>(n_segments=100)</sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/segmentation.html#uniformvoronoi"">UniformVoronoi</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/segmentation.html#regulargridvoronoi"">RegularGridVoronoi: rows/cols</a><br/>(p_drop_points=0)</sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/segmentation.html#regulargridvoronoi"">RegularGridVoronoi: p_drop_points</a><br/>(n_rows=n_cols=30)</sub></td>\n</tr>\n<tr>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/segmentation/superpixels_p_replace_1.gif"" height=""148"" width=""100"" alt=""Superpixels p_replace=1""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/segmentation/superpixels_n_segments_100.gif"" height=""148"" width=""100"" alt=""Superpixels n_segments=100""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/segmentation/uniformvoronoi.gif"" height=""148"" width=""100"" alt=""UniformVoronoi""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/segmentation/regulargridvoronoi_rows_cols_p_drop_points_0.gif"" height=""148"" width=""100"" alt=""RegularGridVoronoi: rows/cols p_drop_points=0""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/segmentation/regulargridvoronoi_p_drop_points_n_rows_n_cols_30.gif"" height=""148"" width=""100"" alt=""RegularGridVoronoi: p_drop_points n_rows=n_cols=30""></td>\n</tr>\n<tr>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/segmentation.html#regulargridvoronoi"">RegularGridVoronoi: p_replace</a><br/>(n_rows=n_cols=16)</sub></td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n</tr>\n<tr>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/segmentation/regulargridvoronoi_p_replace_n_rows_n_cols_16.gif"" height=""148"" width=""100"" alt=""RegularGridVoronoi: p_replace n_rows=n_cols=16""></td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n</tr>\n<tr>\n\n</tr>\n<tr>\n<td colspan=""5"">See also: <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/segmentation.html#voronoi"">Voronoi</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/segmentation.html#relativeregulargridvoronoi"">RelativeRegularGridVoronoi</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/api_augmenters_segmentation.html#imgaug.augmenters.segmentation.RegularGridPointsSampler"">RegularGridPointsSampler</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/api_augmenters_segmentation.html#imgaug.augmenters.segmentation.RelativeRegularGridPointsSampler"">RelativeRegularGridPointsSampler</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/api_augmenters_segmentation.html#imgaug.augmenters.segmentation.DropoutPointsSampler"">DropoutPointsSampler</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/api_augmenters_segmentation.html#imgaug.augmenters.segmentation.UniformPointsSampler"">UniformPointsSampler</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/api_augmenters_segmentation.html#imgaug.augmenters.segmentation.SubsamplingPointsSampler"">SubsamplingPointsSampler</a></td>\n</tr>\n<tr><td colspan=""5""><strong>size</strong></td></tr>\n<tr>\n<td colspan=""2""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/size.html#cropandpad"">CropAndPad</a></sub></td>\n<td colspan=""2""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/size.html#crop"">Crop</a></sub></td>\n<td>&nbsp;</td>\n</tr>\n<tr>\n<td colspan=""2""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/size/cropandpad.gif"" height=""148"" width=""300"" alt=""CropAndPad""></td>\n<td colspan=""2""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/size/crop.gif"" height=""148"" width=""300"" alt=""Crop""></td>\n<td>&nbsp;</td>\n</tr>\n<tr>\n<td colspan=""2""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/size.html#pad"">Pad</a></sub></td>\n<td colspan=""2""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/size.html#padtofixedsize"">PadToFixedSize</a><br/>(height\'=height+32,<br/>width\'=width+32)</sub></td>\n<td>&nbsp;</td>\n</tr>\n<tr>\n<td colspan=""2""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/size/pad.gif"" height=""148"" width=""300"" alt=""Pad""></td>\n<td colspan=""2""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/size/padtofixedsize_height_height_32_width_width_32.gif"" height=""148"" width=""300"" alt=""PadToFixedSize height\'=height+32, width\'=width+32""></td>\n<td>&nbsp;</td>\n</tr>\n<tr>\n<td colspan=""2""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/size.html#croptofixedsize"">CropToFixedSize</a><br/>(height\'=height-32,<br/>width\'=width-32)</sub></td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n</tr>\n<tr>\n<td colspan=""2""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/size/croptofixedsize_height_height_32_width_width_32.gif"" height=""148"" width=""300"" alt=""CropToFixedSize height\'=height-32, width\'=width-32""></td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n<td>&nbsp;</td>\n</tr>\n<tr>\n\n</tr>\n<tr>\n<td colspan=""5"">See also: <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/size.html#resize"">Resize</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/size.html#croptomultiplesof"">CropToMultiplesOf</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/size.html#padtomultiplesof"">PadToMultiplesOf</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/size.html#croptopowersof"">CropToPowersOf</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/size.html#padtopowersof"">PadToPowersOf</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/size.html#croptoaspectratio"">CropToAspectRatio</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/size.html#padtoaspectratio"">PadToAspectRatio</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/size.html#croptosquare"">CropToSquare</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/size.html#padtosquare"">PadToSquare</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/size.html#centercroptofixedsize"">CenterCropToFixedSize</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/size.html#centerpadtofixedsize"">CenterPadToFixedSize</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/size.html#centercroptomultiplesof"">CenterCropToMultiplesOf</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/size.html#centerpadtomultiplesof"">CenterPadToMultiplesOf</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/size.html#centercroptopowersof"">CenterCropToPowersOf</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/size.html#centerpadtopowersof"">CenterPadToPowersOf</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/size.html#centercroptoaspectratio"">CenterCropToAspectRatio</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/size.html#centerpadtoaspectratio"">CenterPadToAspectRatio</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/size.html#centercroptosquare"">CenterCropToSquare</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/size.html#centerpadtosquare"">CenterPadToSquare</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/size.html#keepsizebyresize"">KeepSizeByResize</a></td>\n</tr>\n<tr><td colspan=""5""><strong>weather</strong></td></tr>\n<tr>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/weather.html#fastsnowylandscape"">FastSnowyLandscape</a><br/>(lightness_multiplier=2.0)</sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/weather.html#clouds"">Clouds</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/weather.html#fog"">Fog</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/weather.html#snowflakes"">Snowflakes</a></sub></td>\n<td colspan=""1""><sub><a href=""https://imgaug.readthedocs.io/en/latest/source/overview/weather.html#rain"">Rain</a></sub></td>\n</tr>\n<tr>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/weather/fastsnowylandscape_lightness_multiplier_2_0.gif"" height=""144"" width=""128"" alt=""FastSnowyLandscape lightness_multiplier=2.0""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/weather/clouds.gif"" height=""144"" width=""128"" alt=""Clouds""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/weather/fog.gif"" height=""144"" width=""128"" alt=""Fog""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/weather/snowflakes.gif"" height=""144"" width=""128"" alt=""Snowflakes""></td>\n<td colspan=""1""><img src=""https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/weather/rain.gif"" height=""144"" width=""128"" alt=""Rain""></td>\n</tr>\n<tr>\n\n</tr>\n<tr>\n<td colspan=""5"">See also: <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/weather.html#cloudlayer"">CloudLayer</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/weather.html#snowflakeslayer"">SnowflakesLayer</a>, <a href=""https://imgaug.readthedocs.io/en/latest/source/overview/weather.html#rainlayer"">RainLayer</a></td>\n</tr>\n\n</table>\n\n\n\n<a name=""code_examples""/>\n\n\n## Code Examples\n\n### Example: Simple Training Setting\n\nA standard machine learning situation.\nTrain on batches of images and augment each batch via crop, horizontal\nflip (""Fliplr"") and gaussian blur:\n```python\nimport numpy as np\nimport imgaug.augmenters as iaa\n\ndef load_batch(batch_idx):\n    # dummy function, implement this\n    # Return a numpy array of shape (N, height, width, #channels)\n    # or a list of (height, width, #channels) arrays (may have different image\n    # sizes).\n    # Images should be in RGB for colorspace augmentations.\n    # (cv2.imread() returns BGR!)\n    # Images should usually be in uint8 with values from 0-255.\n    return np.zeros((128, 32, 32, 3), dtype=np.uint8) + (batch_idx % 255)\n\ndef train_on_images(images):\n    # dummy function, implement this\n    pass\n\n# Pipeline:\n# (1) Crop images from each side by 1-16px, do not resize the results\n#     images back to the input size. Keep them at the cropped size.\n# (2) Horizontally flip 50% of the images.\n# (3) Blur images using a gaussian kernel with sigma between 0.0 and 3.0.\nseq = iaa.Sequential([\n    iaa.Crop(px=(1, 16), keep_size=False),\n    iaa.Fliplr(0.5),\n    iaa.GaussianBlur(sigma=(0, 3.0))\n])\n\nfor batch_idx in range(100):\n    images = load_batch(batch_idx)\n    images_aug = seq(images=images)  # done by the library\n    train_on_images(images_aug)\n```\n\n\n### Example: Very Complex Augmentation Pipeline\n\nApply a very heavy augmentation pipeline to images (used to create the image \nat the very top of this readme):\n```python\nimport numpy as np\nimport imgaug as ia\nimport imgaug.augmenters as iaa\n\n# random example images\nimages = np.random.randint(0, 255, (16, 128, 128, 3), dtype=np.uint8)\n\n# Sometimes(0.5, ...) applies the given augmenter in 50% of all cases,\n# e.g. Sometimes(0.5, GaussianBlur(0.3)) would blur roughly every second image.\nsometimes = lambda aug: iaa.Sometimes(0.5, aug)\n\n# Define our sequence of augmentation steps that will be applied to every image\n# All augmenters with per_channel=0.5 will sample one value _per image_\n# in 50% of all cases. In all other cases they will sample new values\n# _per channel_.\n\nseq = iaa.Sequential(\n    [\n        # apply the following augmenters to most images\n        iaa.Fliplr(0.5), # horizontally flip 50% of all images\n        iaa.Flipud(0.2), # vertically flip 20% of all images\n        # crop images by -5% to 10% of their height/width\n        sometimes(iaa.CropAndPad(\n            percent=(-0.05, 0.1),\n            pad_mode=ia.ALL,\n            pad_cval=(0, 255)\n        )),\n        sometimes(iaa.Affine(\n            scale={""x"": (0.8, 1.2), ""y"": (0.8, 1.2)}, # scale images to 80-120% of their size, individually per axis\n            translate_percent={""x"": (-0.2, 0.2), ""y"": (-0.2, 0.2)}, # translate by -20 to +20 percent (per axis)\n            rotate=(-45, 45), # rotate by -45 to +45 degrees\n            shear=(-16, 16), # shear by -16 to +16 degrees\n            order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n            cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n            mode=ia.ALL # use any of scikit-image\'s warping modes (see 2nd image from the top for examples)\n        )),\n        # execute 0 to 5 of the following (less important) augmenters per image\n        # don\'t execute all of them, as that would often be way too strong\n        iaa.SomeOf((0, 5),\n            [\n                sometimes(iaa.Superpixels(p_replace=(0, 1.0), n_segments=(20, 200))), # convert images into their superpixel representation\n                iaa.OneOf([\n                    iaa.GaussianBlur((0, 3.0)), # blur images with a sigma between 0 and 3.0\n                    iaa.AverageBlur(k=(2, 7)), # blur image using local means with kernel sizes between 2 and 7\n                    iaa.MedianBlur(k=(3, 11)), # blur image using local medians with kernel sizes between 2 and 7\n                ]),\n                iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)), # sharpen images\n                iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)), # emboss images\n                # search either for all edges or for directed edges,\n                # blend the result with the original image using a blobby mask\n                iaa.SimplexNoiseAlpha(iaa.OneOf([\n                    iaa.EdgeDetect(alpha=(0.5, 1.0)),\n                    iaa.DirectedEdgeDetect(alpha=(0.5, 1.0), direction=(0.0, 1.0)),\n                ])),\n                iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5), # add gaussian noise to images\n                iaa.OneOf([\n                    iaa.Dropout((0.01, 0.1), per_channel=0.5), # randomly remove up to 10% of the pixels\n                    iaa.CoarseDropout((0.03, 0.15), size_percent=(0.02, 0.05), per_channel=0.2),\n                ]),\n                iaa.Invert(0.05, per_channel=True), # invert color channels\n                iaa.Add((-10, 10), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\n                iaa.AddToHueAndSaturation((-20, 20)), # change hue and saturation\n                # either change the brightness of the whole image (sometimes\n                # per channel) or change the brightness of subareas\n                iaa.OneOf([\n                    iaa.Multiply((0.5, 1.5), per_channel=0.5),\n                    iaa.FrequencyNoiseAlpha(\n                        exponent=(-4, 0),\n                        first=iaa.Multiply((0.5, 1.5), per_channel=True),\n                        second=iaa.LinearContrast((0.5, 2.0))\n                    )\n                ]),\n                iaa.LinearContrast((0.5, 2.0), per_channel=0.5), # improve or worsen the contrast\n                iaa.Grayscale(alpha=(0.0, 1.0)),\n                sometimes(iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)), # move pixels locally around (with random strengths)\n                sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))), # sometimes move parts of the image around\n                sometimes(iaa.PerspectiveTransform(scale=(0.01, 0.1)))\n            ],\n            random_order=True\n        )\n    ],\n    random_order=True\n)\nimages_aug = seq(images=images)\n```\n\n\n### Example: Augment Images and Keypoints\n\nAugment images and keypoints/landmarks on the same images:\n```python\nimport numpy as np\nimport imgaug.augmenters as iaa\n\nimages = np.zeros((2, 128, 128, 3), dtype=np.uint8)  # two example images\nimages[:, 64, 64, :] = 255\npoints = [\n    [(10.5, 20.5)],  # points on first image\n    [(50.5, 50.5), (60.5, 60.5), (70.5, 70.5)]  # points on second image\n]\n\nseq = iaa.Sequential([\n    iaa.AdditiveGaussianNoise(scale=0.05*255),\n    iaa.Affine(translate_px={""x"": (1, 5)})\n])\n\n# augment keypoints and images\nimages_aug, points_aug = seq(images=images, keypoints=points)\n\nprint(""Image 1 center"", np.argmax(images_aug[0, 64, 64:64+6, 0]))\nprint(""Image 2 center"", np.argmax(images_aug[1, 64, 64:64+6, 0]))\nprint(""Points 1"", points_aug[0])\nprint(""Points 2"", points_aug[1])\n```\nNote that all coordinates in `imgaug` are subpixel-accurate, which is\nwhy `x=0.5, y=0.5` denotes the center of the top left pixel.\n\n\n### Example: Augment Images and Bounding Boxes\n\n```python\nimport numpy as np\nimport imgaug as ia\nimport imgaug.augmenters as iaa\n\nimages = np.zeros((2, 128, 128, 3), dtype=np.uint8)  # two example images\nimages[:, 64, 64, :] = 255\nbbs = [\n    [ia.BoundingBox(x1=10.5, y1=15.5, x2=30.5, y2=50.5)],\n    [ia.BoundingBox(x1=10.5, y1=20.5, x2=50.5, y2=50.5),\n     ia.BoundingBox(x1=40.5, y1=75.5, x2=70.5, y2=100.5)]\n]\n\nseq = iaa.Sequential([\n    iaa.AdditiveGaussianNoise(scale=0.05*255),\n    iaa.Affine(translate_px={""x"": (1, 5)})\n])\n\nimages_aug, bbs_aug = seq(images=images, bounding_boxes=bbs)\n```\n\n\n### Example: Augment Images and Polygons\n\n```python\nimport numpy as np\nimport imgaug as ia\nimport imgaug.augmenters as iaa\n\nimages = np.zeros((2, 128, 128, 3), dtype=np.uint8)  # two example images\nimages[:, 64, 64, :] = 255\npolygons = [\n    [ia.Polygon([(10.5, 10.5), (50.5, 10.5), (50.5, 50.5)])],\n    [ia.Polygon([(0.0, 64.5), (64.5, 0.0), (128.0, 128.0), (64.5, 128.0)])]\n]\n\nseq = iaa.Sequential([\n    iaa.AdditiveGaussianNoise(scale=0.05*255),\n    iaa.Affine(translate_px={""x"": (1, 5)})\n])\n\nimages_aug, polygons_aug = seq(images=images, polygons=polygons)\n```\n\n\n### Example: Augment Images and LineStrings\n\nLineStrings are similar to polygons, but are not closed, may intersect with\nthemselves and don\'t have an inner area.\n```python\nimport numpy as np\nimport imgaug as ia\nimport imgaug.augmenters as iaa\n\nimages = np.zeros((2, 128, 128, 3), dtype=np.uint8)  # two example images\nimages[:, 64, 64, :] = 255\nls = [\n    [ia.LineString([(10.5, 10.5), (50.5, 10.5), (50.5, 50.5)])],\n    [ia.LineString([(0.0, 64.5), (64.5, 0.0), (128.0, 128.0), (64.5, 128.0),\n                    (128.0, 0.0)])]\n]\n\nseq = iaa.Sequential([\n    iaa.AdditiveGaussianNoise(scale=0.05*255),\n    iaa.Affine(translate_px={""x"": (1, 5)})\n])\n\nimages_aug, ls_aug = seq(images=images, line_strings=ls)\n```\n\n\n### Example: Augment Images and Heatmaps\n\nHeatmaps are dense float arrays with values between `0.0` and `1.0`.\nThey can be used e.g. when training models to predict facial landmark\nlocations. Note that the heatmaps here have lower height and width than the\nimages. `imgaug` handles that case automatically. The crop pixel amounts will\nbe halved for the heatmaps.\n\n```python\nimport numpy as np\nimport imgaug.augmenters as iaa\n\n# Standard scenario: You have N RGB-images and additionally 21 heatmaps per\n# image. You want to augment each image and its heatmaps identically.\nimages = np.random.randint(0, 255, (16, 128, 128, 3), dtype=np.uint8)\nheatmaps = np.random.random(size=(16, 64, 64, 1)).astype(np.float32)\n\nseq = iaa.Sequential([\n    iaa.GaussianBlur((0, 3.0)),\n    iaa.Affine(translate_px={""x"": (-40, 40)}),\n    iaa.Crop(px=(0, 10))\n])\n\nimages_aug, heatmaps_aug = seq(images=images, heatmaps=heatmaps)\n```\n\n\n### Example: Augment Images and Segmentation Maps\n\nThis is similar to heatmaps, but the dense arrays have dtype `int32`.\nOperations such as resizing will automatically use nearest neighbour\ninterpolation.\n\n```python\nimport numpy as np\nimport imgaug.augmenters as iaa\n\n# Standard scenario: You have N=16 RGB-images and additionally one segmentation\n# map per image. You want to augment each image and its heatmaps identically.\nimages = np.random.randint(0, 255, (16, 128, 128, 3), dtype=np.uint8)\nsegmaps = np.random.randint(0, 10, size=(16, 64, 64, 1), dtype=np.int32)\n\nseq = iaa.Sequential([\n    iaa.GaussianBlur((0, 3.0)),\n    iaa.Affine(translate_px={""x"": (-40, 40)}),\n    iaa.Crop(px=(0, 10))\n])\n\nimages_aug, segmaps_aug = seq(images=images, segmentation_maps=segmaps)\n```\n\n\n### Example: Visualize Augmented Images\n\nQuickly show example results of your augmentation sequence:\n```python\nimport numpy as np\nimport imgaug.augmenters as iaa\n\nimages = np.random.randint(0, 255, (16, 128, 128, 3), dtype=np.uint8)\nseq = iaa.Sequential([iaa.Fliplr(0.5), iaa.GaussianBlur((0, 3.0))])\n\n# Show an image with 8*8 augmented versions of image 0 and 8*8 augmented\n# versions of image 1. Identical augmentations will be applied to\n# image 0 and 1.\nseq.show_grid([images[0], images[1]], cols=8, rows=8)\n```\n\n\n### Example: Visualize Augmented Non-Image Data\n\n`imgaug` contains many helper function, among these functions to quickly\nvisualize augmented non-image results, such as bounding boxes or heatmaps.\n\n```python\nimport numpy as np\nimport imgaug as ia\n\nimage = np.zeros((64, 64, 3), dtype=np.uint8)\n\n# points\nkps = [ia.Keypoint(x=10.5, y=20.5), ia.Keypoint(x=60.5, y=60.5)]\nkpsoi = ia.KeypointsOnImage(kps, shape=image.shape)\nimage_with_kps = kpsoi.draw_on_image(image, size=7, color=(0, 0, 255))\nia.imshow(image_with_kps)\n\n# bbs\nbbsoi = ia.BoundingBoxesOnImage([\n    ia.BoundingBox(x1=10.5, y1=20.5, x2=50.5, y2=30.5)\n], shape=image.shape)\nimage_with_bbs = bbsoi.draw_on_image(image)\nimage_with_bbs = ia.BoundingBox(\n    x1=50.5, y1=10.5, x2=100.5, y2=16.5\n).draw_on_image(image_with_bbs, color=(255, 0, 0), size=3)\nia.imshow(image_with_bbs)\n\n# polygons\npsoi = ia.PolygonsOnImage([\n    ia.Polygon([(10.5, 20.5), (50.5, 30.5), (10.5, 50.5)])\n], shape=image.shape)\nimage_with_polys = psoi.draw_on_image(\n    image, alpha_points=0, alpha_face=0.5, color_lines=(255, 0, 0))\nia.imshow(image_with_polys)\n\n# heatmaps\nhms = ia.HeatmapsOnImage(np.random.random(size=(32, 32, 1)).astype(np.float32),\n                         shape=image.shape)\nimage_with_hms = hms.draw_on_image(image)\nia.imshow(image_with_hms)\n```\n\nLineStrings and segmentation maps support similar methods as shown above.\n\n\n### Example: Using Augmenters Only Once \n\nWhile the interface is adapted towards re-using instances of augmenters\nmany times, you are also free to use them only once. The overhead to\ninstantiate the augmenters each time is usually negligible.\n\n```python\nfrom imgaug import augmenters as iaa\nimport numpy as np\n\nimages = np.random.randint(0, 255, (16, 128, 128, 3), dtype=np.uint8)\n\n# always horizontally flip each input image\nimages_aug = iaa.Fliplr(1.0)(images=images)\n\n# vertically flip each input image with 90% probability\nimages_aug = iaa.Flipud(0.9)(images=images)\n\n# blur 50% of all images using a gaussian kernel with a sigma of 3.0\nimages_aug = iaa.Sometimes(0.5, iaa.GaussianBlur(3.0))(images=images)\n```\n\n\n### Example: Multicore Augmentation\n\nImages can be augmented in **background processes** using the\nmethod `augment_batches(batches, background=True)`, where `batches` is\na list/generator of\n[imgaug.augmentables.batches.UnnormalizedBatch](https://imgaug.readthedocs.io/en/latest/_modules/imgaug/augmentables/batches.html#UnnormalizedBatch)\nor\n[imgaug.augmentables.batches.Batch](https://imgaug.readthedocs.io/en/latest/source/api_augmentables_batches.html#imgaug.augmentables.batches.Batch).\nThe following example augments a list of image batches in the background:\n```python\nimport skimage.data\nimport imgaug as ia\nimport imgaug.augmenters as iaa\nfrom imgaug.augmentables.batches import UnnormalizedBatch\n\n# Number of batches and batch size for this example\nnb_batches = 10\nbatch_size = 32\n\n# Example augmentation sequence to run in the background\naugseq = iaa.Sequential([\n    iaa.Fliplr(0.5),\n    iaa.CoarseDropout(p=0.1, size_percent=0.1)\n])\n\n# For simplicity, we use the same image here many times\nastronaut = skimage.data.astronaut()\nastronaut = ia.imresize_single_image(astronaut, (64, 64))\n\n# Make batches out of the example image (here: 10 batches, each 32 times\n# the example image)\nbatches = []\nfor _ in range(nb_batches):\n    batches.append(UnnormalizedBatch(images=[astronaut] * batch_size))\n\n# Show the augmented images.\n# Note that augment_batches() returns a generator.\nfor images_aug in augseq.augment_batches(batches, background=True):\n    ia.imshow(ia.draw_grid(images_aug.images_aug, cols=8))\n```\n\nIf you need more control over the background augmentation, e.g. to set\nseeds, control the number of used CPU cores or constraint the memory usage,\nsee the corresponding\n[multicore augmentation notebook](https://nbviewer.jupyter.org/github/aleju/imgaug-doc/blob/master/notebooks/A03%20-%20Multicore%20Augmentation.ipynb)\nor the API about\n[Augmenter.pool()](https://imgaug.readthedocs.io/en/latest/source/api_augmenters_meta.html#imgaug.augmenters.meta.Augmenter.pool)\nand\n[imgaug.multicore.Pool](https://imgaug.readthedocs.io/en/latest/source/api_multicore.html#imgaug.multicore.Pool).\n\n\n### Example: Probability Distributions as Parameters\n\nMost augmenters support using tuples `(a, b)` as a shortcut to denote\n`uniform(a, b)` or lists `[a, b, c]` to denote a set of allowed values from\nwhich one will be picked randomly. If you require more complex probability\ndistributions (e.g. gaussians, truncated gaussians or poisson distributions)\nyou can use stochastic parameters from `imgaug.parameters`:\n\n```python\nimport numpy as np\nfrom imgaug import augmenters as iaa\nfrom imgaug import parameters as iap\n\nimages = np.random.randint(0, 255, (16, 128, 128, 3), dtype=np.uint8)\n\n# Blur by a value sigma which is sampled from a uniform distribution\n# of range 10.1 <= x < 13.0.\n# The convenience shortcut for this is: GaussianBlur((10.1, 13.0))\nblurer = iaa.GaussianBlur(10 + iap.Uniform(0.1, 3.0))\nimages_aug = blurer(images=images)\n\n# Blur by a value sigma which is sampled from a gaussian distribution\n# N(1.0, 0.1), i.e. sample a value that is usually around 1.0.\n# Clip the resulting value so that it never gets below 0.1 or above 3.0.\nblurer = iaa.GaussianBlur(iap.Clip(iap.Normal(1.0, 0.1), 0.1, 3.0))\nimages_aug = blurer(images=images)\n```\n\nThere are many more probability distributions in the library, e.g. truncated\ngaussian distribution, poisson distribution or beta distribution.\n\n\n### Example: WithChannels\n\nApply an augmenter only to specific image channels:\n```python\nimport numpy as np\nimport imgaug.augmenters as iaa\n\n# fake RGB images\nimages = np.random.randint(0, 255, (16, 128, 128, 3), dtype=np.uint8)\n\n# add a random value from the range (-30, 30) to the first two channels of\n# input images (e.g. to the R and G channels)\naug = iaa.WithChannels(\n  channels=[0, 1],\n  children=iaa.Add((-30, 30))\n)\n\nimages_aug = aug(images=images)\n```\n\n\n<a name=""citation""/>\n\n## Citation\n\n<!--\nNote: the table only lists people who have their real names (publicly)\nset in their github\n\nList of username-realname matching based on\nhttps://github.com/aleju/imgaug/graphs/contributors ordered by commits:\n\nwkentaro            Wada, Kentaro\nErotemic            Crall, Jon\nstnk20              Tanaka, Satoshi\njgraving            Graving, Jake\ncreinders           Reinders, Christoph     (lastname not public on github, guessed from username)\nSarthakYadav        Yadav, Sarthak\nnektor211           ?\njoybanerjee08       Banerjee, Joy\ngaborvecsei         Vecsei, G\xc3\xa1bor\nadamwkraft          Kraft, Adam\nZhengRui            Rui, Zheng\nBorda               Borovec, Jirka\nvallentin           Vallentin, Christian\nss18                Zhydenko, Semen\nkilsenp             Pfeiffer, Kilian\nkacper1095          ?\nismaelfm            Fern\xc3\xa1ndez, Ismael\nfmder               De Rainville, Fran\xc3\xa7ois-Michel\nfchouteau           ?\nchi-hung            Weng, Chi-Hung\napatsekin           ?\nabnera              Ayala-Acevedo, Abner\nRephaelMeudec       Meudec, Raphael\nPetemir             Laporte, Matias\n\n-->\nIf this library has helped you during your research, feel free to cite it:\n```latex\n@misc{imgaug,\n  author = {Jung, Alexander B.\n            and Wada, Kentaro\n            and Crall, Jon\n            and Tanaka, Satoshi\n            and Graving, Jake\n            and Reinders, Christoph\n            and Yadav, Sarthak\n            and Banerjee, Joy\n            and Vecsei, G\xc3\xa1bor\n            and Kraft, Adam\n            and Rui, Zheng\n            and Borovec, Jirka\n            and Vallentin, Christian\n            and Zhydenko, Semen\n            and Pfeiffer, Kilian\n            and Cook, Ben\n            and Fern\xc3\xa1ndez, Ismael\n            and De Rainville, Fran\xc3\xa7ois-Michel\n            and Weng, Chi-Hung\n            and Ayala-Acevedo, Abner\n            and Meudec, Raphael\n            and Laporte, Matias\n            and others},\n  title = {{imgaug}},\n  howpublished = {\\url{https://github.com/aleju/imgaug}},\n  year = {2020},\n  note = {Online; accessed 01-Feb-2020}\n}\n```\n'"
